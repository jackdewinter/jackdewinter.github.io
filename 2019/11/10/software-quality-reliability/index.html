<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <meta name="author" content="Jack De Winter" />

        <meta name="description" content="In the main article titled What is Software Quality?, I took a high level look at what I believe are the 4 pillars of software quality. This article will focus specifically on the Reliability pillar, with suggestions on how to measure Reliability and how to write good requirements for this …
" />
        <meta property="og:type" content="article" />
        <meta name="twitter:card" content="summary">

<meta name="keywords" content="measuring software quality, software reliability, end-to-end tests, scenario tests, functional tests, unit tests, code coverage, scenario coverage, Software Quality, " />

<meta property="og:title" content="Software Quality: Reliability "/>
<meta property="og:url" content="https://jackdewinter.github.io/2019/11/10/software-quality-reliability/" />
<meta property="og:description" content="In the main article titled What is Software Quality?, I took a high level look at what I believe are the 4 pillars of software quality. This article will focus specifically on the Reliability pillar, with suggestions on how to measure Reliability and how to write good requirements for this …" />
<meta property="og:site_name" content="Jack&#39;s Digital Workbench" />
<meta property="og:article:author" content="Jack De Winter" />
<meta property="og:article:published_time" content="2019-11-10T00:00:00-08:00" />
<meta name="twitter:title" content="Software Quality: Reliability ">
<meta name="twitter:description" content="In the main article titled What is Software Quality?, I took a high level look at what I believe are the 4 pillars of software quality. This article will focus specifically on the Reliability pillar, with suggestions on how to measure Reliability and how to write good requirements for this …">

        <title>Software Quality: Reliability  · Jack&#39;s Digital Workbench
</title>
        <link href="//netdna.bootstrapcdn.com/twitter-bootstrap/2.3.2/css/bootstrap-combined.min.css" rel="stylesheet">
<link rel="stylesheet" href="https://jackdewinter.github.io/theme/css/style.min.css?bec7d543">

        <link href="https://jackdewinter.github.io/feeds/all.atom.xml" type="application/atom+xml" rel="alternate" title="Jack&#39;s Digital Workbench - Full Atom Feed" />


    </head>
    <body>
        <div id="content">
            <div class="navbar navbar-static-top">
                <div class="navbar-inner">
                    <div class="container-fluid">
                        <a class="btn btn-navbar" data-toggle="collapse" data-target=".nav-collapse">
                            <span class="icon-bar"></span>
                            <span class="icon-bar"></span>
                            <span class="icon-bar"></span>
                        </a>
                        <a class="brand" href="https://jackdewinter.github.io/"><span class=site-name>Jack's Digital Workbench</span></a>
                        <div class="nav-collapse collapse">
                            <ul class="nav pull-right top-menu">
                                <li >
                                    <a href=
                                       https://jackdewinter.github.io
                                    >Home</a>
                                </li>
                                <li ><a href="https://jackdewinter.github.io/categories">Categories</a></li>
                                <li ><a href="https://jackdewinter.github.io/tags">Tags</a></li>
                                <li ><a href="https://jackdewinter.github.io/archives">Archives</a></li>
                                <li><form class="navbar-search" action="https://jackdewinter.github.io/search.html" onsubmit="return validateForm(this.elements['q'].value);"> <input type="text" class="search-query" placeholder="Search" name="q" id="tipue_search_input"></form></li>
                            </ul>
                        </div>
                    </div>
                </div>
            </div>
            <div class="container-fluid">
                <div class="row-fluid">
                    <div class="span1"></div>
                    <div class="span10">
<article itemscope>
<div class="row-fluid">
    <header class="page-header span10 offset2">
        <h1>
            <a href="https://jackdewinter.github.io/2019/11/10/software-quality-reliability/">
                Software Quality: Reliability
            </a>
        </h1>
    </header>
</div>

<div class="row-fluid">
    <div class="span2 table-of-content">
        <nav>
        <h4>Contents</h4>
        <div class="toc">
<ul>
<li><a href="#introduction">Introduction</a></li>
<li><a href="#how-does-testing-help-measure-reliability">How Does Testing Help Measure Reliability?</a></li>
<li><a href="#can-we-identify-groups-of-tests">Can We Identify Groups of Tests?</a></li>
<li><a href="#give-me-an-example">Give Me an Example</a><ul>
<li><a href="#end-to-end-tests">End-To-End Tests</a></li>
<li><a href="#scenario-tests">Scenario Tests</a><ul>
<li><a href="#why-only-those-3-scenario-tests">Why only those 3 scenario tests?</a></li>
<li><a href="#how-did-i-get-there">How did I get there?</a></li>
</ul>
</li>
<li><a href="#commonalities-between-end-to-end-tests-and-scenario-tests">Commonalities between End-to-end tests and scenario tests</a></li>
<li><a href="#unit-tests-and-functional-tests">Unit Tests and Functional Tests</a><ul>
<li><a href="#back-to-our-example">Back to our example</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#how-is-each-group-of-tests-measured">How is each group of Tests Measured?</a></li>
<li><a href="#back-to-the-original-question">Back to the original question</a></li>
<li><a href="#what-is-really-important">What Is Really Important</a></li>
<li><a href="#how-to-measure-reliability">How To Measure Reliability</a></li>
<li><a href="#wrapping-it-up">Wrapping It Up</a></li>
</ul>
</div>
        </nav>
    </div>
    <div class="span8 article-content">
            
            
<p>In the main article titled <a href="https://jackdewinter.github.io/2019/09/15/what-is-software-quality/">What is Software Quality?</a>, I
took a high level look at what I believe are the 4 pillars of software quality.  This article
will focus specifically on the Reliability pillar, with suggestions on how to measure
Reliability and how to write good requirements for this pillar.</p>
<h2 id="introduction">Introduction<a class="headerlink" href="#introduction" title="Permanent link">¶</a></h2>
<p>From the main article on
<a href="https://jackdewinter.github.io/2019/09/15/what-is-software-quality/">What is Software Quality?</a>,
the essence of this pillar can be broken down into two questions:</p>
<ul>
<li>Does the software do the task that it is supposed to do?</li>
<li>Does the software execute that task in a consistent manner?</li>
</ul>
<p>This article will take an in-depth look at common types of tests, discussing how those
tests can help us gather the information necessary to answer those questions.  At
the end of this article, the section
<a href="https://jackdewinter.github.io/2019/11/10/software-quality-reliability/#how-to-measure-reliability">How To Measure Reliability</a> will use that information to provide a cohesive answer
to those questions.</p>
<h2 id="how-does-testing-help-measure-reliability">How Does Testing Help Measure Reliability?<a class="headerlink" href="#how-does-testing-help-measure-reliability" title="Permanent link">¶</a></h2>
<p>As discussed in the main article’s section on
<a href="https://jackdewinter.github.io/2019/09/15/what-is-software-quality/#Reliability">Reliability</a>,
many articles on testing and reliability refer to a test pyramid that defines the 4
basic types of reliability tests: unit tests, functional/integration tests, scenario
tests, and end-to-end tests.  While those articles often have slightly different takes
on what the pyramid represents, a general reading of most of those articles leaves me
with the opinion that each test in each section of the pyramid must pass every time.
With tests and reliability being closely related, it is easy for me to draw the
conclusion that if tests must pass every time, then reliability is a binary choice:
they all pass and the project is reliable, or one or more fail and the project is not
reliable.</p>
<p>As such, my main question is: Does it have to be a
binary choice?  Are the only two choices that either all tests did pass or all tests did
not pass? If the answer to that question is a binary answer, then the answer is simple:
it is either 100% reliable or 0% reliable.  More likely, there are other answers that
will give use a better understanding of how to measure reliability and how to interpret
those measurements.</p>
<h2 id="can-we-identify-groups-of-tests">Can We Identify Groups of Tests?<a class="headerlink" href="#can-we-identify-groups-of-tests" title="Permanent link">¶</a></h2>
<p>Before determining whether or not reliability is a binary choice, I feel that it is important
to make some foundational decisions on how to measure reliability based on the types of tests
that are already identified.  To aid in making those decisions, it helps to examine the four
categories of tests, looking for groupings between them.</p>
<p><img alt="test pyramid" src="https://jackdewinter.github.io/images/quality-1/test-pyramid.png"/></p>
<p>Using the definitions established in the main article, unit tests are used to test
the reliability of individual software components and functional tests are used to test the
reliability of more than one of those components working together.  Both of these categories
are used to determine the reliability of the components themselves, and not their objectives.
As such, they make for a good grouping as they have a common responsibility: technical
reliability.</p>
<p>Observing the scenario tests and end-to-end tests through a similar lens, those tests are used to
determine whether or not the software project meets its business requirements.  The end-to-end tests are often a set of
tests that are very narrow and deep of purpose.   At a slightly lower level, the scenario
tests provide extra support to those end-to-end tests by breaking those “bulky” end-to-end
tests into more discrete actions matched to the overall business use cases for the project.
A good grouping for these tests is by what they: business reliability.</p>
<p>Another way to think about it is to view the groups of tests in terms of whether or not they
are inside or outside of the
<a href="https://www.techopedia.com/definition/3552/black-box-testing">black box</a>
that is the software project.  The first group of tests verify the inside of that black box,
ensuring that all of the technical requirements or “what needs to be done to meet
expectations” are met.  The second group of tests verify the outside of that black box,
ensuring that all of the business requirements or “what is expected of the project” are met.</p>
<p>[Add picture of pyramid showing inside and outside?]</p>
<h2 id="give-me-an-example">Give Me an Example<a class="headerlink" href="#give-me-an-example" title="Permanent link">¶</a></h2>
<p>For the follow sections, I use the example of a simple project that uses a data store to
keep track of contact information. By providing a simple example that most developers have
encountered before, my hope is that it will make it easier for the reader to picture the
different types of tests and how they will interact with their team’s project.  As I
examine each type of tests, I try and explain my thinking on what I write and how
I write it for that group of tests, hoping to guide others on making better decisions
for their testing strategy.</p>
<p>Note that I do not believe that the definition of “data store” is relevant to the example,
therefore the definition of “data store” is left up to the reader’s imagination and
experience.</p>
<h3 id="end-to-end-tests">End-To-End Tests<a class="headerlink" href="#end-to-end-tests" title="Permanent link">¶</a></h3>
<p>Starting at the top of test pyramid, each end-to-end test needs to be a solid,
representative test of the main focus of the project itself.  These tests are usually a
small set of tests meant as a solid litmus test on whether the software project is
reliably meeting the requirements of the project.  In forming the initial end-to-end
tests, my intent is to start with a focus on positive cases which occur more than
60% of the time.</p>
<p>For the example project, I started with a test to successfully add a new contact. As a
nice bonus, starting with that test allowed me to add the remove, list, and update
end-to-end tests, as they all need to add a new contact as a foundation of each of those
3 individual tests. Given my experience measuring quality, I believe that all of those
tests together provide that check with confidence for the example project.  If I had
found out
that the number of end-to-end tests I needed was more than a handful of tests, I would
have then examined the requirements and try to determine if the project had too many
responsibilities.  Doing this exercise with a new project often helps me figure out if
the project is properly scoped and designed, or if it requires further refinement.</p>
<p>Having identified the end-to-end tests for a project and assuming that no further
refinement is necessary, I rarely write source code for these tests right away.  Most
of the time I just add some simple documentation to the project outlined in
<a href="https://en.wikipedia.org/wiki/Pseudocode">pseudocode</a> to capture that information.  I
find that the main benefit of doing this in the early stages is to provide a
well-defined high level goal that myself and my team can work towards. Even having rough
notes on what the test will eventually look like can help the team work towards that
goal of a properly reliable project.</p>
<h3 id="scenario-tests">Scenario Tests<a class="headerlink" href="#scenario-tests" title="Permanent link">¶</a></h3>
<p>Still on the outside of the box, I then add a number of scenario tests to expand on the
scope of each of end-to-end tests.  For these tests, I focus on
<a href="https://en.wikipedia.org/wiki/Use_case">use cases</a>
that the user of the project will experience in typical scenarios. The intent here is to
identify the scenario tests that collectively satisfy 90% or more of the projected
business use cases for a given slice of the project.</p>
<p>For the example project, adding a test to verify that I can successfully add a contact
was the first scenario test that I added.  I then added a scenario for the negative use
case of adding a contact and being told there are invalid fields in my request and a
third for a contact name that already existed.  Together, these scenarios met my bar for
the “add a contact” slice of the scenarios for the project.</p>
<p>It is important to remember that these are tests that are facing the user and systems
they interact with. Unless there is a very strong reason to, I try and avoid scenario
tests that depend on any specific state of the project unless the test explicitly sets
that state up.  From my experience, such a dependency on external setup of state is very
fragile and hard to maintain.  It also raises the question on whether or not it is a
realistic or valuable test if that setup is not something that the project itself sets
up.</p>
<h4 id="why-only-those-3-scenario-tests">Why only those 3 scenario tests?<a class="headerlink" href="#why-only-those-3-scenario-tests" title="Permanent link">¶</a></h4>
<p>Here is a simple table on what types of scenario tests to add that I quickly put
together for that project.  The estimates are just that, examples,  but helped me
determine if I hit the 90% mark I was aiming for.</p>
<table>
<thead>
<tr>
<th>Category</th>
<th>Percentage</th>
<th>Scenario</th>
</tr>
</thead>
<tbody>
<tr>
<td>Success</td>
<td>60%</td>
<td>Add a contact successfully to the project.</td>
</tr>
<tr>
<td>Bad/Invalid Data</td>
<td>25%</td>
<td>Add an invalid contact name and validate that a ValidateError response is returned.</td>
</tr>
<tr>
<td>Processing Error</td>
<td>10%</td>
<td>Add an contact name for an already existing contact and validate that a ProcessingError response is returned.</td>
</tr>
</tbody>
</table>
<p>I sincerely believe that between those 3 scenario tests, I can easily defend that they
represent 90%+ of the expected usage of the project for the specific task of adding a
contact. While the percentages in the table are
<a href="https://en.wikipedia.org/wiki/Scientific_wild-ass_guess">swags</a>
that seem to be “plucked out of thing air”, I believe they can be reasonably
defended<sup id="fnref:defense"><a class="footnote-ref" href="#fn:defense">1</a></sup>.  This defense only needs to be reasonable enough to get the project
going. Once the project is going, real data can be obtained by monitoring and more
data-driven percentages can be used, if desired.</p>
<h4 id="how-did-i-get-there">How did I get there?<a class="headerlink" href="#how-did-i-get-there" title="Permanent link">¶</a></h4>
<p>From experience, there are typically 4 groups of action results, and therefore,
scenarios: the action succeeded, the action failed due to bad data, the action failed
due to a processing error, or the action failed due to a system error.</p>
<p>The first scenario test represents the first category.  Unless there was a good reason to
show another successful “add” use case, I will typically stick with a single “add” test.
As the goal is to achieve 90% of the typical use cases for the project, unless a
variant of that success case is justified by it’s potential contribution towards the 90%
total, it can be better performed by other tests.  In addition, tests on variations of
the input data are better performed by unit tests and functional tests, where executing
those tests have lower setup costs and lower execution costs.</p>
<p>The second scenario test is used to satisfy the second group of tests where the data is
found to be bad or invalid. In general, I use these to test that there is consistent
error handling <sup id="fnref:errorHandling"><a class="footnote-ref" href="#fn:errorHandling">2</a></sup> on the boundary between the user and the project.  At
this level, I ideally need only one or two tests to verify that any reporting of bad or
invalid data is being done consistently. By leaving the bulk of the invalid testing to
unit testing and/or functional testing, I can simulate many error conditions and check
them for consistent output at a low execution cost.  To be clear, if possible I try and
verify the general ability that consistent error handling is in place and not that a
specific instance of error is being reported properly.</p>
<p>The third scenario test is used to verify the third group of tests where data is valid
but fails during processing.  Similar to the second group of tests, there is an
assumption that the reporting of processing errors should be done consistently.  However,
as most processing errors result due to a sequence of actions originating from the user,
representative types of processing errors should be tested individually.  The key to this
type of scenario tests is to represent processing errors that will help the group of
scenario tests hit that 90% mark.  Relating this to the example project, getting a
“already add a record with that name” response from the project is something that would
occur with enough frequency to qualify in my books.</p>
<p>From experience, the fourth group of tests, testing for system errors, rarely makes it
to the level of a scenario test.  In this example, unless a system error is so
consistent that it was estimated to occur more than 10% of the time, a higher priority
is placed on the other types of responses.</p>
<p>One of the exceptions to these generic rules are when a business requirement exists to
provide extra focus on a given portion of the interface.  These requirements are often
added to a project based on a past event, either in the project or in a related project.
As the business owners have taken the time to add the business requirement due to its
perceived priority, it should have a scenario test to verify that requirement is met.</p>
<p>In the contact manager example, I made a big assumption that unless there were
requirements that stated otherwise, the data store is local and easy to reach.  If
instead we are talking about a project where the data is being collected on a mobile
device and relayed to a server, then a test in this last group of system errors would
increase in value.  The difference that this context introduces is that it is expected
that project will fail to reach the data store on a frequent basis, and hence, providing
a scenario for that happening helps us reach that 90% goal.</p>
<h3 id="commonalities-between-end-to-end-tests-and-scenario-tests">Commonalities between End-to-end tests and scenario tests<a class="headerlink" href="#commonalities-between-end-to-end-tests-and-scenario-tests" title="Permanent link">¶</a></h3>
<p>While I took the long way around describing end-to-end tests and scenario tests, I
believe the journey was worth it.  These two types of tests test against the external
surface of the project, together painting a solid picture of what that external surface
will look like once the project is done.  For both of those tests, the project needs
clear business requirements on what benefit it provides to the user, which will be
highlighted by translating the requirements into the various tests.  By including either
actual data (for existing projects) or projected data (for new projects) on the usage
patterns for that project, the requirements can be prioritized to ensure the most
frequently used requirements are more fully tested.</p>
<p>For each of those requirements and goals, the team can then set goals for the project
based on those documented requirements.  By codifying those goals and requirements with
end-to-end and scenario tests, you firm up those goals into something concrete.  Those
actions allow the team to present a set of tests or test outlines to the authors of the
requirements, validating that things are going in the right direction before writing too
much source code or setting up of interfaces with the user.  That communication and
changing the course before writing code can save a team hours, days, or weeks,
depending on any course changes discovered.</p>
<p>What happens if the requirements change?  The project has a set of tests that
explicitly test against the outside of the box, and informs the team on what changes
will be needed if that requirement change is applied to the project.  At the very least,
it starts a conversation with the author of the requirement about what the external
surface of the project will look like before and after the change.  With that
conversation started, the team can have a good understanding of how things will change,
with some level of confidence that the change is the change specified by the
requirements author.</p>
<h3 id="unit-tests-and-functional-tests">Unit Tests and Functional Tests<a class="headerlink" href="#unit-tests-and-functional-tests" title="Permanent link">¶</a></h3>
<p>Transitioning to inside of the black box, unit tests and functional tests are more
understood by developers and more frequently used than end-to-end tests or scenario
tests. The unit tests isolate a single component (usually a class) and attempt to test
that each interface of that component and is functioning properly.  The functional tests
do the same thing, but with a single group of components that work together as a single
component rather than a single component itself.</p>
<p>From an implementation point of view, the main difference is in how these tests are
created. Unit tests, as they are testing a single component, should only contain a
project reference to the one component being tested.  If the components are created
properly and have a good separation from the rest of the project, this should be
achievable for a good number of
components for the project, especially the support components.  Therefore, the degree to
which these tests are successful is determined by the amount of clean division of
responsibilities the project has between it’s components.</p>
<p>Functional tests complete the rest of the inside-of-the-box testing by testing individual
components with related components, in the way they are used in a production
environment.  With these tests, the degree to which these tests are successful is the
ability to inject the project dependencies into one or more of the components being
tested, coupled with the clean division of responsibilities needed for good unit tests.
While using a concept such as the interface concept from Java and C# is not required, it
does allow the injection of dependencies to be performed cleanly and with purpose.</p>
<p>To enable groups of functional tests to be as independent of the components outside of
their group as possible, <a href="https://en.wikipedia.org/wiki/Mock_object">mock objects</a> are
often used to replace concrete classes that are part of your project.  If interfaces are
used in your project to allow for better
<a href="https://en.wikipedia.org/wiki/Dependency_injection">dependency injection</a>,
your functional tests can create mock objects that reside with your tests.  This provides
more control and reliability on what changes you are making from the live instance of
the interfaces, for the sake of testing.  If interfaces are not supplied for better
dependency injection, a mocking library such as the Java
<a href="https://site.mockito.org/">Mockito</a>
are required to replace test dependencies with reliable objects.</p>
<h4 id="back-to-our-example">Back to our example<a class="headerlink" href="#back-to-our-example" title="Permanent link">¶</a></h4>
<p>Using the example project as a template, we know from the section on
<a href="https://jackdewinter.github.io/2019/11/10/software-quality-reliability/#Scenario-Tests">scenario tests</a>
that we need to test for valid inputs when adding a new contact.  To add
coverage for the component containing the “add a contact” logic as a unit test, it’s
success is determined by how much of the handling the external interface is in the one
component. If that component contains all of the code needed to handle that external
request in one method, it is extremely hard to test that component without bringing in
the other components.  That is definition of a functional test, not a unit test.  As an
alternative, if the validation of the input can be condensed into it’s own component and
removed from that method, that validation component can be unit tested very effectively.</p>
<p>Applying that refactoring pattern a couple of more times in the right ways, the project’s
ability to be functionally tested increases.  As an added bonus,  depending on how the
refactoring is accomplished, new unit tests can be added based on the refactoring,
gaining measurable confidence on each additional component tested.  </p>
<p>Using the adding a contact example again, having refactored the input validation to a
validation class could be followed by the following changes:</p>
<ul>
<li>create a new component for the handling of “add a contact” and decouple it from logic of the handling of the external interface</li>
<li>move the user authentication and authorization logic into it’s own component</li>
<li>move the persisting of the new contact logic into it’s own component</li>
</ul>
<p>From a functional test point of view, each of these refactorings makes it easier to test.
For the first refactoring, instead of having to rely on all functional testing going
through the external interface, which may include costly setup, we can create a local
instance of the new component and test against that.  If interfaces are used for the
remaining two refactorings, then test objects can be used instead of the “live” objects,
otherwise a mocking library can be used to replace those objects with more predictable
objects.</p>
<h2 id="how-is-each-group-of-tests-measured">How is each group of Tests Measured?<a class="headerlink" href="#how-is-each-group-of-tests-measured" title="Permanent link">¶</a></h2>
<p>On this winding journey to determine how to measure reliability, I explored the relevant
elements of the four main types of tests.  I believe that I was successful in showing a
clear delineation between the two groups of tests and the benefits each group provides.
To recap, the outside-of-the-box group validates the expectations to be met, matched
against the requirements set out for the project.  The inside-of-the-box group validates
how those exceptions are met, matched against the external interfaces for the project.</p>
<p>These two distinct foundations are important, as the two distinct groups of tests require
two distinct groups of measurements.</p>
<p>The first group, scenario tests and end-to-end tests, are measured by scenario coverage.
Scenario coverage measures the number of tests that successfully pass against the total
number of scenario tests and end-to-end tests for that project.  As this group of tests
is measuring the business expectations of the project, this measurement is a simple
fraction: the number of passing tests as the numerator and the number of defined tests
as the denominator.</p>
<p>The second group, unit tests and functional tests, are measured by source code coverage,
or code coverage for short.  Code coverage can be specified along 6 different axes:
class, method, line, complexity, blocks, and lines.  Different measurement tools will
provide different subsets of those measurements, but in the end they are all relaying
the same thing: the points in the project’s source code that are not properly tested.</p>
<h2 id="back-to-the-original-question">Back to the original question<a class="headerlink" href="#back-to-the-original-question" title="Permanent link">¶</a></h2>
<p>Does it (the measuring of reliability) have to be a binary choice?</p>
<p>It depends.</p>
<p>In an ideal world, the answer to that question is yes, but we do not live in an ideal
world.  In the real world, we have a decision to make for either group of tests on what
is good enough for the project and that group of tests.</p>
<p>If the suggestions of this article are followed, then a condition of releasing the
project to a production state is 100% scenario coverage.  Anything less than 100% means
that critical use cases for the project are not complete, hence the project itself is not
complete.  </p>
<p>To achieve the 100% coverage without adding new project code, updated requirements are
needed from the requirements author, say a project manager, to change the composition of
the scenario tests and end-to-end tests.  This may include removing some of these
tests as the release goals for the project are changed.  While changing and removing
goals and their tests, may seem like cheating to some people, the other option is
very risky.</p>
<p>It should be evident that if a project is released without all scenario tests and
end-to-end tests passing, that team is taking a gamble with their reputation and the
reputation of the project.  It is better to adjust the tests and goals, and communicate
those changes, than to take a risk on releasing something before it meets those goals.</p>
<p>Following the suggestions of this article for code coverage is a more nuanced goal, and
really does depend on the project and the situation. If architected and designed to
support proper testing from the beginning, I would argue that 95%+ code coverage is easy
and desirable.  If you are adding testing to an already existing project or do not have
the full support of the developers on the project, this number is going to be lower.</p>
<p>Another factor is the type of project that is being tested and who will use it.  If you
are creating this project to support people inside of your company, it is possible that
one of the requirements is to have a lower initial code coverage target to allow the
project to be used right away and alleviate some internal company pressure.  If the
project is something that will represent you and your company on the international stage,
you will have to balance the time and effort needed to meet a higher bar for code
coverage with the need to get the project out where it can be used.  As with many things,
it is a matter of negotiation and balance between the various requirements.</p>
<h2 id="what-is-really-important">What Is Really Important<a class="headerlink" href="#what-is-really-important" title="Permanent link">¶</a></h2>
<p>I want to stress that I believe that the important thing is that each project measures
where they are against whatever goals they set for their project. The team doesn’t need
to always maintain a near-100% code coverage measure, but that team needs to know where
they stand.  This will influence and inform the people that author the requirements and
adjust the priorities for the team.  Any negotiations within the team can then cite this
information and use it to help with the balancing act of adding new features, fixing
existing bugs, and enhancing code quality (in this case, increasing code coverage).</p>
<h2 id="how-to-measure-reliability">How To Measure Reliability<a class="headerlink" href="#how-to-measure-reliability" title="Permanent link">¶</a></h2>
<p>To answer the question “Does the software do the task that it is supposed to do?”,
scenario coverage is measured.  Scenario coverage for end-to-end tests and scenario
tests should always be at 100% when a production release of the project is performed.
This measurement is binary.  Until that release (or next production release) is
performed, adding or changing these tests based on the requirements for the next release
will inform the team and any stakeholders of how close the team is to satisfying those
requirements for that release.</p>
<p>To answer the question “Does the software execute that task in a consistent manner?”,
code coverage is measured.  Code coverage for unit tests and functional tests should
strive for 95% code coverage along all 6 axes with all active tests completing
successfully 100% of the time.  The test completion percentage must be non-negotiable,
but the code coverage percentage must take into account the maturity of the project and
the usage of the project.  This measurement is non-binary.  However, it is important to
know your project’s code coverage measurement, and how it trends over time. While the
measurement is non-binary, it is suggested to create a binary rule that
specifies what the minimum percentage is for each axis, failing the rule if that
specific metric falls below the goal percentage.</p>
<h2 id="wrapping-it-up">Wrapping It Up<a class="headerlink" href="#wrapping-it-up" title="Permanent link">¶</a></h2>
<p>By breaking down the types of tests that are expected for a given project, the two
different types of measurements of reliably become more evident.  Scenario coverage
is determined by outlining the major scenarios for using a project and writing
end-to-end tests and scenario tests against them.  Scenario coverage must be a binary
measurement at release time.  Code coverage is determined by using tools to measure
which parts of the code are executed when running functional tests and unit tests.
Code coverage is a non-binary metric that must have a minimum bar for coverage that is
met for the project, and determined on the merits of the project itself.</p>
<p>By using these two measurements, I hope that I have shown that it is possible to provide
a way to empirically measure reliability.  By having a project be transparent about how
it is reaching those measurements and what they are, any team can provide meaningful and
understandable measurements of reliability.</p>
<div class="footnote">
<hr/>
<ol>
<li id="fn:defense">
<p>If asked, I could easily defend the percentages.  For the success case, I would assume that half the 60% number will come from first try successes and half the number will come from success that occurred after people fixed errors returned from the other two tests and resubmitted the data.  While the other two categories are somewhat guesswork, from my experience validation errors are 2-3 times more common than an “existing contact” processing error.  Note that in the absence of real data, these are estimates that do not have to be perfect, just reasonable. <a class="footnote-backref" href="#fnref:defense" title="Jump back to footnote 1 in the text">↩</a></p>
</li>
<li id="fn:errorHandling">
<p>In designing any type of project, you should seek to have clear and consistent interfaces between your project and the users of the project.  An extension of that statement is that any responses you return to your user should be grouped with related responses and returned in a common data structure or UI element to avoid confusion. <a class="footnote-backref" href="#fnref:errorHandling" title="Jump back to footnote 2 in the text">↩</a></p>
</li>
</ol>
</div>


             
 
                <p id="post-share-links">
    Like this post? Share on:
    <a href="https://twitter.com/intent/tweet?text=Software%20Quality%3A%20Reliability&url=https%3A//jackdewinter.github.io/2019/11/10/software-quality-reliability/&hashtags=measuring-software-quality,software-reliability,end-to-end-tests,scenario-tests,functional-tests,unit-tests,code-coverage,scenario-coverage" target="_blank" rel="nofollow noopener noreferrer" title="Share on Twitter">Twitter</a>
    ❄
    <a href="https://www.facebook.com/sharer/sharer.php?u=https%3A//jackdewinter.github.io/2019/11/10/software-quality-reliability/" target="_blank" rel="nofollow noopener noreferrer" title="Share on Facebook">Facebook</a>
    ❄
    <a href="mailto:?subject=Software%20Quality%3A%20Reliability&amp;body=https%3A//jackdewinter.github.io/2019/11/10/software-quality-reliability/" target="_blank" rel="nofollow noopener noreferrer" title="Share via Email">Email</a>
    </p>

            
            






<section>
    <h6 style="display:none;">Comments</h6>
    <p id="comment-message">So what do you think? Did I miss something? Is any part unclear? Leave your comments below. </p>

    <div class="accordion" id="accordion2">
        <div class="accordion-group">
            <div class="accordion-heading">
                <a class="accordion-toggle disqus-comment-count comment-count"
                   data-toggle="collapse"
                   data-parent="#accordion2"
                   href="https://jackdewinter.github.io/2019/11/10/software-quality-reliability/#comment_thread"
                   id="comment-accordion-toggle">
                    Comments
                </a>
            </div>
            <div id="comment_thread" class="accordion-body collapse">
                <div class="accordion-inner">
                    <div class="comments">

                        <script src="https://utteranc.es/client.js"
        data-repo="jackdewinter/jackdewinter.github.io"
        data-issue-term="software-quality-reliability"
        data-label="Comments"
        data-theme="github-light"
        crossorigin="anonymous"
        async>
</script>

                    </div>
                </div>
            </div>
        </div>
    </div>
</section>

            <hr/>
            <aside>
            <nav>
            <ul class="articles-timeline">
                <li class="previous-article">« <a href="https://jackdewinter.github.io/2019/11/03/fine-tuning-pelican-getting-ready-for-a-soft-launch/" title="Previous: Fine Tuning Pelican: Getting Ready For a Soft-Launch">Fine Tuning Pelican: Getting Ready For a Soft-Launch</a></li>
                <li class="next-article"><a href="https://jackdewinter.github.io/2019/11/15/the-inspiration-for-jacks-digital-workbench/" title="Next: The Inspiration For Jack&#39;s Digital Workbench">The Inspiration For Jack's Digital Workbench</a> »</li>
            </ul>
            </nav>
            </aside>
        </div>
        <section id="article-sidebar" class="span2">
    <h4>Reading Time</h4>
    <p>~19 min read</p>
            <h4>Published</h4>
            <time itemprop="dateCreated" datetime="2019-11-10T00:00:00-08:00">Nov 10, 2019</time>
        <h4>Software Quality</h4>
    <ul class="multi-parts-list">
            <li >
            <a href="https://jackdewinter.github.io/2019/09/15/what-is-software-quality/" title="What is Software Quality?">Part 1: What is Software Quality?</a>
            </li>
            <li  class="active-part">
            Part 2: Software Quality: Reliability
            </li>
    </ul>
            <h4>Category</h4>
            <a class="category-link" href="https://jackdewinter.github.io/categories#software-quality-ref">Software Quality</a>
            <h4>Tags</h4>
            <ul class="list-of-tags tags-in-article">
                <li><a href="https://jackdewinter.github.io/tags#code-coverage-ref">code coverage
                    <span>1</span>
</a></li>
                <li><a href="https://jackdewinter.github.io/tags#end-to-end-tests-ref">end-to-end tests
                    <span>1</span>
</a></li>
                <li><a href="https://jackdewinter.github.io/tags#functional-tests-ref">functional tests
                    <span>1</span>
</a></li>
                <li><a href="https://jackdewinter.github.io/tags#measuring-software-quality-ref">measuring software quality
                    <span>2</span>
</a></li>
                <li><a href="https://jackdewinter.github.io/tags#scenario-coverage-ref">scenario coverage
                    <span>1</span>
</a></li>
                <li><a href="https://jackdewinter.github.io/tags#scenario-tests-ref">scenario tests
                    <span>1</span>
</a></li>
                <li><a href="https://jackdewinter.github.io/tags#software-reliability-ref">software reliability
                    <span>2</span>
</a></li>
                <li><a href="https://jackdewinter.github.io/tags#unit-tests-ref">unit tests
                    <span>1</span>
</a></li>
            </ul>
<h4>Stay in Touch</h4>
<div id="sidebar-social-link">
    <a href="https://github.com/jackdewinter" title="github-alt" target="_blank" rel="nofollow noopener noreferrer">
        <svg xmlns="http://www.w3.org/2000/svg" aria-label="GitHub" role="img" viewBox="0 0 512 512"><rect width="512" height="512" rx="15%" fill="#1B1817"/><path fill="#fff" d="M335 499c14 0 12 17 12 17H165s-2-17 12-17c13 0 16-6 16-12l-1-50c-71 16-86-28-86-28-12-30-28-37-28-37-24-16 1-16 1-16 26 2 40 26 40 26 22 39 59 28 74 22 2-17 9-28 16-35-57-6-116-28-116-126 0-28 10-51 26-69-3-6-11-32 3-67 0 0 21-7 70 26 42-12 86-12 128 0 49-33 70-26 70-26 14 35 6 61 3 67 16 18 26 41 26 69 0 98-60 120-117 126 10 8 18 24 18 48l-1 70c0 6 3 12 16 12z"/></svg>
    </a>
    <a href="https://www.linkedin.com/in/jackdewinter/" title="linkedin" target="_blank" rel="nofollow noopener noreferrer">
        <svg xmlns="http://www.w3.org/2000/svg" aria-label="LinkedIn" role="img" viewBox="0 0 512 512" fill="#fff"><rect width="512" height="512" rx="15%" fill="#0077b5"/><circle cx="142" cy="138" r="37"/><path stroke="#fff" stroke-width="66" d="M244 194v198M142 194v198"/><path d="M276 282c0-20 13-40 36-40 24 0 33 18 33 45v105h66V279c0-61-32-89-76-89-34 0-51 19-59 32"/></svg>
    </a>
    <a href="https://jackdewinter.github.io/feeds/all.atom.xml" title="" target="_blank" rel="nofollow noopener noreferrer">
        <svg xmlns="http://www.w3.org/2000/svg" aria-label="RSS" role="img" viewBox="0 0 512 512"><rect width="512" height="512" rx="15%" fill="#f80"/><circle cx="145" cy="367" r="35" fill="#fff"/><path fill="none" stroke="#fff" stroke-width="60" d="M109 241c89 0 162 73 162 162M109 127c152 0 276 124 276 276"/></svg>
    </a>
</div>
            





            





        </section>
</div>
</article>
                    </div>
                    <div class="span1"></div>
                </div>
            </div>
        </div>
<footer>
    <div>
        
&copy; Copyright 2020 by Jack De Winter and licensed under a <a rel="license"
  href="http://creativecommons.org/licenses/by/4.0/">
  <img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by/4.0/80x15.png" />
  Creative Commons Attribution 4.0 International License</a>.

    </div>




    <div id="fpowered">
        Powered by: <a href="http://getpelican.com/" title="Pelican Home Page" target="_blank" rel="nofollow noopener noreferrer">Pelican</a>
        Theme: <a href="https://elegant.oncrashreboot.com/" title="Theme Elegant Home Page" target="_blank" rel="nofollow noopener noreferrer">Elegant</a>
    </div>
</footer>            <script src="//code.jquery.com/jquery.min.js"></script>
        <script src="//netdna.bootstrapcdn.com/twitter-bootstrap/2.3.2/js/bootstrap.min.js"></script>
        <script>
            function validateForm(query)
            {
                return (query.length > 0);
            }
        </script>

    <script>
    (function () {
        if (window.location.hash.match(/^#comment-\d+$/)) {
            $('#comment_thread').collapse('show');
        }
    })();
    window.onhashchange=function(){
        if (window.location.hash.match(/^#comment-\d+$/))
            window.location.reload(true);
    }
    $('#comment_thread').on('shown', function () {
        var link = document.getElementById('comment-accordion-toggle');
        var old_innerHTML = link.innerHTML;
        $(link).fadeOut(200, function() {
            $(this).text('Click here to hide comments').fadeIn(200);
        });
        $('#comment_thread').on('hidden', function () {
            $(link).fadeOut(200, function() {
                $(this).text(old_innerHTML).fadeIn(200);
            });
        })
    })
</script>

    </body>
    <!-- Theme: Elegant built for Pelican
        License : MIT -->
</html>