<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Jack's Digital Workbench - Software Quality</title><link href="https://jackdewinter.github.io/" rel="alternate"></link><link href="https://jackdewinter.github.io/feeds/software-quality.atom.xml" rel="self"></link><id>https://jackdewinter.github.io/</id><updated>2020-09-28T00:00:00-07:00</updated><entry><title>Markdown Linter - Delving Into the Issues - 1</title><link href="https://jackdewinter.github.io/2020/09/28/markdown-linter-delving-into-the-issues-1/" rel="alternate"></link><published>2020-09-28T00:00:00-07:00</published><updated>2020-09-28T00:00:00-07:00</updated><author><name>Jack De Winter</name></author><id>tag:jackdewinter.github.io,2020-09-28:/2020/09/28/markdown-linter-delving-into-the-issues-1/</id><summary type="html">
&lt;h2 id="summary"&gt;Summary&lt;a class="headerlink" href="#summary" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;In my
&lt;a href="https://jackdewinter.github.io/2020/09/21/markdown-linter-adding-remaining-inline-tokens/"&gt;last article&lt;/a&gt;,
I completed the last bit of work needed to complete the consistency checks.  However,
as I accumulated some items in my issues list, I decided to take some time and make a
sizable dent in that list.  This article details those issues that I investigated …&lt;/p&gt;</summary><content type="html">
&lt;h2 id="summary"&gt;Summary&lt;a class="headerlink" href="#summary" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;In my
&lt;a href="https://jackdewinter.github.io/2020/09/21/markdown-linter-adding-remaining-inline-tokens/"&gt;last article&lt;/a&gt;,
I completed the last bit of work needed to complete the consistency checks.  However,
as I accumulated some items in my issues list, I decided to take some time and make a
sizable dent in that list.  This article details those issues that I investigated and
their results.&lt;/p&gt;
&lt;h2 id="introduction"&gt;Introduction&lt;a class="headerlink" href="#introduction" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;When I am teaching archery at the camps in my local area, I must
constantly keep a level head and strive to find ways keep the kids motivated.  Faced
with children possessing various levels of archery skill, not only do I have to tailor
any assistance to each individual child, but I also try to figure out how to get that
child to retain some part of that assistance. Luckily, I have a couple of tricks up my
sleeve that helps me in this area.&lt;/p&gt;
&lt;p&gt;The most useful trick involves the difference between moving a mountain and moving
a mountain’s worth of pebbles.  When I ask the camper how easy it is to move a mountain,
they usually look at me like I am the most stupid parent on the planet and then proceed
to express how impossible it is in various colorful forms.   As a follow up, when I then
ask them if they can move that mountain one pebble as a time, they state that it would
take a long time, but eventually they would be able
to move that mountain.  Granted, the description of how long that effort would take
differs from camper to camper, some more colorful than others, but they all convey that
it is ultimately doable.&lt;/p&gt;
&lt;p&gt;At that point, I calmly talk to the camper and explain that we are going to start working
on each pebble of their archery skills, one pebble at a time.  At open range events, I
let each group of kids know that me and the other coaches will be there
all day, and will be as helpful at the end of the day as we are at the beginning.
Admittedly, a bit crazier near the end, but we try our best to remain helpful in
the middle of that craziness.&lt;/p&gt;
&lt;p&gt;The reason I mention this story is that when it comes to the items on the project’s
issues list, the list definitely
looks more like a mountain than a pebble to me.  But by taking the same approach with
the items that I do when teaching archery, I can approach that list calmly and not be hit
with a large wall of anxiety.  Instead of seeing the list as a large mountain, I can
choose to see it as a large group of pebbles, moving them one at a time.  My goal at
this point is not to get rid of all those items at once, but to make steady progress
in reducing the size of the issues list, once pebble at a time.&lt;/p&gt;
&lt;h2 id="what-is-the-audience-for-this-article"&gt;What Is the Audience for This Article?&lt;a class="headerlink" href="#what-is-the-audience-for-this-article" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;While detailed more eloquently in
&lt;a href="https://jackdewinter.github.io/2020/04/05/what-is-the-audience-for-my-blog/#what-is-the-audience-for-my-blog"&gt;this article&lt;/a&gt;,
my goal for this technical article is to focus on the reasoning behind my solutions,
rather that the solutions themselves.  For a full record of the solutions presented in
this article, please go to this project’s GitHub repository and consult the
commits between
&lt;a href="https://github.com/jackdewinter/pymarkdown/commit/d56857b8839b2651724935d7b2145b62fb0d20cf"&gt;09 Sep 2020&lt;/a&gt;
and
&lt;a href="https://github.com/jackdewinter/pymarkdown/commit/573cdf32570611cbc61273cef9c6808fe44137ba"&gt;12 Sep 2020&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id="starting-with-an-easy-one"&gt;Starting with An Easy One&lt;a class="headerlink" href="#starting-with-an-easy-one" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Now that I have the consistency checks in place, when I am faced with a problem with a
line number being off or a column number being off, it is a question of whether the
parser’s calculation is wrong or the check’s calculation is wrong.  While I hope that it
is not an error with the consistency checks, I feel that it is a valid question to ask
myself with each issue.&lt;/p&gt;
&lt;p&gt;That is the mindset that I had when I started looking at this issue.  Leftover from my
previous work on
consistency checks, this was an issue where 15-20 minutes of digging into it with
little success caused me to sideline it for later.  The Markdown sample in question was
a modified
&lt;a href="https://github.github.com/gfm/#example-143"&gt;example 143&lt;/a&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;div&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;foo&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;bar&lt;/span&gt;

&lt;span class="n"&gt;bar&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;At issue was the tokenization of the Blank Line element at the end of the Block Quote
element.  According to the parser, that Blank Line element was tokenized to
&lt;code&gt;[BLANK(4,1):]&lt;/code&gt;.  However, the consistency checks were stating that the proper
tokenization should be &lt;code&gt;[BLANK(4,3):]&lt;/code&gt;.  Which one was correct?  What was the
miscalculation that was causing one of the two to be off?&lt;/p&gt;
&lt;h3 id="digging-in"&gt;Digging In&lt;a class="headerlink" href="#digging-in" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Performing a quick visual check of the tokenization, things seemed to be valid on
the parser side. The Blank Line element was enough to terminate the HTML element,
but not to also terminate the Block Quote element before the Blank Line element itself.
That part of the test looked good. In addition, the Markdown text does not contain any
other text on that Blank Line, so the position of &lt;code&gt;(4,1)&lt;/code&gt; looked to be an accurate
position for the token.  This meant shifting my focus to the consistency checks.&lt;/p&gt;
&lt;p&gt;Looking at the debug information for the consistency checks, something immediately leapt
out at me.  The debug output read:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&amp;gt;&amp;gt;blank_line&amp;gt;&amp;gt;split&amp;gt;['&amp;gt; ', '&amp;gt; ', '&amp;gt; ', '', '']
&amp;gt;&amp;gt;blank_line&amp;gt;&amp;gt;index&amp;gt;1
&amp;gt;&amp;gt;current_position.index_number&amp;gt;&amp;gt;1
&amp;gt;&amp;gt;current_position.index_indent&amp;gt;&amp;gt;0
&amp;gt;&amp;gt;1 + init_ws(2)&amp;gt;&amp;gt;3
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Matching that up against the code that produced the debug, it stated that the
&lt;code&gt;index_number&lt;/code&gt; variable was set to &lt;code&gt;1&lt;/code&gt; while the consistency check calculated the number
&lt;code&gt;3&lt;/code&gt; for that same value.  That matched up with the previous information, so looking at
that last line, I saw that the calculation was determining that there was an initial
whitespace of 2 applied to get to the value of &lt;code&gt;3&lt;/code&gt;.  That did not seem right.&lt;/p&gt;
&lt;p&gt;Adding some temporary debug statements, I was able to quickly determine that the reason
that the
check was adding that indent of 2 characters was due to a bad index on the Block Quote
token.  With every newline that occurs within a given Block Quote, the
&lt;code&gt;leading_text_index&lt;/code&gt; field must be updated to point to the current line.  In this case,
the HTML Block had a number of newline characters within its data but had not updated
the index.  As a result, instead of the index being set to 3, it was set to 0.  This
meant that it was picking up the 0th element of the array&lt;sup id="fnref:zeroBased"&gt;&lt;a class="footnote-ref" href="#fn:zeroBased"&gt;1&lt;/a&gt;&lt;/sup&gt;, &lt;code&gt;&amp;gt;{space}&lt;/code&gt;,
with its length of 2 instead of the 3rd element in the array, an empty string with its
length of 0.&lt;/p&gt;
&lt;h3 id="fixing-the-problem"&gt;Fixing the Problem&lt;a class="headerlink" href="#fixing-the-problem" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Having learned a decent amount of information from my research, fixing the issue was
relatively
simple.  To increase the index by the right amount, I had to count the number of
newlines in the text and apply that number to the &lt;code&gt;leading_text_index&lt;/code&gt; field.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;    &lt;span class="n"&gt;newlines_in_text_token&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;__count_newlines_in_text&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;current_token&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;token_text&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"&amp;gt;&amp;gt;newlines_in_text_token&amp;gt;"&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;newlines_in_text_token&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="n"&gt;container_block_stack&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;leading_text_index&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="n"&gt;newlines_in_text_token&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;To err on the side of caution, I also decided to add a couple of extra scenario tests
with further variations on the example.  Just to make sure that the right thing would
happen with an extra line of text, I added an extra line of text and created test
&lt;code&gt;test_html_blocks_143b&lt;/code&gt;.  This addressed my concern that there may be something special
with 2 lines of text, and a third line of text would either highlight or eliminate that
concern.  Then, to make sure that Block Quote lines and their indents were working
properly, I added test &lt;code&gt;test_html_blocks_143c&lt;/code&gt;.  This test alternated the indents for the
Block Quote element between 0 spaces and 1 space, stressing that part of the fix.&lt;/p&gt;
&lt;h2 id="the-start-of-a-series"&gt;The Start of A Series&lt;a class="headerlink" href="#the-start-of-a-series" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;This next issue was the start of what I would later refer to as the 518 series of tests.
The process started when I looked at
&lt;a href="https://github.github.com/gfm/#example-518"&gt;example 518&lt;/a&gt;
and I wrote down a note check if all the combinations were covered.  To give more
context, I scribbled down “518, are we sure?” which I interpreted as “Am I sure that I
have all the combinations covered?”.  While it may sound like a weird logically jump
to make from a couple of scribbles, in my own way, I wrote down what was needed to make
sure that I followed it up.&lt;/p&gt;
&lt;p&gt;My thinking was simple.  A standard link, such as the following Markdown from example
518:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="n"&gt;link&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="w"&gt;   &lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;uri&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="ss"&gt;"title"&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;has 6 parts: the link label, the whitespace before the URI, the URI, the whitespace
before the title, the title, and the whitespace after the title.  All other parts of
that link are single characters in nature and required elements.  So, what I did with
this series of tests
is to start changing where the newline(s) were, seeing if I could break anything.  To
add some extra flavor to the tests, I also added a couple of tests that included
backslash characters.&lt;/p&gt;
&lt;h3 id="what-did-i-find-out"&gt;What Did I Find Out?&lt;a class="headerlink" href="#what-did-i-find-out" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;The primary thing that I found out was that the parser itself was not handling the
newline characters within links properly.  Specifically, the line numbers and column
numbers were not reflective of the Markdown document that was parsed.  To address
this, the &lt;code&gt;__handle_inline_special&lt;/code&gt; function was modified to handle an alternate
calculation of the line/column number if a Link end token was found.  While the
initial calculation of &lt;code&gt;new_index - next_index&lt;/code&gt; works for any Link tokens that do not
contain a newline character, the calculation for those that included a newline
character was going to be a bit more complicated.&lt;/p&gt;
&lt;p&gt;After trying out a couple of solutions in my head, the only one that gained the
most traction with me
was a staggered approach.  In this approach, I preset an array with the lengths of
various parts of the link, as outlined above.  The function then goes through each of
the parts of the link in their order, checking for newlines for each part as it goes.
If at least one newline character is found, the line variables are updated and the
&lt;code&gt;link_part_index&lt;/code&gt; is set to that part’s index number.  At the end, all values before
that index are reset to 0 and the column number is adjusted by the sum of each value
in the array.&lt;/p&gt;
&lt;p&gt;While there are small fixes along the way to make the algorithm work properly, this
algorithm works well as it keeps things simple.  As each part is checked in turn for
newline characters, the change to the line number variable is accurate.  By setting
and resetting the &lt;code&gt;link_part_index&lt;/code&gt; variable to the last element that had a newline,
only the elements after that index get added to the total, accurately reflecting
the number of characters after the last newline character.&lt;/p&gt;
&lt;p&gt;After that was done, the only extra adjustment that needed to be added was accounting
for whitespace at the start of lines within Paragraph elements, making sure that it
gets applied properly.  That entailed tracking whether or not the parser was currently
processing a paragraph token and using the &lt;code&gt;rehydrate_index&lt;/code&gt; field of the Paragraph
token.  With that in place, manual verification of the newly added case confirmed
that the algorithm was calculating things properly.&lt;/p&gt;
&lt;h3 id="but-what-about"&gt;But What About…?&lt;a class="headerlink" href="#but-what-about" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Finishing up the work, there were two things that I knew I needed to work on:
consistency checks and other types of links.  Strangely, the only changes I needed to
the checks were to change Link Reference Definition checks to ensure that it accounted
for the newlines in various components.  Other than that, the everything seemed to
line up.&lt;/p&gt;
&lt;p&gt;As for other types of links, that answer was clear.  Based on the parser code
and the consistency check code, the only type of link that was being tested for newlines
inside of the link were plain inline links.  To combat this, I added extra items to the
issues list, as well as made a mental note to revisit this later.&lt;/p&gt;
&lt;h2 id="fenced-code-blocks-and-blank-lines"&gt;Fenced Code Blocks and Blank Lines&lt;a class="headerlink" href="#fenced-code-blocks-and-blank-lines" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;While this did not take a long time to solve, it was a good issue to get out of the
way.  At issue was the Markdown for
&lt;a href="https://github.github.com/gfm/#example-99"&gt;example 99&lt;/a&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;```&lt;/span&gt;

&lt;span class="err"&gt;{&lt;/span&gt;&lt;span class="k"&gt;space&lt;/span&gt;&lt;span class="err"&gt;}{&lt;/span&gt;&lt;span class="k"&gt;space&lt;/span&gt;&lt;span class="err"&gt;}&lt;/span&gt;
&lt;span class="o"&gt;```&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;where &lt;code&gt;{space}&lt;/code&gt; stands for an actual space character.  While the actual item reads
&lt;code&gt;fenced, 99 with more blanks&lt;/code&gt;, I knew that I was concerned about not having more
examples with different types of blanks inside of the fenced code block.  To fully
test this, I created many variations on this one test, differing the
number of blank lines and the amount of whitespace on each blank line.&lt;/p&gt;
&lt;p&gt;I was happy to find out that the work on the parser stood up to this extended testing,
and the consistency checks only required a small change.  To be precise, the only
change that it needed was to reset the column number to &lt;code&gt;0&lt;/code&gt; if the
first inline token inside of a Fenced Code block was a Blank Line token.&lt;/p&gt;
&lt;p&gt;I did discover something somewhat puzzling though.  In a Fenced Code block, if the
first token is a Text token, the rest of the body of the block is coalesced. If the
first token is a Blank Line token, then the tokens are not coalesced at all.  Rather
than focus on that at the time, I just noted it down in the issues list, and hoped
to find time soon to figure out if that is the correct solution.&lt;/p&gt;
&lt;h2 id="the-first-inline-token-after-an-atx-heading-token"&gt;The First Inline Token After an Atx Heading Token&lt;a class="headerlink" href="#the-first-inline-token-after-an-atx-heading-token" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Having noticed this one a while ago, it was always something that I wondered about:
why does the parser sometimes insert a whitespace character right after an Atx Heading
token?  I knew I must have a good reason for it, but I could not recall why.  I did find
a couple of scribbles in old notes about Atx Headings, but that was it.  I needed
something more to go on for me to understand this and wrap it up.&lt;/p&gt;
&lt;h3 id="doing-the-research"&gt;Doing the Research&lt;a class="headerlink" href="#doing-the-research" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Going way back in the project’s commit log, I noticed two things:  The first thing was
that this project has been going on for a long while, and the second was that in that
long while, very few of the commits refer to Atx Headings in their commit messages.  To
me, this means that Atx Headings are very stable, something that I felt proud of.
That stability helps me to understand why I did not make any notes around what I was
doing: quite probably they just were not needed.&lt;/p&gt;
&lt;p&gt;There are only 4 times where Atx Headings have
been mentioned in the commit logs:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/jackdewinter/pymarkdown/commit/f66221957d761c930728bb8c462576ac951e3552#diff-99f7c38bdec0a4060beb648f08162098"&gt;Adding atx and setext headings.&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;initial addition for Atx Heading support&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/jackdewinter/pymarkdown/commit/fa7ff7223fd614758b95bf8cde76052671680c7d#diff-99f7c38bdec0a4060beb648f08162098"&gt;Fixing Atx headers to allow better inline processing.&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;moved most text out of the token to allow normal inline processing to take place&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/jackdewinter/pymarkdown/commit/0565ed9db906873b88d224c829c2acbf9bdb6370#diff-99f7c38bdec0a4060beb648f08162098"&gt;Adding line/column support for tax headings.&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;adding line numbers and column numbers to the tokens&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/jackdewinter/pymarkdown/commit/573cdf32570611cbc61273cef9c6808fe44137ba#diff-99f7c38bdec0a4060beb648f08162098"&gt;Added testing of every inline at the start of a Atx heading…&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;this issue&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This summary made it really easy for me to come to the observation that when the change
was made to
allow better inline parsing, the initial whitespace between the Atx Heading and its
enclosed text was placed in the whitespace section of the text token.
By looking at the consistency checks, I also observed that there are zero instances
where an Atx Heading is not immediately followed by a Text token.  After looking at
those two observations and commit history, I do not feel it is a leap to say that
this was a design decision that I made but never recorded.  Further, I feel that the
worst case is that it is a pattern that has a lot going for it and could easily be
adopted as a new design decision.  Either way, it seems to be a winning design.&lt;/p&gt;
&lt;h3 id="backing-up-the-design-decision"&gt;Backing Up the Design Decision&lt;a class="headerlink" href="#backing-up-the-design-decision" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Another thing that I learned from my research was that there was only one case of a
non-Text element following the Atx Heading characters in any of the Markdown examples.
The Markdown for
&lt;a href="https://github.github.com/gfm/#example-183"&gt;example 183&lt;/a&gt; is:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="ss"&gt;""&lt;/span&gt;&lt;span class="err"&gt;"#&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="n"&gt;Foo&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="n"&gt;foo&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;&lt;span class="err"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;url&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;bar&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;which produces an Atx Heading element with a Link element right after it.  Based on
the previous research, I expected the tokenization to include that whitespace character,
and it did not disappoint:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;    &lt;span class="n"&gt;expected_tokens&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;
        &lt;span class="s2"&gt;"[atx(1,1):1:0:]"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="s2"&gt;"[text(1,3)::&lt;/span&gt;&lt;span class="se"&gt;\a&lt;/span&gt;&lt;span class="s2"&gt; &lt;/span&gt;&lt;span class="se"&gt;\a\x03\a&lt;/span&gt;&lt;span class="s2"&gt;]"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="s2"&gt;"[link(1,3):shortcut:/url:::::Foo:::::]"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="s2"&gt;"[text(1,4):Foo:]"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="s2"&gt;"[end-link:::False]"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="s2"&gt;"[end-atx:::False]"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;For readers that have not been following along, the &lt;code&gt;\a&lt;/code&gt; character in an inline text
string represents a replacement of one character for another character.  In this case,
the &lt;code&gt;{space}&lt;/code&gt; character between the first two &lt;code&gt;\a&lt;/code&gt; characters is being replaced by
the character &lt;code&gt;\x03&lt;/code&gt; used as a NOOP character.  To me, this means that when the parser
tokenized that part of the line, it purposefully replaced a space character with an empty
string.  Based on the research, this was the right thing to do.&lt;/p&gt;
&lt;p&gt;The rest of addressing this issue was just replicating various forms of this example for
each inline sequence.  Starting with function &lt;code&gt;test_atx_headings_extra_2&lt;/code&gt; and ending with
function &lt;code&gt;test_atx_headings_extra_12&lt;/code&gt;, I just cycled through each of the newline
sequences, include Hard Line breaks.  And with two exceptions, each of the new test
functions passed.&lt;/p&gt;
&lt;p&gt;The first case where I needed to fix something came even before I added the extra
functions: example 183.  To make sure this was working properly, I needed to add an extra
line to the &lt;code&gt;__process_inline_text_block&lt;/code&gt; function of the &lt;code&gt;InlineProcessor&lt;/code&gt; class.  In
the specific case where I was adding that special replacement, I determined that I was
not clearing the &lt;code&gt;starting_whitespace&lt;/code&gt; variable, and that caused the extra text to occur
within the link instead of before the link.  That caused the rehydration to fail as the
space character was in the wrong position.&lt;/p&gt;
&lt;p&gt;The second case was in the &lt;code&gt;__verify_first_inline_atx&lt;/code&gt; function of the consistency
checks.  The function was first cleaned up removing all the extra &lt;code&gt;assert False&lt;/code&gt;
statements and replacing them with an assert that the first token processed within
the Atx Heading was a Text token.  Once that was done, I just reordered the remaining
lines in the function to keep functionality together, and it was done.&lt;/p&gt;
&lt;h2 id="what-was-my-experience-so-far"&gt;What Was My Experience So Far?&lt;a class="headerlink" href="#what-was-my-experience-so-far" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;I went into this work knowing that at best, I would be able to knock a handful of issues
of the list in one week.  Meeting that goal, it also started to sink in
that the research for each issue was going to take the lion’s share of resolving
each issue.&lt;/p&gt;
&lt;p&gt;If I was lucky, I figured I would stumble upon what I needed to do early in the
research.  But I prepared myself for the probability that, most often, I would need to
add debug statement, add some extra scenario tests, execute all relevant scenario tests,
examine the results of those tests, and iterate.  Sometimes it would only take 1 or 2
iterations, but I figured that most often it would take upwards of 5 to 10 iterations.
Based on my experience with this week’s work, that set of expectations was a healthy
set to start with.&lt;/p&gt;
&lt;p&gt;At this point, I was feeling decently okay.  Not to sound too vague, but what I went
through was right down the middle of what I expected to happen.  As such, I was not
feeling over positive or overly negative, just… well… okay.  If anything, I was
hoping that this “down the middle” result would apply most of the time.  Having too
many quick issues would get my hopes up for the remaining issues and having too many
long running issues would stop any momentum I was gaining.&lt;/p&gt;
&lt;p&gt;But more importantly, I just wanted to keep on working through the issues list.  I was
okay with moving issues to the “nice to have” section that I had created.  But I was
only okay with that if I honestly though it was not required.  If I kept myself
honest, it was a good way to move forward without jeopardizing the project.&lt;/p&gt;
&lt;p&gt;And with that, I ended the work for the week, on a mostly positive note.&lt;/p&gt;
&lt;h2 id="what-is-next"&gt;What is Next?&lt;a class="headerlink" href="#what-is-next" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Having completed resolving a small number of issues, I was hoping to keep up some
momentum by continuing to solve more issues in the next week.  Simple as that!&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr/&gt;
&lt;ol&gt;
&lt;li id="fn:zeroBased"&gt;
&lt;p&gt;A simple reminder that when most people talk about arrays, they refer to an index into that array.  As such, the first element of the array in the zeroth (0th) element of the array. &lt;a class="footnote-backref" href="#fnref:zeroBased" title="Jump back to footnote 1 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</content><category term="Software Quality"></category><category term="markdown linter"></category><category term="core linter"></category></entry><entry><title>Markdown Linter - Adding Remaining Inline Tokens</title><link href="https://jackdewinter.github.io/2020/09/21/markdown-linter-adding-remaining-inline-tokens/" rel="alternate"></link><published>2020-09-21T00:00:00-07:00</published><updated>2020-09-21T00:00:00-07:00</updated><author><name>Jack De Winter</name></author><id>tag:jackdewinter.github.io,2020-09-21:/2020/09/21/markdown-linter-adding-remaining-inline-tokens/</id><summary type="html">
&lt;h2 id="summary"&gt;Summary&lt;a class="headerlink" href="#summary" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;In my
&lt;a href="https://jackdewinter.github.io/2020/09/14/markdown-linter-adding-consistency-checks-for-emphasis-and-text-tokens/"&gt;last article&lt;/a&gt;,
I completed the addition of proper support for line and column numbers for the
text token and emphasis tokens by finishing the consistency checks.  In this article,
I talk about the efforts and issues required to finish implementing the line and
column numbers for the …&lt;/p&gt;</summary><content type="html">
&lt;h2 id="summary"&gt;Summary&lt;a class="headerlink" href="#summary" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;In my
&lt;a href="https://jackdewinter.github.io/2020/09/14/markdown-linter-adding-consistency-checks-for-emphasis-and-text-tokens/"&gt;last article&lt;/a&gt;,
I completed the addition of proper support for line and column numbers for the
text token and emphasis tokens by finishing the consistency checks.  In this article,
I talk about the efforts and issues required to finish implementing the line and
column numbers for the remaining inline tokens, including their consistency checks.&lt;/p&gt;
&lt;h2 id="introduction"&gt;Introduction&lt;a class="headerlink" href="#introduction" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;From a wholistic point of view, I felt that the accuracy and consistency of the tokens
were getting more solid with each change.  While I expected a fair number of tests to fail
when I started to add the consistency checks, I was now at a point where a failing test
would be a novel thing. And that was good!  But even with that positive outlook on the
project and the consistency checks, I knew I still had a way to go to finish
things up properly with respect to the tokens.&lt;/p&gt;
&lt;p&gt;After having finished adding the line/column numbers for the Emphasis tokens and the
Text token, the remaining inline tokens were the only things left in the way of
finishing that work.  After the work
I had done on that group of tokens, I was hoping that this would be an easy batch of
work to complete.  But only time would tell.&lt;/p&gt;
&lt;h2 id="what-is-the-audience-for-this-article"&gt;What Is the Audience for This Article?&lt;a class="headerlink" href="#what-is-the-audience-for-this-article" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;While detailed more eloquently in
&lt;a href="https://jackdewinter.github.io/2020/04/05/what-is-the-audience-for-my-blog/#what-is-the-audience-for-my-blog"&gt;this article&lt;/a&gt;,
my goal for this technical article is to focus on the reasoning behind my solutions,
rather that the solutions themselves.  For a full record of the solutions presented in
this article, please go to this project’s GitHub repository and consult the
commits between
&lt;a href="https://github.com/jackdewinter/pymarkdown/commit/f518085e03979439ea20f48a787213f1f145eb3a"&gt;04 Sep 2020&lt;/a&gt;
and
&lt;a href="https://github.com/jackdewinter/pymarkdown/commit/0d7be8514f459102853974a88810ce6842618e58"&gt;09 Sep 2020&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id="remaining-inline-tokens"&gt;Remaining Inline Tokens&lt;a class="headerlink" href="#remaining-inline-tokens" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Having taken care of the Emphasis tokens and the Text token, all the other inline tokens
remained: Raw-HTML, Links, Images, Autolinks, Code Spans and Hard Line Breaks.
Before starting work on each of these tokens, I was not sure if the effort required
to implement each one would be more like the Emphasis tokens or more like the Text
token.  I hoped it would be a simple case and easy to work on, but there were no
guarantees.&lt;/p&gt;
&lt;p&gt;With some optimism in mind, and my fingers crossed, I started my work.&lt;/p&gt;
&lt;h3 id="raw-html-and-links"&gt;Raw HTML and Links&lt;a class="headerlink" href="#raw-html-and-links" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;As I write this article and look back at my notes, I fully admit that I am a bit
stumped.  Picking one of these two inline tokens to work on makes sense to me.  I have
no notes to myself saying, “two for the price of one” or “these will be simple”.&lt;br/&gt;
I am left scratching my head as to why I decided to work on both at the same time.
Regardless of why I decided to do both, they were both completed.&lt;/p&gt;
&lt;p&gt;I believed that working on both items at the same time would just be asking for
something to go wrong, so I chose to focus first on the Raw HTML token.  The initial
change was easy, changing the creation of the token from:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;RawHtmlMarkdownToken&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;valid_raw_html&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;to:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;RawHtmlMarkdownToken&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;valid_raw_html&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;line_number&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;column_number&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;thereby passing the line number and the column number to the constructor for the
&lt;code&gt;RawHtmlMarkdownToken&lt;/code&gt; class.  Once that was done, another simple change was made
to the &lt;code&gt;handle_angle_brackets&lt;/code&gt; function to pass the current line number and column
number as arguments, as such:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;        &lt;span class="n"&gt;new_token&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;after_index&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;HtmlHelper&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;parse_raw_html&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
            &lt;span class="n"&gt;between_brackets&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
            &lt;span class="n"&gt;remaining_line&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
            &lt;span class="n"&gt;inline_request&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;line_number&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
            &lt;span class="n"&gt;inline_request&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;column_number&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h4 id="testing-and-iterating"&gt;Testing and Iterating&lt;a class="headerlink" href="#testing-and-iterating" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;Running the tests for the Raw HTML token, it was immediately obvious to me that in
certain cases, the column number was off by a bit.  After a bit of research, I noticed
that in cases where there was a Text token before the Raw HTML token, the new Raw HTML
token had the same line/column number as the Text token.  Digging a bit deeper, it
appeared that in those cases, the &lt;code&gt;remaining_line&lt;/code&gt; field of the &lt;code&gt;inline_request&lt;/code&gt; object
had the correct number of characters to make up the difference, but they were not being
applied.&lt;/p&gt;
&lt;p&gt;To address that inadequacy, I made a small change to the above example.  Following the
logic of the inline algorithm, once a new token is created to be inserted, the text
leading up to that token is determined, largely based off the &lt;code&gt;remaining_line&lt;/code&gt;
variable.  While this seems slightly out of order, it ensures that the proper Text token
with the proper line/column number is inserted in the correct order.  However, because
the new token is created before that Text token is inserted, it does not have the
right column number.  By simply adding the length of the &lt;code&gt;remaining_line&lt;/code&gt; variable to
the column number, the difference is accounted for.  This was accomplished by first
calculating that new column number:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;            &lt;span class="n"&gt;new_column_number&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;inline_request&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;column_number&lt;/span&gt;
            &lt;span class="n"&gt;new_column_number&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;inline_request&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;remaining_line&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;and then passing that new &lt;code&gt;new_column_number&lt;/code&gt; value into the call to the
&lt;code&gt;HtmlHelper.parse_raw_html&lt;/code&gt; function in the previous example instead of the
&lt;code&gt;inline_request.column_number&lt;/code&gt; argument.&lt;/p&gt;
&lt;h4 id="new-lines-inside-of-the-token"&gt;New Lines Inside of the Token&lt;a class="headerlink" href="#new-lines-inside-of-the-token" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;After running through the tests again, almost all the tests were passing, except for
the test for
&lt;a href="https://github.github.com/gfm/#example-500"&gt;example 500&lt;/a&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="n"&gt;link&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;foo&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="n"&gt;bar&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This case may look weird, but everything is computed properly as a series of Text
tokens and a Raw HTML token.  Because of
the newline in the URI, the text is not eligible to be a link, but since the URI part
is enclosed in “angle brackets”, it is eligible to be a Raw HTML token.  But even with
the Raw HTML token being parsed, the Text token containing the trailing &lt;code&gt;)&lt;/code&gt; character was
off.  Instead of being reported as &lt;code&gt;(2,5)&lt;/code&gt;, it was being reported as &lt;code&gt;(1,17)&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;To investigate this further, I created the new scenario test &lt;code&gt;test_raw_html_634a&lt;/code&gt;.  This
new test was a more isolated
case of example 500, a copy of the test function &lt;code&gt;test_raw_html_634&lt;/code&gt; with a newline
character inserted inside of the &lt;code&gt;b2&lt;/code&gt; HTML tag, as follows:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;  &lt;span class="o"&gt;/&amp;gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;b2&lt;/span&gt;
&lt;span class="k"&gt;data&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="ss"&gt;"foo"&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&amp;lt;&lt;/span&gt;&lt;span class="k"&gt;c&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;I started to look at this issue and
it turned out to be an easy issue to overcome.&lt;/p&gt;
&lt;h4 id="fixing-newlines"&gt;Fixing Newlines&lt;a class="headerlink" href="#fixing-newlines" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;With this isolated scenario test, it was very easy to see that the issue was with the
&lt;code&gt;raw_tag&lt;/code&gt;
field of the Raw HTML token.  When the token contained a newline character, that newline
was treated as a normal character and added to the character count.  What I needed to
do was to make sure that the algorithm understood that the newline character was special
and to handle it differently.  So, to address that
behavior, I introduced some extra code to the &lt;code&gt;handle_angle_brackets&lt;/code&gt; function:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="n"&gt;new_token&lt;/span&gt;
    &lt;span class="ow"&gt;and&lt;/span&gt; &lt;span class="n"&gt;new_token&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;token_name&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;MarkdownToken&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;token_inline_raw_html&lt;/span&gt;
    &lt;span class="ow"&gt;and&lt;/span&gt; &lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;new_token&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;raw_tag&lt;/span&gt;
&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;split_raw_tag&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;new_token&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;raw_tag&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;split&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;inline_response&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;delta_line_number&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;split_raw_tag&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
    &lt;span class="n"&gt;length_of_last_elements&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;split_raw_tag&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
    &lt;span class="n"&gt;inline_response&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;delta_column_number&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;length_of_last_elements&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;inline_response&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;delta_column_number&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="n"&gt;inline_response&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;new_index&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;inline_request&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;next_index&lt;/span&gt;
    &lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;inline_response&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Basically, since the existing code already handled the case with zero newlines perfectly,
I did not need to change that aspect of the function.  However, in the case of a Raw HTML
token that contained a newline in its &lt;code&gt;raw_tag&lt;/code&gt; field, I needed special processing to
kick in.  The first thing I
needed was a clear picture of the &lt;code&gt;raw_tag&lt;/code&gt; field and its newline characters, so I
split the string on newline characters into the &lt;code&gt;split_raw_tag&lt;/code&gt; variable.  Then I
addressed the line number calculation first, correcting the line number calculation by
adding the number of newline characters found to the &lt;code&gt;inline_response.delta_line_number&lt;/code&gt;
variable.&lt;sup id="fnref:splitLine"&gt;&lt;a class="footnote-ref" href="#fn:splitLine"&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;p&gt;After I was sure that the line number was being correctly calculated, it was time for me
to focus on the column number.  While each of the lines in the &lt;code&gt;raw_tag&lt;/code&gt; field were
important, their content was already mostly covered by the calculation for the change to
the line number.  Each line except the last line that is.  That last line was the new
information that would lead the text after the Raw HTML token.  As such, the column
number was at least as many characters along as the length of any text past that last
newline character, as calculated for the &lt;code&gt;length_of_last_elements&lt;/code&gt; variable.  With
that calculation completed, all that was required was to add 2 to that value for
constant element overhead: 1 for
the length of the closing angle brackets (&lt;code&gt;&amp;gt;&lt;/code&gt;) and 1 to translate the value from an
index to a position.&lt;sup id="fnref:indexPosition"&gt;&lt;a class="footnote-ref" href="#fn:indexPosition"&gt;2&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;h4 id="conveying-that-information-back-to-the-caller"&gt;Conveying That Information Back to The Caller&lt;a class="headerlink" href="#conveying-that-information-back-to-the-caller" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;With everything else completed, I then had to decide how I was going to get the newly
calculated column number back to the calling function.  According to the debug
statements that I had added, the value was being calculated properly.  While there were
a couple of options on the table, I decided to go for a simple approach: a negative
number.&lt;/p&gt;
&lt;p&gt;I am not sure if this choice is
&lt;a href="https://blog.startifact.com/posts/older/what-is-pythonic.html"&gt;pythonic&lt;/a&gt;
or not, I believe that it conveys the right information in an efficient manner.
If the column number is zero or positive, it represents a simple change or delta to the
column
number, a simple value to be added to the current column number to arrive at the new
column number.  However, if the column number is negative, it represents an absolute
number that should be used for the column number.  For example, if the token contains
a newline character, it makes sense that the returned value would indicate a value
from the start of the new line, not from the last know position.&lt;/p&gt;
&lt;p&gt;Why a negative number?  While I could have returned an extra value that determined
whether the number was referential or absolute, that seemed too bulky.  For me, this
was keeping it lean within its limited scope.&lt;/p&gt;
&lt;h4 id="adding-validation"&gt;Adding Validation&lt;a class="headerlink" href="#adding-validation" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;After all that work, the validation was very anti-climactic.  It may appear that I
cheated and copied the calculation from above as-is into the new
&lt;code&gt;__verify_next_inline_raw_html&lt;/code&gt; function.  Rather than being a cheat, I worked
through the calculations again on paper, making sure that I did not miss any weird
boundary conditions.  After generating the algorithm in the
&lt;code&gt;__verify_next_inline_raw_html&lt;/code&gt; function from scratch, I compared the two algorithms
together and the algorithms themselves were the same.  Rather than cheating,
I considered it a validation that I had derived the right algorithm twice.&lt;/p&gt;
&lt;h4 id="what-about-the-links"&gt;What About the Links?&lt;a class="headerlink" href="#what-about-the-links" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;As I mentioned at the start of this section, I am not sure why I decided to work on
these two tokens together.  I can only guess that perhaps
I thought that adding line/column numbers to the Link tokens would uncover something
important that adding line/column numbers to the Raw HTML tokens would not.
The reality was that after completing the Raw HTML token work, the changes needed
to implement the line/column numbers for Link tokens was trivially easy.&lt;/p&gt;
&lt;p&gt;Unexpectantly, this would foreshadow the following work on the other inline tokens.&lt;/p&gt;
&lt;h2 id="autolinks-code-spans-images-and-hard-line-breaks"&gt;Autolinks, Code Spans, Images and Hard Line Breaks&lt;a class="headerlink" href="#autolinks-code-spans-images-and-hard-line-breaks" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;I expected some manner of difficulty in implementing the line/column numbers
for these tokens, however the previous work made the implementation of the new code easy.
There were issues that needed to be properly addressed for each specific type of
token, but the hard work had already been done.  As such, the work was more akin
to copy-and-paste-and-adjust than anything else.&lt;/p&gt;
&lt;p&gt;In the implementation of each of the tokens, the initial calculation for each of the
tokens included values for the length of the constant part of the element and the
variable part of
the element.  Once that was complete and the easy tests were passing, any multiline
parts were addressed, with progress being made to get closer to having the remaining
scenario tests passing.  To finish that work, consistency checks were added that were
simply verifying the algorithms used previous and verifying the work.&lt;/p&gt;
&lt;p&gt;This process was a simple rehash of the work that I did for the Raw HTML token, and
then again for the Link token.  But it was working and working well.  While a part
of me was saying “this is too easy, what’s wrong?”, I double checked all my work
to quiet that voice and assure myself that I had not missed anything.&lt;/p&gt;
&lt;p&gt;While it was simple work, it did take a couple of days to complete.  But at the end
of that work, each relevant token had a line number and a column number, and they
had been verified.  Even more interesting, while some extra scenarios were added to
deal with missing cases (mostly to deal with multiline element parts), no new issues
had been found.  Things were looking good.  Almost.&lt;/p&gt;
&lt;h2 id="last-inline-vs-next-block"&gt;Last Inline vs Next Block&lt;a class="headerlink" href="#last-inline-vs-next-block" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;With all the inline tokens supporting line/column numbers, I felt as if a bit of
a load was taken off of my shoulders.  I was not really worried that there was something
wrong, but as I mentioned
&lt;a href="https://jackdewinter.github.io/2020/09/14/markdown-linter-adding-consistency-checks-for-emphasis-and-text-tokens/#introduction"&gt;in the last article&lt;/a&gt;:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;I know that I am fallible.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;There was no proof that I could see that I had missed something, but I just had a
nagging feeling that I had left something out.  Trying to get rid of that feeling, I went
through the work that I had just completed and checked it again, finding nothing out
of the ordinary.  On top of that, I had automation in place to catch any miscalculations
that I made, something that was welcome.&lt;/p&gt;
&lt;p&gt;After that extra checking was completed, I could not find anything wrong and I was ready
to move on.  But as I was getting ready to start working on some of the items
in the issue list, I noticed something.  Reading my previous article to gain some
extra perspective on where I was in the project, I noticed the part where I stated:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;So, whether I liked the idea or not, validation of the first element in the list was mandatory.  The last element is a different story.  While it would be nice to tie the last inline token to the following block token, I felt that it was not as important as the verification of the first element.  However, I added in a placeholder to the code to make sure that I would follow up on it later.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;I remembered!&lt;/p&gt;
&lt;h3 id="the-other-anchor-for-the-inline-tokens"&gt;The Other Anchor for the Inline Tokens&lt;a class="headerlink" href="#the-other-anchor-for-the-inline-tokens" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;As I mentioned before, I started with the outer token and the first token because
I wanted to ensure that was able to anchor the list, and the anchoring the first token
was the easiest solution at the time.  Having finished that task off and
also having finished validation of the inline tokens within the list, it was now time to
work on anchoring the other side of the list: the last inline token and the following
block token.  That is what the nagging feeling was! That is what I was trying to
remember.&lt;/p&gt;
&lt;p&gt;Starting to research what I needed to do to resolve this anchor issue, I came to an
interesting
observation.  While all groups of inline tokens start after a block token, not all
groups of inline tokens end with a block token.  Because of the way tokenization is
performed, I decided not to expose line/column numbers for any of the end tokens that
did not add something to the data stream.  This means that except for the
Emphasis end token, none of the other end tokens have a line/column associated with
them.&lt;/p&gt;
&lt;p&gt;Why is that observation on tokenization important?  A good example is the Markdown
document for
&lt;a href="https://github.github.com/gfm/#example-364"&gt;example 364&lt;/a&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;foo&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;bar&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;From that Markdown,
I can surmise that the tokens for that document will start with a Paragraph
start token and end with a Paragraph end token.  Inside of the paragraph, there will be
a Text token containing &lt;code&gt;foo&lt;/code&gt;, an Emphasis start token, a Text token containing &lt;code&gt;bar&lt;/code&gt;,
and an Emphasis end token.  This is backed up by the realized tokens for the example,
which are:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;    &lt;span class="n"&gt;expected_tokens&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;
        &lt;span class="s2"&gt;"[para(1,1):]"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="s2"&gt;"[text(1,1):foo:]"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="s2"&gt;"[emphasis(1,4):1:*]"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="s2"&gt;"[text(1,5):bar:]"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="s2"&gt;"[end-emphasis(1,8)::1:*:False]"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="s2"&gt;"[end-para:::True]"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="p"&gt;]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;From looking at this tokenization, the last token with a line/column number attached
to it is the Emphasis end token, an inline token.  Getting an actual block token to
appear after those tokens is as simple as changing the Markdown to:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;foo&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;bar&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This adds a new Blank Line token to the end of the array, adding the tokenization
&lt;code&gt;'[BLANK(2,1):]'&lt;/code&gt;.  However, I knew the real trick would be to determine that value
without having to add that extra token.&lt;/p&gt;
&lt;h3 id="focusing-on-that-line-number"&gt;Focusing on That Line Number&lt;a class="headerlink" href="#focusing-on-that-line-number" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Working through the issue from the previous section helped me understand something
else about the relationship with the last inline token and the possible following
block token: only the line number was important.  Because the inline tokens
are always contained within a container block element or a leaf block element, the
last token in an inline token group is guaranteed to be either an end token for a
previously started block element or a start token for a new block element.&lt;/p&gt;
&lt;p&gt;If the next block token after the inline tokens is a block start token, because of
the work up to this point, a line/column number is guaranteed.  If the next block
token is a block end token, one of two things happens.  Either a block start token
follows with the start of a new block element, or the end of the document is reached.
If a block start token follows, the line/column number is guaranteed as above.
In the case of the end of the document, as no token with a valid line/column number
follows, some other calculation is needed to determine the line number to compare
to.&lt;/p&gt;
&lt;p&gt;The good news is that only the line number is important.  Because only the line number
is important, there is another available number that we can use: the number of lines
in the Markdown document.  As such, if there is a block start token after the inline
block, I used the line number from that token as the line number to compare against.
If no such token existed, I used the number of lines in the document.&lt;/p&gt;
&lt;p&gt;I tested this approach with a handful of scenarios, some with eligible following block
tokens and some with an absence of eligible following block tokens.  On paper it seemed
to work without fail.  The only thing that was left was to test that approach with
actual code.&lt;/p&gt;
&lt;h3 id="completing-the-checks"&gt;Completing the Checks&lt;a class="headerlink" href="#completing-the-checks" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;To calculate the line number to compare to, I added the &lt;code&gt;__verify_last_inline&lt;/code&gt;
function with my usual development pattern.  Following that pattern, I started
adding handlers for each of the inline tokens it encountered, just trying to
get to a steady state where all the handlers were present.  Once that was achieved,
I started adding the content to each handler to calculate the height of the inline
token.&lt;/p&gt;
&lt;p&gt;Now I wish I could say it was good planning, but it was just serendipity that I
did this work right after the work on adding the line/column number support to most
of the inline tokens.  Based on that recent work, adding the calculations for the
heights of each of the tokens was exceedingly easy.  While it was easy, it took
a couple of days for me to work through each case and verify each twist and turn
of the token.  But in the end, with only one planned failure&lt;sup id="fnref:IKnew"&gt;&lt;a class="footnote-ref" href="#fn:IKnew"&gt;3&lt;/a&gt;&lt;/sup&gt; to address and
one or two items to look at later, the token validation was complete!&lt;/p&gt;
&lt;h2 id="what-was-my-experience-so-far"&gt;What Was My Experience So Far?&lt;a class="headerlink" href="#what-was-my-experience-so-far" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Getting to this point in the PyMarkdown project was a momentous achievement for
me, measured in months rather than days.  Along the way, I had developed a
Markdown parser, ensured that it emitted tokens that include line numbers and
column numbers, verified its output against both expected HTML output and the original
Markdown input, and had a good array of consistency checks on the line numbers and
column numbers.  Phew.  It was a long list, but the project has come a long way.&lt;/p&gt;
&lt;p&gt;I was relieved that I got to this point with my original design mostly intact.  I
was aware that I was going to have to do some refactoring in the future to make the
code more modifiable, but I believe it is in a decent position to make that happen.
Besides, when I start doing that, I have almost 1400 scenario tests that will make
sure any changes are not negatively impacting the code.&lt;/p&gt;
&lt;p&gt;With all that good stuff in mind, I started to look at the issues list, and paged
through it.  At just over 200 lines of text, it was a bit daunting to look at initially.
But as I progressed with the project, any idea or question I had was put into that
list.  There were ideas for better tests, questions on whether something was done right,
and notes on things I wanted to check because they looked weird in some way.  And during
the project’s development to date, I had taken proactive efforts to get any
serious issues out of the way.  Being the optimistic, I hoped that I was left with a
solid set of enhancements.  Regardless
of what remained in the list, I was sure that I could tackle it.  And sure, there
might be some rewrites that I would need to do, but they would make the project stronger,
leaner, faster, and more maintainable.&lt;/p&gt;
&lt;p&gt;So how was I feeling?  Very optimistic.  There were quite the number of items in the
issues list, but if I tackled them one at I time, I could get through them.  And going
through them would either fix an issue or confirm that the project did not have that
particular issue.  And to me, both outcomes were positive.&lt;/p&gt;
&lt;h2 id="what-is-next"&gt;What is Next?&lt;a class="headerlink" href="#what-is-next" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Having completed all the consistency checks, I now had operating scenario tests with
values and line/column numbers that I was very confident about.  But along the way,
I had accumulated a decent number of items in the issues list.  Before getting back
to filling out the set of rules, it was time to address those items.&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr/&gt;
&lt;ol&gt;
&lt;li id="fn:splitLine"&gt;
&lt;p&gt;Python’s &lt;code&gt;split&lt;/code&gt; function works as expected.  If you have a string that does not contain the sequence to split on, it returns an array with one element.  If you have a string that has one or more instances of the sequence to split on, it returns an array with each element being any text between those instances.  As such, if a string has one newline character and is split, it will result in an array with a length of 2.  Therefore, I used &lt;code&gt;len(split_raw_tag) - 1&lt;/code&gt; to figure out the number of newline characters found in the &lt;code&gt;raw_tag&lt;/code&gt; field. &lt;a class="footnote-backref" href="#fnref:splitLine" title="Jump back to footnote 1 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:indexPosition"&gt;
&lt;p&gt;By their nature, an index starts at 0 and a position starts at 1.  As a column number is a position on a line but was being computed as an index, I needed to add 1 to the value to transition it into being a position. &lt;a class="footnote-backref" href="#fnref:indexPosition" title="Jump back to footnote 2 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:IKnew"&gt;
&lt;p&gt;Ahead of time, I had already determined that the scenario test &lt;code&gt;test_inline_links_518b&lt;/code&gt; was split over multiple lines and would be addressed by this validation. &lt;a class="footnote-backref" href="#fnref:IKnew" title="Jump back to footnote 3 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</content><category term="Software Quality"></category><category term="markdown linter"></category><category term="core linter"></category></entry><entry><title>Markdown Linter - Adding Consistency Checks for Emphasis and Text Tokens</title><link href="https://jackdewinter.github.io/2020/09/14/markdown-linter-adding-consistency-checks-for-emphasis-and-text-tokens/" rel="alternate"></link><published>2020-09-14T00:00:00-07:00</published><updated>2020-09-14T00:00:00-07:00</updated><author><name>Jack De Winter</name></author><id>tag:jackdewinter.github.io,2020-09-14:/2020/09/14/markdown-linter-adding-consistency-checks-for-emphasis-and-text-tokens/</id><summary type="html">
&lt;h2 id="summary"&gt;Summary&lt;a class="headerlink" href="#summary" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;In my
&lt;a href="https://jackdewinter.github.io/2020/09/07/markdown-linter-starting-to-add-linecolumn-numbers-for-inline-tokens/"&gt;last article&lt;/a&gt;,
I started to add the proper support for line and column numbers for both the text
tokens and the emphasis tokens.  In this article, I increase my confidence in the
line and column numbers for those two inline tokens by adding the consistency checks
for …&lt;/p&gt;</summary><content type="html">
&lt;h2 id="summary"&gt;Summary&lt;a class="headerlink" href="#summary" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;In my
&lt;a href="https://jackdewinter.github.io/2020/09/07/markdown-linter-starting-to-add-linecolumn-numbers-for-inline-tokens/"&gt;last article&lt;/a&gt;,
I started to add the proper support for line and column numbers for both the text
tokens and the emphasis tokens.  In this article, I increase my confidence in the
line and column numbers for those two inline tokens by adding the consistency checks
for those tokens.&lt;/p&gt;
&lt;h2 id="introduction"&gt;Introduction&lt;a class="headerlink" href="#introduction" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;I know that I am fallible.  It therefore stands to
reason that any code that I write will have some issues with it.  Those issues may be
obvious issues, or they may be issues that only occur under a bizarre set of
circumstances, but they are there.   Rather than fight against them, I embrace
the attitude that good test automation will help me to identify those types of issues
as early as possible.&lt;/p&gt;
&lt;p&gt;For the PyMarkdown project, this test automation takes the form of scenario tests
containing consistency checks.  These consistency checks validate that the Markdown
documents in the scenario tests are properly interpreted by the PyMarkdown project.
But while these consistency checks are beneficial, the consistency checks have
taken a long while to complete.  After 3 calendar months have passed, it can easily be
said that my decision
to add consistency checks to the project removed 3 months of project development time
and replaced it with 3 months of project test time.  Plain and simple, those statements
are facts.&lt;/p&gt;
&lt;p&gt;My confidence about the project and its ability to work correctly is an emotional and
abstract statement.  However, with effort, I have been able to move it in the direction
of being more of a fact than a feeling.  The consistency checks are a form
of test automation that apply a generalized set of rules over a group of tokens,
looking for each group to behave in a predictable manner.  Before this work,
my confidence was expressed as a feeling: “I believe the project is stable”.  With
this work nearing its completion, I can now point to the scenario tests and consistency
checks that run within those scenario tests.  I can state that each of the scenario
tests is passing a rigorous set of criteria before it is marked as passing.  That
confidence can now be expressed as: “Here are the tests that are passing and the
checks that are being performed on each test.”&lt;/p&gt;
&lt;p&gt;From that point of view, it made sense that before I start working on setting the
line/column numbers for the remaining inline tokens that I would implement the
consistency checks for the Text token and the Emphasis tokens.&lt;/p&gt;
&lt;h2 id="what-is-the-audience-for-this-article"&gt;What Is the Audience for This Article?&lt;a class="headerlink" href="#what-is-the-audience-for-this-article" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;While detailed more eloquently in
&lt;a href="https://jackdewinter.github.io/2020/04/05/what-is-the-audience-for-my-blog/#what-is-the-audience-for-my-blog"&gt;this article&lt;/a&gt;,
my goal for this technical article is to focus on the reasoning behind my solutions,
rather that the solutions themselves.  For a full record of the solutions presented in
this article, please go to this project’s GitHub repository and consult the
commit of
&lt;a href="https://github.com/jackdewinter/pymarkdown/commit/c6cc992fa4c5c7c25f2a93038010dfab84a22da8"&gt;02 Sep 2020&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id="getting-started-with-inline-token-validation"&gt;Getting Started With Inline Token Validation&lt;a class="headerlink" href="#getting-started-with-inline-token-validation" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;At the start of the week, the code used to verify the consistency of inline tokens was
extremely simple:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;    &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"&amp;gt;&amp;gt;last_token:"&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;ParserHelper&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;make_value_visible&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;last_token&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="n"&gt;next_token_index&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;last_token_index&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
    &lt;span class="k"&gt;while&lt;/span&gt; &lt;span class="n"&gt;actual_tokens&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;next_token_index&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;!=&lt;/span&gt; &lt;span class="n"&gt;current_token&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
            &lt;span class="s2"&gt;"-token:"&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;ParserHelper&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;make_value_visible&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;actual_tokens&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;next_token_index&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
        &lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;next_token_index&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Added in as a placeholder to allow me to see what was going on with the inline tokens,
it served its purpose well.  But as I started to work on the inline tokens
and their line/column numbers, I needed to facilitate better consistency checking of
those inline tokens.&lt;/p&gt;
&lt;p&gt;To start the work off, I removed that placeholder code from two places in the code
and replaced both with a call to a new function &lt;code&gt;verify_inline&lt;/code&gt;.  The only
difference between the two
invocations of the function were the fourth argument, &lt;code&gt;current_token&lt;/code&gt;.  Called for
the first time from the_&lt;code&gt;__verify_token_height&lt;/code&gt; function, the &lt;code&gt;current_token&lt;/code&gt; variable
is set to the block token after a series of inline tokens.  The second time it is
called, it is called at the end of processing to capture any inline tokens that are
within one of the valid text elements, but at the very end of the document.  When it
is invoked from that location, that same argument is set to &lt;code&gt;None&lt;/code&gt;.  In both cases,
the inline tokens to be validated were clearly outlined for the &lt;code&gt;verify_inline&lt;/code&gt;
function.&lt;/p&gt;
&lt;h3 id="clearly-defining-the-problem"&gt;Clearly Defining the Problem&lt;a class="headerlink" href="#clearly-defining-the-problem" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Before doing any real processing with the inline tokens, I needed to create a simple
list containing the actual inline tokens that I wanted to check.  I could have done that
with the main list of tokens and the previously document outlining.  However, I thought
about it and decided that it was clearer to have a separate list that just
contained the tokens that I was concerned about.  Once I had all the inline tokens
between the two block tokens in that new list, there was a small amount of work to do
before the list was usable.  While it was not difficult, the new list had some extra
end tokens at the end of the list that needed to be removed.  Working around
those extra end tokens would have been okay, but I just felt that it was simpler to
remove them from the list before I did any further processing.&lt;/p&gt;
&lt;p&gt;Having a simple list of the inline tokens to work with, the first iteration of the
checking algorithm started with an easy outline to follow:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;inline_tokens&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;token_index&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;current_inline_token&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;enumerate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;inline_tokens&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
            &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="n"&gt;token_index&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="n"&gt;__verify_first_inline&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;last_token&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;inline_tokens&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
            &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="n"&gt;__verify_next_inline&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
                    &lt;span class="n"&gt;last_token&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                    &lt;span class="n"&gt;inline_tokens&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;token_index&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
                    &lt;span class="n"&gt;current_inline_token&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                &lt;span class="p"&gt;)&lt;/span&gt;

        &lt;span class="c1"&gt;# verify_last_inline(inline_tokens[-1], current_inline_token)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;From my viewpoint, the processing of the inline tokens had 3 distinct phases: the first
element in that list, each element after it, and the last element in that list.  Based
on their locations, the first and last elements are special in that they anchor the
other inline tokens to the block tokens on either side of the middle elements.  Without
those anchors, the middle elements lack a foundation with which they can based their
positions on.&lt;/p&gt;
&lt;p&gt;Based on those observations, I chose to implement the check for the first inline token
against the previous block token, and not the check for the last inline token against
the following block token.  Without validating the first element, validating any of the
elements on the inside of the list would be useless.  So, whether I liked the idea or
not, validation of the first element in the list was mandatory.  The last element
is a different story.  While it would be nice to tie the last inline token to the
following block token, I felt that it was not as important as the verification of the
first element.  However, I added in a placeholder to the code to make sure that I
would follow up on it later.&lt;/p&gt;
&lt;h3 id="validating-the-first-element"&gt;Validating the First Element&lt;a class="headerlink" href="#validating-the-first-element" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Following the pattern that I have used for validation in the past, I created the
&lt;code&gt;__verify_first_inline&lt;/code&gt; function with my standard starting template:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;__verify_first_inline&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;last_non_inline_token&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;first_inline_token&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;something&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;pass&lt;/span&gt;
    &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;assert&lt;/span&gt; &lt;span class="bp"&gt;False&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;last_non_inline_token&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;token_name&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;As this function is comparing the starting position of the first inline token to the
last valid block token, the &lt;code&gt;&amp;lt;something&amp;gt;&lt;/code&gt; in the above code sample was quickly replaced
with:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;last_non_inline_token&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;token_name&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;MarkdownToken&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;token_atx_heading&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;assert&lt;/span&gt; &lt;span class="bp"&gt;False&lt;/span&gt;
    &lt;span class="k"&gt;elif&lt;/span&gt; &lt;span class="n"&gt;last_non_inline_token&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;token_name&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;MarkdownToken&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;token_setext_heading&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;assert&lt;/span&gt; &lt;span class="bp"&gt;False&lt;/span&gt;
    &lt;span class="k"&gt;elif&lt;/span&gt; &lt;span class="n"&gt;last_non_inline_token&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;token_name&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;MarkdownToken&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;token_paragraph&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;assert&lt;/span&gt; &lt;span class="bp"&gt;False&lt;/span&gt;
    &lt;span class="k"&gt;elif&lt;/span&gt; &lt;span class="n"&gt;last_non_inline_token&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;token_name&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;MarkdownToken&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;token_fenced_code_block&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;assert&lt;/span&gt; &lt;span class="bp"&gt;False&lt;/span&gt;
    &lt;span class="k"&gt;elif&lt;/span&gt; &lt;span class="n"&gt;last_non_inline_token&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;token_name&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;MarkdownToken&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;token_indented_code_block&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;assert&lt;/span&gt; &lt;span class="bp"&gt;False&lt;/span&gt;
    &lt;span class="k"&gt;elif&lt;/span&gt; &lt;span class="n"&gt;last_non_inline_token&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;token_name&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;MarkdownToken&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;token_html_block&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;assert&lt;/span&gt; &lt;span class="bp"&gt;False&lt;/span&gt;
    &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;assert&lt;/span&gt; &lt;span class="bp"&gt;False&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;last_non_inline_token&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;token_name&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;and one by one I added the validation functions to replace the &lt;code&gt;assert False&lt;/code&gt;
statements.  Following that same pattern for
resolving these as I have before, I ran the scenario tests over the entire project
using the command line:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;pipenv run pytest -m gfm
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Each time, I just picked one of the failing tests, and worked on that tests in that
group until they were all passing.  For each validation function, I repeated the same
pattern with the first inline
token that was observed.  For example, the &lt;code&gt;__verify_first_inline_atx&lt;/code&gt; function quickly
evolved to look like:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;__verify_first_inline_atx&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;last_non_inline_token&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;first_inline_token&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="sd"&gt;"""&lt;/span&gt;
&lt;span class="sd"&gt;    Handle the case where the last non-inline token is an Atx Heading token.&lt;/span&gt;
&lt;span class="sd"&gt;    """&lt;/span&gt;

    &lt;span class="n"&gt;col_pos&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;last_non_inline_token&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;column_number&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;last_non_inline_token&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;hash_count&lt;/span&gt;

    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;first_inline_token&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;token_name&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;MarkdownToken&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;token_text&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;replaced_extracted_whitespace&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;ParserHelper&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;resolve_replacement_markers_from_text&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
            &lt;span class="n"&gt;first_inline_token&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;extracted_whitespace&lt;/span&gt;
        &lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;col_pos&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;replaced_extracted_whitespace&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;assert&lt;/span&gt; &lt;span class="n"&gt;first_inline_token&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;line_number&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;last_non_inline_token&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;line_number&lt;/span&gt;
        &lt;span class="k"&gt;assert&lt;/span&gt; &lt;span class="n"&gt;first_inline_token&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;column_number&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;col_pos&lt;/span&gt;
    &lt;span class="k"&gt;elif&lt;/span&gt; &lt;span class="n"&gt;first_inline_token&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;token_name&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;MarkdownToken&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;token_inline_hard_break&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;assert&lt;/span&gt; &lt;span class="bp"&gt;False&lt;/span&gt;
        &lt;span class="o"&gt;...&lt;/span&gt;

    &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;assert&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;
            &lt;span class="n"&gt;first_inline_token&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;token_name&lt;/span&gt; &lt;span class="o"&gt;!=&lt;/span&gt; &lt;span class="n"&gt;MarkdownToken&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;token_inline_link&lt;/span&gt;
            &lt;span class="ow"&gt;and&lt;/span&gt; &lt;span class="n"&gt;first_inline_token&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;token_name&lt;/span&gt;
            &lt;span class="o"&gt;!=&lt;/span&gt; &lt;span class="n"&gt;EndMarkdownToken&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;type_name_prefix&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;MarkdownToken&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;token_inline_link&lt;/span&gt;
        &lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;first_inline_token&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;token_name&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h3 id="what-did-i-discover"&gt;What Did I Discover?&lt;a class="headerlink" href="#what-did-i-discover" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Predictably, I discovered that there are 2 groups of text within block tokens: ones
that support
inline tokens other than the Text token, and ones that do not.  The ones that do not
support inline tokens are
mostly easy: assert that the inline token is a Text token, and then assert on a simple
calculation of the first line/column number.  The validation of the HTML Block token and
the Indented Code Block token both followed this pattern, with very simple validation.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;__verify_first_inline_html_block&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;last_non_inline_token&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;first_inline_token&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;assert&lt;/span&gt; &lt;span class="n"&gt;first_inline_token&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;token_name&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;MarkdownToken&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;token_text&lt;/span&gt;
    &lt;span class="n"&gt;leading_whitespace_count&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;first_inline_token&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;extracted_whitespace&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;assert&lt;/span&gt; &lt;span class="n"&gt;last_non_inline_token&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;line_number&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;first_inline_token&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;line_number&lt;/span&gt;
    &lt;span class="k"&gt;assert&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="n"&gt;last_non_inline_token&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;column_number&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;leading_whitespace_count&lt;/span&gt;
        &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;first_inline_token&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;column_number&lt;/span&gt;
    &lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The Fenced Code Block tokens required a bit more effort, but not much. As the Fenced
Code Blocks can start with 0-3 space characters that then need to be managed on any
subsequent line in the code block, the owning block token’s &lt;code&gt;leading_spaces&lt;/code&gt; variable
holds the information on what leading spaces were already removed.  As such, when
calculating the proper position of the first Text token inside of a Fenced Code Block,
that removed space needs to be accounted for.  To properly facilitate that, the
&lt;code&gt;last_token_stack&lt;/code&gt; argument needed to be plumbed through so the verification function
could calculate the proper owning blocking token.&lt;/p&gt;
&lt;p&gt;The second group of block tokens were the more interesting group of tokens to deal with.
This group of tokens includes the Atx Heading tokens (as shown in the above example),
SetExt Heading tokens, and Paragraph tokens.  The &lt;code&gt;__verify_first_inline_atx&lt;/code&gt; function
and the &lt;code&gt;__verify_first_inline_setext&lt;/code&gt; function ended up looking similar: the Text
inline token case was populated, but all the other types of inline tokens were handled
with &lt;code&gt;assert False&lt;/code&gt; statements.  The &lt;code&gt;__verify_first_inline_paragraph&lt;/code&gt; function was
similar, but also slightly different.  The same template was used to generate the
function, but each of the conditions in the &lt;code&gt;if-elif-else&lt;/code&gt; block were met at least once.
However, since only the Text token and the Emphasis token have line/column numbers,
allowing this comparison to be performed for them:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;        &lt;span class="k"&gt;assert&lt;/span&gt; &lt;span class="n"&gt;first_inline_token&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;line_number&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;last_non_inline_token&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;line_number&lt;/span&gt;
        &lt;span class="k"&gt;assert&lt;/span&gt; &lt;span class="n"&gt;first_inline_token&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;column_number&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;last_non_inline_token&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;column_number&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;All the other inline tokens, the ones that did not currently have a line/column assigned
to them (yet), used the following comparison:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;        &lt;span class="k"&gt;assert&lt;/span&gt; &lt;span class="n"&gt;first_inline_token&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;line_number&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;
        &lt;span class="k"&gt;assert&lt;/span&gt; &lt;span class="n"&gt;first_inline_token&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;column_number&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;It was not much, but it gave me two important bits of information.  The first was that
there was at least one case where each available inline token was the first inline
token inside of a Paragraph token.  The second was that both heading tokens, the Atx
Heading token and the SetExt Heading token, only contained scenario tests that started
with Text tokens.  I made a note of that observation in the issue’s list and moved on.&lt;/p&gt;
&lt;h2 id="verifying-the-middle-tokens"&gt;Verifying the Middle Tokens&lt;a class="headerlink" href="#verifying-the-middle-tokens" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;With the validation of the first element out of the way, it was time to start working
on the &lt;code&gt;__verify_next_inline&lt;/code&gt; function.  Now that the middle tokens were anchored at
the beginning, each of the middle inline tokens could be validated against the inline
token that preceded it.  Since I knew that most of the inline tokens had not
been handled yet, I started out that function with a slight change to the template:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;__verify_next_inline&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="n"&gt;last_token&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;pre_previous_inline_token&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;previous_inline_token&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;current_inline_token&lt;/span&gt;
&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="n"&gt;previous_inline_token&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;line_number&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;
        &lt;span class="ow"&gt;and&lt;/span&gt; &lt;span class="n"&gt;previous_inline_token&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;column_number&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;
    &lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="n"&gt;current_inline_token&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;line_number&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;
        &lt;span class="ow"&gt;and&lt;/span&gt; &lt;span class="n"&gt;current_inline_token&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;column_number&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;
    &lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt;

    &lt;span class="n"&gt;estimated_line_number&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;previous_inline_token&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;line_number&lt;/span&gt;
    &lt;span class="n"&gt;estiated_column_number&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;previous_inline_token&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;column_number&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;previous_inline_token&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;token_name&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;MarkdownToken&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;token_text&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;assert&lt;/span&gt; &lt;span class="bp"&gt;False&lt;/span&gt;
    &lt;span class="o"&gt;...&lt;/span&gt;
    &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;assert&lt;/span&gt; &lt;span class="bp"&gt;False&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;previous_inline_token&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;token_name&lt;/span&gt;

    &lt;span class="k"&gt;assert&lt;/span&gt; &lt;span class="n"&gt;estimated_line_number&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;current_inline_token&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;line_number&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="s2"&gt;"&amp;gt;&amp;gt;est&amp;gt;"&lt;/span&gt;
        &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;estimated_line_number&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="s2"&gt;"&amp;gt;act&amp;gt;"&lt;/span&gt;
        &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;current_inline_token&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;line_number&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;assert&lt;/span&gt; &lt;span class="n"&gt;estiated_column_number&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;current_inline_token&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;column_number&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="s2"&gt;"&amp;gt;&amp;gt;est&amp;gt;"&lt;/span&gt;
        &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;estiated_column_number&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="s2"&gt;"&amp;gt;act&amp;gt;"&lt;/span&gt;
        &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;current_inline_token&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;column_number&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The first set of &lt;code&gt;if&lt;/code&gt; statements made sure that if either the previous inline token or
the current inline token
was one that I had not worked on yet, it would return right away.  While this assumed
that the line/column numbers were correct to a certain extent, I was okay with that
assumption in the short term.  The second part computed a starting point for the new
line/column numbers, and then went into the usual pattern of dealing with
each of the eligible tokens by name.  Finally, the third part compared the modified
line/column numbers against the actual line/column numbers of the current token,
asserting with meaningful information if there were any issues.&lt;/p&gt;
&lt;h3 id="emphasis-tokens"&gt;Emphasis Tokens&lt;a class="headerlink" href="#emphasis-tokens" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;I thought it would be quick to get emphasis out of the way, and it was!  As both the
start and end Emphasis tokens contain the &lt;code&gt;emphasis_length&lt;/code&gt;, it was a quick matter of
adjusting the column number by that amount.  As both tokens are confined to
a single line, there was no adjusting of the line number to worry about.&lt;/p&gt;
&lt;h3 id="text-tokens"&gt;Text Tokens&lt;a class="headerlink" href="#text-tokens" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;As mentioned in a previous section, there are two major groups of block tokens
that contain Text tokens: ones that allow all inline tokens and ones that do not allow
inline tokens except for the Text token.  The ones that do not allow inline tokens are
simple, as all the
information about the Text token is contained within the token itself.  It is the
other group that are interesting to deal with.&lt;/p&gt;
&lt;p&gt;The easy part of dealing with the Text token is determining the new line number.
With the exception of a Text token that occurs right after a Hard Line Break token,
the calculation is simple:  split the text by the newline character, subtract 1,
and that is the number of newlines in the Text token.  If the token before the Text
token was a Hard Line Break token, it already increased the line number, but the
Text token that followed also started with a newline character.  To remedy this,
that pattern is looked for, and the &lt;code&gt;current_line&lt;/code&gt; variable adjusted to remove the
newline character at the start of the line.&lt;sup id="fnref:noted"&gt;&lt;a class="footnote-ref" href="#fn:noted"&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;p&gt;Determining the column number is a more interesting task to undertake.  For any
Text tokens occurring within a block that does not allow for extra inline tokens,
the column number information is already in the token itself, and the calculation
is as simple.  The column delta is equal to the number of text characters stored
within the token&lt;sup id="fnref:processing"&gt;&lt;a class="footnote-ref" href="#fn:processing"&gt;2&lt;/a&gt;&lt;/sup&gt;.  If there was a newline in the token’s text, this
count is started after the last newline character.&lt;/p&gt;
&lt;p&gt;The second group of block tokens that can contain text are the Atx Heading token, the
SetExt Heading token, and the Paragraph token.  Since the Atx Heading token can only
contain a single line’s worth of data, no extra calculations are required to handle
multiple line scenarios.  In the case of the other Heading token, the SetExt Heading
token, the starting whitespace is stored in the Text token’s &lt;code&gt;end_whitespace&lt;/code&gt; field.
The processing of this information is a bit tricky in that the starting and ending
whitespace for the Text tokens within the SetExt Heading token is stored in that
field using the &lt;code&gt;\x02&lt;/code&gt; character as a separator.  Still, determining the proper
indent and applying it to the column number is relatively simple.&lt;/p&gt;
&lt;p&gt;Dealing with a Text token within a Paragraph token is a lot more work.  Due to other
design reasons, the whitespace indent for these Text tokens is stored within the
owning Paragraph token.  While that is not difficult by itself, keeping track of which
indent goes with which line is a bit of a chore.  Luckily, when I was working on the
Markdown transformer, I introduced a variable &lt;code&gt;rehydrate_index&lt;/code&gt; to the Text token.
When rehydrating the Text token, I used this variable to keep track of which stripped
indent needed to be added back to which line of any subsequent Text tokens. Given
the prefix whitespace for any line within the Paragraph block, calculating the
column number delta was easy.&lt;/p&gt;
&lt;h3 id="blank-line-tokens"&gt;Blank Line Tokens&lt;a class="headerlink" href="#blank-line-tokens" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;That left the Blank Line tokens to deal with, and I hoped that the effort needed to
complete them was more in line with the Emphasis tokens than the Text tokens.  I was
lucky, and the Blank Line tokens were easy, but with a couple of small twists.
Intrinsically, a blank line
increases the line number and resets the column number to 1.  That was the easy part.
The first twist is that if the current token is a Text token, that text token can
provide leading whitespace that needs to be considered.  That was easily dealt
with by adding the following lines to the handler:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;current_inline_token&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;token_name&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;MarkdownToken&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;token_text&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;estiated_column_number&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;current_inline_token&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;extracted_whitespace&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The more difficult problem occurred when 2 blank line tokens appear one after the
other within a Fenced Code Block token.  Because of how the numbers added up, I needed
to adjust the &lt;code&gt;estimated_line_number&lt;/code&gt; variable by one.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;current_inline_token&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;token_name&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;MarkdownToken&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;token_blank_line&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;previous_inline_token&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;token_name&lt;/span&gt; &lt;span class="o"&gt;!=&lt;/span&gt; &lt;span class="n"&gt;MarkdownToken&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;token_blank_line&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;estimated_line_number&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
        &lt;span class="n"&gt;estiated_column_number&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;With that tweak being done, all the tests were then passing, and it was time to
wrap it up.&lt;/p&gt;
&lt;h2 id="was-it-worth-it"&gt;Was It Worth It?&lt;a class="headerlink" href="#was-it-worth-it" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;The interesting part about defensive code is that sometimes you are not aware of how
good that defense is.  Using the analogy of a castle, is a castle better defensible if
it can withstand attack or if it deters others from attacking the castle?  While I
did not have any information about potential attacks that were stopped ahead of time,
there were 2 actual issues that the current round of consistency checks did find.&lt;/p&gt;
&lt;h3 id="issue-1-image-link"&gt;Issue #1: Image Link&lt;a class="headerlink" href="#issue-1-image-link" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;The first of those issues was an issue with the column number for
&lt;a href="https://github.github.com/gfm/#example-600"&gt;example 600&lt;/a&gt;
as follows:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;!\&lt;/span&gt;&lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="n"&gt;foo&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="n"&gt;foo&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;&lt;span class="err"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;url&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="ss"&gt;"title"&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Before these inline consistency checks were added, the text for the &lt;code&gt;]&lt;/code&gt;
character was reported as &lt;code&gt;(1,6)&lt;/code&gt;.  By simply counting the characters, the &lt;code&gt;!&lt;/code&gt;
character starts at position 1 and the second &lt;code&gt;o&lt;/code&gt; character is at position 6.  As
such, the &lt;code&gt;]&lt;/code&gt; character should be reported as &lt;code&gt;(1,7)&lt;/code&gt;.  &lt;/p&gt;
&lt;p&gt;Doing some research, I concluded that the handling of a properly initiated Image
token was being handled properly.  However, with a failed Image token sequence,
the &lt;code&gt;!&lt;/code&gt; character followed by any other character than the &lt;code&gt;[&lt;/code&gt; character, the
&lt;code&gt;!&lt;/code&gt; character was being emitted, but the column number’s delta wasn’t being set.
Adding the line&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;    &lt;span class="n"&gt;inline_response&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;delta_column_number&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;at the end of the &lt;code&gt;__handle_inline_image_link_start_character&lt;/code&gt; function solved that
issue.&lt;/p&gt;
&lt;h3 id="issue-2-a-simple-adjustment"&gt;Issue 2: A Simple Adjustment&lt;a class="headerlink" href="#issue-2-a-simple-adjustment" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;The second of those issues was more of a nitpick that an actual issue.  In the
tokenization for
&lt;a href="https://github.github.com/gfm/#example-183"&gt;example 183&lt;/a&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;#&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="n"&gt;Foo&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="n"&gt;foo&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;&lt;span class="err"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;url&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;bar&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;the first line was tokenized as:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;        "[atx(1,1):1:0:]",
        "[text(1,3):\a \a\x03\a:]",
        "[link:shortcut:/url:::::Foo:::::]",
        "[text(1,4):Foo: ]",
        "[end-link:::False]",
        "[end-atx:::False]",
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Having a lot of experience sight reading serializations for all the tokens, the
information in the Text token leapt out at me right away.  In that token, the extra
data associated with the token is composed by adding the &lt;code&gt;self.token_text&lt;/code&gt; field,
the &lt;code&gt;:&lt;/code&gt; character, and the &lt;code&gt;self.extracted_whitespace&lt;/code&gt;.  Based on the above
tokenization, that meant that the text sequence &lt;code&gt;\a \a\x03\a&lt;/code&gt; was being considered
as text instead of whitespace.&lt;/p&gt;
&lt;p&gt;To understand why I thought this is wrong requires an understanding of the
existence of that character sequence.  The &lt;code&gt;\a&lt;/code&gt; sequence is used to denote that
a sequence of characters in the original Markdown document was interpreted and
replaced with another sequence of characters.  The &lt;code&gt;\x03&lt;/code&gt; character within the
second half of that sequence means that the &lt;code&gt;{space}&lt;/code&gt; character in the first part
of the sequence is being replaced with the empty string.  Basically, to properly
represent the space between the &lt;code&gt;#&lt;/code&gt; character denoting the Atx Heading element
and the &lt;code&gt;[&lt;/code&gt; that starts the Link element, I needed to add a space character that
would not appear in any HTML transformation.&lt;/p&gt;
&lt;p&gt;And here is where the nitpicking comes in.  When I originally added that sequence
when working on the Markdown transformer, it made sense to me to assign it to
the token’s &lt;code&gt;self.text_token&lt;/code&gt; field.  But since then, I have grown to think of
that sequence as being more extracted whitespace than token text.  To resolve
that, I decided to move the call to generate the replacement text from the
&lt;code&gt;self.token_text&lt;/code&gt; field to the &lt;code&gt;self.extracted_whitespace&lt;/code&gt; field.  It wasn’t
a big move, but it was something that I thought was the right thing to do.&lt;/p&gt;
&lt;h2 id="what-was-my-experience-so-far"&gt;What Was My Experience So Far?&lt;a class="headerlink" href="#what-was-my-experience-so-far" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;While this batch of work wasn’t as laborious as last week’s work, the effort required
to make sure it was correct was equal to or exceeding last week’s work.  I knew that
if I made any mistakes last week, they would be caught when I implemented the
consistency checks.  Well, these were the consistency checks that would capture
any such issues that slipped through.&lt;/p&gt;
&lt;p&gt;I am both happy and proud that I am coming to the end of implementing the consistency
checks.  It has been a long 3 month voyage since I decided that consistency checks
were the best way to ensure that the quality that I wanted in the PyMarkdown project
was maintained.  And while there were times that I questioned if I made the right
decision in dedicating this large block of time to this aspect of the project, I was
confident that I had made the right decision.&lt;/p&gt;
&lt;p&gt;But looking ahead to what I needed to do after the consistency checks, I saw a
fair number of items in the issues list that would need researching and possibly
fixing.  While I could start to release the project without them, I didn’t feel
comfortable doing that.  I wanted to give the project the best chance it could to
make a first impression, and then move from there.  And that would mean more work
up front.  So while I was happy that the consistency check work was coming to an
end, there seemed to be a deep pool of issues that would need to be research… and
I wasn’t sure how much I was looking forward to that.&lt;/p&gt;
&lt;p&gt;I still believe that adding the consistency checks was the right move.  Of that
I am still certain.  Instead of a feeling that I have the right code in place to
do the Markdown transformations, I have hard, solid checks that verify the results
of each and every scenario test.  It also gave me the interesting bit of information
that the scenario tests did not include any cases where the Atx Heading token and the
SetExt Heading token were followed by anything other than a Text token.  Something
interesting to follow up on later.&lt;/p&gt;
&lt;p&gt;To me, adding more of those checks for the inline
tokens was just another solid step forward in quality.&lt;/p&gt;
&lt;h2 id="what-is-next"&gt;What is Next?&lt;a class="headerlink" href="#what-is-next" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Having completed the hardest inline token (Text token) and the easiest inline tokens
(Emphasis tokens), it was time to buckle down and get the remaining tokens done.  If
I was lucky, the foundational work that I had already completed would make completing
those tokens easy.  If I was unlucky, there would be a whole selection of edge cases
that I needed to account for.  Realistically, I was expecting something square in the
middle between those two scenarios.  The next batch worth of work would answer that
question!&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr/&gt;
&lt;ol&gt;
&lt;li id="fn:noted"&gt;
&lt;p&gt;This has been noted in the issue’s list, and I am hoping to look at it soon. &lt;a class="footnote-backref" href="#fnref:noted" title="Jump back to footnote 1 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:processing"&gt;
&lt;p&gt;That is, after removing any special characters and leaving the original text used to create those special characters. &lt;a class="footnote-backref" href="#fnref:processing" title="Jump back to footnote 2 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</content><category term="Software Quality"></category><category term="markdown linter"></category><category term="core linter"></category></entry><entry><title>Markdown Linter - Starting to Add Line/Column Numbers For Inline Tokens</title><link href="https://jackdewinter.github.io/2020/09/07/markdown-linter-starting-to-add-linecolumn-numbers-for-inline-tokens/" rel="alternate"></link><published>2020-09-07T00:00:00-07:00</published><updated>2020-09-07T00:00:00-07:00</updated><author><name>Jack De Winter</name></author><id>tag:jackdewinter.github.io,2020-09-07:/2020/09/07/markdown-linter-starting-to-add-linecolumn-numbers-for-inline-tokens/</id><summary type="html">
&lt;h2 id="summary"&gt;Summary&lt;a class="headerlink" href="#summary" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;In my
&lt;a href="https://jackdewinter.github.io/2020/08/31/markdown-linter-adding-consistency-to-token-heights/"&gt;last article&lt;/a&gt;,
I took care of completing the consistency checks by verifying the height of all block
tokens.  In this article, with all the block tokens now properly covered, I
start to add proper support for line and column numbers for the text inline tokens
and the …&lt;/p&gt;</summary><content type="html">
&lt;h2 id="summary"&gt;Summary&lt;a class="headerlink" href="#summary" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;In my
&lt;a href="https://jackdewinter.github.io/2020/08/31/markdown-linter-adding-consistency-to-token-heights/"&gt;last article&lt;/a&gt;,
I took care of completing the consistency checks by verifying the height of all block
tokens.  In this article, with all the block tokens now properly covered, I
start to add proper support for line and column numbers for the text inline tokens
and the emphasis inline tokens.&lt;/p&gt;
&lt;h2 id="introduction"&gt;Introduction&lt;a class="headerlink" href="#introduction" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;As I mentioned in the last article:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;To properly verify any of the inline tokens, the tokens around it needed to be verified to give that token a solid foundation. Without those other tokens as a foundation, any attempt at verifying inline tokens would be shaky at best.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;With that foundation now firmly in place, it was then time for me to start adding the
line/column numbers to the inline tokens.&lt;/p&gt;
&lt;p&gt;The scope of what I was about to start was not lost on me.  From the outset, I knew
that adding the line/column numbers to the Text tokens was going to be expensive.
Starting with the obvious, the Text tokens are the default “capture-all” for anything
Markdown that does not firmly fall under another token’s purview.  That alone meant
there were going to be a fair number of scenarios in which Text tokens were present.
Add to
that number the various forms of text that the token contains, and each form’s
way of dealing with the Text tokens within their bounds.  Also, as I wanted
to have a good gauge on how hard it was going to be to add the other inline tokens,
I added support for Emphasis tokens to the worklist.&lt;/p&gt;
&lt;p&gt;I was clear about the scope of this change with myself from the outset.  It was going to
be a long trek to complete all this work in one week.  I did contemplate updating the
consistency checks to accommodate the changes to the inline tokens, but discretion got
the better part of me.  This work was going to be tough enough on its own, no need to
add some extra tasks to the list.&lt;/p&gt;
&lt;h2 id="what-is-the-audience-for-this-article"&gt;What Is the Audience for This Article?&lt;a class="headerlink" href="#what-is-the-audience-for-this-article" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;While detailed more eloquently in
&lt;a href="https://jackdewinter.github.io/2020/04/05/what-is-the-audience-for-my-blog/#what-is-the-audience-for-my-blog"&gt;this article&lt;/a&gt;,
my goal for this technical article is to focus on the reasoning behind my solutions,
rather that the solutions themselves.  For a full record of the solutions presented in
this article, please go to this project’s GitHub repository and consult the
commit of
&lt;a href="https://github.com/jackdewinter/pymarkdown/commit/7eb893cf1b7c815666946661b790b956fa87278d"&gt;29 Aug 2020&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id="framing-a-big-problem-in-a-better-light"&gt;Framing a Big Problem in a Better Light&lt;a class="headerlink" href="#framing-a-big-problem-in-a-better-light" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Before starting with this monumental task, I wanted to take a step back and really
understand the task and its intricacies.  When I
started looking at the sheer depth of this task, I will admit I was a bit scared at
first.
The work this task requires is daunting.  Doing a simple search over the project’s
scenario tests, I found 1577 instances of a Text token in a scenario test and 161
instances of Emphasis Start tokens in a scenario test.  That meant between the Text
tokens and both Emphasis Start and Emphasis End tokens, I was looking at 1899 instances
that needed to be changed and manually verified.  That was indeed overwhelming.&lt;/p&gt;
&lt;p&gt;This is where my experience with test automation came in handy.  I took a breath and
started to look for
&lt;a href="https://en.wikipedia.org/wiki/Equivalence_partitioning"&gt;equivalence partitions&lt;/a&gt;
that I could use.  While the number of discrete instances of Text tokens and Emphasis
tokens were facts that
I could not change, I decided to apply equivalence partitioning and reduce the effective
number of instances down to a more manageable number.&lt;/p&gt;
&lt;h3 id="how-does-that-work"&gt;How Does That Work?&lt;a class="headerlink" href="#how-does-that-work" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Let me take a small sample function that is in the &lt;code&gt;ParserHelper&lt;/code&gt; class,
the &lt;code&gt;is_character_at_index&lt;/code&gt; function.  This function is as follows:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;    &lt;span class="nd"&gt;@staticmethod&lt;/span&gt;
    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;is_character_at_index&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;source_string&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;index_in_string&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;valid_character&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;
            &lt;span class="mi"&gt;0&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;=&lt;/span&gt; &lt;span class="n"&gt;index_in_string&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;source_string&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="ow"&gt;and&lt;/span&gt; &lt;span class="n"&gt;source_string&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;index_in_string&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;valid_character&lt;/span&gt;
        &lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The function is simple in that given a large variation on the parameters, it will
simply return a &lt;code&gt;True&lt;/code&gt; response or a &lt;code&gt;False&lt;/code&gt; response.&lt;sup id="fnref:mostlyTrue"&gt;&lt;a class="footnote-ref" href="#fn:mostlyTrue"&gt;1&lt;/a&gt;&lt;/sup&gt;  While the number of
variations are largely finite&lt;sup id="fnref:largeFinite"&gt;&lt;a class="footnote-ref" href="#fn:largeFinite"&gt;2&lt;/a&gt;&lt;/sup&gt;, they do fall into a number of
categories.  Starting with
the &lt;code&gt;index_in_string&lt;/code&gt; argument, those groups are: less than 0, equal to 0,
greater than 0
and less then &lt;code&gt;len(source_string)&lt;/code&gt;, equal to &lt;code&gt;len(source_string)&lt;/code&gt;, and greater than
&lt;code&gt;len(source_string)&lt;/code&gt;.  Of those groups, only if the &lt;code&gt;index_in_string&lt;/code&gt; argument is in
the &lt;code&gt;equal to 0&lt;/code&gt; group or the &lt;code&gt;greater than 0 and less then len(source_string)&lt;/code&gt; group do
I need to check to see if the character at the specified index is equivalent to the
argument &lt;code&gt;valid_character&lt;/code&gt;.  As the value to compare against is a single character, the
only two groups for that part of the comparison are that it matches that single
character or it does not.&lt;/p&gt;
&lt;p&gt;Based on this information, I can use those groups as equivalence partitions or
equivalence groups or  to partition the data to test into 7 distinct test groups.  The
first 3
equivalence groups are the ones that cause the first comparison to fail: &lt;code&gt;less than 0&lt;/code&gt;,
&lt;code&gt;equal to len(source_string)&lt;/code&gt;, and &lt;code&gt;greater than len(source_string)&lt;/code&gt;.  For this group,
the negative group, a simple test with one value in each group is required.  For the
other 2 tests, the positive group, in addition to the comparison to get it into one of
the 5 groups, one test is required where the index specifies the
a character matching the &lt;code&gt;valid_character&lt;/code&gt; argument, and one where it does not match.
In all, 3 tests in the first group, and 2 sets of 2 tests in the second group, for a
grand total of 7 tests.&lt;/p&gt;
&lt;p&gt;This works well because it reduces the scope of the testing to a manageable number.
Given the &lt;code&gt;less than 0&lt;/code&gt; group, it does not matter if the &lt;code&gt;index_in_string&lt;/code&gt; argument is
&lt;code&gt;-1&lt;/code&gt;, &lt;code&gt;-2&lt;/code&gt;, or any other negative number.  They all fit into that group and they all
evoke the same behavior: they cause the expression to be evaluated as &lt;code&gt;False&lt;/code&gt;.
By applying this process to many testing problems, it can quickly break down the
problem from an unmanageable number of possibilities down to a smaller number of more
easily handled cases.&lt;/p&gt;
&lt;h3 id="how-does-that-apply-to-this-work"&gt;How Does That Apply to This Work?&lt;a class="headerlink" href="#how-does-that-apply-to-this-work" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;No matter how it is viewed, having to change the serialization of 1577 instances of a
Text token is a big job.  That part of the work I cannot change.  However, I can make
the manual validation part of the changes more efficient by applying equivalence
classes to those changes.  While I was not sure at the onset what those classes were
going to be, I was confident that I could work out those groups would be one-by-one.&lt;/p&gt;
&lt;p&gt;But it was still a big task, just not as big.  Looking back at my notes, I have a
scribble that says:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;~40 variations for text, ~10 for emphasis&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;I believe that was a note to myself to boost my confidence by estimating how many
equivalence classes that I believed I would get the tests down to.  As I wrote this
article and looked at that scribble, for a second, I was back at the point in time when
I wrote that down.  Like an echo, I vaguely remembered the feeling of optimism that
washed over me when I wrote those numbers down.  While I am not 100% certain of what I
was thinking at the time, I am confident that it was something like:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;1600 validations is insane!  On the other hand, 40 is okay.  I can do 40.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;At that moment, it was not about whether those numbers were accurate, just that I had
confidence that those numbers were in the general vicinity.  While having to validate
each of
approximately 1600 variations of Text tokens filled me with dread, having to validate
approximately 40 variations of those same Text tokens and approximately 10 variations
of Emphasis tokens was something I had confidence that I could easily handle.&lt;/p&gt;
&lt;h2 id="updating-the-text-token"&gt;Updating the Text Token&lt;a class="headerlink" href="#updating-the-text-token" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Before I was ready to start with the Text tokens, I needed to get ready.
Not a lot of work, but some solid foundational stuff to make the rest of the
processing go easier.&lt;/p&gt;
&lt;h3 id="getting-ready"&gt;Getting Ready&lt;a class="headerlink" href="#getting-ready" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;My main drive for updating the Text token to support line/column numbers was never
about the small stuff.  It was that boring work, stuff was easy to do and quickly
finished, that I wanted to get out of the way.  Adding the ability
to pass in either a &lt;code&gt;position_marker&lt;/code&gt; argument or the &lt;code&gt;line_number&lt;/code&gt; and &lt;code&gt;column_number&lt;/code&gt;
arguments?  Done.  Making sure they got copied along with the other information when
the &lt;code&gt;create_copy&lt;/code&gt; function was called? Done.  Changing the &lt;code&gt;InlineRequest&lt;/code&gt; and
&lt;code&gt;InlineResponse&lt;/code&gt; classes to handle line numbers and column numbers?  Done.  If my
memory and notes are accurate, those changes were all completed in the first half-hour
that I used to work on these changes.&lt;/p&gt;
&lt;p&gt;Then,
to ensure things were setup to verify the consistency of the changes in
the future, I made some changes to the
&lt;code&gt;verify_line_and_column_numbers.py&lt;/code&gt; module. While I knew I was going to write the actual
validations in a separate task, I wanted to make sure that I had a good view of what
inline tokens were going to be handed off to the future consistency validators.
To accomplish this, I added two sets of print statements: one as part of the
&lt;code&gt;__verify_token_height&lt;/code&gt; function and one at the end of the
&lt;code&gt;verify_line_and_column_numbers&lt;/code&gt; function.  My plan here was to not only set myself
up for the inline consistency checks to come, but to be able to see what the group
of inline tokens to be processed was, to allow me to plan future sets of equivalence
classes.&lt;/p&gt;
&lt;p&gt;With that setup work done, it was on to the actual classes.&lt;/p&gt;
&lt;h3 id="starting-with-the-paragraph-tests"&gt;Starting with the Paragraph Tests&lt;a class="headerlink" href="#starting-with-the-paragraph-tests" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;With that foundational work completed, I decided to start with the tests in the
&lt;code&gt;test_markdown_paragraph_blocks.py&lt;/code&gt; module.  Since the Paragraph Block tokens are the
default containers for Text tokens, I figured that this was the best bet to get started
with some of the simple stuff.  That bet paid off with the first equivalence class,
a Text token following a Paragraph token.&lt;/p&gt;
&lt;p&gt;If I had to point out the simplest case of a Text element in a Markdown document, I
would definitely point to an example similar to
&lt;a href="https://github.github.com/gfm/#example-189"&gt;example 189&lt;/a&gt;.
Despite its high index number, to me this is the simplest example of all Markdown
documents:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;aaa&lt;/span&gt;

&lt;span class="n"&gt;bbb&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Simply speaking, it is two paragraphs separated by a single newline.  While it is true
that a single line of text would be simpler, to me, that is not a realistic example of
a Markdown document.  To me, a document means multiple paragraphs of text that
conveys some information.  From experience, it is very hard to convey anything except
the most basic forms of
information in a single paragraph.  Also, as a realistic example, example 189 shows how
you can separate two paragraphs in a Markdown document.  As such, I consider this the
root example.&lt;/p&gt;
&lt;p&gt;As this was the root example to me, it also contained the first and root equivalence
class: a Text token
contained as the first token after a Paragraph token.  While there are numerous
variations of this equivalence class, for me this is the base class itself.  And as I
looked through the code on how to isolate this equivalence class, I came to an
interesting observation. It should have been an obvious observation, but it took me a
bit to work through from “huh?” to obvious.  I forgot that equivalence classes deal with
input and output, but that source code rarely follows those same patterns.&lt;/p&gt;
&lt;h3 id="this-is-a-good-thing"&gt;This Is A Good Thing&lt;a class="headerlink" href="#this-is-a-good-thing" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;When I started to look for the source code behind my first equivalence class, I found
that it was hard to isolate the source code to just that equivalence class.  But as
I looked at the source code more, that made sense.  One reason that it made sense was
that if the cases were isolated based on equivalence class, it would mean that there
was a lot of duplicated code in the project.  Another reason was that such separation
would force distinct paths through the source code that would not be natural from any
other viewpoint than that of equivalence classes.&lt;/p&gt;
&lt;p&gt;The way the project was designed was to have an initial parsing phase to get all the raw
information together, then a coalesce phase to combine any text tokens where possible,
and finally an inline parse phase to handle the inline tokens.  Dragging any artificial
grouping of output across those phases seemed very counter-productive to me.  But
I still needed to figure things out.  It was time for a bit of a regroup.&lt;/p&gt;
&lt;h3 id="rethinking-my-approach"&gt;Rethinking My Approach&lt;a class="headerlink" href="#rethinking-my-approach" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;After performing a global search for &lt;code&gt;TextMarkdownToken(&lt;/code&gt; on the project, I was rewarded
with a small number of occurrences of a &lt;code&gt;TextMarkdownToken&lt;/code&gt; being created within the
project.  This was good because it meant the number of actual changes that I would
need to make was small, and hopefully each change would carry over multiple equivalence
classes.&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;__handle_fenced_code_block&lt;/code&gt; function and the &lt;code&gt;__handle_html_block&lt;/code&gt; function
(through the &lt;code&gt;check_normal_html_block_end&lt;/code&gt; function) were
both responsible for handling the additional Text tokens as part of container
processing, so they were the first to be changed.  In addition, the
&lt;code&gt;parse_indented_code_block&lt;/code&gt; function, the &lt;code&gt;parse_atx_headings&lt;/code&gt; function, and the
&lt;code&gt;parse_paragraph&lt;/code&gt; functions all included the creation of new instances of the
&lt;code&gt;TextMarkdownToken&lt;/code&gt;.  Making those changes took care of all cases where the
Parsing Processor created Text tokens.  From there, a quick check confirmed that the
Coalescing Processor only modified existing Text tokens and did not create any new
ones.&lt;/p&gt;
&lt;p&gt;After a bit of double checking to make sure I did not miss anything, I acknowledged
that the preparation work was done, and it was now onto inline processing.&lt;/p&gt;
&lt;h3 id="how-the-inline-processing-works"&gt;How The Inline Processing Works&lt;a class="headerlink" href="#how-the-inline-processing-works" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;When the Inline Processor starts, it loops through all the tokens, explicitly looking
for Text tokens, as they are the only tokens that can contain inline sequences.  Once
such a Text token is found, a further check is done to make sure that the Text token
is within a Paragraph element or a SetExt Heading element (the only two block elements
in which inline tokens are allowed) before proceeding with
the actual processing of the Text Token.&lt;/p&gt;
&lt;p&gt;For any readers that have not been following along on the project’s journey, let me
provide a bit of a recap on how that processing works.  Back in the article
&lt;a href="https://jackdewinter.github.io/2020/02/24/markdown-linter-starting-inline-processing/"&gt;on starting inline processing&lt;/a&gt;,
I go through the algorithm that I use in the inline processor:&lt;sup id="fnref:hidden"&gt;&lt;a class="footnote-ref" href="#fn:hidden"&gt;3&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;set the &lt;em&gt;start point&lt;/em&gt; to the beginning of the string&lt;/li&gt;
&lt;li&gt;look from the &lt;em&gt;start point&lt;/em&gt; for a new &lt;em&gt;interesting sequence&lt;/em&gt;&lt;ul&gt;
&lt;li&gt;if none is found&lt;ul&gt;
&lt;li&gt;emit the rest of the line from the &lt;em&gt;start point&lt;/em&gt; and exit&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;if one is found&lt;ul&gt;
&lt;li&gt;emit the text from the &lt;em&gt;start point&lt;/em&gt; to the start of the &lt;em&gt;interesting sequence&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;handle the current &lt;em&gt;interesting sequence&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;update the &lt;em&gt;start point&lt;/em&gt; to the end of the &lt;em&gt;interesting sequence&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;go back to the top&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;From the Text token perspective, the important parts of that algorithm are
the &lt;code&gt;emit the rest of the line&lt;/code&gt; part and the &lt;code&gt;emit the text from...&lt;/code&gt; part.  When most
of the other parts
of the algorithm emit their own token&lt;sup id="fnref:twoExceptions"&gt;&lt;a class="footnote-ref" href="#fn:twoExceptions"&gt;4&lt;/a&gt;&lt;/sup&gt;, a check it made to see what
text has been “emitted” before that point.  Then a new Text token is created with
that emitted text, followed by the newly created token that represents the &lt;em&gt;interesting
sequence&lt;/em&gt;, followed by the algorithm looks for the next &lt;em&gt;interesting sequence&lt;/em&gt; to deal
with.&lt;/p&gt;
&lt;p&gt;In the end, there were only 4 places where I had to change the creation of the
Text tokens to provide the line/column number information.  In all, there were only
9 places in the project where I had to change the creation of the Text token.
Far from being lulled into thinking the hard work was done, I figured it would be
in the updating of the scenario tests that things would get interesting.  And I was
not disappointed!&lt;/p&gt;
&lt;h3 id="scenarios"&gt;Scenarios&lt;a class="headerlink" href="#scenarios" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;With the code changes made to the Inline Processor, it was time to focus on the
scenario tests and getting their data changed and manually validated.  Using the
command line:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;pipenv run pytest -k test_paragraph_blocks
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;I executed each of the paragraph specific scenario tests, looking for the expected
failures in each test that contains a Text token.  Except for three tests,
each of these tests were simple cases of the base equivalence class, which meant that
they were quickly updated and verified.  Of those three tests, two new equivalence
classes emerged: the first Text token within an Indented Code Block token, and a Text
token following a Hard Break token.&lt;/p&gt;
&lt;p&gt;The scenario test for
&lt;a href="https://github.github.com/gfm/#example-195"&gt;example 195&lt;/a&gt;
is as follows:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;    &lt;span class="n"&gt;aaa&lt;/span&gt;
&lt;span class="n"&gt;bbb&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;which was properly parsed into new equivalence class of an Indented Code Block token
containing a single Text token and a normal Paragraph token containing a single Text
token.  As code blocks
do not contain any inline processing and no extra inline processing was specified, this
was an easy validation of that new equivalence class.  Quick, easy, done.&lt;/p&gt;
&lt;p&gt;The other failing scenario test, the test for
&lt;a href="https://github.github.com/gfm/#example-196"&gt;example 196&lt;/a&gt;
is as follows:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;aaa&lt;/span&gt;&lt;span class="err"&gt;{&lt;/span&gt;&lt;span class="k"&gt;space&lt;/span&gt;&lt;span class="err"&gt;}{&lt;/span&gt;&lt;span class="k"&gt;space&lt;/span&gt;&lt;span class="err"&gt;}{&lt;/span&gt;&lt;span class="k"&gt;space&lt;/span&gt;&lt;span class="err"&gt;}{&lt;/span&gt;&lt;span class="k"&gt;space&lt;/span&gt;&lt;span class="err"&gt;}{&lt;/span&gt;&lt;span class="k"&gt;space&lt;/span&gt;&lt;span class="err"&gt;}&lt;/span&gt;
&lt;span class="n"&gt;bbb&lt;/span&gt;&lt;span class="err"&gt;{&lt;/span&gt;&lt;span class="k"&gt;space&lt;/span&gt;&lt;span class="err"&gt;}{&lt;/span&gt;&lt;span class="k"&gt;space&lt;/span&gt;&lt;span class="err"&gt;}{&lt;/span&gt;&lt;span class="k"&gt;space&lt;/span&gt;&lt;span class="err"&gt;}{&lt;/span&gt;&lt;span class="k"&gt;space&lt;/span&gt;&lt;span class="err"&gt;}{&lt;/span&gt;&lt;span class="k"&gt;space&lt;/span&gt;&lt;span class="err"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;where the sequence &lt;code&gt;{space}&lt;/code&gt; was replaced with actual space characters.  I replaced
the tokens with what I thought was their proper line/column numbers and was surprised
to find out that the tests were still failing.
As I started
to work through the research on why this was happening, I came to an interesting
conclusion.  I was not going to get away from handling the other inline tokens after
all.&lt;/p&gt;
&lt;h3 id="the-truth-always-wins"&gt;The Truth Always Wins&lt;a class="headerlink" href="#the-truth-always-wins" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Based on the above Markdown, the tokens that were generated for that scenario test were
a Text Token, a Hard Line Break token, and another Text Token.  The first Text token
was fine, I had that covered, and the Hard Line Break token was not what we were
focusing on, so the fact that it did not have a line/column number associated with it
was fine.  But that left the second Text token in a bit of a conundrum.  Based on the
code at that time, the line/column number was &lt;code&gt;1,4&lt;/code&gt;, which based on the existing logic
was correct.  But from a validation point of view it was incorrect: it should be &lt;code&gt;2,1&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;It took me a bit to realize that if I was going to change each Text token, I would at
least have to partially handle the other inline tokens.  In this case, unless
I added some code that understood the Hard Line Break token, the source code would
correctly state that the line/column number was &lt;code&gt;1,4&lt;/code&gt;.  To be clear, it is not that
the line/column number of &lt;code&gt;1,4&lt;/code&gt; is actually correct, but according to the information
that the algorithm has, that is the correct value to compute for that token. So,
while I did not have to output the line/column number for the other inline tokens
yet, I at least had to figure out what change that token was
going to impart to the stream of inline tokens in that group.&lt;/p&gt;
&lt;h3 id="and-it-happened-with-the-most-complicated-inline-token"&gt;And It Happened with The Most Complicated Inline Token&lt;a class="headerlink" href="#and-it-happened-with-the-most-complicated-inline-token" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;The Hard Line Break token just happened to be the token I needed to figure out.  And
it would end up being the most
difficult inline token to figure out the new line/column number for.  One reason was
that, for whatever reason, I placed the newline for the Hard Line Break token with the
following
Text token, and not the Hard Line Break token itself.&lt;sup id="fnref:yesIDid"&gt;&lt;a class="footnote-ref" href="#fn:yesIDid"&gt;5&lt;/a&gt;&lt;/sup&gt;  This meant that
to properly deal with that token, I needed to reduce the vertical height of the
following Text token by 1, as the Hard Line Break token had already increased the
line number. The other reason for it being complicated is that the proper setting of
the column
number relied on checking with the owning Paragraph token, grabbing any leading space
for that next line from that token.&lt;/p&gt;
&lt;p&gt;All in all, in took a bit of work, but not too much before all the tests in that
scenario test group were passing.  While I knew there were 10s of hundreds more changes
to make, I knew I could do this.  Yeah, it would be slow, but if I just kept my
focus on the task at hand, I could do this.&lt;/p&gt;
&lt;h3 id="lather-rinse-repeat"&gt;Lather-Rinse-Repeat&lt;a class="headerlink" href="#lather-rinse-repeat" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;While I could go through each of the other equivalence classes that I discovered and
processed, I will leave that for a future article where I talk about the inline
consistency checks.  It was enough of a brutal and time-consuming process that I will not make it more so by talking about it.  Each time, I literally picked a new section of
scenario tests, replaced the &lt;code&gt;test_paragraph_blocks&lt;/code&gt; in the command line with the
prefix for another group of
tests and ran it again.  With the results of that test run, I picked off one of the
failing tests, correcting the line/column number for the Text tokens, and running
the tests again to repeat the process.  As I went, I manually validated each
test’s changes, and I rechecked my results as I staged the changes into the project’s
GitHub repository.&lt;/p&gt;
&lt;p&gt;A good example of this process was the next group of tests that I tackled: the Hard
Line Block group.  The
first couple of tests were a rehash of what I had already done, so determining the
proper line/column numbers for those tests were easy, and quickly verified.  That
left tests that included Emphasis tokens and Text tokens within Atx Heading tokens.
I just buckled down and followed at the same process as documented before, adjusting
as I went.&lt;/p&gt;
&lt;p&gt;Yes, it was slow, but it was also good.  While it dragged on, I was getting predictable
results with the application of my process.  In my mind, I had confidence that it was
no longer a matter of “um… around 1600 tokens? how am I going to…”.  I was making
that transition to “how can I get these done more efficiently and reduce my time on
each test without sacrificing quality?”&lt;/p&gt;
&lt;h2 id="updating-the-emphasis-token"&gt;Updating the Emphasis Token&lt;a class="headerlink" href="#updating-the-emphasis-token" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Compared to the work required to change the Text token, updating the Emphasis token
to include line/column numbers was trivial.  As the work had already been done to
determine the width to apply to the start and end tokens, the main change was to pass
the line/column number information to the constructor of the EmphasisMarkdownToken
and the EndMarkdownToken.&lt;/p&gt;
&lt;p&gt;With that change in place, I started running the scenario tests in the emphasis group
and only had to make one small change.  In the cases where the end Emphasis token
were completely consumed, everything was fine.  But in the cases where an end Emphasis
token were partially consumed, the column number was off by one.  That took a bit
of puzzling, but after some thinking, the answer leapt out at me.  I will not kid you
though, without me scribbling down the various cases and working through the scenarios,
it would have taken me a lot longer.&lt;/p&gt;
&lt;p&gt;For the start and end Emphasis tokens, the Inline Processor creates a Special Text token
that contains either the &lt;code&gt;*&lt;/code&gt; or &lt;code&gt;_&lt;/code&gt; character and the number of those characters found.
Because emphasis is processed from the inside out&lt;sup id="fnref:empExample"&gt;&lt;a class="footnote-ref" href="#fn:empExample"&gt;6&lt;/a&gt;&lt;/sup&gt;, the emphasis characters
taken from those Special Text tokens occur at the end of the Special Text token for the
start Emphasis token and the beginning for the end Emphasis token.  As a result of that,
the start Emphasis token’s column number needed to be adjusted by the number of
characters consumed, to ensure it pointed at the right location.  Once that adjusted
was added, the remaining scenario tests passed.&lt;/p&gt;
&lt;p&gt;While I was not sure if the other inline tokens would be as easy as the Emphasis
tokens, I was hopeful.  And in a long project, that is a good thing!&lt;/p&gt;
&lt;h2 id="what-was-my-experience-so-far"&gt;What Was My Experience So Far?&lt;a class="headerlink" href="#what-was-my-experience-so-far" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;When I start to write these sections in my articles, I always refer to my notes and try
to put my mind back into the frame of mind I was in at that time.  While there are
sparse notes here and there about this section of work, there is really only one of
those notes that properly sums up the work:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Phew!&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;While there were times during that slog that I did not think it would ever end, I was
adamant that I was going to get through it and complete it.  In my mind, it was not
a question of confidence, it was a question of endurance.  My change algorithm was
simple enough, and I had confidence that the validation part of that algorithm was
solid.  It was just a matter of working through what seemed to be a mind-numbing number
of changes until they were all done.&lt;/p&gt;
&lt;p&gt;But I persisted and got through it.  And while I believe it was the right decision
to only focus on the Text token and the Emphasis tokens, in hindsight, it might have
been okay to add the other inline tokens at the same time.  With all the work to
make sure their space was properly accounted for, I believe that most of the work that I
have left with those tokens is to plug in the calculated line/column numbers into the
inline tokens themselves, changing the serialized text, and writing the consistency
checks.  Be it as it may, unless I messed up a calculation, the hard part of making
sure the calculations work has already been done.&lt;/p&gt;
&lt;p&gt;On the technical debt point of view, I am a bit worried, but not too much.  The list
of things to check in the issues list is a bit larger than I like it, but there are
some future ideas and a lot of double-check reminders on there.  At the very least,
I am sure I can start to make short work of a lot of those issues, or properly
prioritize them for later, whichever is best for that issue.&lt;/p&gt;
&lt;h2 id="what-is-next"&gt;What is Next?&lt;a class="headerlink" href="#what-is-next" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;With the Text tokens and the Emphasis tokens out of the way, I decided that it was
better that I add the consistency checks for those tokens before progressing forward.
After having to do a fair amount of work to support “bypassing” those tokens to properly
calculate the line/column number of any following Text token, I had a feeling it would
come in handy if I moved it up the priority list a bit.&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr/&gt;
&lt;ol&gt;
&lt;li id="fn:mostlyTrue"&gt;
&lt;p&gt;This function makes simple assumptions that the &lt;code&gt;source_string&lt;/code&gt; argument is a string of any length, the &lt;code&gt;index_in_string&lt;/code&gt; argument is an integer, and the &lt;code&gt;valid_character&lt;/code&gt; argument is a string of length 1.  Because the argument names are explicit enough and their usage is within a predefined scope, I decided to not verify the type of value for each.  As such, the statement that the function will either return &lt;code&gt;True&lt;/code&gt; or &lt;code&gt;False&lt;/code&gt; assumes that those assumptions are followed. &lt;a class="footnote-backref" href="#fnref:mostlyTrue" title="Jump back to footnote 1 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:largeFinite"&gt;
&lt;p&gt;For more information, &lt;a href="https://en.wikipedia.org/wiki/History_of_large_numbers"&gt;see Wikipedia&lt;/a&gt;.  The short answer to this is that I would start with the first argument containing an empty string, for a count of 1.  Then I would move on to a string with 1 character, and have to populate that string with every viable Unicode character.  Moving on to strings with 2 characters, I would need to take every 1 character string, and repeat that same process with the second character.  Repeating this process, the number of variations on possible strings is not infinite, but mathematically it is called a large finite number, or largely finite. &lt;a class="footnote-backref" href="#fnref:largeFinite" title="Jump back to footnote 2 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:hidden"&gt;
&lt;p&gt;Looking back at it myself, it is a bit hidden, but it is in the section on &lt;a href="https://jackdewinter.github.io/2020/02/24/markdown-linter-starting-inline-processing/#code-spans"&gt;code spans&lt;/a&gt; in the fourth paragraph. &lt;a class="footnote-backref" href="#fnref:hidden" title="Jump back to footnote 3 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:twoExceptions"&gt;
&lt;p&gt;The two exceptions to this are the handling of the backslash sequence and the character entity sequence, both which add to the text that is being accumulated. &lt;a class="footnote-backref" href="#fnref:twoExceptions" title="Jump back to footnote 4 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:yesIDid"&gt;
&lt;p&gt;Yes, I did add an item to the issues list for this. &lt;a class="footnote-backref" href="#fnref:yesIDid" title="Jump back to footnote 5 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:empExample"&gt;
&lt;p&gt;For a good example of this, look at &lt;a href="https://github.github.com/gfm/#example-422"&gt;example 422&lt;/a&gt;. &lt;a class="footnote-backref" href="#fnref:empExample" title="Jump back to footnote 6 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</content><category term="Software Quality"></category><category term="markdown linter"></category><category term="core linter"></category></entry><entry><title>Markdown Linter - Adding Consistency to Token Heights</title><link href="https://jackdewinter.github.io/2020/08/31/markdown-linter-adding-consistency-to-token-heights/" rel="alternate"></link><published>2020-08-31T00:00:00-07:00</published><updated>2020-08-31T00:00:00-07:00</updated><author><name>Jack De Winter</name></author><id>tag:jackdewinter.github.io,2020-08-31:/2020/08/31/markdown-linter-adding-consistency-to-token-heights/</id><summary type="html">
&lt;h2 id="summary"&gt;Summary&lt;a class="headerlink" href="#summary" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;In my
&lt;a href="https://jackdewinter.github.io/2020/08/25/markdown-linter-adding-consistency-to-block-quotes/"&gt;last article&lt;/a&gt;,
I took care of completing the consistency checks by verifying for the second half of the
container block tokens: the Block Quote tokens.  In this article, I fill out the
line/column number consistency checks by adding support for determining and verifying
the height of …&lt;/p&gt;</summary><content type="html">
&lt;h2 id="summary"&gt;Summary&lt;a class="headerlink" href="#summary" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;In my
&lt;a href="https://jackdewinter.github.io/2020/08/25/markdown-linter-adding-consistency-to-block-quotes/"&gt;last article&lt;/a&gt;,
I took care of completing the consistency checks by verifying for the second half of the
container block tokens: the Block Quote tokens.  In this article, I fill out the
line/column number consistency checks by adding support for determining and verifying
the height of all block tokens.&lt;/p&gt;
&lt;h2 id="introduction"&gt;Introduction&lt;a class="headerlink" href="#introduction" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;From a high-level point of view, I believe that the project is coming together nicely.
Each of the examples in the base
&lt;a href="https://github.github.com/gfm/"&gt;GFM specification&lt;/a&gt;
have been tested, and their proscribed HTML output verified.  The consistency check that
verifies that that Markdown tokens contain the correct information is also in place,
covering all existing tokens.  What was left was a bit of unfinished business with
the consistency checks to verify those same tokens.  Two parts of that check were left:
verifying the token height and verifying the inline tokens.&lt;/p&gt;
&lt;p&gt;I had always intended the verification of inline tokens to be the final verification.
That was always immediately clear to me.  To properly verify any of the inline
tokens, the tokens around it needed to be verified to give that token a solid
foundation.  Without those other tokens as a foundation, any attempt at verifying
inline tokens would be shaky at best. It only made sense for me to start working on
the verification of token heights before verifying the inline tokens.&lt;/p&gt;
&lt;h2 id="what-is-the-audience-for-this-article"&gt;What Is the Audience for This Article?&lt;a class="headerlink" href="#what-is-the-audience-for-this-article" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;While detailed more eloquently in
&lt;a href="https://jackdewinter.github.io/2020/04/05/what-is-the-audience-for-my-blog/#what-is-the-audience-for-my-blog"&gt;this article&lt;/a&gt;,
my goal for this technical article is to focus on the reasoning behind my solutions,
rather that the solutions themselves.  For a full record of the solutions presented in
this article, please go to this project’s GitHub repository and consult the
commits between
&lt;a href="https://github.com/jackdewinter/pymarkdown/commit/4ae90e7b0a6e242f4364ec8bb4fe667d9d024580"&gt;15 Aug 2020&lt;/a&gt;
and
&lt;a href="https://github.com/jackdewinter/pymarkdown/commit/3fe81f2d4ffa65f1fb2d7818cab739e9e8b20470"&gt;19 Aug 2020&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id="looking-back-at-last-weeks-issue"&gt;Looking Back at Last Week’s Issue&lt;a class="headerlink" href="#looking-back-at-last-weeks-issue" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;After finishing the work on last week’s article, I took it easy for a few days,
working on the project when I could, but not pushing to hard.  As someone who uses
his brain heavily in both his professional capacity and his personal capacity, it was a
bit of a wakeup call for me.  When I saw the end of the project getting closer and
closer, I started to put in extra effort towards the project, thinking that I could get
there faster.  This normally would not be a bad thing. But to achieve that extra effort,
I diverted some of my energy away from the energy that I normally use to take care of
myself.  I did not really think about it before I started doing it, it just happened.&lt;/p&gt;
&lt;p&gt;While the result was me taking an extra day to complete the article, it could have
been worse.  From an article
point of view, I needed to rework 2-3 sections, but it was not too bad.  From a personal
point of view, if I had continued to push myself, I believe it would have multiplied
the time needed to recover substantially. I forgot that taking care of yourself and
your mental well-being is very important, especially in times of crisis.  In normal
times, I might have been able to make that trade off work, but currently, I do not
believe it is a viable option for me.  I just do not have tons of extra energy to spare.
Like it or not, those are just the times we are living in right now.&lt;/p&gt;
&lt;p&gt;And that is okay.  It is taking me a bit to accept that, but I am working on it.
What is important to me is this project and writing about it… all about it.  Not
just the rosy stuff you read in other blogs, but the actual problems I encountered
and how I approached them.  At that includes problems like these.&lt;/p&gt;
&lt;h2 id="getting-ready-for-the-changes"&gt;Getting Ready for the Changes&lt;a class="headerlink" href="#getting-ready-for-the-changes" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Knowing that I was going to be making a lot of changes to the verification logic for
line/column numbers, I wanted to prepare for that work by moving that code into its own
module.  Having seen this feature organization work well for the Markdown transformer
and the HTML transformer, I figured that moving the line/column verification code into
its own
module was an easy choice.  Further increasing the benefit of that choice was the fact
that I was going to add more logic to the code.  Keeping all that logic in one place
just made a lot of sense to me.&lt;/p&gt;
&lt;p&gt;The movement of the code was a pretty painless process, will all functions that
handle the verification
of line/column numbers being moved into the &lt;code&gt;verify_line_and_column_numbers.py&lt;/code&gt; module.
Once moved, any functions that did not need to be public were prefixed with &lt;code&gt;__&lt;/code&gt; and
their invocations were also changed to add the &lt;code&gt;__&lt;/code&gt; prefix.  Having a good set of
scenario tests added to the ease of this change, as I was able to verify that the
code was still working properly at each stage of the change.&lt;/p&gt;
&lt;p&gt;With the new module created, it was time to add to that new module.&lt;/p&gt;
&lt;h2 id="verifying-the-height-of-tokens"&gt;Verifying the Height of Tokens&lt;a class="headerlink" href="#verifying-the-height-of-tokens" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;As with any of the consistency checks, the verification of the token height started as
a very small and compact function.  At the beginning, the &lt;code&gt;__verify_token_height&lt;/code&gt;
function had 2 parameters: &lt;code&gt;current_token&lt;/code&gt; and &lt;code&gt;last_token&lt;/code&gt;.  Knowing that I had the
SetExt Heading token to process, I encapsulated that logic within that function,
calling the &lt;code&gt;__validate_block_token_height&lt;/code&gt; function to do the heavy lifting.  This
encapsulation allowed me to replace the &lt;code&gt;line_number&lt;/code&gt; and &lt;code&gt;column_number&lt;/code&gt; variables
used by the other tokens with the &lt;code&gt;original_line_number&lt;/code&gt; and &lt;code&gt;original_column_number&lt;/code&gt;
variables used by the SetExt Heading token.&lt;/p&gt;
&lt;p&gt;That verification function, the &lt;code&gt;__verify_token_height&lt;/code&gt; function, needed to be called
from 2 locations: after the &lt;code&gt;__validate_new_line&lt;/code&gt; was called and at the end of
the normal processing.  The call after the &lt;code&gt;__validate_new_line&lt;/code&gt; function was called
ensured that the height of any 2 block tokens not on the same line was calculated. If
the 2 tokens were on the same line, one of them was a container block
token, and they would always be on the same line.  As such, I could just focus on the
tokens on different lines without losing missing anything.  The call at the end of
processing would ensure that the height of the final block would also be verified.&lt;/p&gt;
&lt;p&gt;It was a good start.  With all the little stuff out of the way, it was on to
the heavy lifting part of the change.&lt;/p&gt;
&lt;h3 id="doing-the-heavy-lifting"&gt;Doing the Heavy Lifting&lt;a class="headerlink" href="#doing-the-heavy-lifting" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;The &lt;code&gt;__validate_block_token_height&lt;/code&gt; function was always intended to be a function that
needed to know about every block level token.  From the initial design for this change,
I figured that it was best to have one big function that could be
refactored later, than to have duplicate code in separate handler functions.  As I have
had good success with that pattern so far, I decided to use it again here.&lt;/p&gt;
&lt;p&gt;Like my other uses of the pattern, I started off the function with a large
&lt;code&gt;if-elif-else&lt;/code&gt; statement containing all the leaf block token names, one to each
&lt;code&gt;if&lt;/code&gt; statement.  Each &lt;code&gt;if&lt;/code&gt; statement contained a single line:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;    &lt;span class="k"&gt;assert&lt;/span&gt; &lt;span class="bp"&gt;False&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;and a final:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;    &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;assert&lt;/span&gt; &lt;span class="bp"&gt;False&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"Token "&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;last_token&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;token_name&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="s2"&gt;" not supported."&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Just like before, I had a plan.  I started running tests in groups
based on their name.  So to start, I used the command line:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;pipenv run pytest -k test_paragraph_blocks_
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;to run all the tests that dealt with paragraph blocks.  If I hit a type of leaf block
that I had not worked on yet, the &lt;code&gt;assert False&lt;/code&gt; triggered with the line number
indicating which token type failed.  If I hit a type of block that I was not expecting,
the &lt;code&gt;assert False&lt;/code&gt; in the final &lt;code&gt;else&lt;/code&gt; would be triggered, letting me know which
token I missed.&lt;/p&gt;
&lt;p&gt;And it was a lot of
&lt;a href="https://en.wikipedia.org/wiki/Lather,_rinse,_repeat"&gt;lather-rinse-repeat&lt;/a&gt;.
I ran the tests over and over again using the above command line.  If any tests failed,
I picked either the first test or the last test and examined why the test failed.  If
it was the first time that I was dealing with that specific token, I coded a good guess
as to what the height formula
should be.  Otherwise, I examined the existing formula, and tried a variation of the
code that would handle the new case.  Once all the tests for a given group were
passing, I picked another group.  This repeated until all the scenario tests in
the project were passing.&lt;/p&gt;
&lt;p&gt;For the most part, that seemingly endless processing loop worked.  But as in any
project, there were things that needed to be handled separately.&lt;/p&gt;
&lt;h3 id="counting-newlines"&gt;Counting Newlines&lt;a class="headerlink" href="#counting-newlines" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Shortly into the changes, I figured out that I needed a simple helper function to
calculate the
number of newline characters in each string.  Based on my observations, I was going
to need to count a different set of newline characters for most of the tokens.  Rather
than implementing the algorithm multiple times, it made sense to put it into one
function and in one location.&lt;/p&gt;
&lt;p&gt;After a couple of tries, I ended up with:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;__count_newlines_in_text&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;text_to_examine&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;original_length&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;text_to_examine&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;removed_length&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;text_to_examine&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;replace&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;""&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;original_length&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;removed_length&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;I forget where I encountered this pattern initially, but it was a useful one to
remember. While it does include the possibly expensive creation of a new string, the
algorithm itself is simple.
The number of a given characters in a string is the difference between the original
length of the string and length of that same string with all that specific character
replaced with an empty string.&lt;/p&gt;
&lt;p&gt;Say for example I need to know how many &lt;code&gt;a&lt;/code&gt; characters are in the string
&lt;code&gt;maybe a good day to die&lt;/code&gt;, which has a length of 23.  If I remove all the &lt;code&gt;a&lt;/code&gt;
characters, I am left with the string &lt;code&gt;mybe  good dy to die&lt;/code&gt; which has a length of 20.
Subtracting the second result from the first result leaves a value of 3, the number of
&lt;code&gt;a&lt;/code&gt; characters in the string.&lt;/p&gt;
&lt;p&gt;For Paragraph tokens, the use of this function was simple:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;    &lt;span class="n"&gt;token_height&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;__count_newlines_in_text&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;last_token&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;extracted_whitespace&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;as it was for Indented Code Block tokens:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;    &lt;span class="n"&gt;token_height&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;__count_newlines_in_text&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;last_token&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;indented_whitespace&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;For Link Reference Definitions, it was even more useful:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;    &lt;span class="n"&gt;token_height&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="mi"&gt;1&lt;/span&gt;
        &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;__count_newlines_in_text&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;last_token&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;extracted_whitespace&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;__count_newlines_in_text&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;last_token&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;link_name_debug&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;__count_newlines_in_text&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;last_token&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;link_destination_whitespace&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;__count_newlines_in_text&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;last_token&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;link_title_raw&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;__count_newlines_in_text&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;last_token&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;link_title_whitespace&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;After dealing with those tokens, there were a handful of other tokens
that were easily handled by very simple calculations.  After those tokens
were handled, there were only two troublesome tokens left: the HTML Block token and the
Fenced Code Block token.&lt;/p&gt;
&lt;h3 id="leaf-block-stacks-and-tracking-tokens"&gt;Leaf Block Stacks and Tracking Tokens&lt;a class="headerlink" href="#leaf-block-stacks-and-tracking-tokens" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;To properly process the height of those two troublesome tokens, a pair of concepts were
introduced almost at the same time.  I tried splitting these two concepts into their
own sections, but I found each attempt to do that complicated by their dependencies on
each other.&lt;/p&gt;
&lt;p&gt;The first of those concepts was the ability to track the leaf block that was currently
active at any point.  The primary driver for this concept was to provide context to the
tokens that
occurred within the HTML Block element and the Fenced Code Block element.  As these
two block elements handle their own text parsing, I needed to avoid any “extra”
checking that
occurred within these blocks.  After trying 4 or 5 other alternatives, the
tried-and-true block stack was easily the best, and most reliable, solution.&lt;/p&gt;
&lt;p&gt;The second concept was closely tied to the first concept and dealt with properly
tracking the right tokens.  To finish the handling of the HTML Block element and the
Fenced Code Block element, I needed to make sure that the concept of the “last” token
was correct.  To get that working properly, I added code to check the stack and only
set the new “remembered” token variable if that was not set.&lt;/p&gt;
&lt;h3 id="how-did-this-work"&gt;How Did This work?&lt;a class="headerlink" href="#how-did-this-work" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Unless there was anything to do with HTML Block elements or
Fenced Code Block elements, this code was not invoked.  Except for the 4 block
tokens that do not have close tokens (Blank Line, New List Item, Link Reference
Definition, and Thematic Break), any start token was added to the stack.  When
an end token was encountered, if the name of that end token matched the top
token on the stack, that top element was removed.  Simple stack management.  After
a test revealed that I had forgot to add one of those 4 block tokens to the “do not
stack” list, the stack worked flawlessly.&lt;/p&gt;
&lt;p&gt;The tracking of the tokens to avoid duplication worked as well.
When one of the two special blocks were encountered, the stack logic would add them
to the stack.  Once added, the algorithm assumed that the handling of the HTML Block
tokens and Fenced Code Block token would handle any encapsulated tokens and did not
track any of those encapsulated tokens.  When the end of the block occurred, it was
popped off the stack and the normal processing occurred.  There were a couple of
small issues at the start, but after they were cleaned up, it was smooth sailing after
that.&lt;/p&gt;
&lt;h3 id="why-did-they-need-special-processing"&gt;Why Did They Need Special Processing?&lt;a class="headerlink" href="#why-did-they-need-special-processing" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Although I tried a number of different options, the only thing that worked for
determining the height of these two special block tokens was a brute-force iteration of
all the
inline tokens.  While there were other tokens that persisted information on how many
newlines were contained within their Leaf Block, these two Leaf Block tokens did
not.  Without that information, the only option left was to iterate through each of the
encapsulated inline tokens, counting newline characters as I went.  But with those
tokens already counted, I needed to avoid counting them a second time.&lt;/p&gt;
&lt;p&gt;It was not a great solution, but it was the one that I ended up with.  Up to this
point in the project, there was no reason to change how those two Leaf Blocks stored
(or did not store) any newline, it just was not a problem.  While it was not a
great solution, at this stage it was an efficient solution.  But to check to see if
I could do it better, I created a new item in the issues list, and moved on.&lt;/p&gt;
&lt;h2 id="there-was-one-additional-thing"&gt;There Was One Additional Thing&lt;a class="headerlink" href="#there-was-one-additional-thing" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;As I finished up my work validating the Fenced Code Block token heights, there was one
scenario test that snuck up and surprised me:
&lt;a href="https://github.github.com/gfm/#example-97"&gt;example 97&lt;/a&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;`````&lt;/span&gt;

&lt;span class="o"&gt;```&lt;/span&gt;
&lt;span class="n"&gt;aaa&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This example, and the ones around it, show how an open block is closed when the
container block that owns it is closed or when the end of the document is reached.
While everything else was working properly with this example, the token’s line
height was off by one.  After double checking the math for the consistency check
and for the existing tokens, I confirmed that it was an off-by-one error. Given that
error and the section that the example was in, the next step was an easy one: craft an
example that included the end of the Fenced Code Block element:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;`````&lt;/span&gt;

&lt;span class="o"&gt;```&lt;/span&gt;
&lt;span class="n"&gt;aaa&lt;/span&gt;
&lt;span class="o"&gt;`````&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Running that test, it immediately worked, which meant only one thing to me: the
algorothm needs to know if the end token was forced.&lt;/p&gt;
&lt;h3 id="determining-if-a-token-is-forced"&gt;Determining If A Token Is Forced&lt;a class="headerlink" href="#determining-if-a-token-is-forced" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Right away, I was aware that determining if the end token was forced was not going
to be an easy task.  I immediately figured out one approach but dismissed it as too
costly.  But as I spent hours looking for any other approach that worked, I was coming
up empty with each attempt.  I found some partial solutions, but nothing that worked
in all required cases.  In the end, it was that costly approach that I returned to
as my only solution.&lt;/p&gt;
&lt;p&gt;What was that solution?  Costly as it was, that solution was to add a field to
every end token that indicates whether it was asked to be closed or forced close.
Why was it costly?  A quick scan of the scenario tests revealed almost 200 instances
of an end token… for only the scenario tests starting with &lt;code&gt;test_markdown_a&lt;/code&gt; and
&lt;code&gt;test_markdown_b&lt;/code&gt;.  Extrapolating from that sample, I believed that it would
realistically mean changing between 1250 and 1750 end tokens throughout all the
examples.&lt;/p&gt;
&lt;p&gt;It was not a decision that I made lightly, but with no other viable options, I
started to embrace it.  Making the change was the easy part.  Before the &lt;code&gt;was_forced&lt;/code&gt;
field was added to the &lt;code&gt;EndMarkdownToken&lt;/code&gt; class, the &lt;code&gt;compose_data_field&lt;/code&gt; function
looked like this:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;compose_data_field&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="n"&gt;display_data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;extracted_whitespace&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;extra_end_data&lt;/span&gt; &lt;span class="ow"&gt;is&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="bp"&gt;None&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;display_data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;display_data&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="s2"&gt;":"&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;extra_end_data&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Once the &lt;code&gt;was_forced&lt;/code&gt; field was added, it changed into:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;compose_data_field&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="n"&gt;display_data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;""&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;extra_end_data&lt;/span&gt; &lt;span class="ow"&gt;is&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="bp"&gt;None&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;display_data&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;extracted_whitespace&lt;/span&gt;
        &lt;span class="n"&gt;display_data&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="s2"&gt;":"&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;extra_end_data&lt;/span&gt; &lt;span class="ow"&gt;is&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="bp"&gt;None&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;display_data&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;extra_end_data&lt;/span&gt;
        &lt;span class="n"&gt;display_data&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="s2"&gt;":"&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;was_forced&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;extra_data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;display_data&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;If this looks like I snuck something extra in, it is because I did.  Given the number
of changes that I was going to make, I wanted to ensure that I could efficiently make
those
changes and verify them.  While having optional parts of the token serialization left
out was
more compact, it did make the serialization harder to read.  I figured that if I was
making a thorough change like this, being explicit with each of the fields would
reduce my chances of getting one of the serializations wrong.  Instead of asking myself
“what was the default value of the second and third fields”, I just added those fields
and ensured they were serialized.&lt;/p&gt;
&lt;p&gt;Basically, I gambled.  The cost of making the change to the token’s serialization was
cheap.  It would be in the verification of that change where most of the expense would
come.  And my bet was that serializing all fields explicitly would make that
verification easier and faster.&lt;/p&gt;
&lt;h2 id="was-it-worth-it"&gt;Was It Worth It?&lt;a class="headerlink" href="#was-it-worth-it" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;If anyone would have asked me that question at the start of that process, I would
have
&lt;a href="https://idioms.thefreedictionary.com/hemmed+and+hawed"&gt;hemmed and hawed&lt;/a&gt;,
giving an answer that would be uncertain at best.  But by the time I had finished
the first group of scenario tests, that answer was easily becoming a more solid “Yes!”.&lt;/p&gt;
&lt;p&gt;Was it painful?  Yes!  I purposefully did not keep track of how many changes I had
completed and how many I had left to go.  I felt that keeping track of that number
would be discouraging and focusing my mind on something other than the obvious thing:
this was the right change to do.  I was aware this was going to take a while, and
as the hours ticked by, that was hammered home multiple times.  By the time I
got to the end of this process, it took 4 days and many long hours to complete.&lt;/p&gt;
&lt;p&gt;But, in my eyes, it was worth every step of it.  As this change touched on every
scenario test, I needed to manually verify each scenario test before
going on to the next test.  And while I had test automation in peace, I had not
manually gone through each of the tests and verified for myself if the tokens
looked correct.  For me, I found peace in having inspected the tests for myself,
knowing that the consistency checks were providing me with the same results as
my manual verification.&lt;/p&gt;
&lt;p&gt;Does that mean I want to do it again?  Not really.  But would I do it if I felt that
I needed to?  In a heartbeat.  In terms of confidence,
this was me doing a final read of my article before publishing it.  This was me
running the Static Code Analysis against my code one more time just to make sure
that I did not miss anything.  This was me looking over the changes I am about to
commit to the repository before I submit the commit.  It is easy to argue that
each of those actions is more emotional than logical, but that is the point.&lt;/p&gt;
&lt;p&gt;Sometimes, it is just logical to do an action for a positive emotional reaction.
And that is okay too.&lt;/p&gt;
&lt;h2 id="what-was-my-experience-so-far"&gt;What Was My Experience So Far?&lt;a class="headerlink" href="#what-was-my-experience-so-far" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;I know I will only get one chance to make a good impression with this project, so
I want to make that impression a good one.  If I want to provide a good impression by
having a good linter as the outcome for this project, I will need to test as many of the
combinations of Markdown elements with each other as possible, in as many circumstances
as possible.  From the beginning of the project, a simple calculation made it clear that
the scope of testing required would be difficult if I was lucky.  If I was not lucky,
that hopeful guess of difficult would grow by at least 2 orders of magnitude.&lt;/p&gt;
&lt;p&gt;But even given that prediction that testing everything would be very difficult, I
wanted to give the project the best chance to succeed.  The best way that I know of
doing that is to fully commit to making the right changes to solve the problems
properly.  For the first set of changes, this meant working with what I had, as it
was only the token height calculation that needed that logic.  For the the second set of
changes it meant changing all the tokens, because there really was not any alternative.&lt;/p&gt;
&lt;p&gt;In a strange way, both sets of changes brought me peace, increasing my confidence
about the project.  In the grand scheme of things, the iterative calculations for the
height of the two Leaf Block tokens was not too expensive, and it is localized to that
one module.  Ammortizing the cost of those calculations over all the Leaf Block tokens
makes it even less expensive.  From that point of view, those changes were definitely
cost effective in my eyes.&lt;/p&gt;
&lt;p&gt;And while people can say I am pedantic and a perfectionist, I somewhat liked spending
that time going through each scenario and verifying it.  Before that review, I had
a lot of trust in those consistency checks, but there was always a question of whether
I had missed something important.  With the existing checks in place and a
manual review of those scenario tests, the chances of any major issues being left
are drastically reduced.&lt;/p&gt;
&lt;p&gt;I will never say that any piece of software has zero bugs in it, but I do know that
I feel that I am eliminating many of the paths for bugs to form in this project.&lt;/p&gt;
&lt;p&gt;And that I am confident about!&lt;/p&gt;
&lt;h2 id="what-is-next"&gt;What is Next?&lt;a class="headerlink" href="#what-is-next" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;After completing the token height verification for block tokens, it was time to start
working on the line/column numbers for the inline tokens.  I was not sure how much of a
chore it would be, but it would be gratifying to get them done!&lt;/p&gt;</content><category term="Software Quality"></category><category term="markdown linter"></category><category term="core linter"></category></entry><entry><title>Markdown Linter - Adding Consistency to Block Quotes</title><link href="https://jackdewinter.github.io/2020/08/25/markdown-linter-adding-consistency-to-block-quotes/" rel="alternate"></link><published>2020-08-25T00:00:00-07:00</published><updated>2020-08-25T00:00:00-07:00</updated><author><name>Jack De Winter</name></author><id>tag:jackdewinter.github.io,2020-08-25:/2020/08/25/markdown-linter-adding-consistency-to-block-quotes/</id><summary type="html">
&lt;h2 id="summary"&gt;Summary&lt;a class="headerlink" href="#summary" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;In my
&lt;a href="https://jackdewinter.github.io/2020/08/17/markdown-linter-adding-lists-to-the-markdown-transformer/"&gt;last article&lt;/a&gt;,
I took care of completing the Markdown transformer checks for one half of the container
block tokens: the List Block tokens.  In this article, I tackle both the line/column
number consistency checks and the Markdown transformer checks for the Block Quote
tokens.&lt;/p&gt;
&lt;h2 id="introduction"&gt;Introduction&lt;a class="headerlink" href="#introduction" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;While …&lt;/p&gt;</summary><content type="html">
&lt;h2 id="summary"&gt;Summary&lt;a class="headerlink" href="#summary" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;In my
&lt;a href="https://jackdewinter.github.io/2020/08/17/markdown-linter-adding-lists-to-the-markdown-transformer/"&gt;last article&lt;/a&gt;,
I took care of completing the Markdown transformer checks for one half of the container
block tokens: the List Block tokens.  In this article, I tackle both the line/column
number consistency checks and the Markdown transformer checks for the Block Quote
tokens.&lt;/p&gt;
&lt;h2 id="introduction"&gt;Introduction&lt;a class="headerlink" href="#introduction" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;While the implementation of list tokens went easier than I thought it would, I
remained cautiously optimistic about adding consistency check support for Block Quote
tokens.  During the initial development of the line/column number checks, I noticed
that the Block Quote tokens did not keep any information about removed data.  After
having completed the List Block token support, I knew that it would be pivotal to
get that right.  And that meant more work.  A lot of nitpicking work.&lt;/p&gt;
&lt;p&gt;To add the consistency checks, I was going to have to accomplish 3 things: capture the
removed line start text, use that information to validate the line/column numbers, and
then write the Markdown transformations for it.  The last two items were the easy part,
those parts I had confidence I could complete.  It was the capturing of removed checks
that I was not confident about.  And the capturing of text was the change that I needed
to tackle first.&lt;/p&gt;
&lt;h2 id="what-is-the-audience-for-this-article"&gt;What Is the Audience for This Article?&lt;a class="headerlink" href="#what-is-the-audience-for-this-article" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;While detailed more eloquently in
&lt;a href="https://jackdewinter.github.io/2020/04/05/what-is-the-audience-for-my-blog/#what-is-the-audience-for-my-blog"&gt;this article&lt;/a&gt;,
my goal for this technical article is to focus on the reasoning behind my solutions,
rather that the solutions themselves.  For a full record of the solutions presented in
this article, please go to this project’s GitHub repository and consult the
commits between
&lt;a href="https://github.com/jackdewinter/pymarkdown/commit/255bfce0efab68c0d76ca8d04b03017ba40e6223"&gt;12 Aug 2020&lt;/a&gt;
and
&lt;a href="https://github.com/jackdewinter/pymarkdown/commit/08da2e04c355e0a3bd016e20afce3102696a8107"&gt;14 Aug 2020&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id="lets-talk-about-the-obvious"&gt;Let’s Talk About the Obvious&lt;a class="headerlink" href="#lets-talk-about-the-obvious" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;I am generally very disciplined when it comes to writing my blog.  I keep notes when I
am writing the code, curating those notes into an outline on the
Thursday to Saturday before I post my article.  If I am lucky enough, I will start
the actual writing of my article on
Saturday night, but most often I start writing it early Sunday morning.  This allows
me to take my time to enjoy my Sunday while ending up with a solid version of the
article by Sunday night.  Then, on Monday night, I take that article and add
extra code samples and do some wordsmithing to form the article into its final form.  It
may not be the way others write their articles, but it is a process that works
for me.&lt;/p&gt;
&lt;p&gt;Until this week that is.  Everything was on track until Monday, when I started my edits
with a headache that I just could not ditch.  But process is process, so I started doing
those edits, pushing on until a couple of hours later.  At that point, I looked at
what I was doing and went… huh?  I started looking at my edits and tried to figure
things out, using even more edits to fix any problems I encountered.  Far from making
things better, I was making them worse.  But I would not see that until later.&lt;/p&gt;
&lt;p&gt;It was a while later when I finally stopped and locked my computer.  Above all else,
this was the best thing that I did in that entire situation.  It took me a
while, but I stopped.  However, by that point, a certain amount of damage
was already done.  I had written some things twice and other things not at all. In
some cases, I had sentences that looking at them later, I wonder if I had written them
while drunk.  I knew I could recover from that position, but it would require a clear
head, some extra time, and some hard work.  And it was not going to happen that night.
I came to the realization that I was not going to be able to meet my usual posting
deadline of Monday night.&lt;/p&gt;
&lt;p&gt;At first, I was angry with myself.  Many weeks of not missing a posting deadline and
now I had a bad record.  “I always post on Monday nights, except for…”  Argh!
But after thinking about the purpose of my blog, to educate and help others, I
started to find peace with it.  None of us is perfect, and we all need to take care
of ourselves.  Me included.  My health versus my article’s deadline.  I needed to
take that extra day and get better before finishing… er… unfinishing and then
refinishing the editing.&lt;/p&gt;
&lt;h2 id="capturing-the-leading-block-quote-text"&gt;Capturing the Leading Block Quote Text&lt;a class="headerlink" href="#capturing-the-leading-block-quote-text" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;In its simplest form, the handling of container block elements and their tokens is a
relatively easy concept. Every line of a Markdown document enclosed within a container
block element is usually prefaced with one or more characters that denote the presence
of that container element.  For Block Quotes these are character sequences with the
&lt;code&gt;&amp;gt;&lt;/code&gt; character and an optional whitespace, and for Lists these are whitespaces.  To make
the processing of those contained lines easier, at the start of the project I took some
up-front time to ensure that
the container block element processing is independent of the leaf block element
processing.  As such, I was able to work on that leaf block processing independently of
container block processing.&lt;/p&gt;
&lt;p&gt;When I was doing the initial research for
&lt;a href="https://jackdewinter.github.io/2020/06/29/markdown-linter-rabbit-hole-3-trying-to-dig-myself-out/#keeping-the-scope-small"&gt;container block support&lt;/a&gt;,
I started with List tokens.  I quickly wrote a proof of concept for the line/column
number check and was happy to find that I had already placed the required information
in the token.  However, after using the same process with Block Quote tokens, it was
evident that I had missed the mark with them.  Unlike the List tokens, none of the
required
information was placed within the Block Quote tokens.  At that time, after having
gone down a
&lt;a href="https://jackdewinter.github.io/2020/06/15/markdown-linter-rabbit-hole-1-adding-consistency-checks/"&gt;rabbit hole for a bit&lt;/a&gt;,
I wisely decided to wait until later to implement that.   Well, that time was now and
I knew it was going to take some work to add it.&lt;/p&gt;
&lt;h3 id="addressing-the-issue"&gt;Addressing the Issue&lt;a class="headerlink" href="#addressing-the-issue" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Like the work I did for List Block tokens, the Block Quote stack token needed a
change to support the &lt;code&gt;matching_markdown_token&lt;/code&gt; field.  This field is pivotal to
inform the processor of the latest markdown token that is containing other tokens.
But to properly use this field, it would take a bit of disassembly and reassembly.
Before this change, the code to add the necessary tokens to the two relevant stacks
were:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;    &lt;span class="n"&gt;parser_state&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;token_stack&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;BlockQuoteStackToken&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
    &lt;span class="o"&gt;...&lt;/span&gt;
    &lt;span class="n"&gt;container_level_tokens&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="n"&gt;BlockQuoteMarkdownToken&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;extracted_whitespace&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;adjusted_position_marker&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Two different tokens and two different stacks, with nothing between them.  With this new
functionality in place, that code needed some slight changes:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;    &lt;span class="n"&gt;new_markdown_token&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;BlockQuoteMarkdownToken&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="n"&gt;extracted_whitespace&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;adjusted_position_marker&lt;/span&gt;
    &lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;container_level_tokens&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;new_markdown_token&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;parser_state&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;token_stack&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="n"&gt;BlockQuoteStackToken&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;new_markdown_token&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Instead of two distinct tokens, there was now a stack token that included a reference
to the Markdown token that it represented.  &lt;/p&gt;
&lt;p&gt;With that field properly initialized, the &lt;code&gt;add_leading_spaces&lt;/code&gt; function was then added
to make use of that new field.  It is
a simple function that adds any extracted text (usually whitespace) to its
field, separating any new text from the existing text using a newline character.
The function itself is very boring.  The interesting part about the function would be in
locating where that function needed to be called from and using it properly.&lt;/p&gt;
&lt;h3 id="the-first-one-is-almost-always-easy"&gt;The First One Is Almost Always Easy&lt;a class="headerlink" href="#the-first-one-is-almost-always-easy" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;The first location was obvious: within the &lt;code&gt;__handle_block_quote_section&lt;/code&gt; function
of the &lt;code&gt;BlockQuoteProcessor&lt;/code&gt; class.  This is where the bulk of the processing of
Bulk Quote elements and their effects go through.  In there is an easy to find block of
code that records the number of characters removed and resets the string to exclude
those characters:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;            &lt;span class="n"&gt;line_to_parse&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;line_to_parse&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;start_index&lt;/span&gt;&lt;span class="p"&gt;:]&lt;/span&gt;
            &lt;span class="n"&gt;removed_chars_at_start&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;start_index&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;That block of code was slightly modified to record that removed text and place it into
its own variable:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;            &lt;span class="n"&gt;removed_text&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;
                &lt;span class="n"&gt;line_to_parse&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;position_marker&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;index_number&lt;/span&gt; &lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;start_index&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
            &lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="n"&gt;LOGGER&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;debug&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;...&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="n"&gt;line_to_parse&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;line_to_parse&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;start_index&lt;/span&gt;&lt;span class="p"&gt;:]&lt;/span&gt;
            &lt;span class="n"&gt;removed_chars_at_start&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;start_index&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;With the removed text in hand, the code just needed to know which token to associate the
removed text with. As the code processes Block Quote elements, it was reasonable to
assume that the most relevant Block Quote stack token is the last one on the stack.
That stack token was easily found with a simple for loop:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;            &lt;span class="n"&gt;found_stack_token&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;None&lt;/span&gt;
            &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;stack_index&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;parser_state&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;token_stack&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
                &lt;span class="o"&gt;...&lt;/span&gt;
                &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;parser_state&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;token_stack&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;stack_index&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;is_block_quote&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                    &lt;span class="n"&gt;found_stack_token&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;parser_state&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;token_stack&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;stack_index&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
                    &lt;span class="k"&gt;break&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;With the extracted text and the ‘top’ stack token, the only thing that was left to
do was:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;            &lt;span class="n"&gt;found_stack_token&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;matching_markdown_token&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;add_leading_spaces&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;removed_text&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Almost right away, I was off to a good start on extracting the leading spaces for the
Block Quote token and storing them.&lt;/p&gt;
&lt;h3 id="locating-the-next-issue"&gt;Locating the Next Issue&lt;a class="headerlink" href="#locating-the-next-issue" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;After those changes were in place, I ran the scenario tests again, seeing almost every
test that has a Block Quote token fail.  My heart dropped.  But after a second, I
realized that I wanted that to happen.  As I wanted to make sure each Block Quote token
was verified, I added the leading space data to the end of the string for the
&lt;code&gt;BlockQuoteMarkdownToken&lt;/code&gt; class, separated from the rest with the &lt;code&gt;:&lt;/code&gt; character.  If
things worked properly, that meant every Block Quote token would, at the very least,
now include an extra &lt;code&gt;:&lt;/code&gt; character.  Every serialized Block Quote token was now “wrong”,
so every Block Quote scenario test should fail.  Good!&lt;/p&gt;
&lt;p&gt;Working through each case was decently fast, with a solid methodical process in place:
look at
the results, find the next failing test, and manually determine what change needed to
be made to the Block Quote token.  After making that change to the test data, I would
then re-run that specific scenario test, and check for token differences.&lt;/p&gt;
&lt;p&gt;It was by using this process that I found the next issue: missing leading whitespace.
In some cases, the leading text that was extracted was preceded by one of more
whitespaces. Those whitespaces were stuffed into the &lt;code&gt;extracted_whitespace&lt;/code&gt; variable
and then ignored after that.  The resolution to that issue was
simple.  Instead of only adding the leading space to the &lt;code&gt;removed_text&lt;/code&gt; variable,
the contents of that &lt;code&gt;extracted_whitespace&lt;/code&gt; needed to be added to the variable, as such:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;            &lt;span class="n"&gt;removed_text&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;
                &lt;span class="n"&gt;extracted_whitespace&lt;/span&gt;
                &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;line_to_parse&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;position_marker&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;index_number&lt;/span&gt; &lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;start_index&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
            &lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Running the tests again, a new block of tests started passing.&lt;/p&gt;
&lt;h3 id="and-next-blank-lines"&gt;And Next… Blank Lines&lt;a class="headerlink" href="#and-next-blank-lines" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;As more and more of the Block Quote scenario tests were changed and started passing,
there were a handful of tests that were failing that I left for later.  When I got
to the end of those tests, I went back and started to look at those failing tests
one-by-one.&lt;/p&gt;
&lt;p&gt;The first group of failures that I examined were ones in which there was a Blank
Line element contained within a Block Quote. A good example of this is
&lt;a href="https://github.github.com/gfm/#example-222"&gt;example 222&lt;/a&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;foo&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;bar&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;In these cases, the parsing was
correct, but the newly added &lt;code&gt;add_leading_spaces&lt;/code&gt; function was not being called.  The
outcome
was that the number of newlines contained within the owning Block Quote token did
not match the number of lines within the Block Quote element itself.  To ensure
that those two values lined up, the &lt;code&gt;add_leading_spaces&lt;/code&gt; function was called with
an empty string, thereby evening up those values.&lt;/p&gt;
&lt;p&gt;Running the scenario tests again, all the scenario tests explicitly for Block Quotes
were passing.  I then ran the scenario tests again, checking to make sure that the
scenario tests with Block Quotes and Blank Lines passed. While the new changes were
now passing, there were still a handful of tests to work on.&lt;/p&gt;
&lt;h3 id="and-finally-html-blocks"&gt;And Finally, HTML Blocks&lt;a class="headerlink" href="#and-finally-html-blocks" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Having run the scenario tests again, the only tests that were not passing were
scenario tests that included Block Quotes and HTML blocks.  Doing some research into
the issue, I quickly found
that it looked like the same issue with the Blank Line elements, just with HTML blocks.
This issue was uncovered through one of my additional tests, “cov_2” used to increase
coverage on the various forms of HTML start and end tags:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nt"&gt;&amp;lt;/hrx&lt;/span&gt;
&lt;span class="nt"&gt;&amp;gt;&lt;/span&gt;
&lt;span class="nt"&gt;&amp;lt;/x-table&amp;gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Like the previous issue with Blank Line tokens, the number of new lines were not lining
up between the two sources.  Once again, calling the &lt;code&gt;add_leading_spaces&lt;/code&gt; function
with an empty string in these cases solved the issue.&lt;/p&gt;
&lt;h3 id="closing-out-the-token-changes"&gt;Closing Out the Token Changes&lt;a class="headerlink" href="#closing-out-the-token-changes" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;After those changes has been completed, it was obvious that all the scenario tests were
passing.  Just to be sure, I manually went through each of the scenarios and verified
the newly changed tokens.  As I have said before, maybe I am paranoid, but if I was
depending on those results, I figured an extra pass or two would not hurt.&lt;/p&gt;
&lt;p&gt;It just felt good to get these changes completed.  I had a high degree of confidence
that I was able to find most of these issues, but an even higher degree of confidence
that the remaining work would flush out anything that I missed.  It was with those
positive thoughts in my head that I started working on the consistency checks.&lt;/p&gt;
&lt;h2 id="validating-the-line-numbers-and-column-numbers"&gt;Validating the Line Numbers and Column Numbers&lt;a class="headerlink" href="#validating-the-line-numbers-and-column-numbers" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;With that confidence, I started working on the consistency checks for line numbers
and column numbers.  The first step in doing this was removing a couple of lines
of code that prevented the consistency checks from firing if one of the tokens was
a Block Quote token.  It was useful when I did not have anything in place, but now
it would just get in the way.&lt;/p&gt;
&lt;p&gt;After that change, tests predictably started failing, but I was ready for them.  From
the work
that I had just completed, I figured that I would have to follow a similar path in
implementing the consistency check.  Therefore, the first thing I did to help with
the consistency check is to reset the &lt;code&gt;leading_text_index&lt;/code&gt; field of the
&lt;code&gt;BlockQuoteMarkdownToken&lt;/code&gt; instance to 0 when it is encountered.  This made sure that
the tracking of the leading spaces would always start with the first entry.&lt;/p&gt;
&lt;p&gt;With that done, the code needed to take advantage of that was easy to write.
When a token exists on a new line, it’s indent must be determined by tracking the
size of the removed text and adding that measurement to the column number.  Based
on the previous work, this becomes trivially easy:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;    &lt;span class="n"&gt;split_leading_spaces&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;top_block&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;leading_spaces&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;split&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;init_ws&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;split_leading_spaces&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;top_block&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;leading_text_index&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Basically, grab the top Block Quote token, split it into lines, and use the
&lt;code&gt;leading_text_index&lt;/code&gt; value of that topmost token to grab the right leading space.&lt;/p&gt;
&lt;p&gt;From there, the new work mirrored the work that I did in preparing the tokens.  When a
Blank Line token is encountered, that index is incremented.  For each line of
text within an HTML block, that index is incremented.  And in addition, that
&lt;code&gt;leading_text_index&lt;/code&gt; field needed to be tweaked at the end of HTML blocks,
Atx Heading blocks, and Paragraph blocks, which was something I figured might
come up.  Just some simple cases where a bit of extra finessing was needed.&lt;/p&gt;
&lt;p&gt;To be clear, I was not 100% percent sure that this would happen, but I was hoping that
it would.  To me it made sense that if I needed to add code to track the leading
spaces that were removed, any consistency check would need to follow that same path
to verify the information.  And as to the extra tweak for the end tokens, I was
confident that it was a solid change, and was not worried about that deviation from
the previous work.&lt;/p&gt;
&lt;h2 id="writing-the-block-quote-markdown-transformations"&gt;Writing the Block Quote Markdown Transformations&lt;a class="headerlink" href="#writing-the-block-quote-markdown-transformations" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Given the work I had just completed to get to this point, it was obvious to me that
I was going to have to do a lot of fiddling with spaces to get the transformations
correct.  To make that job a bit easier, I decided for the moment to eliminate any
Markdown documents which contained both Block Quote elements and List elements.
I would get back to these quickly, but at that moment, it was just too much.&lt;/p&gt;
&lt;p&gt;The processing of the start and end of the Block Quote elements were simple,
largely mimicking the work I did for the List elements.  When a Block Quote token
was processed, it created a copy of itself and added that copy to the top of the
&lt;code&gt;container_token_stack&lt;/code&gt; list.  From there, the leading space were retrieved from
their storage in the token and added to the sequence to be emitted.  The end
of the Block Quote element was even easier, returning an empty string after removing
the top token off the &lt;code&gt;container_token_stack&lt;/code&gt; list.  The work I had previously done
on setting up the leading spaces was really paying off.&lt;/p&gt;
&lt;p&gt;With the work to recognize and process the actual tokens taken care of, the main
task ahead of me was to add and populate the &lt;code&gt;__perform_container_post_processing_block_quote&lt;/code&gt; function.  Like how List
Block tokens were handled in the
&lt;code&gt;__perform_container_post_processing_lists&lt;/code&gt; function, this new function was used
to handle the newline processing for text enclosed within Block Quote elements.
After having completed all this other work, that work was relatively simple to do.
With all the individual token processing already
performed, this function just needed to focus on detecting newline characters.
For each of these characters encountered, the top Block Quote token would be
used to determine the current &lt;code&gt;leading_text_index&lt;/code&gt; to start with.  With each
newline encountered, the current split value would be used, incrementing the
&lt;code&gt;leading_text_index&lt;/code&gt; value afterwards.  This pretty much worked flawlessly out
of the box.&lt;/p&gt;
&lt;h3 id="as-i-was-cleaning-up"&gt;As I was cleaning up&lt;a class="headerlink" href="#as-i-was-cleaning-up" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;An interesting issue came up as I was generating these transformations.
For some reason, I had missed some cases involving Block Quote elements that
contained Fenced Code Block elements.  With the Markdown transformer now rehydrating
the Markdown, it was obvious that things were missing.  It did not take me long to
figure out that the Fenced Code Blocks were missing their Block Quote leading
characters.  This was found for
&lt;a href="https://github.github.com/gfm/#example-98"&gt;example 98&lt;/a&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="o"&gt;```&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;aaa&lt;/span&gt;

&lt;span class="n"&gt;bbb&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;When the transformer tried to rehydrate the document, it rehydrated that Markdown
text without the leading &lt;code&gt;&amp;gt;&lt;/code&gt; sequence before the text &lt;code&gt;aaa&lt;/code&gt;.  Having just gone
through that research for other elements, I was quick to spot it and realize where
the issue was.  A couple of quick changes, and that change was passing!&lt;/p&gt;
&lt;h3 id="along-the-way"&gt;Along the Way&lt;a class="headerlink" href="#along-the-way" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;And to hammer home the point that this consistency checking is good, it found some
issues along the way.&lt;/p&gt;
&lt;p&gt;The first one was an interesting issue where the starting whitespace for one
transformation was missing.  And it was such a weird case.  It was an Atx Heading
element that contained a Shortcut Link element as its only text, separated from the Atx
Heading character ( &lt;code&gt;#&lt;/code&gt; ) by the mandatory single space. That is really important.  Two
space it was okay with, but the one space, nope! Due to the way that
it was parsed, that spaces were missing and not accounted for.  The fix to this was
to add that starting whitespace as a new token containing that removed text, but with
a twist.  That twist was to use the &lt;code&gt;create_replace_with_nothing_marker&lt;/code&gt; function to
add that text as itself for the Markdown transformer, but keep it as removed for the
HTML transformer.  With both transformers appeased, it was on to the next issue.&lt;/p&gt;
&lt;p&gt;The second issue that I uncovered was that, in rare cases, the leading spaces for
certain lines were missing.  After doing some digging, it only appeared to be lines
that did not have any block quote prefix characters removed from the line.  So
after adding a new &lt;code&gt;__adjust_paragraph_for_block_quotes&lt;/code&gt; function to the
&lt;code&gt;LeafBlockProcessor&lt;/code&gt; and wiring it into the &lt;code&gt;parse_paragraph&lt;/code&gt; function, the debug
confirmed that it was only those few cases where that was an issue.&lt;/p&gt;
&lt;h2 id="and-of-course-some-cleanup"&gt;And Of Course, Some Cleanup&lt;a class="headerlink" href="#and-of-course-some-cleanup" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;It would not be a proper week of coding if I did not do some cleanup.  In this case,
the cleanup was simple: relocating the line/column number logic to its own
module.  One of the things that made the Markdown transformations easy to deal with
is that those transformations are in their own &lt;code&gt;TransformToMarkdown&lt;/code&gt; class.
That worked well.  The
line/column number checks were in with some other validation code in the &lt;code&gt;utils.py&lt;/code&gt;
module.  That worked… well… okay?&lt;/p&gt;
&lt;p&gt;When I started with the consistency checks, they were new, and keeping all that code
in the &lt;code&gt;utils.py&lt;/code&gt; module made sense.  But as the amount of code in the module grew, I
never took the time to to some refactoring.  As such, the module developed two
responsibilities. The first was to be the location for all the &lt;code&gt;assert_*&lt;/code&gt; functions
and the &lt;code&gt;write_temporary_configuration&lt;/code&gt; functions.  Those are all the functions that are
called directly from the tests, mostly in the final Assert stage of the test.  The
second was to house the logic for the line/column number consistency checks.&lt;/p&gt;
&lt;p&gt;It just seemed logical, now that that part of the code was stable and well-tested, to
take that second responsibility and put it into its own module. I created the
&lt;code&gt;verify_line_and_column_numbers.py&lt;/code&gt; module and started moving the functions into it,
with the &lt;code&gt;verify_line_and_column_numbers&lt;/code&gt; function being the main entry point for
the module.  It just seemed cleaner and more compact.  One module, one responsibility.&lt;/p&gt;
&lt;h2 id="what-was-my-experience-so-far"&gt;What Was My Experience So Far?&lt;a class="headerlink" href="#what-was-my-experience-so-far" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;The dominant part of my experience at the current moment is one of humility and
patience.  Yes, it is Tuesday night. And after a little over 3 hours of extra work,
I have finally recovered the article to where it was at this time last night. I
do feel an impulse to be hard on myself about this delay, but I also am working
hard to remember to be patient with myself.  This is one time where I am missing a
deadline, and it probably will not be the last.&lt;/p&gt;
&lt;p&gt;The humility that I am trying to practice is in understanding that I cannot do
everything all the time.  I know that sounds like it should be an obvious thing to
know, but I think we all forget it from time to time.  I was so focused on making
sure that I met my deadline, that I neglected to have a conversation with myself
on whether that was the right choice.  But it was not a large rabbit hole,
just a small one that I was able to easily recover from.&lt;/p&gt;
&lt;p&gt;Focusing more on the actual work that I accomplished, I was buoyed.  I was long
worried about how hard it would be to implement the consistency checks for Block
Quote tokens.  Having completed that work, I now am trying to figure out why I was
worried.  Trying to figure it out now, I would guess I would focus on what it took
to complete that work with lists.  That work was very nitpicky because it contained a
lot of “empty” whitespace, if I am remembering it clearly.  From the effort that it
took to deal with that, I can see how I might have thought it would have taken the same
effort for Block Quote tokens.&lt;/p&gt;
&lt;p&gt;But it did not.  The work I had done in that area on List tokens forced me to get things
set up to make List token processing easier, which I believe Block Quotes benefited
from.  Regardless, I was glad that I could close the books on the Block Quote tokens
and their consistency checks.&lt;/p&gt;
&lt;h2 id="what-is-next"&gt;What is Next?&lt;a class="headerlink" href="#what-is-next" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;With all the block token consistency checks now taken care of, there was a bit of clean
up to do with determining the height of each block token.  While I initially thought
that it would be easy, it did not turn out that way.&lt;/p&gt;</content><category term="Software Quality"></category><category term="markdown linter"></category><category term="core linter"></category></entry><entry><title>Markdown Linter - Adding Lists to the Markdown Transformer</title><link href="https://jackdewinter.github.io/2020/08/17/markdown-linter-adding-lists-to-the-markdown-transformer/" rel="alternate"></link><published>2020-08-17T00:00:00-07:00</published><updated>2020-08-17T00:00:00-07:00</updated><author><name>Jack De Winter</name></author><id>tag:jackdewinter.github.io,2020-08-17:/2020/08/17/markdown-linter-adding-lists-to-the-markdown-transformer/</id><summary type="html">
&lt;h2 id="summary"&gt;Summary&lt;a class="headerlink" href="#summary" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;In my
&lt;a href="https://jackdewinter.github.io/2020/08/10/markdown-linter-adding-links-to-the-markdown-transformer/"&gt;last article&lt;/a&gt;,
I increased the coverage provided by the token to Markdown transformer by adding
support for the link related tokens. In this article, I take another large step
towards completing the consistency checks by adding support for list related tokens.&lt;/p&gt;
&lt;h2 id="introduction"&gt;Introduction&lt;a class="headerlink" href="#introduction" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Having implemented the link related …&lt;/p&gt;</summary><content type="html">
&lt;h2 id="summary"&gt;Summary&lt;a class="headerlink" href="#summary" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;In my
&lt;a href="https://jackdewinter.github.io/2020/08/10/markdown-linter-adding-links-to-the-markdown-transformer/"&gt;last article&lt;/a&gt;,
I increased the coverage provided by the token to Markdown transformer by adding
support for the link related tokens. In this article, I take another large step
towards completing the consistency checks by adding support for list related tokens.&lt;/p&gt;
&lt;h2 id="introduction"&gt;Introduction&lt;a class="headerlink" href="#introduction" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Having implemented the link related tokens, I was now down to one large group:
the container related tokens.  Even with the confidence I gained from the work that
I performed with link related tokens, I felt that “container related tokens” was
too large of a group for me to be comfortable working with.  Given that the container
related tokens group contained only 2 types of tokens, it only seemed natural to focus
on one of those two tokens: the list tokens.  More specifically, I was going to
start with the Unordered List tokens.&lt;/p&gt;
&lt;h2 id="what-is-the-audience-for-this-article"&gt;What Is the Audience for This Article?&lt;a class="headerlink" href="#what-is-the-audience-for-this-article" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;While detailed more eloquently in
&lt;a href="https://jackdewinter.github.io/2020/04/05/what-is-the-audience-for-my-blog/#what-is-the-audience-for-my-blog"&gt;this article&lt;/a&gt;,
my goal for this technical article is to focus on the reasoning behind my solutions,
rather that the solutions themselves.  For a full record of the solutions presented in
this article, please go to this project’s GitHub repository and consult the
commits between
&lt;a href="https://github.com/jackdewinter/pymarkdown/commit/6f7fa825b3cd6bad52cd5b9772a0f35dc816b629"&gt;04 Aug 2020&lt;/a&gt;
and
&lt;a href="https://github.com/jackdewinter/pymarkdown/commit/07d6f81c6c6b46c3ae9c526a3d176d65ddf06c54"&gt;08 Aug 2020&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id="starting-with-unordered-lists"&gt;Starting with Unordered Lists&lt;a class="headerlink" href="#starting-with-unordered-lists" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Taking a wander through the scenario tests with unordered lists in their examples,
two things were clear to me.  The first thing is that with few exceptions, they were all
working well from the point of view of existing consistency checks.  Those few examples
were 1 case with nested links and 4 cases which mixed up block quotes with list.
Those examples are
&lt;a href="https://github.github.com/gfm/#example-528"&gt;example 528&lt;/a&gt;,
&lt;a href="https://github.github.com/gfm/#example-237"&gt;example 237&lt;/a&gt;,
&lt;a href="https://github.github.com/gfm/#example-238"&gt;example 238&lt;/a&gt;,
&lt;a href="https://github.github.com/gfm/#example-270"&gt;example 270&lt;/a&gt;, and
&lt;a href="https://github.github.com/gfm/#example-271"&gt;example 271&lt;/a&gt;.
The second thing that was clear was that because of the first
point, I had a high degree of confidence that I was going to be addressing issues that
almost exclusively focused on whitespace.  With the HTML output already being verified,
I was certain that properly transforming Unordered List tokens back into list Markdown
would mostly boil down to whitespaces.&lt;/p&gt;
&lt;h3 id="thinking-about-the-design"&gt;Thinking About the Design&lt;a class="headerlink" href="#thinking-about-the-design" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Before I leapt into the coding, I sat back and thought long and hard about the approach
I was going to take with the transformation of these tokens.  When I started sketching
out what my approach would be, I started to understand that there would be two issues
I would have to deal with.  They were the transformation of the tokens themselves, and
the whitespace they would inject before other tokens.  The first part was the easy
part: see
an unordered list token, use the elements in the token to figure out its transformed
form, and emit that transformed form.  Done.&lt;/p&gt;
&lt;p&gt;Managing the whitespace was going to be a lot more difficult.  The thing that helped
me was that I knew I already had experience with handling that initial whitespace from
writing the main parser.  What helped me immeasurably in the
parser was to keep the processing of the two container elements, lists and block
quotes, separate from the processing of the leaf tokens.  By only passing “container
element free” text to the
leaf token processor, that processor was kept simple.  To keep the container handling
for the Markdown transformer simple, I decided that employing the same approach was
pivotal.&lt;/p&gt;
&lt;p&gt;But even with the decision to keep that processing separate, I figured that it would
only get me
part of the way there.  To complete the management of the whitespaces, I would need to
be able to calculate the whitespace used before each line contained within a list block.
The more I looked at the problems to be solved, the more I was sure that most of my
time was going to be managing that initial whitespace.&lt;/p&gt;
&lt;p&gt;It was not going to be fun getting the transformations done for the Unordered List
tokens, but I had a feeling that it would be really satisfying when it was done!&lt;/p&gt;
&lt;h3 id="and-go"&gt;And… Go!&lt;a class="headerlink" href="#and-go" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;I began this block of work with the moving of the if statement that avoided processing
any scenario test that included block quotes or lists starts.  Before that move, it
was buried in a large collection of if statements, and I wanted to make sure I called
it out until it was fixed. Making it even better, when I moved it, I broke that single
statement into three explicit statements. As I knew I was going to be enabling
each one in the next week or so, being explicit about that work just seemed like the
right thing to do.  But even though the move was mostly for aesthetics, I confess
that it was also to remind me that I only had those tokens left to go.&lt;/p&gt;
&lt;p&gt;Once that was completed, I did the easy work first and added the
&lt;code&gt;rehydrate_unordered_list_start&lt;/code&gt; function and the &lt;code&gt;rehydrate_unordered_list_start_end&lt;/code&gt;
function to the main processing loop.  After running the scenario tests again, I
was reminded by the test output that the &lt;code&gt;rehydrate_next_list_item&lt;/code&gt; function would have
to be added to deal with the Next List Item tokens in the stream.  Another quick run of
the tests and a lot of comparison failures, but no missing token failures.  A good
step in the right direction!&lt;/p&gt;
&lt;h3 id="first-step-list-indentation"&gt;First Step: List Indentation&lt;a class="headerlink" href="#first-step-list-indentation" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;With the actual token handlers dealt with, it was time to focus on the effects that
those tokens had
on the leaf blocks.  Following my usual pattern, instead of immediately creating a
new function to specifically handle the lists, I kept that code inline with the
existing &lt;code&gt;transform&lt;/code&gt; method the Markdown transformer.  While I recognize that it
looks messy and sloppy and the outset, it helps me think more clearly without worrying
about that I need to pass where.&lt;/p&gt;
&lt;p&gt;Therefore, following my usual pattern, I first added a simple post-processing step that
took the
contents of the variable &lt;code&gt;continue_seq&lt;/code&gt; and applied them to start of the output of
specific tokens.  The &lt;code&gt;continue_seq&lt;/code&gt; variable was initialized with an empty string,
but I altered the &lt;code&gt;rehydrate_unordered_list_start&lt;/code&gt; function to reset this variable
to the amount of indent specified by the list.  With the change in place, the end
of the loop processing was simple:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;        &lt;span class="n"&gt;new_data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;new_data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;replace&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;continue_seq&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This gained some traction in getting the
scenario tests passing, but that processing needed to be made a bit more complicated.  &lt;/p&gt;
&lt;p&gt;The first complication that needed to be addressed was that both list starts, and list
ends modified the &lt;code&gt;continue_seq&lt;/code&gt; variable, but needed to avoid applying it to
the line on which they element resided.  This was because the processing of the
Unordered List start token
already had the required indenting taking care of, so the postprocessing would just
add extra “garbage” whitespace. To remedy this, I added the &lt;code&gt;skip_merge&lt;/code&gt; variable to
allow the Unordered
List token handlers to inform the main loop to skip any post-processing.&lt;/p&gt;
&lt;p&gt;The second complication was the handling the list terminations using the
&lt;code&gt;rehydrate_unordered_list_start_end&lt;/code&gt; function.  In some of the easy cases, what was
there was fine, but as soon a list was nested in another list, that processing fell
apart.  What was missing was a recalculation of the indent level once the prior list
ends.  That was quickly addressed by doing a recalculation of the contents for the
&lt;code&gt;continue_seq&lt;/code&gt; variable for the new list token at the top of the stack.&lt;/p&gt;
&lt;p&gt;With those easy fixes, and with the main replacement call in the main loop, a lot
of the scenario tests were passing, while keeping the processing simple.&lt;/p&gt;
&lt;p&gt;That simplicity would soon change.&lt;/p&gt;
&lt;h3 id="indented-code-blocks"&gt;Indented Code Blocks&lt;a class="headerlink" href="#indented-code-blocks" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;As I went through the test failures, there were a few failures that stood out as an odd
grouping: indented code blocks and lists.  Doing some more research, I found out
that due to a bug in my code, the indented code blocks were not being checked
properly.  It only involved one list item scenario test, but nonetheless,
it still needed to be fixed.&lt;/p&gt;
&lt;p&gt;In that newly found bug, the problem was that the indented code blocks were always
adding their indented padding at the beginning of the lines.  This was not usually a
problem, but with any examples that contained blank lines within the indented code
block, it was an issue.  A good example of this is
&lt;a href="https://github.github.com/gfm/#example-81"&gt;example 81&lt;/a&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;    &lt;span class="n"&gt;chunk1&lt;/span&gt;

    &lt;span class="n"&gt;chunk2&lt;/span&gt;
&lt;span class="err"&gt;{&lt;/span&gt;&lt;span class="k"&gt;space&lt;/span&gt;&lt;span class="err"&gt;}{&lt;/span&gt;&lt;span class="k"&gt;space&lt;/span&gt;&lt;span class="err"&gt;}&lt;/span&gt;
&lt;span class="err"&gt;{&lt;/span&gt;&lt;span class="k"&gt;space&lt;/span&gt;&lt;span class="err"&gt;}&lt;/span&gt;
&lt;span class="err"&gt;{&lt;/span&gt;&lt;span class="k"&gt;space&lt;/span&gt;&lt;span class="err"&gt;}&lt;/span&gt;
    &lt;span class="n"&gt;chunk3&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;When the parser tokenizes this example, the Blank Line tokens that are generated
already include any whitespace that is present on that line.  Taking care of their own
whitespace data, when the Markdown transformer interprets those Blank Line tokens,
it needs to accept those Blank Line elements as they are.
Modifications were needed to enforce this behavior.  The &lt;code&gt;combine&lt;/code&gt; function of the
&lt;code&gt;TextMarkdownToken&lt;/code&gt; class containing the indented blank line was changed to insert
a NOOP character and then a newline character.  As text used in an indented code
block was the only &lt;code&gt;paragraph-like&lt;/code&gt; encapsulating token that inserted a blank line
into the composed text, had confidence this was isolated.&lt;/p&gt;
&lt;p&gt;With those NOOP characters in place, the Markdown transformer needed some modifications
to
understand how to deal with this.  Before proceeding with the normal insertion of
any whitespace in the &lt;code&gt;continue_seq&lt;/code&gt; variable, a quick check was made to see if
the &lt;code&gt;new_data&lt;/code&gt; variable contained a NOOP character.  If so, the string in the
&lt;code&gt;new_data&lt;/code&gt; variable was split and processed.  For each element in the split list,
the element was checked to see if it started with a NOOP character.  If it did it
simply removed the NOOP character by setting the &lt;code&gt;replacement_data&lt;/code&gt; variable to
the contents of the &lt;code&gt;new_data&lt;/code&gt; variable after that first NOOP character.  If it did not
find it, it set the &lt;code&gt;replacement_data&lt;/code&gt; variable to the contents of the &lt;code&gt;continue_seq&lt;/code&gt;
variable plus the contents of the &lt;code&gt;new_data&lt;/code&gt; variable.  Once that was done, the value
was put back in into the array at the same index.  Then,
when the processing was done, it reconstituted the &lt;code&gt;new_data&lt;/code&gt; variable by joining the
elements of the list back together using the &lt;code&gt;\n&lt;/code&gt; character as a joining character.&lt;/p&gt;
&lt;p&gt;While I was not looking for that, I was glad I found it. A bit embarrassed that I
did not find it right away, but I did find it!&lt;/p&gt;
&lt;h3 id="handling-lazy-continuations-lines"&gt;Handling Lazy Continuations Lines&lt;a class="headerlink" href="#handling-lazy-continuations-lines" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;With most of the scenario tests now passing, my focus was centered on a set of tests
that dealt with lists and lazy handling.  While this took me a bit to get my head
around, it basically says:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;If a string of lines Ls constitute a list item with contents Bs, then the result of deleting some or all the indentation from one or more lines in which the next non-whitespace character after the indentation is paragraph continuation text is a list item with the same contents and attributes. The unindented lines are called lazy continuation lines.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Huh?  Let me translate:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;If you have a list already started, and you encounter lines that should be in the list except for the fact that they are not indented properly, they are lazy continuation lines, and are included.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The best way to explain is with an example:&lt;sup id="fnref:lazyList"&gt;&lt;a class="footnote-ref" href="#fn:lazyList"&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nv"&gt;first&lt;/span&gt; &lt;span class="nv"&gt;list&lt;/span&gt; &lt;span class="nv"&gt;item&lt;/span&gt;
&lt;span class="k"&gt;next&lt;/span&gt; &lt;span class="nv"&gt;line&lt;/span&gt; &lt;span class="nv"&gt;of&lt;/span&gt; &lt;span class="nv"&gt;first&lt;/span&gt; &lt;span class="nv"&gt;list&lt;/span&gt; &lt;span class="nv"&gt;item&lt;/span&gt;
 &lt;span class="k"&gt;next&lt;/span&gt; &lt;span class="k"&gt;next&lt;/span&gt; &lt;span class="nv"&gt;line&lt;/span&gt; &lt;span class="nv"&gt;of&lt;/span&gt; &lt;span class="nv"&gt;first&lt;/span&gt; &lt;span class="nv"&gt;list&lt;/span&gt; &lt;span class="nv"&gt;item&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;In that example, all three of those lines are considered part of the list item, even
though the line is indented less than the indent of 2 specified by the initial list
item element.  But that presented a bit of a problem.&lt;/p&gt;
&lt;p&gt;When parsing the Markdown document, the indent level was being tracked, and any
additional whitespace was added to the contained token.  But as I was writing the
Markdown transformer, I noticed that I had missed the case where the amount of indent
was less than the current list’s indent level.  This was not an issue with the HTML
transformer, as that transformer does not rely on any of the extracted whitespace.
However, the Markdown transformer does.&lt;/p&gt;
&lt;p&gt;To fix this issue, I needed to first make a change in the &lt;code&gt;parse_paragraph&lt;/code&gt; function of
the &lt;code&gt;LeafBlockProcessor&lt;/code&gt; class.  In that function, I reconstituted the actual indent
of the given line and compared it against the indent level from the dominant unordered
list item token.  If that actual indent level was less than the dominant indent level,
I adjusted the actual whitespace by prefacing that whitespace with…well… blech
characters.&lt;/p&gt;
&lt;p&gt;Yes, blech characters.  Blech, according to
&lt;a href="https://www.merriam-webster.com/dictionary/blech"&gt;Webster’s&lt;/a&gt; means “used to express
disgust”.  While I knew I had to track those indenting characters somehow, I really
was not happy with it.  Disgust may be a bit too intense of an emotion, but when I
figured out what I had to do, that was the most printable word that I uttered.&lt;/p&gt;
&lt;p&gt;Using the above example, the tokenized text looks like:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;- first list item{newline}
{blech}{blech}next line of first list item{newline}
{blech}next next line of first list item{newline}
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;In this way, the indent was properly represented in the token, and the Markdown
transformer had enough information to rehydrate the data afterwards.  With those
changes locked into the tokens, the Markdown transformer was then able to be
changed to understand those tokens.  That processing was simple.  If a line of
the text output started with a blech character, those blech characters were
replaced with a space character.  If no blech characters were there, the normal
replacement of the newline character would occur.&lt;/p&gt;
&lt;p&gt;And I could
have changed the name of the character from “blech character”, but after a while,
it just kind of stuck with me.&lt;/p&gt;
&lt;h3 id="new-list-item-tokens"&gt;New List Item Tokens&lt;a class="headerlink" href="#new-list-item-tokens" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;It was about this time when I decided to tackle the New List Item tokens.  While I had
been working around them somewhat, it was starting to get to the point where they were
unavoidable.  At first, I did not think these tokens would be an issue, but I forgot
about one little part of the New List Item tokens: they reset the indent for the
list.&lt;/p&gt;
&lt;p&gt;A good example of this is &lt;a href="https://github.github.com/gfm/#example-290"&gt;example 290&lt;/a&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;a&lt;/span&gt;
 &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;b&lt;/span&gt;
  &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="k"&gt;c&lt;/span&gt;
   &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;d&lt;/span&gt;
  &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;e&lt;/span&gt;
 &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;f&lt;/span&gt;
&lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="k"&gt;g&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;In this case, the first line starts a list and each line after that starts a new list
item.  As the new list items are gradually increasing and then decreasing the indent,
the 3 middle lines (&lt;code&gt;c&lt;/code&gt;, &lt;code&gt;d&lt;/code&gt;, and &lt;code&gt;e&lt;/code&gt;) are interpreted as a new list item element,
rather than a sublist.  If it was not for the new list item elements resetting that
indent, those 3 lines are indented to the point where their indent would make them
eligible to start a new sublist.&lt;/p&gt;
&lt;p&gt;But to properly track this indent change, it required some interesting thinking.  If
I tracked the indent change in the actual token, it would mean changing that token.
To me, that was a non-starter.  Instead, I added a separate stack for container tokens
in the Markdown transformer and added copies of the container tokens to this stack.
As I added copies of the tokens to the stack, I was free to change the indent value
located within the Unordered List token without worrying about side effects.&lt;/p&gt;
&lt;p&gt;With those changes in place, the Markdown transformer was able to reset the indent
level and make sure it was being properly tracked.  This meant that the indents
were able to be properly reset to the correct value once a List Item end token was
received for a sublist.&lt;/p&gt;
&lt;p&gt;Taking a bit of a deep breath and a pause, I noticed that I was close to finishing
off the Unordered List Item tokens.  That gave me a bit of a jump in my step to
clean things up!&lt;/p&gt;
&lt;h2 id="taking-care-of-stragglers"&gt;Taking Care of Stragglers&lt;a class="headerlink" href="#taking-care-of-stragglers" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;With all the major and minor cases of lists dealt with, I started going through
the other scenario tests, fixing up the token lists after verifying that the new
tokens were correct.  Everything else was easily resolved at this point, except for
some lists in a couple of cases.  Those cases were interesting in that there was
actually too much whitespace, not too little.  And in this case, it was a newline
character, not a space.&lt;/p&gt;
&lt;p&gt;The Fenced Code Block element and the SetExt Heading element are unique in that they
have a line-based sequence that delimits the end of the element.  Usually this is not
a problem, but in the case of interacting with lists, the transformer was inserting
a newline after the element itself, and then another newline to make the end of that
line.  While this duplication did not occur all the time, it took a bit to figure
the exact sequence that triggered this.&lt;/p&gt;
&lt;p&gt;After doing some research, it was weird to me, but it only occurred if:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;it was one of these two elements&lt;/li&gt;
&lt;li&gt;the new block of data ends with a newline character&lt;/li&gt;
&lt;li&gt;the next token to be processed is a New List Item token&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;While the sequence of thing that had to occur was weird, the solution was easy:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;        &lt;span class="n"&gt;block_should_end_with_newline&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;False&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;next_token&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;token_name&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s2"&gt;"end-fcode-block"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;block_should_end_with_newline&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;True&lt;/span&gt;
            &lt;span class="n"&gt;delayed_continue&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;""&lt;/span&gt;
        &lt;span class="k"&gt;elif&lt;/span&gt; &lt;span class="n"&gt;next_token&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;token_name&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s2"&gt;"end-setext"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;block_should_end_with_newline&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;True&lt;/span&gt;
        &lt;span class="o"&gt;...&lt;/span&gt;
        &lt;span class="n"&gt;block_ends_with_newline&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; \
            &lt;span class="n"&gt;block_should_end_with_newline&lt;/span&gt; &lt;span class="ow"&gt;and&lt;/span&gt; &lt;span class="n"&gt;new_data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;endswith&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="o"&gt;...&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;
            &lt;span class="n"&gt;block_ends_with_newline&lt;/span&gt;
            &lt;span class="ow"&gt;and&lt;/span&gt; &lt;span class="n"&gt;next_one&lt;/span&gt;
            &lt;span class="ow"&gt;and&lt;/span&gt; &lt;span class="n"&gt;next_one&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;token_name&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;MarkdownToken&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;token_new_list_item&lt;/span&gt;
        &lt;span class="p"&gt;):&lt;/span&gt;
            &lt;span class="n"&gt;new_data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;new_data&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt; &lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;continue_seq&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Basically, if we hit that situation, just remove the excess character.  I was
hoping to refactor it into something more elegant, but it worked at the time and
I wanted to get on to the handling of Ordered List Item tokens.&lt;/p&gt;
&lt;h2 id="second-verse"&gt;Second Verse…&lt;a class="headerlink" href="#second-verse" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;I fondly remember being a kid at a summer camp and hearing the words “Second verse, same
the first, a little bit louder, and a little bit worse!”.  Working on the ordered list
tokens made me think of that saying almost immediately.  Except for the fact that it
was not a little bit worse, it was a lot easier.&lt;/p&gt;
&lt;p&gt;There were two main reasons for that.  The first reason is that looking at the samples as
a group, there are objectively fewer examples with ordered lists than unordered lists.
In the
&lt;a href="https://spec.commonmark.org/0.29/#list-items"&gt;list items section&lt;/a&gt;
of the GFM specification, there are 20 of each, but in the
&lt;a href="https://spec.commonmark.org/0.29/#lists"&gt;lists section&lt;/a&gt;
of the specification, there are 20 examples of unordered lists and 7 examples of ordered
lists.  The second reason was that most of the work was either completed when working on
the unordered list token transformations, or it was used in a copy-and-paste manner.&lt;/p&gt;
&lt;p&gt;However, knowing that lists are one of the two container elements in Markdown, I took
some extra time and reverified all the scenario tests, both ordered lists and unordered
lists.  I was able to find a couple of small things that were quickly fixed, but other
than that, everything looked fine!&lt;/p&gt;
&lt;h2 id="cleanup"&gt;Cleanup&lt;a class="headerlink" href="#cleanup" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;As with a lot of my free project time recently, I used some extra time that I had to
focus on a few cleanup items for the project.  While none of them was important
on its own, I just felt that the project would be cleaner with them done.&lt;/p&gt;
&lt;p&gt;The first one was an easy one, going through the HTML transformer and the Markdown
transformer, and ensuring that all the token handlers were private.  There really
was not any pressing need to do this, but it was just cleaner.  The only code that was
using those handlers was in the same class, so it was just tidier that way.&lt;/p&gt;
&lt;p&gt;Next was the creation of the &lt;code&gt;__create_link_token&lt;/code&gt; function to help tidy up the
&lt;code&gt;__handle_link_types&lt;/code&gt; function.  The &lt;code&gt;__handle_link_types&lt;/code&gt; function was already messy
enough handling the processing of the link information, the creating of the normal or
image link was just complicating things.  While I still want to go back and clean
functions like that up, for the time, moving the creation code to &lt;code&gt;__create_link_token&lt;/code&gt;
was a good step.&lt;/p&gt;
&lt;p&gt;Finally, there was the case of the justification function calls throughout the code.
Not to sound like a purist, but I felt that they were messy.  I often had to remind
myself of what the three operands were: string to perform on, the justification amount,
and the character to use for the justification.  The actual use of the function was
correct, it just felt like its usage was not clear.  So instead of having code
like this around the code base:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;        &lt;span class="n"&gt;some_value&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;""&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;rjust&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;repeat_count&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;character_to_repeat&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;I replaced it with:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;        &lt;span class="n"&gt;some_value&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;ParserHelper&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;repeat_string&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;character_to_repeat&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;repeat_count&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;While the code for this operation was a one-line function, now located in the
&lt;code&gt;ParserHelper&lt;/code&gt; class, I felt it now made sense and was in an easy to find
place.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;repeat_string&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;string_to_repeat&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;repeat_count&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="sd"&gt;"""&lt;/span&gt;
&lt;span class="sd"&gt;        Repeat the given character the specified number of times.&lt;/span&gt;
&lt;span class="sd"&gt;        """&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="s2"&gt;""&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;rjust&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;repeat_count&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;string_to_repeat&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h1 id="fixing-example-528"&gt;“Fixing” Example 528&lt;a class="headerlink" href="#fixing-example-528" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;I do not want to spoil the surprise too much, but the fact that I have a section called
&lt;code&gt;"Fixing" Example 528&lt;/code&gt; probably gives it away.  I fixed it.  But the story is more
interesting than that.&lt;/p&gt;
&lt;p&gt;In the last article, I talked about
&lt;a href="https://github.github.com/gfm/#example-528"&gt;example 528&lt;/a&gt;
and how I was having problems getting it to
&lt;a href="https://jackdewinter.github.io/2020/08/10/markdown-linter-adding-links-to-the-markdown-transformer/#example-528"&gt;parse properly&lt;/a&gt;.
Even having done thorough research on the example and the algorithm, I came up with
nothing.  To me, it looked like the parsing was being performed according to the
&lt;a href="(https://github.github.com/gfm/#phase-2-inline-structure)"&gt;GFM specification’s algorithm&lt;/a&gt;,
but the parsing was just off.  After yet another attempt to figure this example out
and get it working, I posted my research and a request for help to the CommonMark
&lt;a href="https://talk.commonmark.org/t/spec-algorithm-error-in-links-within-links-within-images/3571"&gt;discussion forums.&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Keeping my head down and focused on writing that week’s article, I did not notice that I
had received a reply the very next day.  As a matter of fact, while I did notice that I
had a response to my post, it was not until Friday night that it clicked that it was a
response to “THAT” post.  After getting the cleanup documented in the previous section
taken care of, I reserved some dedicated time to walk through the reply.&lt;/p&gt;
&lt;h2 id="kudos"&gt;Kudos&lt;a class="headerlink" href="#kudos" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;First off, I would like to extend kudos to the replier, John MacFarlane, one of the
maintainers of the Markdown GFM specification.  While he would have been within his
right to tell me to RTFM&lt;sup id="fnref:RTFM"&gt;&lt;a class="footnote-ref" href="#fn:RTFM"&gt;2&lt;/a&gt;&lt;/sup&gt;, he took some time to walk me through the algorithm
as it applied to that example, even providing me with some debug output from his
program for that example.  His response was just a classy response with just the
right amount of information.&lt;/p&gt;
&lt;h2 id="side-by-side-comparisons"&gt;Side by Side Comparisons&lt;a class="headerlink" href="#side-by-side-comparisons" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Armed with that new information, I turned on the debug output and ran through the output
from my implementation of the algorithm again.  Slowly, with my own written notes as an
additional guide, I began to walk through the output.  &lt;code&gt;Found closer at 8&lt;/code&gt;.  Check.
&lt;code&gt;Found matching opener at 4&lt;/code&gt;. Check.  &lt;code&gt;Deactivating opener at 3&lt;/code&gt;. Check.
&lt;code&gt;Found closer at 15&lt;/code&gt;.  Check.  &lt;code&gt;Popping inactive opener at 3&lt;/code&gt;.  Ch…er… what?
“Popping”?&lt;/p&gt;
&lt;p&gt;Going back to the algorithm and the text that John provided, it hit me.  The popping that
he was referring to was this part of the algorithm:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;If we do find one, but it’s not active, we remove the inactive delimiter from the stack, and return a literal text node ].&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;For some reason, when I read that before, I thought it was referring to removing the
token from consideration, not actually removing it from the stack.  It probably also
confused things in that I did not maintain a separate stack for the link resolution.
Instead, I added an instance of the &lt;code&gt;SpecialTextMarkdownToken&lt;/code&gt; token to the inline block
list whenever I hit a link sequence.  In either case, I was not doing that.  To compound
the issue, I did not stop at that inactive token, I just kept on looking for the next
active &lt;code&gt;SpecialTextMarkdownToken&lt;/code&gt; token, finding the image start token.  Ah… everything
was now falling into place in my mind.&lt;/p&gt;
&lt;h2 id="fixing-the-issue"&gt;Fixing the Issue&lt;a class="headerlink" href="#fixing-the-issue" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;The fix was very anticlimactic.  I created the new
&lt;code&gt;__revert_token_to_normal_text_token&lt;/code&gt; function, which removed the
&lt;code&gt;SpecialTextMarkdownToken&lt;/code&gt; token and replaced it with a normal &lt;code&gt;TextMarkdownToken&lt;/code&gt;
token.  In addition, I changed the algorithm to make sure that when this happened,
it stopped processing for that link end sequence, as per the algorithm.  With the start
character sequence now being effectively invisible to the algorithm, the rest of the
parsing went fine, with the correct results coming out.  Well, almost.  A small fix was
needed to the
&lt;code&gt;__consume_text_for_image_alt_text&lt;/code&gt; function to make it properly emit the correct text
if an instance of a &lt;code&gt;SpecialTextMarkdownToken&lt;/code&gt; token was encountered.&lt;/p&gt;
&lt;p&gt;With the big fix and the little fix both completed, the scenario test for Example 528
was fully enabled and fully passing.  Finally!&lt;/p&gt;
&lt;h3 id="reminder-to-self-be-humble"&gt;Reminder to Self: Be Humble&lt;a class="headerlink" href="#reminder-to-self-be-humble" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Having taken a quite a few attempts at implementing the algorithm and making sure it
passed all test cases, I hit a wall. A seemingly rock-solid wall.  That was fine.
During any project, be it software or hardware, things happen.  When it got to
that point, I gave myself some time, I knuckled down&lt;sup id="fnref:knuck"&gt;&lt;a class="footnote-ref" href="#fn:knuck"&gt;3&lt;/a&gt;&lt;/sup&gt;, and I did some solid
research on the problem.  Keeping good notes, I was then able to share those notes with
peers in the community, along with a sincere and humble request for help.&lt;/p&gt;
&lt;p&gt;I do not always get a good response to requests for help.  However, I have noticed that
doing good research and presenting that research with humility increases the chance of
getting a positive response.  At no point did I rant and say, “it’s broken” or
“my way works, what is wrong with yours”.  Instead I said, “Is there something wrong
with the algorithm?” and
“Based on my implementation of that algorithm”.  By acknowledging that it could be an
issue with my implementation, I feel that I opened the doors for someone to help, rather
than slamming them shut with negative talk.&lt;/p&gt;
&lt;p&gt;And as I mentioned in the Kudos section above, mostly in what I believe was a humble
approach to asking for help, I got a real good response.&lt;/p&gt;
&lt;h2 id="what-was-my-experience-so-far"&gt;What Was My Experience So Far?&lt;a class="headerlink" href="#what-was-my-experience-so-far" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Wow… that work was intense.  For one, I was right, it was a lot of addressing issues
with whitespace and running scenario tests repeatedly.  But it was more than
that for me.  I knew I had the leaf blocks taken care of, but I was really concerned
about how difficult the implementation of the container transformations would be. If
I did it right and kept to my design, I was confident that I could keep the complexity
down, but I still figured it would be complex.&lt;/p&gt;
&lt;p&gt;I guess that led to me second guessing every line of code and getting in the way of
myself a bit.  I did prevail, but that concern or fear of damaging existing tests was
somewhat paralyzing at times.  And while the logical half of my brain was telling me
that I had plenty of tests to reinforce my completed work, the emotional half was
another story.  That is where that fear was coming from, my emotional side.  Only
when I took a moment to take another breath and focus on the tests was I able to banish
that concern for a while.&lt;/p&gt;
&lt;p&gt;And it also helped me to do a bit of self-analysis on why I was concerned.  After a lot
of thinking, I came to a simple conclusion. The closer I get closer to getting a
complete project, the more I am concerned that I have not architected and designed it
properly.  If I have done that, small changes can be accomplished with few or no
unintended side effects.  If not, encountering side effects should be frequent.
Seeing as I know I have identified some areas of the code
base that I want to refactor, I questioned whether the current state was good enough.&lt;/p&gt;
&lt;p&gt;Knowing that, it helped me figure it out for myself.  I do believe that I have
confidence with my
architecture and design, and at the same time, I believe that I can improve it.
It might seem like a dichotomy, but I am starting to think that both can be correct
at the same time.  But knowing that was the issue that was causing me concern helps
me combat it.  I am a lot less worried about it, but it is a work in progress,
much like the project.&lt;/p&gt;
&lt;p&gt;With that information in hand, I felt better.  Cautious about the next steps in getting
the checks closer to the finish line, but better! And let’s not forget about finally
closing the issue with Example 528.  That was good!&lt;/p&gt;
&lt;h2 id="what-is-next"&gt;What is Next?&lt;a class="headerlink" href="#what-is-next" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;With the Markdown transformer almost completed, the only tokens left that need a
transformation are the Block Quote tokens.  In addition, as the line/column number
consistency checks do not currently deal with Block Quote tokens either, I will need
to add both checks in the next block of work.&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr/&gt;
&lt;ol&gt;
&lt;li id="fn:lazyList"&gt;
&lt;p&gt;The only example 249, but ordered list. &lt;a class="footnote-backref" href="#fnref:lazyList" title="Jump back to footnote 1 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:RTFM"&gt;
&lt;p&gt;Read The F&amp;amp;$#ing Manual… or I guess RTFS in this case. &lt;a class="footnote-backref" href="#fnref:RTFM" title="Jump back to footnote 2 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:knuck"&gt;
&lt;p&gt;According to &lt;a href="https://www.merriam-webster.com/thesaurus/knuckle%20down"&gt;Webster’s&lt;/a&gt;: “pitch in, dig in”. &lt;a class="footnote-backref" href="#fnref:knuck" title="Jump back to footnote 3 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</content><category term="Software Quality"></category><category term="markdown linter"></category><category term="core linter"></category></entry><entry><title>Python Projects - Using PipEnv</title><link href="https://jackdewinter.github.io/2020/08/14/python-projects-using-pipenv/" rel="alternate"></link><published>2020-08-14T00:00:00-07:00</published><updated>2020-08-14T00:00:00-07:00</updated><author><name>Jack De Winter</name></author><id>tag:jackdewinter.github.io,2020-08-14:/2020/08/14/python-projects-using-pipenv/</id><summary type="html">
&lt;h2 id="summary"&gt;Summary&lt;a class="headerlink" href="#summary" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;With almost a year of Python development under my belt, I wanted to start talking about
the Python elements that I feel have made my development of the
&lt;a href="https://github.com/jackdewinter/pymarkdown"&gt;PyMarkdown project&lt;/a&gt;
successful.  When thinking about where to start, the first thing that came to mind was
my use of PipEnv …&lt;/p&gt;</summary><content type="html">
&lt;h2 id="summary"&gt;Summary&lt;a class="headerlink" href="#summary" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;With almost a year of Python development under my belt, I wanted to start talking about
the Python elements that I feel have made my development of the
&lt;a href="https://github.com/jackdewinter/pymarkdown"&gt;PyMarkdown project&lt;/a&gt;
successful.  When thinking about where to start, the first thing that came to mind was
my use of PipEnv to maintain the project environment.&lt;/p&gt;
&lt;h2 id="introduction"&gt;Introduction&lt;a class="headerlink" href="#introduction" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;While I am relatively new to Python, I am an old hat at trying to maintain a cohesive
way to keep my projects usable yet portable.  From my early days in C and Pascal to my
current days in Go and Java, I have always tried to have a cohesive story around how to
package my project’s source code to be used by multiple developers.  In the end, I
found that the main goals were always the same: how do I keep a project usable by all
interested developers, while keeping the maintenance of that project to a minimum?&lt;/p&gt;
&lt;p&gt;From my point of view,
&lt;a href="https://pipenv.pypa.io/en/latest/"&gt;PipEnv&lt;/a&gt;
meets those goals for Python by solving a lot of the common issues that project
maintainers and developers have.  This in turn makes two of the harder parts of
developing programs mostly disappear: dependency management and portability.  Using the
simple command &lt;code&gt;pip install --user pipenv&lt;/code&gt; to install into any Python system, PipEnv quickly became a useful tool in my toolbox and has stayed there.
During this article, I will talk about why PipEnv keeps that position in my toolbox.&lt;/p&gt;
&lt;h2 id="quick-note"&gt;Quick Note&lt;a class="headerlink" href="#quick-note" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;While I realize some projects may still be on Python version 2, this article is
targeted for people developing on Python 3 and above.  More precisely, these examples
were all tested with Python 3.7.&lt;/p&gt;
&lt;h2 id="what-is-pipenv"&gt;What Is PipEnv?&lt;a class="headerlink" href="#what-is-pipenv" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;While the full answer can be seen at the top of the
&lt;a href="https://pipenv.pypa.io/en/latest/"&gt;PipEnv home page&lt;/a&gt;,
my summary of that answer is as follows:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;PipEnv is a Python module that cleanly manages your Python project and its dependencies, ensuring that the project can be easily rebuilt on other systems.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;While that might seem like an easy thing to accomplish, PipEnv or tools like it are
usually only employed after a journey through other, less efficient solutions.&lt;/p&gt;
&lt;p&gt;To understand those solutions and the problems that they present, let’s start at
the beginning with dependency management.&lt;/p&gt;
&lt;h3 id="starting-with-dependencies"&gt;Starting with Dependencies&lt;a class="headerlink" href="#starting-with-dependencies" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;In Python, as with most modern languages, a lot of the heavy lifting is done in
libraries.  For Python, these libraries must be installed directly into the current
instance of Python for those libraries to be visible to the Python programs.  The most
common way of installing and managing those libraries locally is to use the
&lt;a href="https://pip.pypa.io/en/stable/"&gt;&lt;code&gt;pip&lt;/code&gt;&lt;/a&gt;
tool. For example, to add the latest version of the &lt;code&gt;colorama&lt;/code&gt; library to the local
Python installation, the following command is used:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;pip install colorama
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;But that command has a problem in that it installs the specified library into the global
instance of Python.  Even addressing that problem using a user-specific variation of
that command:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;pip install --user colorama
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;that caching still takes effect for all Python programs that are run as that user.
That is a bit better, but not optimal.&lt;/p&gt;
&lt;p&gt;The big issue is that it is hard to replicate which libraries are installed for any given project without maintaining a per-project
script with many lines in it, one for each library. With multiple projects sharing the
same global cache of libraries, a clear way to enforce the libraries and versions
needed for a specific project is needed.&lt;/p&gt;
&lt;p&gt;Enter the &lt;code&gt;requirements.txt&lt;/code&gt; file.&lt;/p&gt;
&lt;h3 id="explicitly-specifying-requirements-as-code"&gt;Explicitly Specifying Requirements as Code&lt;a class="headerlink" href="#explicitly-specifying-requirements-as-code" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;The first step that many people take on their Python project journey is to create a
&lt;code&gt;requirements.txt&lt;/code&gt; file to hold all the library requirements for their project. The
file has a format of:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;colorama=0.4.3
Pygments==2.4.2
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;with each library being listed on its own line, optionally followed by the version
of the library to install. To apply these library requirements to a given Python
environment, the command:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;pip install --user -r requirements.txt
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;is used.  This usage of &lt;code&gt;pip&lt;/code&gt; is used as a shortcut for having to call &lt;code&gt;pip install&lt;/code&gt;
once for every library needed in the project.  By
this point in the project process, most developers understand that nailing down a
specific version of the library being used is critical to the project’s success.  By
specifying an exact version of the library to be referenced, the &lt;code&gt;pip&lt;/code&gt; tool guarantees
that it will always reference that specific version of the library, locking down the
behavior of the library and making it predictable.&lt;/p&gt;
&lt;p&gt;While the tool usage is simple enough, there are problems with using the &lt;code&gt;pip&lt;/code&gt; tool
in this way.  The first problem is that to ensure that I have the right libraries for
my program, every time I run that program, I need to re-run that
&lt;code&gt;pip install --user -r requirements.txt&lt;/code&gt; command before I run my program.  If I do not
run that command, I risk the chance that another program has changed
the libraries on my program, either causing the program to fail or rendering its output
questionable.  Even when I created a script to run the above command and my program
together, I felt that the combination often feels slow, bothersome, and inelegant.&lt;/p&gt;
&lt;p&gt;The second problem is that of “phantom” dependencies.  For argument’s sake, let’s assume
that I am maintaining 2 projects and their dependencies.  Project A has a dependency
on Library 1 and Project B has a dependency on Library 2, with Library 1 and
Library 2 being separate libraries.  Furthermore, let’s assume that both
projects use a &lt;code&gt;requirements.txt&lt;/code&gt; file and the above &lt;code&gt;pipenv install&lt;/code&gt; method to manage
their project
dependencies.  Because of the way these files are applied, if Project B is used after
Project A, it retains access to Library 1 that was installed by Project A.  After
all, with nothing to remove Project A’s dependencies, they stay in the user’s global
cache of libraries.  This means Project B’s dependencies are not clearly defined and
may prove difficult to replicate on someone else’s machine.&lt;/p&gt;
&lt;p&gt;Given those problems, how can the project move away from using global library caches?&lt;/p&gt;
&lt;h3 id="another-step-forward-virtual-environments"&gt;Another Step Forward: Virtual Environments&lt;a class="headerlink" href="#another-step-forward-virtual-environments" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;The next step forward is to use the tools accumulated so far and to add virtual
environments into that group of tools.  Installed using the following command:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;pip install --user virtualenv
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;the user can then run the following command to create a virtual environment under the
current directory:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;virtualenv venv
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This command may take some time to complete, but once it is done, there will be a local
&lt;code&gt;virtualenv&lt;/code&gt; directory that contains a completely distinct version of the Python
installation that it was created from.&lt;/p&gt;
&lt;p&gt;Even with that environment in place, there is some work to do before executing the
project’s Python program.  To use the virtual environment, the execution of an
activator script is
required to set the shell’s environment to point at the correct environment.
Located in either the
&lt;code&gt;virtualenv\Scripts&lt;/code&gt; directory (on Windows systems) or the &lt;code&gt;virtualenv\bin&lt;/code&gt; directory
(on Posix systems) are a group of scripts with the name &lt;code&gt;activate&lt;/code&gt; or matching the
pattern &lt;code&gt;activate.*&lt;/code&gt;.  Executing the correct script activates the virtual environment
for a given shell, isolating any changes to the Python environment into that
virtual environment.&lt;/p&gt;
&lt;p&gt;The usage of this tool seems beneficial so far, so what are the issues with this tool?
The
big issue for me is that you must remember to deactivate the environment before
leaving the project folder.  If you do not deactivate the environment before leaving the
project’s directories, you can be doing something else in another directory and forget
the directory that you anchored that environment to .  Without noticing it, a simple
&lt;code&gt;pip install&lt;/code&gt; command will then alter the requirements of that environment, and not of
the environment in the current directory.   This is a realistic scenario.  In my early
days of Python development, I did this numerous times!  And each time, it took a while to
figure out what I had done and how to reverse it.&lt;/p&gt;
&lt;p&gt;A smaller issue with these environments is that they are specific to the local system
but are anchored within the project.  This means that when dealing with version control
systems such as Git, the project needs to explicitly ignore the files in the project’s
&lt;code&gt;virtualenv&lt;/code&gt; directory to prevent local environment files from being committed.
However, even with that directory ignored, the project requires extra scripts as part
of its project code that specify how developers need to create the required virtual
environment.&lt;/p&gt;
&lt;p&gt;Given those issues, how do we take the best parts of &lt;code&gt;pip&lt;/code&gt; and &lt;code&gt;virtualenv&lt;/code&gt; and merge
them together?&lt;/p&gt;
&lt;h3 id="enter-pipenv"&gt;Enter PipEnv&lt;a class="headerlink" href="#enter-pipenv" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Installed using the following command:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;pip install --user pipenv
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;code&gt;PipEnv&lt;/code&gt; combines the best aspects of the previous concepts while getting rid of a fair
number of the problems.  To illustrate this, I created a sample project from scratch to
say, “Hello world!”  Setting up the project was easy.  I created a new directory,
changed my current directory to that directory, and entered the command:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;pipenv --three
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;It took a while for the command to complete, but upon its completion I had a directory
that contained the file &lt;code&gt;Pipfile&lt;/code&gt; and a “hidden”&lt;sup id="fnref:hidden"&gt;&lt;a class="footnote-ref" href="#fn:hidden"&gt;1&lt;/a&gt;&lt;/sup&gt; virtual environment.  To see
the location of that virtual environment, I entered the command:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;pipenv --venv
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;and PipEnv returned the path to the virtual environment.  To be specific, it created
a virtual environment that was not in my project directory, but in my local system’s
user space. This meant that the virtual environment directory did not show up in any
scans of the project directory, meaning that I did not have to ignore that directory
by any version control systems.  That was definitely a win!&lt;/p&gt;
&lt;p&gt;From there, I decided I wanted to add a splash of color to the program, brightening up
a normally dull Hello World program.  While a simple Hello World program would look
like this:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"Hello World!"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;I decided to go with using the &lt;code&gt;colorama&lt;/code&gt; library to add that color.  Installing the
&lt;code&gt;colorama&lt;/code&gt; library to the current project was easy, using the following command:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;pipenv install colorama
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;That command looked for the latest version of the &lt;code&gt;colorama&lt;/code&gt; library, installed it in
the virtual environment, updated the &lt;code&gt;Pipfile&lt;/code&gt; and generated a new &lt;code&gt;Pipfile.lock&lt;/code&gt; file.
Once that was completed, I created the file &lt;code&gt;main.py&lt;/code&gt; with the following contents:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;colorama&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;init&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Fore&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Back&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Style&lt;/span&gt;

&lt;span class="n"&gt;init&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"Hello "&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;Fore&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;BLACK&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;Back&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;GREEN&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="s2"&gt;"World!"&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;Style&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;RESET_ALL&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;and saved that file.  After a quick check for spelling and grammar mistakes, I executed
that program with the command:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;pipenv run python main.py
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;and I was greeted with this response:&lt;/p&gt;
&lt;p&gt;&lt;img alt="image" src="https://jackdewinter.github.io/images/project-1/hello_world.png"/&gt;&lt;/p&gt;
&lt;p&gt;To be clear, with 3 commands and 3 lines of Python code, I was able to create a simple
program that referenced a library to colorize the output for my simple program and to
write a single line of text to the console.  An even bigger win for me was that I knew
that if I needed this project to be portable, I could easily bundle up the source in
the directory and recreate the project elsewhere.  Having used PipEnv for months, this
was not a theory for me, this was something that I have done in practice multiple times.&lt;/p&gt;
&lt;p&gt;But unless you have performed that action, it may be hard to appreciate.  So let’s
prove it!&lt;/p&gt;
&lt;h3 id="proving-that-the-project-really-is-portable"&gt;Proving That the Project Really Is Portable&lt;a class="headerlink" href="#proving-that-the-project-really-is-portable" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;To prove that the project is portable, I created a separate directory and copied the
contents of my sample directory into that directory.  While that is not exactly what
happens when I clone a project from Git, I believe it is a close enough estimate for
the purpose of this example.  To be specific, there were only 3 files in the source
directory for my sample project, and all of them were copied over: &lt;code&gt;main.py&lt;/code&gt;,
&lt;code&gt;Pipfile&lt;/code&gt;, and &lt;code&gt;Pipfile.lock&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;To properly setup the project, I entered the directory and executed the command:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;pipenv sync
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;After a while, control returned to my shell, with the &lt;code&gt;pipenv&lt;/code&gt; output clearly detailing
that it created a new virtual environment and downloaded the needed libraries.&lt;/p&gt;
&lt;p&gt;&lt;img alt="image" src="https://jackdewinter.github.io/images/project-1/sync.png"/&gt;&lt;/p&gt;
&lt;p&gt;From there, entering the command:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;pipenv run python main.py
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;yielded the same output as the example project in the original directory.&lt;/p&gt;
&lt;p&gt;&lt;img alt="image" src="https://jackdewinter.github.io/images/project-1/hello_world.png"/&gt; &lt;sup id="fnref:myWord"&gt;&lt;a class="footnote-ref" href="#fn:myWord"&gt;2&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;p&gt;While the
typical project will be more complicated than this small project, the underlying
principles are the same.  If a project uses PipEnv to manage library dependencies,
the &lt;code&gt;Pipfile&lt;/code&gt; and &lt;code&gt;Pipfile.lock&lt;/code&gt; files become part of the project’s source and
allows the project’s dependencies to be replicated in another directory or on another
system.&lt;/p&gt;
&lt;p&gt;Satisfied with the portability test passing, and not wanting to be a bad consumer of
system resources, I then used the following command to remove the virtual environment
from my local machine:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;pipenv --rm
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;By using the &lt;code&gt;pipenv --venv&lt;/code&gt; command both before and after this command, I was
able to verify that the directory containing the virtual environment was removed from
my local system.&lt;/p&gt;
&lt;h2 id="why-do-i-like-it"&gt;Why Do I Like It?&lt;a class="headerlink" href="#why-do-i-like-it" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;I like using PipEnv because it is simple to setup, simple to maintain, and easy to
use.  I am lazy in that I want to have the right tools at my fingertips to do the simple
and easy stuff for me.  Having to remember to activate a virtual environment when I go
into a directory and deactivate it when I leave was a headache.  There were many times
I forgot to do just that, and it caused a bit of chaos.&lt;/p&gt;
&lt;p&gt;I feel that PipEnv keeps everything I need together and keeps it in the right place
for me: the base of the project.  If I need to run a Python script from the project,
I use &lt;code&gt;pipenv run python {script-name}.py&lt;/code&gt;, a format that makes sense to me. If I need
to check the project’s dependencies, the &lt;code&gt;pipenv graph&lt;/code&gt; command is there, with an
intuitive output format. If I need to recreate the project in a new directory, the
&lt;code&gt;pipenv sync&lt;/code&gt; command is there, and completes its job properly&lt;/p&gt;
&lt;p&gt;Basically, it is a tool that I find useful and that I think makes sense.&lt;/p&gt;
&lt;h2 id="wrap-up"&gt;Wrap Up&lt;a class="headerlink" href="#wrap-up" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;While there are options out there on how to maintain Python projects, the
one that I prefer is PipEnv.  Newer options exist, such as
&lt;a href="https://python-poetry.org/"&gt;Poetry&lt;/a&gt;,
but for projects that I rely on, I want something that has been battle tested
thoroughly.&lt;/p&gt;
&lt;p&gt;I feel that PipEnv is the best option that easily meets my requirements.&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr/&gt;
&lt;ol&gt;
&lt;li id="fn:hidden"&gt;
&lt;p&gt;The directory is not hidden according to the file system.  However, from the project’s point of view, it does not appear anywhere within the bounds of the project. &lt;a class="footnote-backref" href="#fnref:hidden" title="Jump back to footnote 1 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:myWord"&gt;
&lt;p&gt;You’ll have to take my word that the output was the same.  I am using the same picture for both, but that is only because the output was the same. &lt;a class="footnote-backref" href="#fnref:myWord" title="Jump back to footnote 2 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</content><category term="Software Quality"></category><category term="python"></category><category term="python projects"></category></entry><entry><title>Markdown Linter - Adding Links to the Markdown Transformer</title><link href="https://jackdewinter.github.io/2020/08/10/markdown-linter-adding-links-to-the-markdown-transformer/" rel="alternate"></link><published>2020-08-10T00:00:00-07:00</published><updated>2020-08-10T00:00:00-07:00</updated><author><name>Jack De Winter</name></author><id>tag:jackdewinter.github.io,2020-08-10:/2020/08/10/markdown-linter-adding-links-to-the-markdown-transformer/</id><summary type="html">
&lt;h2 id="summary"&gt;Summary&lt;a class="headerlink" href="#summary" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;In my
&lt;a href="https://jackdewinter.github.io/2020/08/03/markdown-linter-improving-the-markdown-transformer/"&gt;last article&lt;/a&gt;,
I increased the coverage provided by the token to Markdown transformer by adding
support for all tokens except for container related tokens and link related tokens.
In this article, I take a large step forward towards complete consistency checks by
adding support for link related …&lt;/p&gt;</summary><content type="html">
&lt;h2 id="summary"&gt;Summary&lt;a class="headerlink" href="#summary" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;In my
&lt;a href="https://jackdewinter.github.io/2020/08/03/markdown-linter-improving-the-markdown-transformer/"&gt;last article&lt;/a&gt;,
I increased the coverage provided by the token to Markdown transformer by adding
support for all tokens except for container related tokens and link related tokens.
In this article, I take a large step forward towards complete consistency checks by
adding support for link related tokens.&lt;/p&gt;
&lt;h2 id="introduction"&gt;Introduction&lt;a class="headerlink" href="#introduction" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Starting with a large group of tokens to implement, I was now down to two smaller
groups of tokens left to implement in the Markdown transformer: container related
tokens and link related tokens.  Before starting with the container related tokens, I
wanted to make sure that all the leaf block tokens were complete, so the link related
tokens were the solid choice for the next block of work.  But even with confidence in
that choice I was still concerned.&lt;/p&gt;
&lt;p&gt;Why was I concerned?  Because outside of container related tokens and text tokens, I
feel that link related tokens are the most used group of tokens.  While a good
argument can also be made that Atx Heading token is the most used token, I feel that
the importance of links in any document somewhat overpowers the argument for the Atx
Heading token, if only a bit. In my own writing, I believe headings are useful,
but I feel that it is the links that I add to a document that really increase the
quality of my documents to the next level.  It is possible that others may not agree
with my reasoning, but it was one of the sources of my concern.&lt;/p&gt;
&lt;p&gt;Another reason for my concern?  Links are complex.  Just on a normal link alone, I
counted at least 12
different properties that I am going to have to represent in the token to allow me to
properly rehydrate it.  And then there are the Link Reference Definitions, the only
multiline element in the base GFM document.  I hoped that I already had dealt with most
of the complexity of that token, but I knew that adding support for this group of tokens
to the Markdown transformer was going to include some serious work.&lt;/p&gt;
&lt;p&gt;Regardless of how often the link related tokens are used or how difficult I thought they would be to be implemented, they needed to be implemented.  And as the last group
of tokens before the container tokens, the time was now to work on them.&lt;/p&gt;
&lt;h2 id="what-is-the-audience-for-this-article"&gt;What Is the Audience for This Article?&lt;a class="headerlink" href="#what-is-the-audience-for-this-article" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;While detailed more eloquently in
&lt;a href="https://jackdewinter.github.io/2020/04/05/what-is-the-audience-for-my-blog/#what-is-the-audience-for-my-blog"&gt;this article&lt;/a&gt;,
my goal for this technical article is to focus on the reasoning behind my solutions,
rather that the solutions themselves.  For a full record of the solutions presented in
this article, please go to this project’s GitHub repository and consult the
commits between
&lt;a href="https://github.com/jackdewinter/pymarkdown/commit/73e7634b99bc05c2484f9ce672648170a84beb17"&gt;31 Jul 2020&lt;/a&gt;
and
&lt;a href="https://github.com/jackdewinter/pymarkdown/commit/7151ea88a180bdc4b977940e90e9db4908b13ede"&gt;31 Jul 2020&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id="where-to-start"&gt;Where to Start?&lt;a class="headerlink" href="#where-to-start" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Before I started making any changes, I knew I was going to take a significant amount of
time to complete the work on links.  I also knew that all that work was not going to
just happen. To get it right, I needed to plan it out properly.&lt;/p&gt;
&lt;p&gt;I started that process by breaking down the Link tokens groups into 4 smaller groups:
Inline Links, Reference Links, Link Reference Definitions, and Image Links.  The Image
Link tokens were the first one to get prioritized into the first position, as they had
no dependencies and could set the foundations for the other groups.  Next, I looked at
the Image Link
tokens. As Image Link tokens were normal Link tokens with a couple of differences, it
made sense to me that they would go last.  By going last, the link token foundations
would be tested and stable before adding support for the Image tokens on top of that.
That just left the Link Reference Definition tokens and Reference Link tokens.&lt;/p&gt;
&lt;p&gt;The ordering between Link Reference Definition tokens and Reference Link tokens was
going to be a bit tricky, but it would be a process that I knew I could manage.  To
ensure that I could
properly test the Link Reference Definition tokens, I needed to start with a
rudimentary rehydration of the Shortcut Link token.  Once that was done, I
could complete the work for the Link Reference Definition tokens, hopefully not
hitting any difficult Shortcut Link tokens cases or other link types along the way.  At
that point, I could switch back to the Shortcut Link token scenario tests before
completing the other Link scenario tests.&lt;/p&gt;
&lt;p&gt;With research done, the relative ordering of the tasks was easy.
Start with Inline Link tokens with their lack of dependencies.  Then work on the
pair of Link Reference Definition tokens and Reference Link tokens, using the Inline
Link tokens as a foundation.  Finally, work on Image tokens using all that other work
as a solid foundation to make the changes required of the transformer.&lt;/p&gt;
&lt;p&gt;It was not a complicated plan, but it was a decent plan that I believed in.  And
with that plan in place, I started to work on Inline links!&lt;/p&gt;
&lt;h2 id="inline-links"&gt;Inline Links&lt;a class="headerlink" href="#inline-links" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;In the same way that I start all my transformer additions, like the addition of
&lt;a href="https://jackdewinter.github.io/2020/08/03/markdown-linter-improving-the-markdown-transformer/#adding-emphasis-support"&gt;emphasis support&lt;/a&gt;
in the last article, I found a
good, easy example and started with the scenario test for that example.  The needs to
pass that first scenario test,
&lt;a href="https://github.github.com/gfm/#example-493"&gt;example 493&lt;/a&gt;,
were simple.  The &lt;code&gt;LinkStartMarkdownToken&lt;/code&gt; class already had all the necessary fields,
so no changes were needed there.  I then proceeded to add the
&lt;code&gt;rehydrate_inline_link_text_from_token&lt;/code&gt; function into the transformer, containing a
simple transformation:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;    &lt;span class="n"&gt;link_text&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="s2"&gt;"["&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;link_token&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;text_from_blocks&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="s2"&gt;"]("&lt;/span&gt;
        &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;link_token&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;link_uri&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="s2"&gt;" &lt;/span&gt;&lt;span class="se"&gt;\"&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;link_token&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;link_title&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="se"&gt;\"&lt;/span&gt;&lt;span class="s2"&gt;)"&lt;/span&gt;
    &lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;From there, each additional scenario test introduced another variation on
what an acceptable Link token was.  For example, the scenario test for
&lt;a href="https://github.github.com/gfm/#example-494"&gt;Example 494&lt;/a&gt;
introduced a link title that was not present.  That changed the transformation into:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;    &lt;span class="n"&gt;link_text&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="s2"&gt;"["&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;link_token&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;text_from_blocks&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="s2"&gt;"]("&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;link_token&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;link_uri&lt;/span&gt;
    &lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;link_token&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;link_title&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;link_text&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="s2"&gt;" &lt;/span&gt;&lt;span class="se"&gt;\"&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;link_token&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;link_title&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="se"&gt;\"&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;
    &lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;link_text&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="s2"&gt;"\)"&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;And so on, and so on.  For any readers of my articles, this is the same pattern I
have been following since I started this project: get a simple case working, then keep
on adding on little changes until the big change is complete.  This set of changes was
no different in that regard.&lt;/p&gt;
&lt;h3 id="then-why-did-i-think-it-was-difficult"&gt;Then Why Did I Think It Was Difficult?&lt;a class="headerlink" href="#then-why-did-i-think-it-was-difficult" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;The daunting aspect of this group was its volume. To be able to recreate the inline link
token properly, I needed to ensure that every part of the data was properly catalogued
and stored in the token.  Doing this exercise for the Inline Link token, I came
up with the following diagram and mapping:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;[foo](   &amp;lt;/my url&amp;gt;     "  a title "     )
|---|||-|||-----|||---|||--------|||---||
  |  | | |   |   |  |  |     |    |  |  |
  A  B C D   E   D  F  G     H    G  I  B
&lt;/pre&gt;&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;A - &lt;code&gt;ex_label&lt;/code&gt; and &lt;code&gt;text_from_blocks&lt;/code&gt;&lt;ul&gt;
&lt;li&gt;extracted link label, in final and original states&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;B - &lt;code&gt;self.label_type&lt;/code&gt;&lt;ul&gt;
&lt;li&gt;the use of &lt;code&gt;(&lt;/code&gt; and &lt;code&gt;)&lt;/code&gt; denoting an inline link&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;C - &lt;code&gt;before_link_whitespace&lt;/code&gt;&lt;ul&gt;
&lt;li&gt;whitespace before the link starts&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;D - &lt;code&gt;did_use_angle_start&lt;/code&gt;&lt;ul&gt;
&lt;li&gt;&lt;code&gt;True&lt;/code&gt; indicating that this URI was encapsulated&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;E - &lt;code&gt;self.link_uri&lt;/code&gt; and &lt;code&gt;self.pre_link_uri&lt;/code&gt;&lt;ul&gt;
&lt;li&gt;extracted link URI, in final and original states&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;F - &lt;code&gt;before_title_whitespace&lt;/code&gt;&lt;ul&gt;
&lt;li&gt;whitespace before the title starts&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;G - &lt;code&gt;inline_title_bounding_character&lt;/code&gt;&lt;ul&gt;
&lt;li&gt;character used to bound the title&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;H - &lt;code&gt;link_title&lt;/code&gt; and &lt;code&gt;pre_link_title&lt;/code&gt;&lt;ul&gt;
&lt;li&gt;extracted link title, in final and original states&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;I - &lt;code&gt;after_title_whitespace&lt;/code&gt;&lt;ul&gt;
&lt;li&gt;whitespace after the title is completed&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;While this may seem overly thorough, I felt that without a complete map of the Inline
Link, any Markdown transformation would be incomplete.  Especially with so many moving
parts, I was convinced that without a solid plan, I would miss a combination or
a permutation of the test data.  &lt;/p&gt;
&lt;h3 id="how-did-those-changes-go"&gt;How Did Those Changes Go?&lt;a class="headerlink" href="#how-did-those-changes-go" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;The scenario tests were not really difficult to get working properly, it was just the
sheer volume of them.  Behind each of those scenario tests were a set of Markdown
parser functions that needed to be properly exercised.  While those functions had
already been tested against their HTML output, this work was to add more information in
each token, to ensure that the data in the tokens are complete.  And that completeness
came at a cost.&lt;/p&gt;
&lt;p&gt;One of those costs was an increase in the number of results returned by functions,
such as by the &lt;code&gt;__process_inline_link_body&lt;/code&gt; function.  To accomplish the extraction
requirements of these changes, this function went from returning a tuple containing 5
variables to returning a tuple containing 10 variables.  And while that may seem
like a simple refactor to complete, I am still debating with myself on how to handle
that change.  Do I create a new class that is only used internally in this one case,
or do I throw it into an instance of the &lt;code&gt;LinkStartMarkdownToken&lt;/code&gt; class that I can pass
around more easily?  While the token data is not complete, the &lt;code&gt;LinkStartMarkdownToken&lt;/code&gt;
class has all the necessary fields, with 2 fields to spare.  Which to choose?
As I said, still thinking on that one.&lt;/p&gt;
&lt;p&gt;Another function that I want to clean up is the &lt;code&gt;rehydrate_inline_link_text_from_token&lt;/code&gt;
function.  At 57 lines, it is a bit larger than I usually like in my projects.  But in
this case, maybe it is warranted.  This function does have a single responsibility, the
rehydration of the token, and it sticks solidly to that purpose.  With the 12 fields
that it uses to rehydrate, the implementation difficulty is there.  And that
is only for the Inline Link tokens, not the other 3 types of link tokens.  They will
need implementations too.&lt;/p&gt;
&lt;p&gt;For me, the really tough part was that I needed to slog&lt;sup id="fnref:slog"&gt;&lt;a class="footnote-ref" href="#fn:slog"&gt;1&lt;/a&gt;&lt;/sup&gt; through the sheer number
of combinations presented in the examples.  Using link labels as an example,
the link label can contain normal text, backslashes, character entities and inline
tokens.  To make sure I had all these covered, I needed to make sure I had
representative scenario tests for each of these groups of combinations.  And then there
are the link URIs and link titles.  It just got to the point where I used a small
spreadsheet to keep track of things, ticking off combinations as I went… just to be
sure.&lt;/p&gt;
&lt;h2 id="reference-links-and-link-reference-definitions"&gt;Reference Links and Link Reference Definitions&lt;a class="headerlink" href="#reference-links-and-link-reference-definitions" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Implementing the transformations for these two tokens was different than the other
tokens in that I had to develop the transformations in coordination with each other.
For example, I started adding support for these tokens using the scenario test for
&lt;a href="https://github.github.com/gfm/#example-161"&gt;example 161&lt;/a&gt;, which has the following
Markdown:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="n"&gt;foo&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;&lt;span class="err"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;url&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="ss"&gt;"title"&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="n"&gt;foo&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;As I mentioned in a previous section, to properly get this test passing, I needed to
start by implementing a bare bones version of the
&lt;a href="https://github.github.com/gfm/#shortcut-reference-link"&gt;Shortcut Reference Link&lt;/a&gt;.
After all, if I could not reference the Link Reference Definition, how could I know if
it was working properly?&lt;/p&gt;
&lt;h3 id="starting-with-simple-shortcut-links"&gt;Starting with Simple Shortcut Links&lt;a class="headerlink" href="#starting-with-simple-shortcut-links" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Thankfully, after looking at Link Reference Definition examples
&lt;a href="https://github.github.com/gfm/#example-161"&gt;example 161&lt;/a&gt; to
&lt;a href="https://github.github.com/gfm/#example-188"&gt;example 188&lt;/a&gt;,
the only extra link requirement in each of these tests was a Shortcut Reference
Link.  Having already written the transformer to handle Inline Link tokens, adding
code to deal with Shortcut Link tokens was almost trivial.&lt;/p&gt;
&lt;p&gt;A Shortcut Reference Link is merely an Inline Link without the inline specifier, so
modifying the &lt;code&gt;rehydrate_inline_link_text_from_token&lt;/code&gt; function to handle the extra link
type was quick and efficient.  Reusing code already in that function, I came up
with these changes within 5 minutes:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;         &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;link_token&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;label_type&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s2"&gt;"shortcut"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;link_label&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;link_token&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;text_from_blocks&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;replace&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
                &lt;span class="n"&gt;InlineHelper&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;backspace_character&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;""&lt;/span&gt;
            &lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;replace&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="se"&gt;\x08&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;""&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="n"&gt;link_text&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;"["&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;link_label&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="s2"&gt;"]"&lt;/span&gt;
         &lt;span class="k"&gt;elif&lt;/span&gt; &lt;span class="n"&gt;link_token&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;label_type&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s2"&gt;"inline"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
         &lt;span class="o"&gt;...&lt;/span&gt;
         &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
             &lt;span class="k"&gt;assert&lt;/span&gt; &lt;span class="bp"&gt;False&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Everything looked good from the shortcut link point of view.  However, since most of
the tests that have Shortcut Links also have Link Reference Definitions to provide the
reference for those links, I needed to switch to get the Link Reference Definition
tokens done.&lt;/p&gt;
&lt;p&gt;While I was not 100% comfortable with leaving that implementation untested, I understood
that I would have to wait a while to complete the testing.  To do that, on to
Link Reference Definitions!&lt;/p&gt;
&lt;h3 id="moving-over-to-link-reference-definitions"&gt;Moving Over to Link Reference Definitions&lt;a class="headerlink" href="#moving-over-to-link-reference-definitions" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;With a good stab at a transformation for Shortcut Links in place, I turned my attention
to the Link Reference Definition transformation.  When I started putting the code for 
this transformation together, I was greeted by good news.&lt;/p&gt;
&lt;p&gt;The first bit of good news is that since the support for Link Reference Definition
tokens was added more recently
&lt;a href="https://jackdewinter.github.io/2020/06/15/markdown-linter-rabbit-hole-1-adding-consistency-checks/#link-reference-definitions"&gt;than the other tokens&lt;/a&gt;,
I had created that token with a better idea of what information I might need later.  As
such, all the fields that I required to properly represent a Link Reference Definition
element were already in place.  That allowed
me to implement a near-complete version of the &lt;code&gt;rehydrate_link_reference_definition&lt;/code&gt;
function after only 3 tries and 10 minutes.  That was very refreshing.&lt;/p&gt;
&lt;p&gt;The second bit of good news was that the previous work on this token had already dealt
with all the token’s complexity.  As I had a lot of issues in implementing the parser’s
support for
the Link Reference Definition element, I assumed that the rehydration of the token
would also be a lot of work.  It turned out that because of all that hard work, that
near-complete version of the &lt;code&gt;rehydrate_link_reference_definition&lt;/code&gt; function was very
simple.  I had even collected both pre-processed and post-processed versions of the
link label, link destination URI, and link title!  &lt;/p&gt;
&lt;p&gt;Now back to the other Link tokens.&lt;/p&gt;
&lt;h3 id="back-to-finishing-up-links"&gt;Back to Finishing Up Links&lt;a class="headerlink" href="#back-to-finishing-up-links" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;With all the hard work done, finishing off the rest of the links was easier than I
had previously anticipated.  With Link Reference Definition support in place, the
scenario tests that included both Link Reference Definition elements and Shortcut
Links were executed and, with a few tweaks, passed.  Like the effort required to
support Shortcut Reference Link tokens, the support for Full Reference Link tokens and
Collapsed Reference Link tokens was added quickly.&lt;/p&gt;
&lt;p&gt;Within a couple of hours, a good percentage of the scenario tests that involved any
4 of the Link tokens were completed and passing.  The remaining tests were those
scenario tests that gave me some real issues with determining the original text.  A
good example of this was the scenario test for
&lt;a href="https://github.github.com/gfm/#example-540"&gt;example 540&lt;/a&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;[foo [bar](/uri)][ref]&lt;/span&gt;

&lt;span class="na"&gt;[ref]: /uri&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;which produces the HTML output:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;p&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;[foo &lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;a&lt;/span&gt; &lt;span class="na"&gt;href&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;"/uri"&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;bar&lt;span class="p"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;a&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;]&lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;a&lt;/span&gt; &lt;span class="na"&gt;href&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;"/uri"&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;ref&lt;span class="p"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;a&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;p&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The first link that gets interpreted from
that text is the Inline Link &lt;code&gt;[bar](/uri)&lt;/code&gt;.  When the &lt;code&gt;]&lt;/code&gt; character is encountered
after that link text, due to
&lt;a href="https://github.github.com/gfm/#phase-2-inline-structure"&gt;the provided algorithm&lt;/a&gt;,
it is kept as a &lt;code&gt;]&lt;/code&gt; character as there is a valid link between it and its matching
opening &lt;code&gt;[&lt;/code&gt; character.  Finally, the &lt;code&gt;[ref]&lt;/code&gt; is a valid Shortcut Link, matching the
reference set up by the Link Reference Definition.&lt;/p&gt;
&lt;p&gt;Getting the correct, original text to insert into the Link tokens was a bit of an
effort.  The &lt;code&gt;__collect_text_from_blocks&lt;/code&gt; function took a bit of fiddling to make
sure that the original text that was extracted matched the actual original text.
As with other things in this project, it took a couple of tries to find something
that worked and worked well, but that time was well worth it.  A bit frustrating
at time, but worth it.&lt;/p&gt;
&lt;p&gt;Having completed adding the support for all the non-image link scenario tests, it was
time to add the image links into that mix.&lt;/p&gt;
&lt;h2 id="images"&gt;Images&lt;a class="headerlink" href="#images" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Looking at the
&lt;a href="https://github.github.com/gfm/#images"&gt;GFM specification for images&lt;/a&gt;,
it clearly states:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The rules for this are the same as for link text, except that (a) an image description starts with ![ rather than [, and (b) an image description may contain links.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Basically, as I stated before, the Image Link tokens get to use a lot of the work done
for the other link tokens as a foundation, with just 2 changes.  The first part of that
difference was easy to deal with in the transformer: emit the sequence &lt;code&gt;![&lt;/code&gt; instead of
the sequence &lt;code&gt;[&lt;/code&gt;.  Done.&lt;/p&gt;
&lt;p&gt;The second part of that difference was handling examples of links within image links
and image links within links.  While avoiding the scenario test for
&lt;a href="https://github.github.com/gfm/#example-528"&gt;example 528&lt;/a&gt;&lt;sup id="fnref:example528"&gt;&lt;a class="footnote-ref" href="#fn:example528"&gt;2&lt;/a&gt;&lt;/sup&gt;, there were plenty of
other cases such as
&lt;a href="https://github.github.com/gfm/#example-525"&gt;example 525&lt;/a&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="n"&gt;![moon&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;moon&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;jpg&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="err"&gt;]&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;uri&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;and &lt;a href="https://github.github.com/gfm/#example-583"&gt;example 583&lt;/a&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;!&lt;/span&gt;&lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="n"&gt;foo [bar&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;url&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="err"&gt;]&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;url2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;that I needed to deal with.  The actual parsing of those images and their transformation
to HTML were already tested and working. It was just the extraction of the original
text that gave me issues.  However, having dealt with similar examples in the previous
changes for the &lt;code&gt;__collect_text_from_blocks&lt;/code&gt; function, I was able to finish up those
cases quickly.&lt;/p&gt;
&lt;p&gt;The good part about getting to the end of this work took a bit to sink in.  I had
budgeted and entire week to complete these changes.  But even after making
sure the commit was clean, it was early on Saturday morning.  It was Saturday morning
and the link token group was completed.  Well, almost completed.  More on example 528
later.  But it was good enough to mark this block of work done and complete.  With some
extra time left in my schedule, I decided to put it to good use.&lt;/p&gt;
&lt;h2 id="code-coverage"&gt;Code Coverage&lt;a class="headerlink" href="#code-coverage" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;The first good use that I put that extra time to was improving code coverage.  While
there were only 3 cases where I needed to tighten up the code coverage, it was just
something I wanted to make sure got done.  It is true that I almost always argue that
the scenario
coverage metric is more important than the code coverage metric.  But with the code
coverage percentage in the high 99’s, I just wanted to nail this down while the required
changes would be small and manageable.&lt;/p&gt;
&lt;h2 id="moving-special-character-support"&gt;Moving Special Character Support&lt;a class="headerlink" href="#moving-special-character-support" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;The second good use for my extra time was to move the special character support in the
parser into the &lt;code&gt;ParserHelper&lt;/code&gt; class.  Along the way, adding proper support for the
Markdown transformer was accomplished using a
small set of special characters.  These special characters allowed the normal processing
of the tokens by the HTML transformer to generate the proper HTML output, while at the
same time allowing the Markdown transformer to rehydrate the token into its original
Markdown.&lt;/p&gt;
&lt;p&gt;With the use of the characters scattered around the project’s code base, I felt it was
useful to centralize the usage of those characters into the &lt;code&gt;ParserHelper&lt;/code&gt; class.
To complete that centralization, I also introduced a number of functions that either
resolved the characters (for HTML) or removed the characters (for Markdown).&lt;sup id="fnref:better"&gt;&lt;a class="footnote-ref" href="#fn:better"&gt;3&lt;/a&gt;&lt;/sup&gt;
Those characters and their behaviors are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;the &lt;code&gt;\b&lt;/code&gt; or backspace character, used primarily for the &lt;code&gt;\\&lt;/code&gt; or backslash character&lt;ul&gt;
&lt;li&gt;when resolved, removes the character and the character before it&lt;/li&gt;
&lt;li&gt;when removed, leaves the previous character in place&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;the &lt;code&gt;\a&lt;/code&gt; or alert character, used to provide an “X was replaced with Y” notation&lt;ul&gt;
&lt;li&gt;when resolved, removes the alert characters and the X sequence, leaving the Y sequence&lt;/li&gt;
&lt;li&gt;when removed, removes the alert characters and the Y sequence, leaving the X sequence&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;the &lt;code&gt;\x02&lt;/code&gt; character, used to split whitespaces&lt;ul&gt;
&lt;li&gt;when resolved, is replaced with an empty string&lt;/li&gt;
&lt;li&gt;when removed as part of SetExt Heading whitespace processing, delineates leading whitespace that was removed from trailing whitespace that was removed&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;the &lt;code&gt;\x03&lt;/code&gt; or “NOOP” character, used with the alert character sequence as a Y sequence&lt;ul&gt;
&lt;li&gt;when resolved, replaces the entire sequence with an empty string&lt;/li&gt;
&lt;li&gt;when removed, same as above but used to indicate that the X sequence was a caused by a blank line token&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The centralization of these characters and their usage did help to clean up the code.
In all cases, I created a single variable to represent the character, and enforced
its use throughout the codebase, except in test output.  For example, instead of using
the &lt;code&gt;\b&lt;/code&gt; for the backspace character, I created a new static member variable of
the &lt;code&gt;ParserHelper&lt;/code&gt; class called &lt;code&gt;__backspace_character&lt;/code&gt;.  The use of these variables
in the code made it clear that those characters were being used with purpose, and not
because of convenience.&lt;/p&gt;
&lt;p&gt;But even after that work, I still had a bit of time left.  What else could I do to
help the project?&lt;/p&gt;
&lt;h2 id="example-528"&gt;Example 528&lt;a class="headerlink" href="#example-528" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;With my last remaining bits of extra time, I wanted to take another shot at the proper
processing of
&lt;a href="https://github.github.com/gfm/#example-528"&gt;example 528&lt;/a&gt;.  Having tackled the
Link related group of tokens, I felt that I had a good grasp of the processing
required.  With a sense of purpose and confidence, I felt it was time to put that
belief to the test.&lt;/p&gt;
&lt;p&gt;For some background, example 528 is similar to
&lt;a href="https://github.github.com/gfm/#example-525"&gt;example 525&lt;/a&gt;
and
&lt;a href="https://github.github.com/gfm/#example-583"&gt;example 583&lt;/a&gt;
referenced in the previous sections.  However, while each of those examples deals with
one type of link within the other type of link, example 528 can be considered the
composition of both of those examples together.  The example is as follows:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;!&lt;/span&gt;&lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="n"&gt;[[foo&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;uri1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="err"&gt;]&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;uri2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="err"&gt;]&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;uri3&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;producing the following HTML:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;p&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;img&lt;/span&gt; &lt;span class="na"&gt;src&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;"uri3"&lt;/span&gt; &lt;span class="na"&gt;alt&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;"[foo](uri2)"&lt;/span&gt; &lt;span class="p"&gt;/&amp;gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;p&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;To be clear, this is an inline image link that contains 2 possibly valid inline links
within its link label.  The final result was that the image’s URI is &lt;code&gt;uri3&lt;/code&gt; as expected,
but the &lt;code&gt;alt&lt;/code&gt; parameter’s text is set to &lt;code&gt;[foo](uri2)&lt;/code&gt;, an interpretation of the
text within the link label.  And to make it even more interesting, the
GFM specification also provides an algorithm for
&lt;a href="https://github.github.com/gfm/#phase-2-inline-structure"&gt;evaluating emphasis and links&lt;/a&gt;
which has been tested.&lt;/p&gt;
&lt;p&gt;Yes, I have had the algorithm given to me, and I cannot make it work.  I confess.
I have been over the specification’s algorithm and my own implementation of that
algorithm, and I cannot make it work.  Every couple of weeks, I have spent a couple
of hours looking at the log output, the source code, and the algorithm description,
and… nothing.&lt;/p&gt;
&lt;p&gt;Giving it another shot, I decided that instead of assuming I knew what was going on,
I would try and test it as a new problem.  And with any new problem, I tackle it by
doing research on it, so that is what I set out to do.  I turned
on the logging for the scenario test associated with example 528 and started observing
and scribbling.  By the time I had gone through the algorithm 3 times, I was
convinced that I was either missing something important or there was a problem with
the well-tested algorithm.  If I were a betting man, my money would be on the algorithm
being correct, but I just could not figure out where the issue was!&lt;/p&gt;
&lt;p&gt;What I saw in each of my examinations, was that as the processing progressed, the
string &lt;code&gt;[foo](uri1)&lt;/code&gt; was parsed as a link.  Following the algorithm’s instructions,
any link starts before that point needed to be marked as inactive, so the code
marked the second &lt;code&gt;[&lt;/code&gt; character was marked as inactive.  I also double checked the
handling of the initial &lt;code&gt;![&lt;/code&gt; sequence.  As that sequence denotes an image token and not
a link token, that initial &lt;code&gt;![&lt;/code&gt; sequence was not marked as inactive.  Then, when the
second &lt;code&gt;]&lt;/code&gt; character was processed, the implementation skipped over the inactive &lt;code&gt;[&lt;/code&gt;
character, hitting the &lt;code&gt;![&lt;/code&gt; sequence for the image.  With the start link characters
exhausted, the rest of that string became plain text.&lt;/p&gt;
&lt;p&gt;But that is not the result that was specified in the GFM specification.  It wanted&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;p&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;img&lt;/span&gt; &lt;span class="na"&gt;src&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;"uri3"&lt;/span&gt; &lt;span class="na"&gt;alt&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;"[foo](uri2)"&lt;/span&gt; &lt;span class="p"&gt;/&amp;gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;p&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;and the code was generating:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;p&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;img&lt;/span&gt; &lt;span class="na"&gt;src&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;"uri2"&lt;/span&gt; &lt;span class="na"&gt;alt&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;"foo"&lt;/span&gt; &lt;span class="p"&gt;/&amp;gt;&lt;/span&gt;](uri3)&lt;span class="p"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;p&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;At that point, I decided to seek help from a higher power: the CommonMark specification
site.  I posted a quick message to the forums, making sure I indicated that I was having
a problem, clearly stating my findings from above and that they were based on my
implementation.  A couple of quick checks for spelling and grammar, and I posted
a request for help.  I did get a response to my request rather quickly, and I will
address that in a future article.&lt;/p&gt;
&lt;h2 id="what-was-my-experience-so-far"&gt;What Was My Experience So Far?&lt;a class="headerlink" href="#what-was-my-experience-so-far" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;The goal that I had set for myself for this chunk of work was to make sure that I
added the link token group to the Markdown transformer’s features.  While it did
take me most of the week to accomplish that, I do believe that I accomplished that
with some time to spare.  It felt good to be able to take some time and do some small
tasks to clean up the code a bit.&lt;/p&gt;
&lt;p&gt;The weird thing about being able to see the end of the project’s initial phase is
that while I want a quality project, I also want to hurry up.  I can see the items
in the issue list being resolved and then removed, and I just want to get them all
removed.  I want to push myself harder to finish them quicker, even though I know
that is the wrong thing to do.&lt;/p&gt;
&lt;p&gt;As with all side projects, my time and effort spent on the project is a balancing
act between my personal responsibilities, my professional responsibilities, and the
project’s responsibilities.  And yes, while it is a balancing act, those three
groups of responsibilities are in the correct order.  I need to make sure to take
care of myself and my job first, using any extra bandwidth to work on the project.
While I do want to push myself to hurry and finish the project, from a resource
allocation point of view, it just would not work.&lt;/p&gt;
&lt;p&gt;And there is also the quality point of view.  While I am good at my job, I am keenly
aware that every project has four dials that can be adjusted: scope, cost, time, and
quality.  If I want the project to completed faster, changing the time dial, I need
to adjust the other dials to compensate.  This is a personal side project, so I cannot
adjust the cost dial, leaving the quality and scope dials.  Seeing as I do not want to
change my requirements for either of those two dials, I know I need to keep the time
dial where it is.&lt;/p&gt;
&lt;p&gt;Between the balancing act and the resource logic puzzle, I know I need to stay the
course.  While I was feeling the need to hurry up, I also knew that is not what has
got me to this point in the project.  What has got me here is good planning, solid
effort, and not exhausting myself.  If I upset that balance, I might lose my
desire to finish the project, and that would be a shame.&lt;/p&gt;
&lt;p&gt;So, as always, I started to look at and plan the next chunk of work, making
sure it was a good chunk of work that I could easily accomplish.  After all, slow
and steady went the tortoise…&lt;/p&gt;
&lt;h2 id="what-is-next"&gt;What is Next?&lt;a class="headerlink" href="#what-is-next" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Add all the normal tokens to the Markdown transformer?  Check.  Add the Link-related
token group to the Markdown transformer?  Check.  That just left the Container-related
token group.  Add since I knew that Block Quotes were going to need a lot of work,
taking care of the List-related tokens was a good first step.&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr/&gt;
&lt;ol&gt;
&lt;li id="fn:slog"&gt;
&lt;p&gt;According to &lt;a href="https://www.merriam-webster.com/dictionary/slog"&gt;Webster’s dictionary&lt;/a&gt;: “to plod (one’s way) perseveringly especially against difficulty”. &lt;a class="footnote-backref" href="#fnref:slog" title="Jump back to footnote 1 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:example528"&gt;
&lt;p&gt;More on &lt;a href="https://jackdewinter.github.io/2020/08/10/markdown-linter-adding-links-to-the-markdown-transformer/#example-528"&gt;example 528&lt;/a&gt; later. &lt;a class="footnote-backref" href="#fnref:example528" title="Jump back to footnote 2 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:better"&gt;
&lt;p&gt;While I am sure I can come up with a better name for the two sets of functions, I am not sure what those better names would be.  Ideas? &lt;a class="footnote-backref" href="#fnref:better" title="Jump back to footnote 3 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</content><category term="Software Quality"></category><category term="markdown linter"></category><category term="core linter"></category></entry><entry><title>Markdown Linter - Improving the Markdown Transformer</title><link href="https://jackdewinter.github.io/2020/08/03/markdown-linter-improving-the-markdown-transformer/" rel="alternate"></link><published>2020-08-03T00:00:00-07:00</published><updated>2020-08-03T00:00:00-07:00</updated><author><name>Jack De Winter</name></author><id>tag:jackdewinter.github.io,2020-08-03:/2020/08/03/markdown-linter-improving-the-markdown-transformer/</id><summary type="html">
&lt;h2 id="summary"&gt;Summary&lt;a class="headerlink" href="#summary" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;In my
&lt;a href="https://jackdewinter.github.io/2020/07/27/markdown-linter-addressing-the-initial-markdown-transformer-issues/"&gt;last article&lt;/a&gt;,
I walked through the items that I chose to work on from the issues list, detailing my
process for resolving each one.  In this article, I detail how I continued the march
forward to increase my consistency check confidence by further implementing the token
to …&lt;/p&gt;</summary><content type="html">
&lt;h2 id="summary"&gt;Summary&lt;a class="headerlink" href="#summary" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;In my
&lt;a href="https://jackdewinter.github.io/2020/07/27/markdown-linter-addressing-the-initial-markdown-transformer-issues/"&gt;last article&lt;/a&gt;,
I walked through the items that I chose to work on from the issues list, detailing my
process for resolving each one.  In this article, I detail how I continued the march
forward to increase my consistency check confidence by further implementing the token
to Markdown transformer.&lt;/p&gt;
&lt;h2 id="introduction"&gt;Introduction&lt;a class="headerlink" href="#introduction" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Having removed a good number of items from the issues list, I decided that
it was time to get back to verifying the tokens using the Markdown transformer.  While
my initial attempt at implementing the transformer yielded 8 new items on my issues
list, I was hopeful that this next batch of features for the transformer would uncover
fewer errors. Do not get me wrong. If there are issues with any part of the project, I
want to know about them so I can properly prioritize them.  I was just hoping that the
number of new items that I found would be lower this time.&lt;/p&gt;
&lt;p&gt;It is with that hopeful mindset that I started to work on implementing the
transformations for the other Markdown features, excluding the container blocks and the
link related blocks.  While awkwardly stated, that statement outlined a block of work
that I knew I would be comfortable working on and confident that I could complete.
Looking ahead, I knew that link transformations were next on the list, with container
blocks taking up the final position.  I knew I still needed to tackle those token
groups, but I was far more confident about handling the simpler cases first.  By
handling those simpler cases first, I hoped to build up my confidence to work on the
links in the subsequent section.  At least it would build up if I did not discover as
many errors as with the last chunk of work!&lt;/p&gt;
&lt;h2 id="what-is-the-audience-for-this-article"&gt;What Is the Audience for This Article?&lt;a class="headerlink" href="#what-is-the-audience-for-this-article" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;While detailed more eloquently in
&lt;a href="https://jackdewinter.github.io/2020/04/05/what-is-the-audience-for-my-blog/#what-is-the-audience-for-my-blog"&gt;this article&lt;/a&gt;,
my goal for this technical article is to focus on the reasoning behind my solutions,
rather that the solutions themselves.  For a full record of the solutions presented in
this article, please go to this project’s GitHub repository and consult the
commits between
&lt;a href="https://github.com/jackdewinter/pymarkdown/commit/c9cd5e54a7a6167594dbce593e8869856db6db32"&gt;19 Jul 2020&lt;/a&gt;
and
&lt;a href="https://github.com/jackdewinter/pymarkdown/commit/7151ea88a180bdc4b977940e90e9db4908b13ede"&gt;26 Jul 2020&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id="did-i-take-the-week-off"&gt;Did I Take the Week Off?&lt;a class="headerlink" href="#did-i-take-the-week-off" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Looking at the commits for this chunk of work, it may look like I did the HTML block on
the Sunday, then took the week off, restarting the work on Saturday.  For no other
reason than dumb luck, I just hit a wall when trying to transform the SetExt Heading
tokens. Everything else just flew right by!  More on that in a bit.&lt;/p&gt;
&lt;h2 id="adding-html-support"&gt;Adding HTML Support&lt;a class="headerlink" href="#adding-html-support" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;During the writing of that week’s article, I just felt that I needed a bit of a break.
Being a bit fidgety about the block of work that was coming up next, I decided that I
wanted to start doing some work on a random token type.
The HTML block token support was that work, the type of token to work on chosen randomly
using the time-tested
&lt;a href="https://en.wikipedia.org/wiki/Eeny,_meeny,_miny,_moe"&gt;Eeny, Meeny method&lt;/a&gt;.
I honestly did not think that adding that support would be so easy that I could
complete it with only 25
lines of code changed, even less if I do not include blank lines.  I was just looking
to find something to give my mind a break from writing the article.  Nothing more.&lt;/p&gt;
&lt;p&gt;However, I cannot lie about it.  It was refreshing.  Go in, add the transformation, run
the tests, fix 1 or 2 problems that I found, and… done!  It worked so well, I thought
I would do it with the next token.  And that token is the SetExt Heading Token&lt;/p&gt;
&lt;h2 id="adding-setext-heading-support"&gt;Adding SetExt Heading Support&lt;a class="headerlink" href="#adding-setext-heading-support" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;While you can estimate and plan for hours, there are times where the effort required to
do something seems almost random.  In one of the teams that I worked on, we referred to
this type of work as the spins on the “Wheel of Effort”.  One spin of the wheel and you
may get 1 hour, and another spin for a similar item may get 1 day.  It just depends.
I know there were underlying conditions that were contributing to that calculation of
effort.  However, from my viewpoint, it just seemed like a spin of the wheel.&lt;/p&gt;
&lt;p&gt;And the wheel was about to give me a spin that I really did not like.&lt;/p&gt;
&lt;h3 id="the-initial-push"&gt;The Initial Push&lt;a class="headerlink" href="#the-initial-push" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;From experience dealing with SetExt Heading issues, I had a feeling that adding the
support for the SetExt Heading tokens was going to be more difficult than most other
tokens.  That experience also reminded me that most of the issues that I have had with
SetExt Headings were not with the SetExt Heading tokens themselves, but the text block
contained within.  While the SetExt Heading token itself is created to replace an
existing Paragraph token, the handling of the two text blocks was different enough that
I was immediately cautious about those differences.&lt;/p&gt;
&lt;p&gt;The first change that I made for this feature was to write a simple implementation of
the token handlers.  It was during that implementation that I discovered that while the
SetExt Heading tokens contained information about which heading character was used, the
quantity of those characters in the Markdown document was absent.  That was an easy
fix to implement.  A quick jump over to the &lt;code&gt;SetextHeadingMarkdownToken&lt;/code&gt; class to add
the &lt;code&gt;heading_character_count&lt;/code&gt; argument and member variable.  Then another quick jump
back to the new token handlers to use that new member variable when rehydrating the end
token.  Done.  Easy.&lt;/p&gt;
&lt;p&gt;Except it was not.  A single set of tests were failing in each test run: the
&lt;a href="https://github.github.com/gfm/#example-52"&gt;example 052&lt;/a&gt;
series of tests dealing with SetExt text that starts with whitespace.  To simplify
the test for a previous fix, I created the scenario test &lt;code&gt;test_setext_headings_052a&lt;/code&gt;
to keep the problem simple and easy to diagnose.  The issues for both
&lt;code&gt;test_setext_headings_052&lt;/code&gt; and &lt;code&gt;test_setext_headings_052a&lt;/code&gt; were easily fixed, but I
then noticed
a glaring issue:  there was no tests for SetExt Heading text that had both leading
and trailing whitespace.  To address that, I created
&lt;code&gt;test_setext_headings_052b&lt;/code&gt; to add some trailing whitespace while maintaining the same
HTML output with &lt;code&gt;test_setext_headings_052a&lt;/code&gt;.  From there, the &lt;code&gt;c&lt;/code&gt;, &lt;code&gt;d&lt;/code&gt; and &lt;code&gt;e&lt;/code&gt;
variations were added to test various other patterns that I hoped were working
properly.  All those variations passed immediately, except for scenario test
&lt;code&gt;test_setext_headings_052b&lt;/code&gt;. That was failing and I was not sure why.&lt;/p&gt;
&lt;h3 id="the-problem"&gt;The Problem&lt;a class="headerlink" href="#the-problem" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Scenario test &lt;code&gt;test_setext_headings_052b&lt;/code&gt; is a simpler version of
&lt;a href="https://github.github.com/gfm/#example-52"&gt;example 52&lt;/a&gt;
with some changes thrown in.  In this new scenario test, the data is as follows:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;  &lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="err"&gt;{&lt;/span&gt;&lt;span class="k"&gt;space&lt;/span&gt;&lt;span class="err"&gt;}&lt;/span&gt;
  &lt;span class="n"&gt;b&lt;/span&gt;&lt;span class="err"&gt;{&lt;/span&gt;&lt;span class="k"&gt;space&lt;/span&gt;&lt;span class="err"&gt;}&lt;/span&gt;
  &lt;span class="k"&gt;c&lt;/span&gt;
&lt;span class="o"&gt;===&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;where the literal text &lt;code&gt;{space}&lt;/code&gt; are space characters at the end of each of those lines.
For comparison, the Markdown for test &lt;code&gt;test_setext_headings_052a&lt;/code&gt; is:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;  &lt;span class="n"&gt;a&lt;/span&gt;
  &lt;span class="n"&gt;b&lt;/span&gt;
  &lt;span class="k"&gt;c&lt;/span&gt;
&lt;span class="o"&gt;===&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;and the HTML output for that test is:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;h1&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;a
b
c&lt;span class="p"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;h1&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;By comparison, the new scenario test &lt;code&gt;test_setext_headings_052b&lt;/code&gt;, is a literal copy of
that original
scenario test &lt;code&gt;test_setext_headings_052a&lt;/code&gt; with the addition of a single space
character at the end of the first two lines.  As the GFM specification states that
leading and trailing spaces are removed in normal paragraphs, it makes sense that those
additional space characters would be removed as excess whitespace.  As such, I expected
that the HTML output would be the same, and it was.&lt;/p&gt;
&lt;p&gt;But when the Markdown transformer rehydrated the text, that removed whitespace was
inserted at the start of the line.  The rehydrated Markdown for this initial stage was:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;   &lt;span class="n"&gt;a&lt;/span&gt;
   &lt;span class="n"&gt;b&lt;/span&gt;
  &lt;span class="k"&gt;c&lt;/span&gt;
&lt;span class="o"&gt;===&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Digging a bit deeper, it took a fair amount of additional logging and debugging before
an answer started forming in my head.  The last line was fine, mostly because it did not
have any whitespace at the end of its line.  In the case of the first and second lines,
that trailing space was being placed at the start of the line, instead of the end of
the line.&lt;/p&gt;
&lt;p&gt;The problem?  The 2 spaces removed from the start of the line and the 1 space removed
from the end of the line were being merged.  The result?  When the Markdown
transformer went to rehydrate the token, all 3 of those removed spaces were placed at
the start of the line.  I needed some way to keep the two groups of spaces separate
from each other.&lt;/p&gt;
&lt;h3 id="another-rabbit-hole"&gt;Another Rabbit Hole?&lt;a class="headerlink" href="#another-rabbit-hole" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Yup, that thought had crossed my mind.  By the time that I had debugged the problem and
understood it clearly, it was late Wednesday night and I had already spent 2 nights
working on this issue.  To ensure that I did not go “missing” again, I set a maximum
duration of 2 days to solve this issue.  If not solved in that time, it would go on the
issues list to be dealt with later.&lt;/p&gt;
&lt;p&gt;Was this a bit overboard?  Perhaps.  But given my past history with
&lt;a href="({filename}/articles/SoftwareQuality/core-5.md)"&gt;chasing down issues like this&lt;/a&gt;,
I figured it was better to plan ahead to prevent myself from getting
in that predicament.  Given how much I like puzzles, combined with a gut feeling about
this issue, it just seemed the right thing to do at the time.&lt;/p&gt;
&lt;h3 id="over-the-next-2-days"&gt;Over the Next 2 Days&lt;a class="headerlink" href="#over-the-next-2-days" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Over the next 2 days, I tried 3 or 4 different approaches.  But in each
case, there was some manner of complication that prevented me from going forward with
it. It was frustrating, but I was adamant that I was going to find a solution.  Well,
if it did not exceed my self-imposed deadline of Friday night.  And that
deadline just kept on getting closer and closer.&lt;/p&gt;
&lt;h3 id="the-final-breakthrough"&gt;The Final Breakthrough&lt;a class="headerlink" href="#the-final-breakthrough" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Early on Friday night, I was very frustrated that nothing I tried had worked.  After
resetting the code yet again, I decided I was going to do my best to keep things
simple.  Before, I had tried altering the signatures of the functions and passing
variables around, and that did not get me anywhere.  Turning that effort around, I
figured that the simplest way to separate the two parts of the line was with a
separator character.&lt;/p&gt;
&lt;p&gt;Previously, the tokens for scenario test &lt;code&gt;test_setext_headings_052b&lt;/code&gt; were:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;    expected_tokens = [
        "[setext(4,1):=:3:  :(1,3)]",
        "[text:a\nb\nc:: \n   \n  ]",
        "[end-setext::]",
    ]
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Using a simple separator character of &lt;code&gt;\x02&lt;/code&gt;, I was able to change the serialized form
of the text token to:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;    expected_tokens = [
        "[setext(4,1):=:3:  :(1,3)]",
        "[text:a\nb\nc:: \n  \x02 \n  \x02]",
        "[end-setext::]",
    ]
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;That one change was simple and pivotal, and it struck a chord in me right away.
That separator character clearly separated the two different whitespace sequences from
each other, with no complex variable passing to enforce it.  But that was only part of
it.  Would it the Markdown transformer portion of this fix be as clean and easy?&lt;/p&gt;
&lt;h3 id="the-solution"&gt;The Solution&lt;a class="headerlink" href="#the-solution" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;I needed a come up with a fix to compensate for that change in the token’s text.
Before this change, the token’s text and the token’s whitespace were reintegrated with
each other using a simple algorithm:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;    &lt;span class="n"&gt;rejoined_token_text&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
    &lt;span class="n"&gt;split_token_text&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;main_text&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;split&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;split_parent_whitespace_text&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;next_token&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;end_whitespace&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;split&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;iterator&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;enumerate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;split_token_text&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;start&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="n"&gt;joined_text&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;split_parent_whitespace_text&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;iterator&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]]&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;iterator&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
        &lt;span class="n"&gt;rejoined_token_text&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;joined_text&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;main_text&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;join&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;rejoined_token_text&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Basically, split the text string and the whitespace string into arrays, splitting
them on the newline character.  Then take those two arrays and create a new array with
the concatenation of the element from the whitespace array with the text from the text
token element.  When done with all the elements, create a new string by merging the
contents of the array together, using a newline character to join the lines.&lt;/p&gt;
&lt;p&gt;After this change, that algorithm got a bit more complex, but not by much.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;    &lt;span class="n"&gt;rejoined_token_text&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
    &lt;span class="n"&gt;split_token_text&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;main_text&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;split&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;split_parent_whitespace_text&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;next_token&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;end_whitespace&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;split&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;iterator&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;enumerate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;split_token_text&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;start&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="n"&gt;ws_prefix_text&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;""&lt;/span&gt;
        &lt;span class="n"&gt;ws_suffix_text&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;""&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;split_parent_whitespace_text&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;iterator&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]]:&lt;/span&gt;
            &lt;span class="n"&gt;split_setext_text&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;split_parent_whitespace_text&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;iterator&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;split&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="se"&gt;\x02&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;split_setext_text&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;iterator&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                    &lt;span class="n"&gt;ws_suffix_text&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;split_setext_text&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
                &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                    &lt;span class="n"&gt;ws_prefix_text&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;split_setext_text&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
            &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="n"&gt;ws_prefix_text&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;split_setext_text&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
                &lt;span class="n"&gt;ws_suffix_text&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;split_setext_text&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
        &lt;span class="n"&gt;joined_text&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;ws_prefix_text&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;iterator&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;ws_suffix_text&lt;/span&gt;
        &lt;span class="n"&gt;rejoined_token_text&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;joined_text&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;main_text&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;join&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;rejoined_token_text&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Instead of the very simple concatenation of the whitespace and the text, there was a bit
more work to do.  First, the whitespace needed to be split into two, based on the new
separator character &lt;code&gt;\x02&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;It was more difficult than the original algorithm, but not by much.  Once I did a
refactoring pass on the Markdown transformer, I was sure that I could clean that
algorithm up a lot.  But even without that refactoring, the changes in the algorithm
were easy to understand.&lt;/p&gt;
&lt;p&gt;The root of the changes centered on the splitting on the whitespace in the newly
inserted &lt;code&gt;\x02&lt;/code&gt; character.
Once that given line was split, there were 3 cases to handle.  The easy case
was the one where the &lt;code&gt;\x02&lt;/code&gt; character was present, yielding an array with 2 entries.
In that case, the &lt;code&gt;ws_prefix_text&lt;/code&gt; variable was set to the first element and the
&lt;code&gt;ws_suffix_text&lt;/code&gt; variable was set to the second element.  The second case was where
there was only 1 element in the array and it was the very first entry in the array.  In
that case, the prefix whitespace had already been applied when the SetExt Heading token
was dealt with, therefore the whitespace was assigned to the &lt;code&gt;ws_suffix_text&lt;/code&gt; variable.
Finally, in all other cases, that whitespace was good at the start of the line,
hence it was assigned to the &lt;code&gt;ws_prefix_text&lt;/code&gt; variable.&lt;/p&gt;
&lt;p&gt;Testing this algorithm endlessly in my head, I was pleased when I tested the algorithm
with the actual code and it almost worked.  The first iteration of this algorithm did
not include the properly handling of the second case, as detailed above.  As such,
the other lines were formatted properly, but that first line was still a bit off.
However, the good news is that it only took a little bit of debugging before I had that
cause identified and fixed.  And after 4 days, seeing all the tests pass for this
change was a sweet sight for my eyes!&lt;/p&gt;
&lt;h3 id="hindsight-is-always-clearer"&gt;Hindsight is Always Clearer&lt;a class="headerlink" href="#hindsight-is-always-clearer" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Looking back at the solution, the simplicity and correctness of it is even more
evident. Add an extra marker during the initial processing and interpret it during
the Markdown transformer processing just makes sense.  Looking back, the thing that
made the most sense was that the simplest solution was the one that one.  It was
as complex as it needed to be, and not more complex.&lt;/p&gt;
&lt;p&gt;And after taking the time to add this support properly, I could only hope I would
have enough time to finish adding the support for the other tokens that I had planned
for.&lt;/p&gt;
&lt;h2 id="adding-emphasis-support"&gt;Adding Emphasis Support&lt;a class="headerlink" href="#adding-emphasis-support" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;After the effort required to add the SetExt Heading transformation, I was hesitant to
start working on another token.  It was not a lack of confidence that was causing me to
pause for a bit, it was the work!  After taking 4 days to complete the SetExt Heading
token support, I was exhausted.  Also, by the time the code changes were committed,
I only had about 24 hours to complete the rest of the work!&lt;/p&gt;
&lt;p&gt;After adding my initial attempt to perform a simple transformation of Emphasis tokens,
I was very pleased when I found out that my work for this token was almost complete. The
writing of that initial attempt used the information already present in the
token and was able to satisfy most of the tests in dealing with emphasis.  The only
tests
that had a problem were the tests that used the alternate emphasis character &lt;code&gt;_&lt;/code&gt; and its
slightly altered emphasis rules.  When I originally added the &lt;code&gt;EmphasisMarkdownToken&lt;/code&gt;
class, the HTML transformer did not need to know which character was used for emphasis,
only the level of emphasis in the &lt;code&gt;emphasis_length&lt;/code&gt; field.  As such, any indication of
the emphasis character used was absent from the token.&lt;/p&gt;
&lt;p&gt;To address that problem, I simply added the &lt;code&gt;emphasis_character&lt;/code&gt; field to the
&lt;code&gt;EmphasisMarkdownToken&lt;/code&gt; class.  This was followed up by some small changes in the
&lt;code&gt;__process_emphasis_pair&lt;/code&gt; function to ensure that the new field was being properly
initialized in both the &lt;code&gt;EmphasisMarkdownToken&lt;/code&gt; constructor and the emphasis block’s end
token constructor.  The change in the end token was a bit trickier in that it does not
have a specific place for the character, just a generic &lt;code&gt;extra_end_data&lt;/code&gt; variable.
Those changes modified the code from:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;            &lt;span class="n"&gt;EmphasisMarkdownToken&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;emphasis_length&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
&lt;span class="o"&gt;...&lt;/span&gt;
            &lt;span class="n"&gt;MarkdownToken&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;token_inline_emphasis&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;""&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;emphasis_length&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;to:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;            &lt;span class="n"&gt;EmphasisMarkdownToken&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;emphasis_length&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;emphasis_character&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
&lt;span class="o"&gt;...&lt;/span&gt;
            &lt;span class="n"&gt;MarkdownToken&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;token_inline_emphasis&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;""&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; \
                 &lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;emphasis_length&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="s2"&gt;":"&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;emphasis_character&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;These changes made sure that both the start of the emphasis block and the end of the
emphasis block had access to the emphasis character that had been used.  To accommodate
these changes, a trivial change was needed in the HTML transformer.  Once that was done,
I temporarily disabled the consistency checks and ran the full set of tests against
those changes.&lt;/p&gt;
&lt;p&gt;Perhaps I am paranoid, but even with such a small change, I wanted to
run the full battery of GFM specification tests to ensure that those changes were solid
on their own before adding in more changes.  But with all those changes in place and
all tests passing, I then returned to the Markdown transformer.  Due to the above work,
the Markdown transfer was changed to be aware of the
emphasis character used.  Similar to the HTML transformer, the Markdown transformer
only required a few lines to be changed to accommodate the new versions of the tokens.
After that work was completed, the consistency checks were enabled, and I was glad to
find out that all emphasis tests were passing on the first try.  Compared to the last
element, this element was a breeze!&lt;/p&gt;
&lt;h2 id="adding-autolink-and-raw-html-support"&gt;Adding Autolink and Raw HTML Support&lt;a class="headerlink" href="#adding-autolink-and-raw-html-support" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Seemingly on a roll, the Autolink token support was added in 15 minutes and the raw HTML
token support was added in just over 10 minutes.  In both cases, the tokens contained
all the required information, allowing the transformation to be accomplished with very
simple functions.  The testing for these changes was likewise, quick, as the amount of
code that was changed was small.  As these changes took less than 30 minutes combined,
there really is not anything more to add.&lt;/p&gt;
&lt;h2 id="adding-code-span-support"&gt;Adding Code Span Support&lt;a class="headerlink" href="#adding-code-span-support" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Trivial, Hard, Decent, Trivial.  That was the effort that I required to add support for
the tokens documented in the last 4 sections.  Picking Code Spans by random out of the
group of remaining tokens, I was not
sure where the “Wheel of Effort” would land this time.  It turned out that adding
support for the code span tokens was a bit more difficult than adding support for the
Autolink token and the Raw HTML token, but it was not much more difficult.&lt;/p&gt;
&lt;h3 id="the-initial-attempt"&gt;The Initial Attempt&lt;a class="headerlink" href="#the-initial-attempt" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;To add the support for the Code Span tokens, I first needed to change the constructor
for the
&lt;code&gt;InlineCodeSpanMarkdownToken&lt;/code&gt; class to keep track of three additional fields:
&lt;code&gt;extracted_start_backticks&lt;/code&gt;, &lt;code&gt;leading_whitespace&lt;/code&gt;, and &lt;code&gt;trailing_whitespace&lt;/code&gt;. While
those 3 fields were easy add to the token and populate with the right information,
their use in many of the scenario tests required small changes in each of those tests.
Even those changes were annoying, once they were out of the way, the changes to the
Markdown transformer to properly support the Code Span token were minimal.&lt;/p&gt;
&lt;p&gt;After running the all the tests with the above changes implemented, everything looked
good except for a couple of tests.  When I looked at those tests more closely, in each
test the Markdown contained a code span with a newline
character in the middle of it.  While Code Span tokens keep everything within their
boundaries exactly as they are, including backslashes and character reference sequences,
newline characters are a separate matter.&lt;/p&gt;
&lt;h3 id="addressing-the-issue"&gt;Addressing the Issue&lt;a class="headerlink" href="#addressing-the-issue" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;When a Code Span element has a newline character in it, that newline character gets
replaced with a single space character.  This introduced a bit of a problem for the
Markdown transformer, as the HTML transformer was expecting a space character and the
Markdown transformer was expecting a newline character.  Luckily, I was able to
repurpose some work I did a couple of weeks ago for
&lt;a href="https://jackdewinter.github.io/2020/07/20/markdown-linter-transforming-back-to-markdown/#Handling-Character-References"&gt;character references&lt;/a&gt;
in indented code blocks.
As I wanted to ensure that I represented both states of the code span data in the
tokens, I replaced the
newline characters with the text &lt;code&gt;\a\n\a \a&lt;/code&gt; instead of replacing it with a single space
character.  At that point, depending on which viewpoint I was taking, I was able to know
both the before processing and after processing states of that character.&lt;/p&gt;
&lt;p&gt;Going forward with those changes, I went to look at any errors with the HTML
transformer, but there were not any.  It turned out that the work I did on
&lt;a href="https://github.com/jackdewinter/pymarkdown/commit/20b129ee1b2058b4495395251d25a8fafa88bfa3"&gt;16 Jul 2020&lt;/a&gt;
included adding a call to the &lt;code&gt;resolve_references_from_text&lt;/code&gt; function, then housed in
the &lt;code&gt;tranform_to_gfm.py&lt;/code&gt; module.  To be honest, I was not aware that I did that, but it
was nice that it was already in place.  That just left the changes to the Markdown
transformer to resolve any replacement markers in that data.  And given the the
literal text string &lt;code&gt;\a\n\a \a&lt;/code&gt;, that was a simple task.&lt;/p&gt;
&lt;p&gt;Running the tests at each interval along the way, I was confident that I had made the
right changes.  But there is always that moment where I say to myself “did I remember
everything?”.  Fighting past that though, I ran the all the tests and was happy to
see that Code Spans were now being transformed properly.&lt;/p&gt;
&lt;h2 id="adding-fenced-code-block-support"&gt;Adding Fenced Code Block Support&lt;a class="headerlink" href="#adding-fenced-code-block-support" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Like the work done for the Code Span tokens, the Fenced Code Block tokens were
missing some information. In this case, that information was tied to both the
start token and the end token.  For the start token, the information was being
serialized properly, but I needed to add specific member variables for each of the
arguments being passed in.  This small change allowed me to use that information
in the transformers in subsequent steps.  For the end token, instead
of trying to add a lot of generic information to the token, I opted to add a new
member variable &lt;code&gt;start_markdown_token&lt;/code&gt; to allow for a reference to the start token.  In
this way, I was able to easily reference the data of the start token without having to
duplicate information in a generic way in the end token.&lt;/p&gt;
&lt;p&gt;When I started testing these changes, there were a couple of tests that were trickier
than the others to get working.  Debugging into those tests, I quickly found that the
whitespace removed from the start of lines within the fenced code block was causing
issues for the Markdown transformer.  Having faced a similar problem with the Code
Span tokens, I was quickly able to pivot and replace that removed whitespace with
a similar replaced sequence and a &lt;code&gt;noop&lt;/code&gt; character.&lt;/p&gt;
&lt;p&gt;Based on the work in dealing with Code Spans, if knew that if I needed to replace a
single newline character with a space character, I would replace the newline with the
sequence &lt;code&gt;\a\n\a \a&lt;/code&gt;.  As there are boundary cases where replacements can be nested, I
did not
want to use the sequence &lt;code&gt;\a \a\a&lt;/code&gt; to replace a removed space character.  Instead,
I used the &lt;code&gt;\x03&lt;/code&gt; character to signal a character that did not mean anything, in effect
a
&lt;a href="https://www.urbandictionary.com/define.php?term=noop"&gt;NOOP character&lt;/a&gt;.
Thus, the replacement string became &lt;code&gt;\a \a\x03\a&lt;/code&gt;.  After a few small fixes, everything
passed.&lt;/p&gt;
&lt;h2 id="adding-atx-heading-support"&gt;Adding Atx Heading Support&lt;a class="headerlink" href="#adding-atx-heading-support" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;With the way the “Wheel of Effort” had been spinning for me during this chunk of work,
I had no
clue where the effort for this token would land on that metaphorical wheel.  On one
side, there were plenty of simple changes required to add support for many of the
tokens.  On the other side were the SetExt Heading tokens, which took days.  It was
with trepidation and caution that I started to work on the support for this token.&lt;/p&gt;
&lt;p&gt;And it was within a couple of minutes of starting that I figured out this work was
destined for the the trivial category.  Piggybacking on the work documented in the last
section regarding the &lt;code&gt;start_markdown_token&lt;/code&gt; field, the big change for the parser was
to set this field in the end token for the heading.  Seeing as the change was solely
additive, I jumped to the Markdown transformer, and added the handlers for both the
&lt;code&gt;AtxHeadingMarkdownToken&lt;/code&gt; and its corresponding end token.  The handlers were both
simple, just regurgitating the token’s member variables back into a Markdown form.&lt;/p&gt;
&lt;p&gt;Running the tests, I was pleased to see that most of the tests worked on the first
run.  The ones that did not caused me to look at the tests more closely.  It was there
that I realized that the only tests that were failing were tests with closing
Atx Heading characters.  Looking specifically at the code to handle those closing
characters, I discovered that I had transposed two variables, producing weird results
in the output.  Fixing that error, the tests ran without any issues.&lt;/p&gt;
&lt;h2 id="what-was-my-experience-so-far"&gt;What Was My Experience So Far?&lt;a class="headerlink" href="#what-was-my-experience-so-far" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;While I mentioned in the last article that I started to believe that I could see the
end of the project, it was this chunk of work that brought it into sharper focus for me.
In my mind, anyone can say that they can properly parse a Markdown document, but for me,
anything short of being able to empirically prove that the project can parser the
Markdown project properly is a failure.  For me, it is not about guesswork, it is
whether I can back up my claim with data.&lt;/p&gt;
&lt;p&gt;The comparisons between the HTML parser output
and the HTML output from the GFM specification? They proved the project could get the
HTML right for those specific cases.  The comparisons between the line numbers and
column numbers from the parser’s tokens and the consistency check algorithms?  They
proved that the project could pinpoint the origin of any element in the original
Markdown document.  The consistency check using the Markdown transformer?  It proved
that the project could, with certainty, transform the Markdown document into an
intermediate form and then back again, with no loss of data.&lt;/p&gt;
&lt;p&gt;From my point of view, each one of these checks was building on the work of the other,
providing solid, empirical proof that the parser had properly tokenized the document.
I understand that to some it may seem excessive.  But to me, this was just dotting
my Is and crossing my Ts.  I wanted to make a good first impression with this parser,
and I wanted to take steps to ensure that.&lt;/p&gt;
&lt;p&gt;In addition, that new level of confidence spoke to me. The scenario tests were
effective.  The consistency checks were working.  And in my mind, the project was
clearly past the half-way point on its journey to the finish line!  It was all
starting to come together.&lt;/p&gt;
&lt;h2 id="what-is-next"&gt;What is Next?&lt;a class="headerlink" href="#what-is-next" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;As mentioned above, Link transformations were next on the list of Markdown
transformations to add.  Given the work documented in this article, I was sure that
I would run into at least a couple of issues.  It was just a question of how much
effort it would take for me to push through it!&lt;/p&gt;</content><category term="Software Quality"></category><category term="markdown linter"></category><category term="core linter"></category></entry><entry><title>Markdown Linter - Addressing the Initial Markdown Transformer Issues</title><link href="https://jackdewinter.github.io/2020/07/27/markdown-linter-addressing-the-initial-markdown-transformer-issues/" rel="alternate"></link><published>2020-07-27T00:00:00-07:00</published><updated>2020-07-27T00:00:00-07:00</updated><author><name>Jack De Winter</name></author><id>tag:jackdewinter.github.io,2020-07-27:/2020/07/27/markdown-linter-addressing-the-initial-markdown-transformer-issues/</id><summary type="html">
&lt;h2 id="summary"&gt;Summary&lt;a class="headerlink" href="#summary" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;In my
&lt;a href="https://jackdewinter.github.io/2020/07/20/markdown-linter-transforming-back-to-markdown/"&gt;last article&lt;/a&gt;, I started to work on the
token transformer, a transformer specifically used to verify the PyMarkdown tokens by
rehydrating or reconstituting the original Markdown document from them.  In this
article, I talk about how I went through the items that I added to the issues …&lt;/p&gt;</summary><content type="html">
&lt;h2 id="summary"&gt;Summary&lt;a class="headerlink" href="#summary" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;In my
&lt;a href="https://jackdewinter.github.io/2020/07/20/markdown-linter-transforming-back-to-markdown/"&gt;last article&lt;/a&gt;, I started to work on the
token transformer, a transformer specifically used to verify the PyMarkdown tokens by
rehydrating or reconstituting the original Markdown document from them.  In this
article, I talk about how I went through the items that I added to the issues list as
a result of that work and resolved them.&lt;/p&gt;
&lt;h2 id="introduction"&gt;Introduction&lt;a class="headerlink" href="#introduction" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Normally, I use this space to explain some of the reasoning behind the work which
formed the basis for the article.  Without that bit of preamble, I feel that I am just
dropping the reader off in an unfamiliar location without a compass, a map, or any
indication of where they are.  While that remains true for this article, the reasoning
for this article is so simple that I feel that I do not need a lot of words to explain
it.&lt;/p&gt;
&lt;p&gt;Last week, I added 7 new items to my issues list, with 1 other issue pending from the
week before.  Plain and simple, I just wanted those issues off the list before I
continued with the project’s Markdown transformer.&lt;/p&gt;
&lt;h2 id="what-is-the-audience-for-this-article"&gt;What Is the Audience for This Article?&lt;a class="headerlink" href="#what-is-the-audience-for-this-article" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;While detailed more eloquently in
&lt;a href="https://jackdewinter.github.io/2020/04/05/what-is-the-audience-for-my-blog/#what-is-the-audience-for-my-blog"&gt;this article&lt;/a&gt;,
my goal for this technical article is to focus on the reasoning behind my solutions,
rather that the solutions themselves.  For a full record of the solutions presented in
this article, please go to this project’s GitHub repository and consult the
commits between
&lt;a href="https://github.com/jackdewinter/pymarkdown/commit/20b129ee1b2058b4495395251d25a8fafa88bfa3"&gt;16 Jul 2020&lt;/a&gt;
and
&lt;a href="https://github.com/jackdewinter/pymarkdown/commit/d07237bb4201221d5bcdc88f51a8d8461dfe7c41"&gt;18 Jul 2020&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id="things-continue-to-be-busy"&gt;Things Continue to Be Busy&lt;a class="headerlink" href="#things-continue-to-be-busy" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;While there are often weeks where I wish something interesting would happen, those types
of weeks are not showing up in my life this summer.  Instead, I am having the type of
summer where I wish I had less to do, giving myself some extra time to relax and
recharge.  Thankfully, I have a spouse that is very supportive of my hobbies and
writing, giving me time on the evenings and the weekends to make my project and this
blog happen.  If you check the Git repository for this project, the times when I have
been able to eke out some time to work should be obvious.&lt;/p&gt;
&lt;p&gt;I am hoping, that as the summer continues, more “free” time comes my way.&lt;/p&gt;
&lt;h2 id="nothing-to-worry-about"&gt;Nothing to Worry About&lt;a class="headerlink" href="#nothing-to-worry-about" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Looking at the issues list and the items that I added during my last session,
I did not believe there were any serious issues to address.  Sure, there were some
questions that I wanted to follow up on, but I did not feel that any of
them indicated a serious issue. Similarly, there were some possible bugs
that I had noticed, but I did not feel that any of these possible bugs were severe.  In
the worst case, I figured that each of these issues would each take a couple hours’
worth of effort or less to solve.  Nothing I could not handle.&lt;/p&gt;
&lt;p&gt;But adding those items as I was working on the consistency checks was not
something that I liked doing.  After all, if I was checking the consistency of my work
and there were problems with those checks, did that mean the checks were faulty?
It just made sense to me to address those questions right away, ensuring that my
confidence in the consistency checks remained high.  Besides, if my guesses
were right about the severity of the items, I should be able to address them quickly.&lt;/p&gt;
&lt;p&gt;And with that mindset in place, I started working on removing those items from the
issues list.&lt;/p&gt;
&lt;h3 id="lone-link-reference-definitions"&gt;Lone Link Reference Definitions&lt;a class="headerlink" href="#lone-link-reference-definitions" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Link Reference Definitions are interesting in that they break the mold created by the
other Markdown tokens.  When these elements are parsed from their original Markdown
document into Markdown tokens, they do not add any information to the output HTML
document.  For the elements themselves to be useful, a
separate link element is required that references them.  The absence of such a distinct
link element is the basis for
&lt;a href="https://github.github.com/gfm/#example-176"&gt;example 176&lt;/a&gt; and
&lt;a href="https://github.github.com/gfm/#example-188"&gt;example 188&lt;/a&gt;.  Apparently, this issue was
so important, that the specification includes it twice with the exact same example text
for both examples:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="n"&gt;foo&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;&lt;span class="err"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;url&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;These examples deal with the other unique part of the Link Reference Definition: it is
the only multiline element in the base GFM specification.  This means that the next line
may need to be parsed to determine if the Link Reference Definition on the current line
has ended.  In this specific case, the link
label (&lt;code&gt;[foo]&lt;/code&gt;) and link destination (&lt;code&gt;/url&lt;/code&gt;) have both been provided, but there is the
possibility of the link title occurring on the next line.  So, when the end of the
document is reached, for whatever reason, the partial Link Reference Definition was
being left partially open, resulting in the token was not being emitted.  But why?&lt;/p&gt;
&lt;h4 id="debugging-and-resolving-the-issue"&gt;Debugging and Resolving the Issue&lt;a class="headerlink" href="#debugging-and-resolving-the-issue" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;Adding some debug statements and doing some research with the scenario tests, the cause
of this issue was quick to pop out at me.  At first, I thought it was an issue to do
with the &lt;code&gt;__close_open_blocks&lt;/code&gt; function, as it was a likely candidate.  But a quick
change to example 176 to add a couple of blank lines after the Link Reference Definition
put a quick end to that.  That modified case worked without any problems.  Doing a bit
more digging, the problem seemed to be in the handling of the return value from the
&lt;code&gt;__close_open_blocks&lt;/code&gt; function.  At that time, when the
&lt;code&gt;__close_open_blocks&lt;/code&gt; function was called from the main &lt;code&gt;__parse_blocks_pass&lt;/code&gt; function
to close the document, the return value containing any immediately closed tokens was
discarded.  That definitely did not seem helpful.&lt;/p&gt;
&lt;p&gt;To address this, instead of using the &lt;code&gt;_&lt;/code&gt; variable to capture and ignore the list
returned from the &lt;code&gt;__close_open_blocks&lt;/code&gt; function, I replaced it with the variable
&lt;code&gt;tokens_from_line&lt;/code&gt; to capture that value. Making sure that the list was not being
extended with itself (which caused failures in almost every scenario test) the lines:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;tokens_from_line&lt;/span&gt; &lt;span class="ow"&gt;and&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;tokenized_document&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;tokenized_document&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;extend&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tokens_from_line&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;were added to extend the document list with the previously missing tokens.  A quick
run of all the scenario tests to verify that it was fixed, and this issue was removed
from the issues list!&lt;/p&gt;
&lt;h3 id="getting-rid-of-extra-blank-line-tokens"&gt;Getting Rid of Extra Blank Line Tokens&lt;a class="headerlink" href="#getting-rid-of-extra-blank-line-tokens" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;While
&lt;a href="https://github.github.com/gfm/#example-559"&gt;example 559&lt;/a&gt; and
&lt;a href="https://github.github.com/gfm/#example-560"&gt;example 560&lt;/a&gt; are the two main recorded
issues, there were a total of 6 scenario tests that had this same issue.  With a Link
Reference Definition (or possible Link Reference Definition) being started at the end
of the document, an extra Blank Line token was being inserted before the document was
closed.&lt;/p&gt;
&lt;p&gt;Basically, given the source Markdown document for
&lt;a href="https://github.github.com/gfm/#example-559"&gt;example 559&lt;/a&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="n"&gt;foo&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;&lt;span class="err"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;url&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;or a modification of &lt;a href="https://github.github.com/gfm/#example-188"&gt;example 188&lt;/a&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="n"&gt;foo&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;an extra Blank Line token appeared in the token array without fault.&lt;/p&gt;
&lt;h4 id="debugging-and-resolving-the-issue_1"&gt;Debugging and Resolving the Issue&lt;a class="headerlink" href="#debugging-and-resolving-the-issue_1" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;The cause of this issue was a bit more subtle than the others, so it took me a bit
longer to figure it out.  Most of my initial time on this issue was spent trying to
figure out why this
issue happened with Link tokens and Link Reference Definition tokens, not just Link
Reference Definition tokens.  It was not until I took a look at the log output that
I realized they were the same issue.&lt;/p&gt;
&lt;p&gt;While the text &lt;code&gt;[foo]&lt;/code&gt; can be used as a shortcut
link, that same text can also be used as a link
label for a Link Reference Definition.  As the Link Reference Definitions are processed
in the initial phase and links are processed in the final phase, that text is
considered part of a Link Reference Definition until it can be proven otherwise.  In
this case, that consideration was dropped quickly, as the link label is not followed by
the &lt;code&gt;:&lt;/code&gt; character.  However, it still underwent the initial consideration before being
dropped and requeued for further processing.&lt;/p&gt;
&lt;p&gt;With this new insight, I went through the logs for the &lt;code&gt;__parse_blocks_pass&lt;/code&gt; function
again.  I quickly noticed that in these cases, there was a single blank line getting
requeued. Thinking about it for a while, this did make sense.  At the end of the
document, when a partial Link Reference Definition is closed, an empty string (&lt;code&gt;""&lt;/code&gt;) is
passed into the Link Reference Definition functions to make sure the Link Reference
Definition is terminated properly.  As a blank line in a normal document naturally
closes the element, the passing of the empty string into those functions has proven
to be a smart and efficient solution.  However, following the flow of data in the log
statements, it became obvious that these empty strings were surfacing to the
&lt;code&gt;__parse_blocks_pass&lt;/code&gt; function where that blank line was eventually stored as an entry
in the &lt;code&gt;lines_to_requeue&lt;/code&gt; variable.  Once placed in that variable, it was requeued and
the extra blank line appeared in the array of tokens.&lt;/p&gt;
&lt;p&gt;From this information, I figured out that there were two parts to solving this
problem.  The first was to add this code near the
start of the closing code in the &lt;code&gt;__parse_blocks_pass&lt;/code&gt; function:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;                &lt;span class="n"&gt;was_link_definition_started_before_close&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;False&lt;/span&gt;
                &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;stack&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;was_link_definition_started&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                    &lt;span class="n"&gt;was_link_definition_started_before_close&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;True&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;As this problem only ever occurred with a Link Reference Definition in progress, it
made sense to use that condition as a trigger for the fix.  That change allowed me to
add the code:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;                &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;was_link_definition_started_before_close&lt;/span&gt; &lt;span class="ow"&gt;and&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="n"&gt;lines_to_requeue&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt;
                    &lt;span class="k"&gt;del&lt;/span&gt; &lt;span class="n"&gt;lines_to_requeue&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
                    &lt;span class="n"&gt;line_number&lt;/span&gt; &lt;span class="o"&gt;-=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Basically, in the cases where an open Link Reference Definition is closed at the
end of the document, if there is a blank line at the start of the lines to requeue,
remove it.  As a side effect of removing that line, it also becomes necessary to adjust
the line number by 1 to ensure that the line number is pointing at the correct line.&lt;/p&gt;
&lt;p&gt;My initial thought was that this code was a kludge, but in the end, I grew to be okay
with it.  As the mainline is where the requeued lines are managed, it started to grow
on me that this was the correct place to address that issue.  Fixing it at any other
point seemed to me like I was just going to pass a variable around through various
functions just to handle this one extant case.  This was indeed clearer.&lt;/p&gt;
&lt;h3 id="the-case-of-the-possibly-missing-link-text"&gt;The Case of the Possibly Missing Link Text&lt;a class="headerlink" href="#the-case-of-the-possibly-missing-link-text" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Sometimes, as with
&lt;a href="https://github.github.com/gfm/#example-575"&gt;example 575&lt;/a&gt;,
I look at an example or its scenario test, and I get a feeling that it does not look
quite right.  If am in the middle of something else, which I usually am, I note it down
in the issue list to be worked on later.  When I find the time to start working on it,
I almost always begin by looking around for other supporting cases or documentation
to support any possible answers to the asked question.&lt;/p&gt;
&lt;p&gt;This issue was no different than the rest.  To me:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="n"&gt;foo&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="n"&gt;foo&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;&lt;span class="err"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;url1&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;just looked weird.  Should not it be the shortcut link that took precedence?  The
following example,
&lt;a href="https://github.github.com/gfm/#example-576"&gt;example 576&lt;/a&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="n"&gt;foo&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="ow"&gt;not&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;link&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="n"&gt;foo&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;&lt;span class="err"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;url1&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;produced the following HTML:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;p&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;a&lt;/span&gt; &lt;span class="na"&gt;href&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;"/url1"&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;foo&lt;span class="p"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;a&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;(not a link)&lt;span class="p"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;p&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;If that was the case for example 576’s output, in the HTML output for example 575:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;p&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;a&lt;/span&gt; &lt;span class="na"&gt;href&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;""&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;foo&lt;span class="p"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;a&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;p&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;where were the parentheses?&lt;/p&gt;
&lt;h4 id="debugging-and-resolving-the-issue_2"&gt;Debugging and Resolving the Issue&lt;a class="headerlink" href="#debugging-and-resolving-the-issue_2" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;It took bit of looking around, but I finally found some good supporting
documentation.  In the case of example 576, the text &lt;code&gt;not a link&lt;/code&gt; does fulfil the
link destination requirements of an inline link with &lt;code&gt;not&lt;/code&gt;, but then fails on the link
title requirements because of missing enclosing characters, such as &lt;code&gt;"&lt;/code&gt;.  In a
subsequent processing pass through the tokens, the inline processors looks for a
shortcut link, which it does find with &lt;code&gt;[foo]&lt;/code&gt;, ignoring the text &lt;code&gt;(not a link)&lt;/code&gt;.
This leaves that text as normal text to be dealt with outside of the Link element.&lt;/p&gt;
&lt;p&gt;The case for example 575 is slightly different.  Based on
&lt;a href="https://github.github.com/gfm/#example-495"&gt;example 495&lt;/a&gt;, this Markdown text:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="n"&gt;link&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;is a valid inline, producing the HTML output:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;p&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;a&lt;/span&gt; &lt;span class="na"&gt;href&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;""&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;link&lt;span class="p"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;a&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;p&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This almost exactly matches the desired output for example 576.  In the previous case,
the text between the parentheses, &lt;code&gt;(not a link)&lt;/code&gt; was determined to be invalid, and
hence was not
processed as a valid inline link.  However, in this case, it is perfectly valid for
an inline link to have no text within its parentheses, as example 495 demonstrates.
As that text was a valid part of an inline link element, the entire text
was consumed, leaving nothing else for processing to deal with later.  With nothing
outside of the inline link left for processing, nothing gets added to the surrounding
paragraph as “leftover” text.&lt;/p&gt;
&lt;p&gt;Based on that research, the parsing of the above Markdown into the above HTML is 100%
correct and explainable.  Did it initially look weird? Yes.  But was it correct?  Yes
again. Question resolved and removed from the issues list.&lt;/p&gt;
&lt;h3 id="where-was-that-extra-text-coming-from"&gt;Where Was That Extra &lt;code&gt;text&lt;/code&gt; Coming From?&lt;a class="headerlink" href="#where-was-that-extra-text-coming-from" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;While the 8 scenario tests in which this issue was found were passing, they were only
passing because I had modified the acceptance data in the tests.  In each case, I
simply added &lt;code&gt;text&lt;/code&gt; at the appropriate place in the token data to match what was
expected.  The decision to do that never really sat well with me, so I was happy that
it was time to fix this issue.&lt;/p&gt;
&lt;p&gt;For this issue, I started by looking at the easy (ok, easier) to digest
&lt;a href="https://github.github.com/gfm/#example-524"&gt;example 524&lt;/a&gt;.  The Markdown for this
example is:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;link&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;foo&lt;/span&gt; &lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="n"&gt;bar&lt;/span&gt;&lt;span class="o"&gt;**&lt;/span&gt; &lt;span class="o"&gt;`#`*&lt;/span&gt;&lt;span class="p"&gt;](&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;uri&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;and its HTML output is:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;p&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;a&lt;/span&gt; &lt;span class="na"&gt;href&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;"/uri"&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;link &lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;em&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;foo &lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;strong&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;bar&lt;span class="p"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;strong&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt; &lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;code&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;#&lt;span class="p"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;code&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;em&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;a&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;p&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Double checking those two against each other, and against the GFM specification,
everything looked fine.  However, when I looked at the serialized token for the link:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;[link:inline:/uri:::::link *foo **bar** text*]
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;I noticed that the word &lt;code&gt;text&lt;/code&gt; was showing up in the output instead of the text &lt;code&gt;#&lt;/code&gt;.
At that time, as noted above, I simply added the token information as-is to the output,
created an item in the issues list, and planned to deal with it later.  It was not
that later.  I really wanted to figure out where that &lt;code&gt;text&lt;/code&gt; was coming from.&lt;/p&gt;
&lt;h4 id="debugging-and-resolving-the-issue_3"&gt;Debugging and Resolving the Issue&lt;a class="headerlink" href="#debugging-and-resolving-the-issue_3" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;When I looked at the logs, I arrived at the answer within the first 5 minutes of looking
at the problem.
It turned out that I forgot to add some functionality to the
&lt;code&gt;__collect_text_from_blocks&lt;/code&gt; function.  This function is used to determine the
representative text from a list of inline blocks.  That text is then used to create a
proper record of what the actual text for the link label was before any processing, as
well as a normalized version being used for looking up link information.  In the case
of various inline tokens, instead of placing the original text for the inline element
in the resultant string, the literal text &lt;code&gt;text&lt;/code&gt; was added to that string.&lt;/p&gt;
&lt;p&gt;Fixing this was easy, as in most inline tokens use the &lt;code&gt;token_text&lt;/code&gt; member
variable to contain the correct text.  After running the scenario tests for each of the
failing cases, the &lt;code&gt;__collect_text_from_blocks&lt;/code&gt; function was modified to properly handle
replacement of the text for the various inline cases.  I then manually went through all
eight cases and verified that they were working properly, without the text &lt;code&gt;text&lt;/code&gt;
showing up in the token unless the string &lt;code&gt;text&lt;/code&gt; was in the source Markdown.&lt;/p&gt;
&lt;p&gt;It took a while, but I got it working cleanly, and for all inline tokens.  It just
felt good to get this “dirty” issue off the books!&lt;/p&gt;
&lt;h3 id="where-was-that-extra-not-coming-from"&gt;Where Was That Extra &lt;code&gt;not&lt;/code&gt; Coming From?&lt;a class="headerlink" href="#where-was-that-extra-not-coming-from" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;After working on the last issue, I thought that this issue would take the same level of
effort and research to resolve.  In the tokenization for the link in
&lt;a href="https://github.github.com/gfm/#example-576"&gt;example 576&lt;/a&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;link:shortcut:/url1::not:::foo
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;I wondered why the text &lt;code&gt;not&lt;/code&gt; was in the token.  Spotted when I was debugging
the last issue, that &lt;code&gt;not&lt;/code&gt; value just looked out of place.&lt;/p&gt;
&lt;h4 id="debugging-and-resolving-the-issue_4"&gt;Debugging and Resolving the Issue&lt;a class="headerlink" href="#debugging-and-resolving-the-issue_4" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;Thankfully, this was an easy problem to find, debug, and fix.  In the
&lt;code&gt;handle_link_types&lt;/code&gt; function for the &lt;code&gt;link_helper.py&lt;/code&gt; module, the Markdown for the
example:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="n"&gt;foo&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="ow"&gt;not&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;link&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="n"&gt;foo&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;&lt;span class="err"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;url1&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;was parsed to see if it could be a shortcut link and failed.  However, before it
failed, the link label was set to &lt;code&gt;foo&lt;/code&gt; and the link destination was set to &lt;code&gt;not&lt;/code&gt;.
In the code for &lt;code&gt;handle_link_types&lt;/code&gt;, this meant that the &lt;code&gt;inline_link&lt;/code&gt; variable was
set to the link destination and the &lt;code&gt;pre_inline_link&lt;/code&gt; variable was set to the
original text for the link destination before processing &lt;code&gt;not&lt;/code&gt;.  After the failed
processing, the &lt;code&gt;pre_inline_link&lt;/code&gt; variable was never cleared but was passed into
the constructor for the link token when it was created.&lt;/p&gt;
&lt;p&gt;With that research performed, it was easy to determine out that the statement:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;            &lt;span class="n"&gt;pre_inline_link&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;""&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;was all that was required to resolve this issue quickly and cleanly.&lt;/p&gt;
&lt;h3 id="what-to-do-with-backslashes-in-code-spans"&gt;What to Do With Backslashes in Code Spans?&lt;a class="headerlink" href="#what-to-do-with-backslashes-in-code-spans" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Sometimes the questions I pose to myself have simple answers.  In this case, the
question was:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;backslash&lt;/span&gt; &lt;span class="k"&gt;in&lt;/span&gt; &lt;span class="n"&gt;code&lt;/span&gt; &lt;span class="n"&gt;span&lt;/span&gt;&lt;span class="o"&gt;?&lt;/span&gt; &lt;span class="n"&gt;what&lt;/span&gt; &lt;span class="n"&gt;should&lt;/span&gt; &lt;span class="n"&gt;it&lt;/span&gt; &lt;span class="n"&gt;look&lt;/span&gt; &lt;span class="k"&gt;like&lt;/span&gt;&lt;span class="o"&gt;?&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h4 id="debugging-and-resolving-the-issue_5"&gt;Debugging and Resolving the Issue&lt;a class="headerlink" href="#debugging-and-resolving-the-issue_5" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;Doing a quick check in the backslash section of the GFM specification, I did not see
anything relevant.  However, in the code spans section,
&lt;a href="https://github.github.com/gfm/#example-348"&gt;example 348&lt;/a&gt; provided me with the
information that I needed.&lt;/p&gt;
&lt;p&gt;The preface to the example states simply:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Note that backslash escapes do not work in code spans. All backslashes are treated literally:&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;This is backed up with example 348, whose Markdown:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="ss"&gt;`foo\`bar`&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;produces the following HTML:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;p&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;code&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;foo\&lt;span class="p"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;code&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;bar`&lt;span class="p"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;p&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The answer to my question?  Leave them alone.  They exist as they are, no parsing
or interpretation needed.  As far as code spans go, they are just another normal
character.&lt;/p&gt;
&lt;h4 id="is-it-worth-it"&gt;Is It Worth It?&lt;a class="headerlink" href="#is-it-worth-it" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;As I quickly resolved this issue, I paused before moving on to the next issue.  I
started to wonder whether this practice of noting questions and issues in the
issues list was worth it.  In this case, this was a question whose answer I should have
known. The fact that I did not know it right away was somewhat embarrassing.&lt;/p&gt;
&lt;p&gt;Thinking about it some more, I decided to really devote some serious time to
understand what I felt about this question, and to really think thought through it.
Doing that, it was only 5 minutes later when I noticed that I had changed how I was
feeling from embarrassed to proud and confident.&lt;/p&gt;
&lt;p&gt;It took a bit of time, but I mentally reviewed the other times I have used the
issues list to document questions and possible bugs.  Overwhelmingly, the issues that I
logged either helped identify an issue or helped me solidify my understanding of the
project and the GFM specification.  Should I have known that fact about code spans and
backslashes? Maybe?  While I have a good grasp of the specification, it is also a large
specification with a decent number of exceptional cases along the way.&lt;/p&gt;
&lt;p&gt;But as I thought about that further, I realized that my sincerity about the quality for
the PyMarkdown project was not absolute, but ever increasing.  When I started the
project, I had to look up every fact about every element, just to make sure I had it
right.  I knew that I was now at a level where I usually only had to look up the more
esoteric and exceptional parts of the specification.  If I was sincere about the
quality of the project, I also needed to acknowledge the quality that my learning about
the specification brought to the project.&lt;/p&gt;
&lt;p&gt;Given that altered point of view, I was confident that it was worth it.  Both as an
early problem indicator and as a learning tool, it was indeed worth it.  And besides
folks, I know I am not perfect.  That does not mean I am going to stop trying and stop
learning.  And to me, that is what made the issue list worth it!&lt;/p&gt;
&lt;h3 id="link-labels-and-special-characters"&gt;Link Labels and Special Characters&lt;a class="headerlink" href="#link-labels-and-special-characters" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;When I add a question to my issues list, it is always with the hope that I have
forgotten something simple, and some quick research will resolve the issue.  In this
case, the question was:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;- backslash and char ent in link label? tests?
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Or, for those that do not read native “Jack”:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;- what about the backslash character and the character entities in link labels?
    - are they covered by tests?
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Reading this now, I believe that this was an honest question to verify how backslashes
and character entities are handled in link labels.  Based on my current work solving
these issues, I have a good idea on the answer, but at the time, I probably was not
as sure. The answer?  From previous issues, both backslashes characters and character
entities are allowed in most areas, including link labels.&lt;/p&gt;
&lt;p&gt;But as always, it was time to back up my guess with research.  And something told me
it was not going to be the quick answer I was hoping for.&lt;/p&gt;
&lt;h4 id="researching-the-issue"&gt;Researching the Issue&lt;a class="headerlink" href="#researching-the-issue" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;Starting my search at the beginning, I looked for a scenario test that contained
a backslash in a link label.  It was tricky, but eventually I found
&lt;a href="https://github.github.com/gfm/#example-523"&gt;example 523&lt;/a&gt;
in the section on inline links:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="n"&gt;link \[bar&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;uri&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Checking the HTML output, it is easy to see that the backslash effectively escapes the
character following it, even in the link label:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;p&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;a&lt;/span&gt; &lt;span class="na"&gt;href&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;"/uri"&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;link [bar&lt;span class="p"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;a&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;p&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Backslashes?  Check.  One part of the issue down, one to go.&lt;/p&gt;
&lt;p&gt;To start researching the issue of character entities in link labels, I decided to start
with inline Unicode characters.  Based on my usage of Markdown, I generally use
character entities
to represent characters that I cannot find on my keyboard, usually Unicode characters.
As such, starting with inline Unicode characters seemed like a good first step before
tackling character entities.  This decision was validated by my ease in finding not 1,
but 2 examples in the GFM specification,
&lt;a href="https://github.github.com/gfm/#example-175"&gt;example 175&lt;/a&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="err"&gt;ΑΓΩ&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="err"&gt;φου&lt;/span&gt;

&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="err"&gt;αγω&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;and &lt;a href="https://github.github.com/gfm/#example-548"&gt;example 548&lt;/a&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;[ẞ]&lt;/span&gt;

&lt;span class="na"&gt;[SS]: /url&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;But try as I might, I could not find an example of a character entity reference within
a link label.  As I looked, I did find the text above
&lt;a href="https://github.github.com/gfm/#example-327"&gt;example 327&lt;/a&gt;
which backed up my previous research stating:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Entity and numeric character references are recognized in any context besides code spans or code blocks, including URLs, link titles, and fenced code block info strings:&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;So, while the GFM specification did not explicitly state that character entities in link
labels were rejected, there were no actual examples of the positive case either.  To
me, that was not a showstopper… it was just an invitation to be creative!&lt;/p&gt;
&lt;h4 id="testing-the-issue"&gt;Testing the Issue&lt;a class="headerlink" href="#testing-the-issue" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;The first thing I needed to do was to come up with some good examples to test against.
To do this, I
started by creating the scenario test &lt;code&gt;test_character_references_328a&lt;/code&gt; as a variation
of scenario test &lt;code&gt;test_character_references_328&lt;/code&gt;.  The sole difference between these
two scenario tests was the specification of the link label as &lt;code&gt;[f&amp;amp;ouml;&amp;amp;ouml;]&lt;/code&gt; instead
of &lt;code&gt;[foo]&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;In a similar fashion, I copied the test &lt;code&gt;test_reference_links_558&lt;/code&gt; into the new test
&lt;code&gt;test_reference_links_558a&lt;/code&gt;, altering the link label from &lt;code&gt;[bar\\\\]&lt;/code&gt; to &lt;code&gt;[bar&amp;amp;#x5C;]&lt;/code&gt;.
If I understand the specification properly, both &lt;code&gt;\\\\&lt;/code&gt; and &lt;code&gt;&amp;amp;#x5C;&lt;/code&gt; should produce the
same &lt;code&gt;\&lt;/code&gt; in the HTML output, so to me it was a good test case.  In addition, I added the
test function &lt;code&gt;test_reference_links_558b&lt;/code&gt; with the link label of &lt;code&gt;[bar&amp;amp;beta;]&lt;/code&gt; to
make sure named entities were addressed.&lt;/p&gt;
&lt;p&gt;Finally, before I started debugging and changing code, I created the following Markdown
document from bits and pieces of those new tests:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="n"&gt;ouml&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="n"&gt;ouml&lt;/span&gt;&lt;span class="p"&gt;;](&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="n"&gt;ouml&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="n"&gt;ouml&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="ss"&gt;"f&amp;amp;ouml;&amp;amp;ouml;"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;bar&lt;/span&gt;&lt;span class="err"&gt;\\&lt;/span&gt;&lt;span class="p"&gt;](&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;url&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;bar&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;#&lt;/span&gt;&lt;span class="n"&gt;x5C&lt;/span&gt;&lt;span class="p"&gt;;](&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;url&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Verifying its content, I submitted it to my favorite test harness,
&lt;a href="https://johnmacfarlane.net/babelmark2/?text=%5Bf%26ouml%3B%26ouml%3B%5D(%2Ff%26ouml%3B%26ouml%3B+%22f%26ouml%3B%26ouml%3B%22)%0A%5Bbar%5C%5C%5D(%2Furl)%0A%5Bbar%26%23x5C%3B%5D(%2Furl)%0A"&gt;BabelMark 2&lt;/a&gt;,
getting the following results for reference parser, &lt;code&gt;commonmark.js 0.29.0&lt;/code&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;p&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;a&lt;/span&gt; &lt;span class="na"&gt;href&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;"/f%C3%B6%C3%B6"&lt;/span&gt; &lt;span class="na"&gt;title&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;"föö"&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;föö&lt;span class="p"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;a&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
&lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;a&lt;/span&gt; &lt;span class="na"&gt;href&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;"/url"&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;bar\&lt;span class="p"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;a&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
&lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;a&lt;/span&gt; &lt;span class="na"&gt;href&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;"/url"&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;bar\&lt;span class="p"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;a&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;p&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Taking the specific HTML lines generated for each scenario test, I inserted that text
into the owning scenario test, and verified that the proper HTML was being output.
With that taken care of, it was on to cleaning up the consistency check!&lt;/p&gt;
&lt;h4 id="debugging-and-resolving-the-issue_6"&gt;Debugging and Resolving the Issue&lt;a class="headerlink" href="#debugging-and-resolving-the-issue_6" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;After putting in that hard work to get the scenario tests set up, the resolution to
this issue was anticlimactic.  In the &lt;code&gt;inline_helper.py&lt;/code&gt; module, the
&lt;code&gt;handle_character_reference&lt;/code&gt; was already being called, but its return value was
being ignored.  That was easily addressed by replacing the line:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;            &lt;span class="n"&gt;current_string_unresolved&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;InlineHelper&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append_text&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
                &lt;span class="n"&gt;current_string_unresolved&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;new_string_unresolved&lt;/span&gt;
            &lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;with the line:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;            &lt;span class="n"&gt;current_string_unresolved&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="n"&gt;new_string_unresolved&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The other change that happened at the same time was that the &lt;code&gt;new_string_unresolved&lt;/code&gt;
variable was added directly to the &lt;code&gt;current_string_unresolved&lt;/code&gt; variable instead of
using the &lt;code&gt;append_text&lt;/code&gt; function.  As the &lt;code&gt;append_text&lt;/code&gt; function is used to add
text to a string while respecting any needed encoding, it was adding a step of extra
encoding to the text where it was not needed.  With those two changes in place,
a couple of extra changes were needed to the &lt;code&gt;handle_character_reference&lt;/code&gt; function to
make sure it was returning the correct original string, instead of a mangled version.&lt;/p&gt;
&lt;p&gt;Having made those changes, and a couple of test runs later, the problem was fixed and
verified.  While the research and setup of the new tests took a while, the actual
resolution of the issue took less than 20 minutes to complete.  With everything setup,
the logs were very helpful by showing me where the extra transformation of the text was
taking place, leading to a quick resolution.  Yeah verbose log files!&lt;/p&gt;
&lt;p&gt;Now on to the last issue for this week!&lt;/p&gt;
&lt;h3 id="indented-code-blocks-and-disappearing-leading-spaces"&gt;Indented Code Blocks and Disappearing Leading Spaces&lt;a class="headerlink" href="#indented-code-blocks-and-disappearing-leading-spaces" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;I knew that the spaces were not disappearing, they just were not being recorded
properly.  But the phrase “disappearing leading spaces” sounded cool, so that is
what I called it to myself.  It was also the last thing that I felt I needed to fix
before getting back to implementing the Markdown transformer.  Having been discovered in
&lt;a href="core-11.md#indented-code-blocks-and-blank-lines"&gt;the last article&lt;/a&gt;,
this was the issue with the Markdown transformer check and
&lt;a href="https://github.github.com/gfm/#example-81"&gt;example 81&lt;/a&gt; where leading spaces were not
always being record for later rehydration.&lt;/p&gt;
&lt;p&gt;Doing a bit of research, I deduced that when a blank line is encountered in an
indented code block, there are three possibilities: too much whitespace, too little
whitespace, and just the right amount of whitespace.&lt;/p&gt;
&lt;p&gt;The scenario test for
&lt;a href="https://github.github.com/gfm/#example-82"&gt;example 82&lt;/a&gt; was passing without any
problems:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;    &lt;span class="n"&gt;chunk1&lt;/span&gt;
&lt;span class="err"&gt;{&lt;/span&gt;&lt;span class="k"&gt;space&lt;/span&gt;&lt;span class="err"&gt;}{&lt;/span&gt;&lt;span class="k"&gt;space&lt;/span&gt;&lt;span class="err"&gt;}{&lt;/span&gt;&lt;span class="k"&gt;space&lt;/span&gt;&lt;span class="err"&gt;}{&lt;/span&gt;&lt;span class="k"&gt;space&lt;/span&gt;&lt;span class="err"&gt;}{&lt;/span&gt;&lt;span class="k"&gt;space&lt;/span&gt;&lt;span class="err"&gt;}{&lt;/span&gt;&lt;span class="k"&gt;space&lt;/span&gt;&lt;span class="err"&gt;}&lt;/span&gt;
      &lt;span class="n"&gt;chunk2&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;which took care of the “too many” case.  A quick change of this scenario test&lt;sup id="fnref:recent"&gt;&lt;a class="footnote-ref" href="#fn:recent"&gt;1&lt;/a&gt;&lt;/sup&gt;
to present 4 spaces on the blank line instead of 6 spaces resulted in the expected
behavior. That took care of the “just the right amount” case.  Left was the “too little”
case and the issues demonstrated by example 81.&lt;/p&gt;
&lt;h4 id="debugging-and-resolving-the-issue_7"&gt;Debugging and Resolving the Issue&lt;a class="headerlink" href="#debugging-and-resolving-the-issue_7" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;Originally, my time on this issue was spent looking at the logs with a specific focus
on how the tokens were created.  I had theorized that most of the issue was going
to be concerned with how I extracted and stored the whitespace in the text tokens…
and I was wrong.  Looking at the logs, the tokens looked fine when they exited
the initial processing phase, containing the right number of space characters and the
right number of newline characters.&lt;/p&gt;
&lt;p&gt;Debugging further, after the &lt;code&gt;coalesce_text_blocks&lt;/code&gt; function was invoked on those
tokens, the leading whitespace was missing.  Digging deeper, the first thing that I
noticed is that the variable &lt;code&gt;remove_leading_spaces&lt;/code&gt; was being populated with data from
the text token’s &lt;code&gt;extra_data&lt;/code&gt; field, not the &lt;code&gt;extracted_whitespace&lt;/code&gt; field.  Fixing that
issue got me part of the way there.  The next part was to alter the &lt;code&gt;TextMarkdownToken&lt;/code&gt;
code to allow the &lt;code&gt;combine&lt;/code&gt; function to return any whitespace that it removed.  This
change was pivotal in making sure that any removed whitespace was stored somewhere.
Finally, in the case where the coalescing takes place within an indented code
block, that removed whitespace is added to the active Indented Code Block token.&lt;/p&gt;
&lt;p&gt;Unlike the previous issue, this one took a bit of effort to arrive at the right
solution.  Looking back in hindsight, the path to fix it seems as clear as glass,
but it took getting past a number of failed solutions to get there.  Each one of the
steps outlined in the last paragraph had to be coded, debugged, and tested before
going forward. And in most cases, those steps were not the first solution, but the
third or fourth.&lt;/p&gt;
&lt;p&gt;But still, it was worth it.  Another item off the issues list, and the project’s
quality was raised just a bit higher than before!&lt;/p&gt;
&lt;h2 id="what-was-my-experience-so-far"&gt;What Was My Experience So Far?&lt;a class="headerlink" href="#what-was-my-experience-so-far" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;For any readers that have followed the progression of this project from a simple idea to
its current form, you may have noticed that my confidence and happiness spikes a bit
after a round of refactoring.  There is just something about cleaning up the code and
resolving ambiguity that makes me smile and makes me feel better about the project.
While I can quantitatively show that the number of possible issues and tasks are
declining, I believe that I am more affected by the qualitative changes in the project.
Removing a single large task from the issues list?  Meh.  Removing 6-7 small tasks or
questions from that same list.  Yeah!&lt;/p&gt;
&lt;p&gt;But the interesting part of this block of work was not the work itself, but the
writing of the article about the work.  During the writing of this article, it
suddenly dawned on me.  For the first time
during this project’s lifetime, I believed that I could see the end of the project.
There was just this moment where I remember looking at the issues list, and the
list looked smaller.  That was followed by a moment of clarity that the consistency
checks were making a significant impact on my perception of the project.  Combined,
these two perceptions linked together to form a new level of confidence in my mind.&lt;/p&gt;
&lt;p&gt;That new level of confidence spoke to me. The scenario tests were effective.  The
consistency checks were working.  And in my mind, the project was clearly past the
half-way point on its journey to the finish line!&lt;/p&gt;
&lt;h2 id="what-is-next"&gt;What is Next?&lt;a class="headerlink" href="#what-is-next" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;With the current round of questions and issues addressed, it was time to get back to
adding to the consistency checker.  While I knew I had a busy week of personal stuff
and professional stuff coming up, I also knew that I did not want to lose any momentum
on the project.  And making progress on the Markdown transformer was just the right
kind of thing to help boost my spirits in a long week!&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr/&gt;
&lt;ol&gt;
&lt;li id="fn:recent"&gt;
&lt;p&gt;As part of writing this article, I added scenario test &lt;code&gt;test_indented_code_blocks_082a&lt;/code&gt; which is the result of the number of spaces on the blank line being reduced from 6 to 4. &lt;a class="footnote-backref" href="#fnref:recent" title="Jump back to footnote 1 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</content><category term="Software Quality"></category><category term="markdown linter"></category><category term="core linter"></category></entry><entry><title>Markdown Linter - Transforming Back to Markdown</title><link href="https://jackdewinter.github.io/2020/07/20/markdown-linter-transforming-back-to-markdown/" rel="alternate"></link><published>2020-07-20T00:00:00-07:00</published><updated>2020-07-20T00:00:00-07:00</updated><author><name>Jack De Winter</name></author><id>tag:jackdewinter.github.io,2020-07-20:/2020/07/20/markdown-linter-transforming-back-to-markdown/</id><summary type="html">
&lt;h2 id="summary"&gt;Summary&lt;a class="headerlink" href="#summary" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;In my
&lt;a href="https://jackdewinter.github.io/2020/07/13/markdown-linter-improving-consistency/"&gt;last article&lt;/a&gt;,
I talked about how I believe that the benefit of adding consistency checks to the
project outweighed the costs of developing those tests and maintaining them.  In this
article, I talk about how I decided to double down on the consistency checks by adding
a …&lt;/p&gt;</summary><content type="html">
&lt;h2 id="summary"&gt;Summary&lt;a class="headerlink" href="#summary" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;In my
&lt;a href="https://jackdewinter.github.io/2020/07/13/markdown-linter-improving-consistency/"&gt;last article&lt;/a&gt;,
I talked about how I believe that the benefit of adding consistency checks to the
project outweighed the costs of developing those tests and maintaining them.  In this
article, I talk about how I decided to double down on the consistency checks by adding
a token transformer that transforms the tokenized document back into its original
Markdown.&lt;/p&gt;
&lt;h2 id="introduction"&gt;Introduction&lt;a class="headerlink" href="#introduction" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Since implementing the consistency checks for the line numbers and column numbers in
the tokens produced by PyMarkdown’s parser, I have found enough errors to
remove any questions in my mind regarding their usefulness.  From my point of view,
adding those consistency checks is not a “pull the fire alarm” concern, but more of a
“let’s put some extra water on the campfire and wait to be sure” concern.  These checks
are an important tool in a collection of tools that I use with each build to help me
ensure that my desired level of quality for the project is maintained.&lt;/p&gt;
&lt;p&gt;But while I have made great progress on the automated validation of those line numbers
and column numbers, validating the content of those tokens was a different story.
Each test already includes a comparison of the output text to the reference
implementation’s output, but I felt that it was only testing the scenario’s output, not
the input.  After all, there were times when I introduced a small change to the
structure of the token and token itself changed, but the HTML did not change one bit.
While I knew I had 100% coverage for the token’s output, I did not feel that I had the
right amount of coverage for the tokens themselves.&lt;/p&gt;
&lt;p&gt;The only way to really test this out?  Use the tokens themselves to generate the
Markdown that created them.  If the tokens contained all the needed information,
the regenerated input text should match the actual input text.&lt;/p&gt;
&lt;h2 id="what-is-the-audience-for-this-article"&gt;What Is the Audience for This Article?&lt;a class="headerlink" href="#what-is-the-audience-for-this-article" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;While detailed more eloquently in
&lt;a href="https://jackdewinter.github.io/2020/04/05/what-is-the-audience-for-my-blog/#what-is-the-audience-for-my-blog"&gt;this article&lt;/a&gt;,
my goal for this technical article is to focus on the reasoning behind my solutions,
rather that the solutions themselves.  For a full record of the solutions presented in
this article, please go to this project’s GitHub repository and consult the
commit of
&lt;a href="https://github.com/jackdewinter/pymarkdown/commit/20b129ee1b2058b4495395251d25a8fafa88bfa3"&gt;16 Jul 2020&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id="a-small-note-on-the-commit"&gt;A Small Note on the Commit&lt;a class="headerlink" href="#a-small-note-on-the-commit" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;We all have weeks that are busier than others, and the week of 12 Jul 2020 was one of
those weeks for me.  All the substantial work on the commit was completed and
tested on 12 Jul 2020 before I started writing the last article.  However, it was not
until that Thursday that I was able to complete the usual cleanup and refactoring that
I require before I submit a normal commit.&lt;/p&gt;
&lt;p&gt;While this does not affect the work that was done, the timing of the actual work was
important to me, for reasons described in the next section.&lt;/p&gt;
&lt;h2 id="beware-of-rabbit-holes"&gt;Beware of Rabbit Holes&lt;a class="headerlink" href="#beware-of-rabbit-holes" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;While I feel that I both wanted and needed to add these new checks, I also knew that I
needed to be cautious.  It was less than a month ago when
&lt;a href="https://jackdewinter.github.io/2020/06/22/markdown-linter-rabbit-hole-2-losing-my-way/"&gt;I lost my way&lt;/a&gt;
trying to add tab support to the consistency checks, and I was still smarting from that
experience.  Instead of hitting a difficult problem and taking a step back
to reevaluate the situation, I just kept on going, not realizing how much time had
passed on that one problem.  When I did stop and look up at where I was, it was almost
immediately evident that I got lost in the problem… again.&lt;/p&gt;
&lt;p&gt;As this was another major task for consistency checks, I was keenly aware that I was
going to need to take better precautions this time around.  If I did not, I was likely
to fall into the same pattern and get lost again.  As such, I was determined to come up
with a firm set of rules that I would follow for this task.  After some thought on
those rules, the rules that I came up with are as follows:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;no tab support&lt;ul&gt;
&lt;li&gt;no need to go down that path again so soon!&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;no container block support&lt;ul&gt;
&lt;li&gt;get the basics down, then complicate things!&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;primary support for the text token, the paragraph token, and the blank line token&lt;ul&gt;
&lt;li&gt;these are the primary building blocks for the document&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;no other leaf block support except for the thematic break and the indented code block tokens&lt;ul&gt;
&lt;li&gt;the indented code block token modifies the output from the text tokens, thus making sure that changing that output&lt;/li&gt;
&lt;li&gt;the thematic break token provides another external touchpoint that non-text related tokens are possible&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;no inline support except for the hard break token&lt;ul&gt;
&lt;li&gt;one inline token would prove that the others would be possible&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;proper support for the character sequences and the backslash escape character&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In addition, I decided to help mitigate the risk of going down a rabbit hole for this
new feature by
&lt;a href="https://en.wikipedia.org/wiki/Timeboxing"&gt;timeboxing&lt;/a&gt;
the work on the task to approximately 36 hours clock time.  While I did do a bit of
research before that Friday night, the time I allocated for this task was from Friday
after work until I started writing my article on Sunday morning.  As I have never been
late with an article, despite coming close a couple of times, I knew that it would be a
good stopping point that I would not ignore easily.&lt;/p&gt;
&lt;h2 id="starting-down-the-path"&gt;Starting Down the Path&lt;a class="headerlink" href="#starting-down-the-path" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;While I have plans to simplify it later, as I did with my work on
&lt;a href="https://jackdewinter.github.io/2020/03/16/markdown-linter-verifying-base-scenarios/#adding-translating-into-html"&gt;validating the base scenarios&lt;/a&gt;,
the
first iteration of this code was going to be somewhat messy while I figured
things out.  But the base bones of the transformer started out very cleanly with the
following code:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;transform&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;actual_tokens&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="sd"&gt;"""&lt;/span&gt;
&lt;span class="sd"&gt;        Transform the incoming token stream back into Markdown.&lt;/span&gt;
&lt;span class="sd"&gt;        """&lt;/span&gt;
        &lt;span class="n"&gt;transformed_data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;""&lt;/span&gt;
        &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;next_token&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;actual_tokens&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="c1"&gt;# do stuff&lt;/span&gt;

        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;transformed_data&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Not very glamorous, but a good starting point.  As with anything that transforms
something list related, I needed to perform some action on each token, that action
being represented by the comment &lt;code&gt;do stuff&lt;/code&gt;.  Just a good and solid place to start.&lt;/p&gt;
&lt;h3 id="baby-steps-setting-up-for-token-discovery"&gt;Baby Steps - Setting up for Token Discovery&lt;a class="headerlink" href="#baby-steps-setting-up-for-token-discovery" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;The next step was a simple one: discover all the tokens I would need to eventually
transform.  As I took this same approach with the &lt;code&gt;TransformToGfm&lt;/code&gt; class, and that
approach was successful, I decided to adopt the same process with this new class.
I started by adding this code in place of the &lt;code&gt;# do stuff&lt;/code&gt; comment:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;            &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="bp"&gt;False&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="k"&gt;pass&lt;/span&gt;
            &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="k"&gt;assert&lt;/span&gt; &lt;span class="bp"&gt;False&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"next_token&amp;gt;&amp;gt;"&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;next_token&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Once that was done, I then modified it to take care of the end tokens:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;            &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="bp"&gt;False&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="k"&gt;pass&lt;/span&gt;
            &lt;span class="k"&gt;elif&lt;/span&gt; &lt;span class="n"&gt;next_token&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;token_name&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;startswith&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;EndMarkdownToken&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;type_name_prefix&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
                &lt;span class="n"&gt;adjusted_token_name&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;next_token&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;token_name&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;
                    &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;EndMarkdownToken&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;type_name_prefix&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="p"&gt;]&lt;/span&gt;
                &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="bp"&gt;False&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                    &lt;span class="k"&gt;pass&lt;/span&gt;
                &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                    &lt;span class="k"&gt;assert&lt;/span&gt; &lt;span class="bp"&gt;False&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"end_next_token&amp;gt;&amp;gt;"&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;adjusted_token_name&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="k"&gt;assert&lt;/span&gt; &lt;span class="bp"&gt;False&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"next_token&amp;gt;&amp;gt;"&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;next_token&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Once again, this code is not glamorous, but it is setting up a good solid framework for
later.  The purpose of this code is to make sure that when I start dealing with actual
tokens, I get a clear indication of whether an if statement and a handler function
exist for that token.  If not, the appropriate assert fails and lets me know which
token is not being handled properly.  In this way, any encountered token must have
a matching if statement and handler, or the transformation fails quickly.&lt;/p&gt;
&lt;h3 id="setting-up-the-test"&gt;Setting Up the Test&lt;a class="headerlink" href="#setting-up-the-test" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;With that in place, I started with a very simple test function,
&lt;code&gt;verify_markdown_roundtrip&lt;/code&gt;.  This function started with the code:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;verify_markdown_roundtrip&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;source_markdown&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;actual_tokens&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;

    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="se"&gt;\t&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;source_markdown&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt;

    &lt;span class="n"&gt;transformer&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;TransformToMarkdown&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="n"&gt;original_markdown&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;transformer&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;transform&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;actual_tokens&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;-=-=-&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;Expected&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;-=-=-&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;source_markdown&lt;/span&gt;
        &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;-=-=-&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;Actual&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;-=-=-&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;original_markdown&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;-=-=-&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;assert&lt;/span&gt; &lt;span class="n"&gt;source_markdown&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;original_markdown&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"Strings are not equal."&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;While I added better error reporting over the course of this work, it started
with a simple test and simple error reporting.  The first two lines of this function
check for a tab character and, if present, exit quickly before any real processing is
done, as tab handling is out of scope.  With that check accomplished, the next 2 lines
create an instance of the transformer
and invoke the &lt;code&gt;transform&lt;/code&gt; function on the list of tokens.  Finally, after printing
some debug information, the &lt;code&gt;source_markdown&lt;/code&gt; variable is compared to the
&lt;code&gt;original_markdown&lt;/code&gt; variable containing the regenerated Markdown.  If the two strings
match, the validation passes, and control is passed back to the caller for more
validation.  If not, the assert fails, and the test is halted.&lt;/p&gt;
&lt;p&gt;The invoking of this function was easily added at the top of the
&lt;code&gt;assert_token_consistency&lt;/code&gt; function, which conveniently was already in place and being
called by each of the scenario tests.  As such, the extra consistency checking was
added to the consistency checks with only a single line change to invoke the
&lt;code&gt;verify_markdown_roundtrip&lt;/code&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;assert_token_consistency&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;source_markdown&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;actual_tokens&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="sd"&gt;"""&lt;/span&gt;
&lt;span class="sd"&gt;    Compare the markdown document against the tokens that are expected.&lt;/span&gt;
&lt;span class="sd"&gt;    """&lt;/span&gt;

    &lt;span class="n"&gt;verify_markdown_roundtrip&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;source_markdown&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;actual_tokens&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;split_lines&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;source_markdown&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;split&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="o"&gt;...&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;After running the tests a couple of times, it was obvious that some work needed to be
done to add if statements and handlers.  And as it is the most central part of most
Markdown documents, it made sense to start with the paragraph token.&lt;/p&gt;
&lt;h3 id="starting-to-discover-tokens"&gt;Starting to Discover Tokens&lt;a class="headerlink" href="#starting-to-discover-tokens" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Once that foundational work was done, I started running the tests and dealing with the
asserts that fired. Each time I encountered an assert failure, I added an if statement
to the normal token or end token block as shown here with the paragraph token:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;            &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;next_token&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;token_name&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;MarkdownToken&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;token_paragraph&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="k"&gt;pass&lt;/span&gt;
            &lt;span class="k"&gt;elif&lt;/span&gt; &lt;span class="n"&gt;next_token&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;token_name&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;startswith&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;EndMarkdownToken&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;type_name_prefix&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
                &lt;span class="n"&gt;adjusted_token_name&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;next_token&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;token_name&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;
                    &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;EndMarkdownToken&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;type_name_prefix&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="p"&gt;]&lt;/span&gt;
                &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;adjusted_token_name&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;MarkdownToken&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;token_paragraph&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                    &lt;span class="k"&gt;pass&lt;/span&gt;
                &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                    &lt;span class="k"&gt;assert&lt;/span&gt; &lt;span class="bp"&gt;False&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"end_next_token&amp;gt;&amp;gt;"&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;adjusted_token_name&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="k"&gt;assert&lt;/span&gt; &lt;span class="bp"&gt;False&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"next_token&amp;gt;&amp;gt;"&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;next_token&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Once I was no longer getting failures from one of the two asserts, I was faced with
another issue.  There were tokens that I recognized with an if statement, but any
handler for that token was out of scope for the time being.  To deal with this,
I made a small modification to the &lt;code&gt;transform&lt;/code&gt; function to allow me to skip those
tokens that were not yet supported by setting the &lt;code&gt;avoid_processing&lt;/code&gt; variable to &lt;code&gt;True&lt;/code&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;transform&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;actual_tokens&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="sd"&gt;"""&lt;/span&gt;
&lt;span class="sd"&gt;        Transform the incoming token stream back into Markdown.&lt;/span&gt;
&lt;span class="sd"&gt;        """&lt;/span&gt;
        &lt;span class="n"&gt;transformed_data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;""&lt;/span&gt;
        &lt;span class="n"&gt;avoid_processing&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;False&lt;/span&gt;

        &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;next_token&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;actual_tokens&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;next_token&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;token_name&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;MarkdownToken&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;token_paragraph&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="k"&gt;pass&lt;/span&gt;
            &lt;span class="k"&gt;elif&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt; &lt;span class="n"&gt;next_token&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;token_name&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;MarkdownToken&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;token_thematic_break&lt;/span&gt; &lt;span class="ow"&gt;or&lt;/span&gt;
                &lt;span class="o"&gt;...&lt;/span&gt;
            &lt;span class="p"&gt;):&lt;/span&gt;
                &lt;span class="n"&gt;avoid_processing&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;True&lt;/span&gt;
                &lt;span class="k"&gt;break&lt;/span&gt;
            &lt;span class="k"&gt;elif&lt;/span&gt; &lt;span class="n"&gt;next_token&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;token_name&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;startswith&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;EndMarkdownToken&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;type_name_prefix&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;

                &lt;span class="n"&gt;adjusted_token_name&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;next_token&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;token_name&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;
                    &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;EndMarkdownToken&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;type_name_prefix&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="p"&gt;]&lt;/span&gt;
                &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;adjusted_token_name&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;MarkdownToken&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;token_paragraph&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                    &lt;span class="o"&gt;...&lt;/span&gt;
                &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                    &lt;span class="k"&gt;assert&lt;/span&gt; &lt;span class="bp"&gt;False&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"end_next_token&amp;gt;&amp;gt;"&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;adjusted_token_name&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="k"&gt;assert&lt;/span&gt; &lt;span class="bp"&gt;False&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"next_token&amp;gt;&amp;gt;"&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;next_token&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;transformed_data&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;avoid_processing&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Basically, the &lt;code&gt;avoid_processing&lt;/code&gt; flag was set to &lt;code&gt;True&lt;/code&gt; for any token that was
recognized by the function but did not have a handler implemented.  Then, with a small
change to the &lt;code&gt;verify_markdown_roundtrip&lt;/code&gt; function, that function could then be
instructed to avoid comparing the two markdown variables.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;verify_markdown_roundtrip&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;source_markdown&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;actual_tokens&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="se"&gt;\t&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;source_markdown&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt;

    &lt;span class="n"&gt;transformer&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;TransformToMarkdown&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="n"&gt;original_markdown&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;avoid_processing&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;transformer&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;transform&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;actual_tokens&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;avoid_processing&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"Processing of token avoided."&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;-=-=-&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;Expected&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;-=-=-&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;source_markdown&lt;/span&gt;
            &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;-=-=-&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;Actual&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;-=-=-&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;original_markdown&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;-=-=-&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;assert&lt;/span&gt; &lt;span class="n"&gt;source_markdown&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;original_markdown&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"Strings are not equal."&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;While this sometimes felt like cheating to me, it was a solid plan.  If any
token in the token list was not supported, it clearly stated it was avoiding
processing.  If that statement was not present and the debug output was present,
I was sure that the comparison was made cleanly.&lt;/p&gt;
&lt;h3 id="why-was-this-a-clear-stop-gap-solution"&gt;Why Was This a Clear Stop-gap Solution?&lt;a class="headerlink" href="#why-was-this-a-clear-stop-gap-solution" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;I believe it is a very clean solution. As I knew from the start that I was going to be
implementing this check in stages, returning a boolean value from the &lt;code&gt;transform&lt;/code&gt;
function allows the transformer to specify if it has any trust in the results. But
unlike my emotion-based trust in the code base for the project, this trust was binary:
it was &lt;code&gt;True&lt;/code&gt; if I encountered any tokens that I had not yet accounted for, otherwise
it was &lt;code&gt;False&lt;/code&gt;.  Basically, if there was no code to handle the token, the function
returned &lt;code&gt;True&lt;/code&gt; to indicated that it was confident that the &lt;code&gt;transformed_data&lt;/code&gt; value
was incorrect.&lt;/p&gt;
&lt;p&gt;Given the situation, and wanting to handle the tokens in stages, I believe this is
the cleanest solution that I could come up with.  No hidden parts, a very small
area of code to determine if the check would be skipped, and almost no code to trip
out when handling for all the tokens was completed.&lt;/p&gt;
&lt;h3 id="leaving-the-foundational-work-behind"&gt;Leaving the Foundational Work Behind&lt;a class="headerlink" href="#leaving-the-foundational-work-behind" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;This foundational work put me in a good position to start transforming the tokens back
into their original Markdown.  While I was sure that this was not going to be easy,
I was sure that I had taken the right foundational steps to make this effort as easy
as it could be.  And if I was slightly wrong and needed a couple more things added to
the foundational code, I was sure that I could easily add them.&lt;/p&gt;
&lt;h2 id="terminology"&gt;Terminology&lt;a class="headerlink" href="#terminology" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;As I start to talk about actual work to reconstruct the original Markdown text from the
parsed tokens, I found out that I needed a simple name to describe the process to
myself.  I prefer to have functions named descriptively after the action they are coded for, preferably with at least one verb describing the action.  Repeating the last half
of the first sentence in each function name did not seem to be a sustainable solution,
especially not for the naming of Python variables.  I needed something more compact.&lt;/p&gt;
&lt;p&gt;After a certain amount of thinking, the process that I feel the comes closest to what
this transformation is accomplishing is rehydration.  Possibly taking influence from my
Java experience, the word &lt;code&gt;serialize&lt;/code&gt; means, according to
&lt;a href="https://en.wikipedia.org/wiki/Serialization"&gt;Wikipedia&lt;/a&gt;:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;translating data structures or object state into a format that can be stored […] and reconstructed later in the same or another computer environment&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Since the word is overused a lot, I looked up synonyms for serialize and &lt;code&gt;hydrate&lt;/code&gt;
was one of the words that was in the list.  In my mind, I was “just adding water” to the
data to get the original Markdown text back, so the new word &lt;code&gt;hydrate&lt;/code&gt; fit pretty wel.&lt;/p&gt;
&lt;p&gt;Therefore, I will use the word &lt;code&gt;hydrate&lt;/code&gt; in the rest of the article and in the
transformer code to signal that the transformer is reconstituting the Markdown.&lt;/p&gt;
&lt;h2 id="starting-with-the-paragraph-scenarios"&gt;Starting with The Paragraph Scenarios&lt;a class="headerlink" href="#starting-with-the-paragraph-scenarios" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;In terms of picking a good place to start, I feel that the paragraph tokens were the
best place to start.  As paragraphs are usually the foundation of any Markdown
document, I was confident that cleaning up all the scenario tests in the
&lt;code&gt;test_markdown_paragraph_blocks.py&lt;/code&gt; module would be a good initial case.  Being simple
in their nature, that set of tests would cover the following types of tokens:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;paragraph token (start and end) - all tests&lt;/li&gt;
&lt;li&gt;text token - all tests&lt;/li&gt;
&lt;li&gt;blank line tokens - 3 of 7 tests&lt;/li&gt;
&lt;li&gt;hard line break token - 2 of 7 tests&lt;/li&gt;
&lt;li&gt;indented code block token (start and end) - 1 of 7 tests&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;It was a small set of tokens, easily constrained, and built on afterwards.&lt;/p&gt;
&lt;h3 id="paragraph-tokens-text-tokens-and-blank-line-tokens"&gt;Paragraph Tokens, Text Tokens, and Blank line Tokens&lt;a class="headerlink" href="#paragraph-tokens-text-tokens-and-blank-line-tokens" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;In this group of tests, the simple tests were the easiest to verify, but the most
important to get right. With a grand total of 7 tests, 5 complete tests were simply
around the handling of these 3 basic tokens.  But it was early in the coding of
their handlers when I recognized that I needed to implement a simple stack to process
these tokens properly.&lt;/p&gt;
&lt;h3 id="simple-token-stack"&gt;Simple Token Stack&lt;a class="headerlink" href="#simple-token-stack" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;The reason for the token stack was simple.  While I was just dealing with paragraph
tokens around the text token for the first 6 tests, the last test would require that I
handle a different leaf token around the text token: the indented code block token.
Instead of doing the work twice, once to just save the paragraph token somewhere and
second to implement a proper token stack, I decided to skip right to the stack
implementation.&lt;/p&gt;
&lt;p&gt;This stack was created to be simple in its nature.  The current block would remain at
the top of the stack, to be removed when it went out of scope with the end block token.
The initial test was to make sure that the text tokens for the examples can extract
information from the encompassing paragraph token as needed.  This is important because
any whitespace at the start or end of each paragraph-text line is removed for the HTML
presentation but stored for other uses in the paragraph token.&lt;/p&gt;
&lt;p&gt;Therefore, the following functions were added to handle the task of keeping the stack
synchronized with the paragraph tokens:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;rehydrate_paragraph&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;next_token&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;block_stack&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;next_token&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="s2"&gt;""&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;rehydrate_paragraph_end&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;next_token&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="n"&gt;top_stack_token&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;block_stack&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
        &lt;span class="k"&gt;del&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;block_stack&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="s2"&gt;""&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h3 id="back-to-the-text-token"&gt;Back to the Text Token&lt;a class="headerlink" href="#back-to-the-text-token" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Getting back to the actual hydration cases, the rehydration of the basic text block
is simple to explain but takes a lot of code to accomplish.  The general algorithm
at this stage was as follows:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;rehydrate_text&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;next_token&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="n"&gt;leading_whitespace&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;next_token&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;extracted_whitespace&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;block_stack&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="c1"&gt;# Get whitespace from last token on the stack and split it on new lines&lt;/span&gt;
            &lt;span class="c1"&gt;# Get the text from the current token and split it on new lines&lt;/span&gt;
            &lt;span class="c1"&gt;# Properly recombine the whitespace with the text&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;leading_whitespace&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;combined_text&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;For basic paragraphs, because of the GFM specification, any leading or trailing
whitespace on a line is removed from the text before that text transformed into HTML.
However, as I thought there was a rule about excess space at the start and end of a
line in a paragraph, I made sure to append that text to the owning paragraph token.
In addition, when the paragraph itself starts but before the text token takes over,
there is a potential for leading whitespace that must also be considered.&lt;/p&gt;
&lt;p&gt;So, in addition to the above code to rehydrate the text token, the following changes
were needed to handle the start and end paragraph tokens properly.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;rehydrate_paragraph&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;next_token&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;block_stack&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;next_token&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;extracted_whitespace&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;next_token&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;extracted_whitespace&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;extracted_whitespace&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;line_end_index&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;extracted_whitespace&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;index&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="n"&gt;extracted_whitespace&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;extracted_whitespace&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="n"&gt;line_end_index&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;extracted_whitespace&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;rehydrate_paragraph_end&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;next_token&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="n"&gt;top_stack_token&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;block_stack&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
        &lt;span class="k"&gt;del&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;block_stack&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;top_stack_token&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;final_whitespace&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;With that done, the text within the paragraph and around the paragraph was being
rehydrated properly.  At that point, I raised my glass of water and toasted the
project as the first 2 scenarios were now checking their content and passing. Yes!
From there, it was a short journey to add a 3 more tests to that roster by adding the
handling of the blank line token, as such:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;rehydrate_blank_line&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;next_token&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;next_token&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;extracted_whitespace&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;While it was not a running start, this was the first time the entire content of those
5 scenario tests was validated!  It was enough to make me go for number 6!&lt;/p&gt;
&lt;h3 id="hard-line-breaks"&gt;Hard Line Breaks&lt;a class="headerlink" href="#hard-line-breaks" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;From there, the scenario test for
&lt;a href="https://github.github.com/gfm/#example-196"&gt;example 196&lt;/a&gt;,
was the next test to be enabled, adding
support for hard line breaks.  Interestingly, when I wrote the algorithm for coalescing
the text tokens where possible, the new line character for the hard break was already
setup to be added to the following text token.  This leaves the hard line token
primarily as a “marker” token, with some additional information on the extra whitespace
from the end of the line.  As such, rehydrating the hard break properly was
accomplished by adding the following text.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;rehydrate_hard_break&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;next_token&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;next_token&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;line_end&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;And that made 6 tests that were now fully enabled!  But knowing that the last test in
that group dealt with indented code blocks, I decided to take a bit of a break before
proceeding with that token.  I needed some extra confidence.&lt;/p&gt;
&lt;h2 id="handling-backslash-characters"&gt;Handling Backslash Characters&lt;a class="headerlink" href="#handling-backslash-characters" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;The interesting part about the parsing of this Markdown character is
that once it is dealt with, the original backslash character disappears, having
done its job.  While that was fine for generating HTML, rehydrating the original text
from a tokenized version of a string that originally contained a backslash was a
problem.  If it disappears, how does the code know it was there in the first place?&lt;/p&gt;
&lt;p&gt;To solve this issue, I had to resolve to a bit of trickery.  I needed to
determine a way to make the backslash character visible in the token without it being
visible in the HTML output.  But anything obvious would show up in the HTML output, so
I had to take a preprocessing step on the data and remove whatever it was that I would
add to denote the backslash.&lt;/p&gt;
&lt;h3 id="thinking-inside-of-the-outside-box"&gt;Thinking Inside of the Outside Box&lt;a class="headerlink" href="#thinking-inside-of-the-outside-box" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Trying a couple of solutions out, the one that held the most promise for me was to use
(or misuse) the backspace character.  In Python, I can easily add the sequence &lt;code&gt;\b&lt;/code&gt; to
a string to denote the backspace character.  When use this format to write out the text
for the token containing a backslash, I would now add &lt;code&gt;\\\b&lt;/code&gt; in place of the backslash
to allow it to be placed in the token.&lt;/p&gt;
&lt;p&gt;To show an example of this, consider the Markdown text &lt;code&gt;a\\*b\\*&lt;/code&gt;, used to create HTML
output of &lt;code&gt;a*b*&lt;/code&gt; without the asterisk character getting misinterpreted as emphasis.
Before this change, the text in the token would have been &lt;code&gt;a*b*&lt;/code&gt;, without the inline
processor splitting the emphasis sequences into their own tokens for interpretation.
After this change, the text in the token is &lt;code&gt;a\\\b*b\\\b*&lt;/code&gt;, keeping the backslashes
in the data, but with the backspace character following them.&lt;/p&gt;
&lt;p&gt;But now that I had a special character in there, I would need to preprocess those
strings.&lt;/p&gt;
&lt;h3 id="dealing-with-the-complications"&gt;Dealing with the Complications&lt;a class="headerlink" href="#dealing-with-the-complications" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;How does the preprocessing work?  In the case of the HTML transformer, the
preprocessing uses the new &lt;code&gt;resolve_backspaces_from_text&lt;/code&gt; function to scan the incoming
string for any backspace characters.  When a backspace characters are encountered, it
is removed along with the character proceeding that backspace character.  In this
manner,
the HTML output is identical to how it was before this change.  Using the above example
of &lt;code&gt;a\\\b*b\\\b*&lt;/code&gt;, this preprocessing would render that string as &lt;code&gt;a*b*&lt;/code&gt;, removing
each of the backspace characters and the backslash characters before them.&lt;/p&gt;
&lt;p&gt;In the case of the new Markdown transformer, a similar algorithm is used that simply
replaces any backspace characters with the empty string.  Because the end effect is to
restore the data to the way it was
before, removing the backspace character by itself leaves the data in its original
form. Once again using the above example of &lt;code&gt;a\\\b*b\\\b*&lt;/code&gt;, when the backspace
characters are removed from the string, the string is changed into &lt;code&gt;a\\*b\\*&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;While it took me a while to arrive at this preprocessing solution, it worked flawlessly
without any modifications.  It was just a simple way to handle the situation. And
because it is a simple way, it is also simple to read and understand when dealing
with the data for the scenarios.  After all,
when I type in code or a document, I use the backspace key to erase the last character
I typed.  This just extends that same paradigm a small amount, but to good use.&lt;/p&gt;
&lt;h3 id="the-fallout"&gt;The Fallout&lt;a class="headerlink" href="#the-fallout" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;As this change affects everywhere that a backspace character can be used, there were
some sweeping changes needed in multiple locations to deal with the now escaped
backslash characters.  The &lt;code&gt;InlineHelper&lt;/code&gt; module’s &lt;code&gt;handle_inline_backslash&lt;/code&gt; function
was changed to take an optional parameter &lt;code&gt;add_text_signature&lt;/code&gt; to determine whether
the new &lt;code&gt;\\\b&lt;/code&gt; sequence was added when a backslash was seen in the Markdown.
That was the easy part.&lt;/p&gt;
&lt;p&gt;In any of the places where that function was called, I traced back and figured
out if there was a valid escape for adding the new text signature.  In a handful of
cases, the original string was already present, so no new transformations were
required, passing in a &lt;code&gt;False&lt;/code&gt; for the &lt;code&gt;add_text_signature&lt;/code&gt;.  But the more prevalent
case was for the calls that passed in &lt;code&gt;True&lt;/code&gt;.  And it did not end there.  This process
needed to be repeated with each function that called each of those functions, and so
on.&lt;/p&gt;
&lt;p&gt;In the end, it was worth it.  It was a clean way to deal with having the backslash in
the token if needed and removing the backslash when it was not needed.&lt;/p&gt;
&lt;h2 id="indented-code-block-tokens"&gt;Indented Code Block Tokens&lt;a class="headerlink" href="#indented-code-block-tokens" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;For the most part, the indented code blocks were simple.  Like how the
text tokens were handled for paragraphs, the trick was to make sure that the right
whitespace was added to the text tokens.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;reconstitute_indented_text&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;main_text&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;prefix_text&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;leading_whitespace&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="n"&gt;split_main_text&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;main_text&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;split&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;recombined_text&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;""&lt;/span&gt;
        &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;next_split&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;split_main_text&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;next_split&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="n"&gt;recombined_text&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="n"&gt;prefix_text&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;leading_whitespace&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;next_split&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;
                &lt;span class="n"&gt;leading_whitespace&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;""&lt;/span&gt;
            &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="n"&gt;recombined_text&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="n"&gt;next_split&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;recombined_text&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The nice thing about the new &lt;code&gt;reconstitute_indented_text&lt;/code&gt; function was that it was
simple to start with, as shown above.  Take the text from the text token, and put
it back together, keeping in mind the extra whitespaces at the start of each line.
In short order, the single scenario test in the &lt;code&gt;test_markdown_paragraph_blocks.py&lt;/code&gt;
module dealing with indented code block tokens was passing, and most of the
indented code block scenario tests were also passing.  It was then down to 2
scenario tests to get enabled.&lt;/p&gt;
&lt;h3 id="handling-character-references"&gt;Handling Character References&lt;a class="headerlink" href="#handling-character-references" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Character references on their own are a vital part of Markdown.  When you want to
be specific about a character to use, there is no substitute for using the ampersand
character and the semi-colon character and specifying the specifics of the character
you want between the two.  But as with backslashes, these character references
represented an issue.&lt;/p&gt;
&lt;p&gt;Like the backslash disappearing after it is used, the character references also
disappear once used.  But in this case, the mechanics were slightly different. If
the resultant token and HTML contains the copyright character &lt;code&gt;©&lt;/code&gt;, there are three
paths to getting that Unicode character into the document.  The first is simply to use a
Unicode aware editor that allows the typing of the &lt;code&gt;©&lt;/code&gt; character itself.  If that
fails, the next best approach is to use a named character entity, adding &lt;code&gt;&amp;amp;copy;&lt;/code&gt;
to the document.  Finally, the numeric character reference of &lt;code&gt;&amp;amp;#xA9&lt;/code&gt; or &lt;code&gt;&amp;amp;%169;&lt;/code&gt;
can also be used to insert that character into the token.  The problem is, if the
token contains the character &lt;code&gt;©&lt;/code&gt;, which of the 4 forms were used to place it there?&lt;/p&gt;
&lt;p&gt;Similar to the way I used the backspace character with the backslash character, in
this case I used the alert character (&lt;code&gt;\a&lt;/code&gt;) as a way to specify that a series of
characters have been replaced with another series of characters.  Using the previous
example of the copyright character, if the character was specified by using the
actual Unicode character itself, no alert characters were needed as nothing changed.&lt;/p&gt;
&lt;p&gt;But in the cases where the character entities were used, to indicate “I saw this
entity, and I replaced it with this text”.  For example, if the Markdown contained
the text &lt;code&gt;&amp;amp;copy; 2020&lt;/code&gt;, the text would be replaced with &lt;code&gt;\a&amp;amp;copy;\a©\a 2020&lt;/code&gt;. While
it takes a bit of getting used to, reading this in the samples quickly became easy
to read.  For the HTML output, all 3 occurrences of the alert character were searched
for, and the text between the second and third alert was output, and the rest ignored.
In the case of rehydrating the Markdown text, the text between the first and the second
alert was output, and the rest of that text was ignored.&lt;/p&gt;
&lt;p&gt;The fallout of this change was of a similar scope to that of the fallout for the
backspace character changes.  There were a few places where this change had to be
turned off, but due to sheer luck, most of those places were the same for the backspace
character and for the alert character.  While it took a small amount of time to get
things right, once again it was a clean solution.&lt;/p&gt;
&lt;h3 id="indented-code-blocks-and-blank-lines"&gt;Indented Code Blocks and Blank Lines&lt;a class="headerlink" href="#indented-code-blocks-and-blank-lines" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;All the other scenarios down, and one to go!  And… I hit a wall.  But unlike some of
the other walls that I hit, this one was a good one.  When I looked at this remaining
case, the scenario test for
&lt;a href="https://github.github.com/gfm/#example-81"&gt;example 81&lt;/a&gt;,
I knew that there was going to be a cost to
getting this test to pass its consistency check. And while I could go ahead and
work on it, I made the decision that the work to get this one case passing was out of
the present cope of work that I agreed to do.&lt;/p&gt;
&lt;p&gt;The scenario?  &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;    &lt;span class="n"&gt;chunk1&lt;/span&gt;

    &lt;span class="n"&gt;chunk2&lt;/span&gt;
&lt;span class="err"&gt;{&lt;/span&gt;&lt;span class="k"&gt;space&lt;/span&gt;&lt;span class="err"&gt;}{&lt;/span&gt;&lt;span class="k"&gt;space&lt;/span&gt;&lt;span class="err"&gt;}&lt;/span&gt;
&lt;span class="err"&gt;{&lt;/span&gt;&lt;span class="k"&gt;space&lt;/span&gt;&lt;span class="err"&gt;}&lt;/span&gt;
&lt;span class="err"&gt;{&lt;/span&gt;&lt;span class="k"&gt;space&lt;/span&gt;&lt;span class="err"&gt;}&lt;/span&gt;
    &lt;span class="n"&gt;chunk3&lt;/span&gt;&lt;span class="ss"&gt;""&lt;/span&gt;&lt;span class="err"&gt;"&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;(To make the spaces visible on the blank lines, I replaced them in the above Markdown
sample with the text &lt;code&gt;{space}&lt;/code&gt;.)&lt;/p&gt;
&lt;p&gt;Double checking the code for the indented code blocks,
if the blank lines contained at least 4 or more space characters, the tokenization
proceeded properly, and the rehydration of the text was fine.  But in the case where
the blank lines did not contain enough spaces, that was another issue.&lt;/p&gt;
&lt;p&gt;While it is not specifically spelled out in the GFM specification, example 81 makes it
clear that blank lines do not end indented code blocks, regardless of whether they
start with 4 space characters.  But looking at the tokens, the only way that I
could think of to address this issue was to put any extracted spaces in the
indented code block token itself.  This would allow them to be used later, if needed,
by transformers such as the Markdown transformer.&lt;/p&gt;
&lt;p&gt;But thinking about it clearly, I felt that this work was beyond the scope of the
current rules for this task. I figured that I had a choice between finishing up the
task with thematic break token support completed or getting mired down with this
one scenario and not properly completing the task.  While I was not initially happy
about the idea, I noted the item down in the issues list, disabled the consistency
checks for the test, and continued.&lt;/p&gt;
&lt;h2 id="thematic"&gt;Thematic&lt;a class="headerlink" href="#thematic" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;To wrap up this block of work, I just needed to complete the handling of the thematic
break token.  As this is a simple token, I expected a simple implementation to
rehydrate it, and I was not disappointed.  The text that it took to complete
the rehydration of the thematic breaks was as follows:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;rehydrate_thematic_break&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;next_token&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;next_token&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;extracted_whitespace&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;next_token&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;rest_of_line&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Simple, short, and sweet.  No surprises.  A nice way to end.&lt;/p&gt;
&lt;h2 id="along-the-way"&gt;Along the way…&lt;a class="headerlink" href="#along-the-way" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;In total, I added 6 items to the issue list because of things I noticed during this
work.  While I was
sure that 4-5 were actual issues, I was okay with the remaining issues being good
questions for me to answer later.  It just felt good to be able to write a new item
down and clear it from my mind.  It helped me stay on track and keep my focus.
And that is a good thing!&lt;/p&gt;
&lt;h2 id="what-was-my-experience-so-far"&gt;What Was My Experience So Far?&lt;a class="headerlink" href="#what-was-my-experience-so-far" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;To be honest, I believe I was so worried about going down another rabbit hole that it
got in the way of my creativity a bit.  Not so much that I could not get the work done,
but it was there.  And thinking back to that time, I am not sure if that was a good
thing or a bad thing.&lt;/p&gt;
&lt;p&gt;On the bad side, it caused me to question myself a lot more.  With each decision
I made, I reviewed it against the goals that I specified at the start of this article.
Did it pass?  If no, then try again.  If yes, what was the scope?  If depth of the
scope was too unexpected or too large, then try again.  If yes, start working on it.
At various points within the task, stop to reevaluate those same questions and make sure
I was staying within the scope.   It definitely was annoying at first.&lt;/p&gt;
&lt;p&gt;On the good side, it was probably what I needed. And I hate to say it, it probably was a
good annoying.  I do not need to continue to have this internal conversation for smaller
tasks. But for this big task, that frequent dialogue helped me focus on keeping the
task on track.  If I noticed something that was not in scope, I just added it to the
issues list and moved on.  If I had a question about whether something was written
properly, I just added it to the issues list and moved on.  It is not that I do not care
about these issues, it is that I can more about completing the task and not getting
lost on something that is off task.  There will be time later to deal with those.&lt;/p&gt;
&lt;p&gt;All in all, I believe this chunk of work went well.  Sure, I pushed my 36 hour time
limit to the max, resulting in my article getting written later than I am usually
comfortable with.  I also pushed my definition of “complete” to the max, as I noted in
the section on
&lt;a href="https://jackdewinter.github.io/2020/07/20/markdown-linter-transforming-back-to-markdown/#a-small-note-on-the-commit"&gt;A Small Note on the Commit&lt;/a&gt;.
All the work
was completed before I started that week’s article, even if I took me another 3-4 hours
to clean it up enough before committing it to the repository. After all an agreed upon
rule is a rule, and I kept to each of them.  Even if I strained them a bit.&lt;/p&gt;
&lt;p&gt;I was happy with how I handled myself with this task.  I did not get too bogged down
that I got nothing done, and I did not go down any rabbit holes.  It was a good week!&lt;/p&gt;
&lt;h2 id="what-is-next"&gt;What is Next?&lt;a class="headerlink" href="#what-is-next" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Having encountered a number of bugs and possible logs that were logged in the issue’s
list, it just made sense to tackle those right away.  Especially for something that is
meant to track the consistency of the tokens, it does not look good to have bugs against
it.&lt;/p&gt;</content><category term="Software Quality"></category><category term="markdown linter"></category><category term="core linter"></category></entry><entry><title>Markdown Linter - Improving Consistency</title><link href="https://jackdewinter.github.io/2020/07/13/markdown-linter-improving-consistency/" rel="alternate"></link><published>2020-07-13T00:00:00-07:00</published><updated>2020-07-13T00:00:00-07:00</updated><author><name>Jack De Winter</name></author><id>tag:jackdewinter.github.io,2020-07-13:/2020/07/13/markdown-linter-improving-consistency/</id><summary type="html">
&lt;h2 id="summary"&gt;Summary&lt;a class="headerlink" href="#summary" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;In my
&lt;a href="https://jackdewinter.github.io/2020/07/06/markdown-linter-weeding-the-projects-issue-list/"&gt;last article&lt;/a&gt;,
I talked about how I “weeded” the project’s issues list to build up my confidence that
the PyMarkdown project was going in the right direction.  In this article, I talk about
how I used that confidence to get back to work on the consistency …&lt;/p&gt;</summary><content type="html">
&lt;h2 id="summary"&gt;Summary&lt;a class="headerlink" href="#summary" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;In my
&lt;a href="https://jackdewinter.github.io/2020/07/06/markdown-linter-weeding-the-projects-issue-list/"&gt;last article&lt;/a&gt;,
I talked about how I “weeded” the project’s issues list to build up my confidence that
the PyMarkdown project was going in the right direction.  In this article, I talk about
how I used that confidence to get back to work on the consistency checker for the
tokenizer that is the backbone of the PyMarkdown linter.&lt;/p&gt;
&lt;h2 id="introduction"&gt;Introduction&lt;a class="headerlink" href="#introduction" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;At the
&lt;a href="https://jackdewinter.github.io/2020/07/06/markdown-linter-weeding-the-projects-issue-list/#what-was-my-experience-so-far"&gt;end of the last article&lt;/a&gt;,
I talked about how confidence is more emotional than logical.  From that point of view,
resolving items off my issues list was more to fan my passion for the PyMarkdown
project that any logical reason.  And while there are logical components to my
desire to instill quality to the project at every stage, it is mostly an emotional
desire to make it better.  It is true that part of that desire is due to my experience.
I know the large cost of fixing a bug once a product is released, and I want to avoid
as many of those issues as possible as soon as possible.
But another part of that desire is because that I know that once I put the project out
there, it will be considered a reflection of my abilities. Due to both reasons
and others, I just want the project to have a healthy level of quality that I have
confidence that I can maintain.&lt;/p&gt;
&lt;p&gt;It was because of that desire to maintain or increase quality on the project that I
started to think about whether the cost of my efforts was worth the benefits that I
was seeing.  Was it worth it?&lt;/p&gt;
&lt;h2 id="what-is-the-audience-for-this-article"&gt;What Is the Audience for This Article?&lt;a class="headerlink" href="#what-is-the-audience-for-this-article" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;While detailed more eloquently in
&lt;a href="https://jackdewinter.github.io/2020/04/05/what-is-the-audience-for-my-blog/#what-is-the-audience-for-my-blog"&gt;this article&lt;/a&gt;,
my goal for this technical article is to focus on the reasoning behind my solutions,
rather that the solutions themselves.  For a full record of the solutions presented in
this article, please go to this project’s GitHub repository and consult the
commits between
&lt;a href="https://github.com/jackdewinter/pymarkdown/commit/4b681751cae38ce2007f3b0ada6158ed9a15f353"&gt;28 Jun 2020&lt;/a&gt; and
&lt;a href="https://github.com/jackdewinter/pymarkdown/commit/e1fad8fc839d78f52040ef849e444d1d9b623c4a"&gt;05 Jul 2020&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id="is-the-cost-worth-the-benefit"&gt;Is the Cost Worth The Benefit?&lt;a class="headerlink" href="#is-the-cost-worth-the-benefit" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;In the end, the tokens that are generated by the project’s parser are just a series of
letters and numbers that must be verified for each scenario.  For the parser’s
scenarios alone, there are 728 scenario tests that are used to verify that parser’s
output whenever a change is made. The validation of those same tests is made easier by
the test foundations that are already in place: checking the produced tokens against a
static list for that scenario, and checking the output from transforming those tokens
against the HTML snippet for that scenario.&lt;/p&gt;
&lt;p&gt;The HTML part of that verification is easy: it either matches the reference HTML output
or it does not.  The tokens are a lot more difficult to verify.  Is the actual content
correct?  Are the line number and column number correct?  Was the correct amount of
whitespace stored in the token to allow us to generate the HTML properly?  While I try
my hardest to ensure that the token information is correct, I do make mistakes.&lt;/p&gt;
&lt;p&gt;And that is where I see the benefit of consistency checks.  As I documented in
&lt;a href="https://jackdewinter.github.io/2020/07/06/markdown-linter-weeding-the-projects-issue-list/"&gt;my last article&lt;/a&gt;,
there are enough parser rules to remember that I regularly add items to the project’s
issues list to check later.  But I have also noticed that even the act of answering
those questions and whether those rules were applied properly can increase my
confidence in the project.  And if those answers can increase my confidence by
themselves, working on
completing those checks should have an even larger impact.&lt;/p&gt;
&lt;p&gt;From where I was, even though the cost of adding the consistency checks was starting to
grow, I felt that my increased confidence in the project was an acceptable
benefit given that cost.  As such, it was forward with the consistency checks!&lt;/p&gt;
&lt;h2 id="lists-and-blank-lines"&gt;Lists and Blank Lines&lt;a class="headerlink" href="#lists-and-blank-lines" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Sometimes it is the large issues that bother us the most. But often, I
find it is the smaller items that really grind away at my mind.  If I have not started
a task, I try to make sure that I have lined up as many of the requirements for that
task as possible up before I start on the task.  This preparation helps me to focus on
the task and
to work on that task without too many interruptions.  But, as is normal in my line of
work, I have had to adapt to make sure that I can switch away from a
task before it is completed.  I am usually okay with this, as I often I find a good
stopping point and document why I stopped and what I was thinking, hoping that it
helps me pick it up later.  But if I am close to finishing a task and I know
there are only a “couple” of things left to go on that task, it is hard for me to
resist getting it over that finish line.  Just so very tough.&lt;/p&gt;
&lt;h3 id="identifying-the-issue"&gt;Identifying the Issue&lt;a class="headerlink" href="#identifying-the-issue" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;This was the case with lists and blank lines, the subject of an item being researched
and further documented in
&lt;a href="{filename}/articles/SoftwareQuality/core-7.md.#scenarios-197-257-and-262-blank-lines-and-lists#scenarios-197-257-and-262-blank-lines-and-lists"&gt;the last article&lt;/a&gt;
This issue was not an overly big issue per se, but it was the issue that was gnawing at
me.  Specifically, I looked at one of the two list examples that start with a blank
line, &lt;a href="example-257"&gt;example 257&lt;/a&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="err"&gt;{&lt;/span&gt;&lt;span class="k"&gt;space&lt;/span&gt;&lt;span class="err"&gt;}{&lt;/span&gt;&lt;span class="k"&gt;space&lt;/span&gt;&lt;span class="err"&gt;}{&lt;/span&gt;&lt;span class="k"&gt;space&lt;/span&gt;&lt;span class="err"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;and the text before example 257, which clearly states:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;When the list item starts with a blank line, the number of spaces following the list marker doesn’t change the required indentation:&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Based on that information, a start unordered list token occupies column 1, and the
number of spaces following the list marker is 1, for a total of 2.  As such, the
blank line, being contained within the list, starts at column number 2, with the extra
whitespaces added to the end of the line.  So why was I seeing the token &lt;code&gt;[BLANK(1,5):]&lt;/code&gt;
instead of the expected token &lt;code&gt;[BLANK(1,2):  ]&lt;/code&gt;?&lt;/p&gt;
&lt;h3 id="working-the-problem"&gt;Working the Problem&lt;a class="headerlink" href="#working-the-problem" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Doing some research, the answer was easy.  The blank line token was not wired up to
capture the following spaces, something that was quickly fixed.  But even with that
fixed, when the whitespace went to the end of the line, the count of the following
spaces was simply zeroed out within the list handler.  To fix this, I had to take
some time and create a new algorithm from scratch, paying extra attention to ensure
that trailing spaces were put in the right location.&lt;/p&gt;
&lt;p&gt;I knew that the block quote tokens needed a rewrite to track the skipped block quote
characters and their trailing space characters, so I left that part alone.  But I did
update the issue to note that the list case had been fixed.  &lt;/p&gt;
&lt;h3 id="improving-consistency"&gt;Improving Consistency&lt;a class="headerlink" href="#improving-consistency" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;With the blank token issue fixed, I then was able to add needed logic to the consistency
checker.  Previously, the content of the &lt;code&gt;__validate_same_line&lt;/code&gt; function was pretty
sparse:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;    &lt;span class="k"&gt;assert&lt;/span&gt; &lt;span class="n"&gt;last_token&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;token_class&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;MarkdownTokenClass&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;CONTAINER_BLOCK&lt;/span&gt;
    &lt;span class="k"&gt;assert&lt;/span&gt; &lt;span class="n"&gt;current_position&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;index_number&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;last_position&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;index_number&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;It was time to change that!&lt;/p&gt;
&lt;p&gt;Keeping in mind that I had only addressed the above issue for blank line tokens within
a list token, the first thing I did was to exclude
the block tokens from the new code.  Then, remembering some previous work that I did,
I knew there were going to be three different asserts that
I would need to do: one for blank lines, one for indented code blocks, and one for
everything else.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;current_token&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;token_name&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;MarkdownToken&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;token_blank_line&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="k"&gt;assert&lt;/span&gt; &lt;span class="n"&gt;current_position&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;index_number&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;last_token&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;indent_level&lt;/span&gt;
        &lt;span class="k"&gt;elif&lt;/span&gt; &lt;span class="n"&gt;current_token&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;token_name&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;MarkdownToken&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;token_indented_code_block&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="k"&gt;assert&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;
                &lt;span class="n"&gt;current_position&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;index_number&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;current_token&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;extracted_whitespace&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
                &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;last_token&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;indent_level&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
            &lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="k"&gt;assert&lt;/span&gt; &lt;span class="n"&gt;current_position&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;index_number&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;last_token&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;indent_level&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;For blank lines tokens on the same line as a list token, the blank line tokens start
right after the list token, so the &lt;code&gt;index_number&lt;/code&gt; is the same as the list’s
&lt;code&gt;indent_level&lt;/code&gt;.  Because the indented code block token includes whitespace in its
column number, there is a bit of correction to do to take that into account.  Other than
that, the remaining leaf block tokens verify that they start at the &lt;code&gt;indent_level&lt;/code&gt;
specified by the list.&lt;/p&gt;
&lt;p&gt;After testing and manual verification, that change to the check was completed and
verified.  I examined around ten related scenario tests, and double checked the
results from the new modifications. But even after that extra validation, I was left
with a feeling that something was left undone.  I was not sure what it was, but
it was something to think about as I worked.&lt;/p&gt;
&lt;h2 id="making-position-markers-immutable"&gt;Making Position Markers Immutable&lt;a class="headerlink" href="#making-position-markers-immutable" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Honestly, the title that I was thinking of for this section was “Making Position
Markers as Immutable as Python Will Allow”, but I thought that was too long.  But let’s
get that out of the way upfront.  Python does not have a concept of an
immutable complex object.  Like most languages, the base objects (such as strings,
integers, and floats) are immutable, meaning they cannot be changed once instantiated.
To me, this makes perfect sense. If you create one of these base objects, it always
retains its properties.  If you add two of these objects together, you create a
third object to contain the results.  Basic computer science 101.&lt;/p&gt;
&lt;p&gt;Python complex objects are not so nice with respect to immutability.  Sure, there are
tricks to
prevent overwriting of well-known objects within a class, but there is no built-in
support for creating an immutable complex object in Python.&lt;sup id="fnref:norOthers"&gt;&lt;a class="footnote-ref" href="#fn:norOthers"&gt;1&lt;/a&gt;&lt;/sup&gt; Conveniently,
I did not need
the &lt;code&gt;PositionMarker&lt;/code&gt; class to be 100% immutable, just immutable enough that I do not add
code that overwrites the member variables from that class by accident.&lt;/p&gt;
&lt;h3 id="benefits-of-immutable-objects"&gt;Benefits of Immutable Objects&lt;a class="headerlink" href="#benefits-of-immutable-objects" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Why is this important to me?  Partly cleanliness and partly experience.  Immutable
objects are just cleaner, as you can guarantee that their values will never change. If
you instantiate an immutable object as the first object in your program, it will still
have the same value that it was instantiated with when the program ends.  From
experience, immutability provides a level of safety that is desirable.&lt;/p&gt;
&lt;p&gt;This sense of safety is because immutable objects are useful where there
is a concern about &lt;em&gt;random&lt;/em&gt; side effects introduced by child objects and functions.
In the case of the parser, I know that before some previous refactorings, I
was passing the variables &lt;code&gt;text_to_parse&lt;/code&gt; and &lt;code&gt;start_index&lt;/code&gt; all over the place.  Even
after that refactoring, I remained concerned that the parser code could &lt;em&gt;accidentally&lt;/em&gt;
alter the existing &lt;code&gt;PositionMarker&lt;/code&gt; objects without a good way for me to detect it
or prevent it.  &lt;/p&gt;
&lt;p&gt;By changing the &lt;code&gt;PositionMarker&lt;/code&gt; class into a &lt;em&gt;mostly&lt;/em&gt; immutable object, those concerns
could be largely eliminated.  Any concerns of side effects would be mitigated by the
simple fact that once the value for the member variable was specified upon creation,
it cannot be changed.  Before this change was put in place, I knew where there were
cases where I was not 100% sure that I understood where the values in the object came
from.  If I did things right, after this change I would probably have a couple of extra
instantiations in the code, but I would know that the values were solid.&lt;/p&gt;
&lt;h3 id="making-the-change"&gt;Making the Change&lt;a class="headerlink" href="#making-the-change" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Far from one of the bulletproof approaches talked about on
&lt;a href="https://stackoverflow.com/questions/4828080/how-to-make-an-immutable-object-in-python"&gt;Stack Overflow&lt;/a&gt;,
I just needed something simple to prevent accidental overwrites.  For my lightweight
approach, I chose to change the &lt;code&gt;PositionMarker&lt;/code&gt; class to expose its member variables
exclusively through properties.&lt;/p&gt;
&lt;p&gt;Before this change, the &lt;code&gt;line_number&lt;/code&gt; member variable was defined in the constructor with:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;    &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;line_number&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;line_number&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;When I needed to access the line number, I would simple take the instance name of
the &lt;code&gt;PositionMarker&lt;/code&gt; class, say &lt;code&gt;position_marker&lt;/code&gt;, and append &lt;code&gt;.line_number&lt;/code&gt; to it:
&lt;code&gt;position_marker.line_number&lt;/code&gt;.  Clean, simple, and neat, but also mutable.  Just
as:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;    &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;position_marker&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;line_number&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;assigns the value of the &lt;code&gt;position_marker&lt;/code&gt; instance’s &lt;code&gt;line_number&lt;/code&gt; member variable to
the local variable &lt;code&gt;x&lt;/code&gt;, the following:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;    &lt;span class="n"&gt;position_marker&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;line_number&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;assigns the value of the local variable &lt;code&gt;x&lt;/code&gt; to the &lt;code&gt;line_number&lt;/code&gt; member variable.&lt;/p&gt;
&lt;p&gt;To make the &lt;code&gt;line_number&lt;/code&gt; member variable &lt;em&gt;mostly&lt;/em&gt; immutable, I simply changed its
instantiation to:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;    &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;__line_number&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;line_number&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;and added a property getter named after the original variable name, but without adding
a property setter:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;    &lt;span class="nd"&gt;@property&lt;/span&gt;
    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;line_number&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="sd"&gt;"""&lt;/span&gt;
&lt;span class="sd"&gt;        Gets the line number.&lt;/span&gt;
&lt;span class="sd"&gt;        """&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;__line_number&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;By doing this for each member variable, two things were accomplished.  The first thing
was that by prefacing the member variable’s name with &lt;code&gt;__&lt;/code&gt;, I declared it as a
private variable.  Variables declared as such are only able to be changed from within
the class that declared them.&lt;sup id="fnref:caveat"&gt;&lt;a class="footnote-ref" href="#fn:caveat"&gt;2&lt;/a&gt;&lt;/sup&gt;  Then, by adding a property that has the name
of the variable without the prefix (&lt;code&gt;line_number&lt;/code&gt; vs. &lt;code&gt;__line_number&lt;/code&gt;), I provided
a simple read-only access to the object’s properties.  It was simple, and it
did not require any renaming of read-only references to the member variables.&lt;/p&gt;
&lt;h3 id="cleanup"&gt;Cleanup&lt;a class="headerlink" href="#cleanup" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;The cleanup that occurred as part of that change was mostly contained within the
&lt;code&gt;ContainerBlockProcessor&lt;/code&gt; class.  That made sense to me, as that is where most of the
manipulation of the position occurred after the block quote tokens and list tokens were
processed.  In that class, there were a handful of cases where I was directly
manipulating the
&lt;code&gt;PositionMarker&lt;/code&gt; member variables, which now required new &lt;code&gt;PositionMarker&lt;/code&gt; objects.
But since those new objects were all created within the &lt;code&gt;ContainerBlockProcessor&lt;/code&gt;
class, where I expected them to be created, it
was okay.  As a nice benefit, once that cleanup was completed, there were a few
functions where the passing in of a new &lt;code&gt;PositionMarker&lt;/code&gt; class was no longer needed,
resulting in some bonus dead code deletion.&lt;/p&gt;
&lt;p&gt;What did I gain by doing this?  Mostly confidence.  Before that change, I was
concerned that I would introduce some &lt;em&gt;random&lt;/em&gt; side effect in one of the processors.
Since the class became &lt;em&gt;mostly&lt;/em&gt; immutable and was only changed in the
&lt;code&gt;ContainerBlockProcessor&lt;/code&gt; class, I gained the confidence that a leaf block cannot
change any &lt;code&gt;PositionMarker&lt;/code&gt; object.  Furthermore, I can easily scan to see where
that class in instantiated, knowing in an instant where any changes are occurring,
and therefore why they occurred.&lt;/p&gt;
&lt;h2 id="preventing-consistency-checks-for-tabs"&gt;Preventing Consistency Checks for Tabs&lt;a class="headerlink" href="#preventing-consistency-checks-for-tabs" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;With all those changes in place, I was able to go back and add extra logic
to prevent the consistency checks from executing if they encountered tab characters.
Until I was able to work on proper tab character support, I felt that this was a
good way to keep the consistency checks active without having to disable them in
scenario tests that dealt with tabs.  From a quality point of view, that felt like
a short-term solution to me, not something I wanted to use long term.&lt;/p&gt;
&lt;p&gt;The change side of this was implemented very quickly.  Within
the &lt;code&gt;utils.py&lt;/code&gt; module, I added calls to the &lt;code&gt;__calc_initial_whitespace&lt;/code&gt; function.
If the second returned value (often called &lt;code&gt;had_tab&lt;/code&gt;) was &lt;code&gt;True&lt;/code&gt;, the whitespace
contains a tab character.  Due to the simple nature of the consistency check
function, when this happened, I simply returned from the function at that point.&lt;/p&gt;
&lt;p&gt;With those changes made, I started to work on the testing and was surprised by the
result.  I was only able to uncomment one scenario test, &lt;code&gt;test_tabs_004&lt;/code&gt;. Digging
into the cases a bit, I came to an interesting realization.  I was missing the most
obvious use of tabs: in the prefixes of list content.&lt;/p&gt;
&lt;h2 id="extracting-list-item-whitespace"&gt;Extracting List Item Whitespace&lt;a class="headerlink" href="#extracting-list-item-whitespace" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;During the early design stages of the parser, I made a simple design choice that I
believe has saved me hours of work.  I designed the container block handlers to remove
any processed text before passing the remaining text on for further processing.  That
design allowed the leaf block processing to be kept simple.  The leaf block processor
only sees the text that it needs to see to do its processing, and nothing more.
Basically, the design
choice was to make sure that each processor, container block and leaf block, had a solid
definition of their responsibilities, and to keep to those responsibilities.&lt;/p&gt;
&lt;p&gt;Following that design, when the list block processing was added, the &lt;code&gt;indent_level&lt;/code&gt; was
used to figure out where the encompassed leaf block tokens would start.  Before the
&lt;code&gt;ListBlockProcessor&lt;/code&gt; passed the line to the &lt;code&gt;LeafBlockProcessor&lt;/code&gt;, it removed exactly
&lt;code&gt;indent_level&lt;/code&gt; characters from the start of the line, per that design.  As those
characters were part of the list’s structural indent, it was the list’s responsibility
to deal with those characters, not the &lt;code&gt;LeafBlockProcessor&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;This approach
worked fine until I needed to understand the composition of that extracted whitespace
to validate the token.  At that time, if the whitespace was composed of space
characters, everything remained fine.  One character of indent equals one space
character, and everything balances out.  But when one of those characters is a tab
character, that calculation was thrown out of whack.&lt;/p&gt;
&lt;p&gt;While properly handling tab characters was out of scope, being able to detect them to
properly disable the consistency check was not.  As far as I could tell, all the
remaining scenario cases that I wanted to uncomment contained a tab character in the
list part of the line.  If done properly, it would keep the responsibility of when
to enable and disable the consistency check in the purview of the check itself.
To me, that was the desired goal.&lt;/p&gt;
&lt;h3 id="correctly-extracting-the-whitespace"&gt;Correctly Extracting the Whitespace&lt;a class="headerlink" href="#correctly-extracting-the-whitespace" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;To be able to detect the tab characters properly, a bit of juggling had to be done.
As the best way to know which container is active was still the token stack,
I modified all three list stack tokens to allow them to keep the instance of the
list markdown token that they started.  This allowed me to add the &lt;code&gt;add_leading_space&lt;/code&gt;
function to the two main list markdown tokens, effectively adding the whitespace
to the list markdown token that owns that whitespace. Once that foundation was setup,
I proceeded to modify the &lt;code&gt;__adjust_line_for_list_in_process&lt;/code&gt; function from the
&lt;code&gt;ListBlockProcessor&lt;/code&gt; to properly account for the leading spaces in the lines.&lt;/p&gt;
&lt;h3 id="properly-enabling-consistency-checks"&gt;Properly Enabling Consistency Checks&lt;a class="headerlink" href="#properly-enabling-consistency-checks" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Having completed that previous task, I knew that I was almost ready to go back and
clean up the work started in the previous section on
&lt;a href="https://jackdewinter.github.io/2020/07/13/markdown-linter-improving-consistency/#preventing-consistency-checks-for-tabs"&gt;Preventing Consistency Checks for Tabs&lt;/a&gt;.
The only thing that I needed to do is to make
sure that if the leading spaces contained the tab character, that the leading spaces
would be set to a single tab character.  While this assignment was a large
simplification of how to handle the tab character, the proper implementation could
wait.  I just needed it to work well enough for me to detect it.&lt;/p&gt;
&lt;p&gt;And it did work well enough.  By adding a couple of extra tab checks in the
right places, I was able to uncomment the remaining calls to the
&lt;code&gt;assert_token_consistency&lt;/code&gt; function within the &lt;code&gt;test_markdown_tabs.py&lt;/code&gt; module.
Between the previous tab checks and the extra tabs checks, the consistency checks were
now able to properly exclude any Markdown with a tab character from the checks.&lt;/p&gt;
&lt;p&gt;For me, this was just the right way to do it.  While I needed to comment out those
function calls at that time, it always felt like I was cheating.  It was not the
test’s responsibility to know when to disable the consistency check, it was the
consistency check that needed to make that decision.  By moving the determination of
how to handle tabs into the consistency checks, I felt that I more properly
constrained the problem to the responsible object.  It did not feel like cheating
any more.  It just felt right.&lt;/p&gt;
&lt;p&gt;But now that the consistency of the line/column numbers was in a better place, how
would I verify that the whitespace that I extracted was the correct whitespace?
If I wanted people to write solid linting rules, I want to give them solid data to
base those rules on.&lt;/p&gt;
&lt;h2 id="this-all-leads-up-to-this"&gt;This All Leads Up to This&lt;a class="headerlink" href="#this-all-leads-up-to-this" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Given my stated desires to check the consistency of the tokens, I could only see
one way to be sure of the content of the tokens.  While in previous weeks it was a
small voice, that small voice was now starting to speak with its outdoor voice.  To
check the content, I would need to write a Markdown transformer.&lt;/p&gt;
&lt;p&gt;I had been thinking about working on this for a while, and even added an item to the
issues list to keep track of it:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;## &lt;span class="nv"&gt;Features&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="nv"&gt;Correctness&lt;/span&gt;

&lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="nv"&gt;can&lt;/span&gt; &lt;span class="nv"&gt;we&lt;/span&gt; &lt;span class="nv"&gt;generate&lt;/span&gt; &lt;span class="nv"&gt;Markdown&lt;/span&gt; &lt;span class="nv"&gt;from&lt;/span&gt; &lt;span class="nv"&gt;tokens&lt;/span&gt;? &lt;span class="k"&gt;do&lt;/span&gt; &lt;span class="nv"&gt;we&lt;/span&gt; &lt;span class="nv"&gt;have&lt;/span&gt; &lt;span class="nv"&gt;enough&lt;/span&gt; &lt;span class="nv"&gt;info&lt;/span&gt;?
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;To me, it felt like I was trying to avoid going down this route, afraid that writing
a Markdown transformer would result in me going down another rabbit hole.  Given my
recent experience, I believe it was an acceptable concern that I needed to address
if I decided to write the Markdown transformer.&lt;/p&gt;
&lt;p&gt;But from a quality point of view, I felt that writing the transformer was inevitable.
Outside of manual validation,
the only way that I could validate that that tokens were accurately representing the
Markdown document was to regenerate the original document from the tokens.  As much
as I tried to convince myself otherwise, I just could not see another path that would
provide me with the same level of quality and confidence I that I believe the project
deserves.&lt;/p&gt;
&lt;h2 id="what-was-my-experience-so-far"&gt;What Was My Experience So Far?&lt;a class="headerlink" href="#what-was-my-experience-so-far" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;While the actual work that was documented in this article varied from the work
documented in the last article, the goals driving both were the same:
quality and confidence.&lt;/p&gt;
&lt;p&gt;For me, it is always important to make sure that
project responsibilities are defined and adhered to.  Some of those responsibilities
are people or role focused, and some of those responsibilities are assigned to
objects within the project.  In both cases, having those clear boundaries helps
to figure out where things go and what should be taking care of any issues.&lt;/p&gt;
&lt;p&gt;Having completed this block of work, I felt good.  For me, commenting out or disabling
a test or a part of a test without a good reason just feels wrong.  Like “nails down
a chalkboard” wrong.  By properly assigning the responsibility for disabling the
consistency check to the consistency check itself, I was restoring the control of
that decision to the object that was responsible for it.  I had restored balance
to one small corner of the universe!&lt;/p&gt;
&lt;p&gt;But it was hard for me not to think about doing a consistency check for the token
content.  But, like before, it boiled down to a cost-benefit analysis.  Did I
think that cost of a deep check like that would justify the benefit?  The more I
thought about it, the more it &lt;em&gt;just made sense&lt;/em&gt;.  Once again, this was not a logical
decision, but an emotional one.  And as such, I did feel that the benefit justified
the cost.  I could not give a solid reason why, just a solid feeling that it would.&lt;/p&gt;
&lt;h2 id="what-is-next"&gt;What is Next?&lt;a class="headerlink" href="#what-is-next" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Once I acknowledged to myself the need for proper verification of the token’s content,
the only true viable path was to write a Markdown transformer.  While I knew that I had
a good foundation for checking the line/column numbers of the tokens, I could not see
any other alternative that would verify the tokens at a level that was acceptable to me.
But how could I start work on that massive task, and not lose myself like I did with
adding tab support?&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr/&gt;
&lt;ol&gt;
&lt;li id="fn:norOthers"&gt;
&lt;p&gt;In all fairness to Python, most popular software languages do not natively support immutable complex objects without some sort of trick, pattern, or additional plugins. &lt;a class="footnote-backref" href="#fnref:norOthers" title="Jump back to footnote 1 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:caveat"&gt;
&lt;p&gt;As with everything, there are caveats.  If you understand the system that Python uses to mangle the names as part of making a variable private, you can &lt;em&gt;technically&lt;/em&gt; get around this.  However, that effort is considered out of scope for this article.  Since all the member variables are base types, any consideration of modifying complex types exposed in this way by such an object are also considered out of scope. &lt;a class="footnote-backref" href="#fnref:caveat" title="Jump back to footnote 2 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</content><category term="Software Quality"></category><category term="markdown linter"></category><category term="core linter"></category></entry><entry><title>Markdown Linter - Weeding the Project's Issue List</title><link href="https://jackdewinter.github.io/2020/07/06/markdown-linter-weeding-the-projects-issue-list/" rel="alternate"></link><published>2020-07-06T00:00:00-07:00</published><updated>2020-07-06T00:00:00-07:00</updated><author><name>Jack De Winter</name></author><id>tag:jackdewinter.github.io,2020-07-06:/2020/07/06/markdown-linter-weeding-the-projects-issue-list/</id><summary type="html">
&lt;h2 id="summary"&gt;Summary&lt;a class="headerlink" href="#summary" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;In my
&lt;a href="https://jackdewinter.github.io/2020/06/29/markdown-linter-rabbit-hole-3-trying-to-dig-myself-out/"&gt;last article&lt;/a&gt;,
I talked about how I was pulling myself out of the rabbit hole that I dug myself into,
by finding a small task, and completing it with panache.&lt;sup id="fnref:panache"&gt;&lt;a class="footnote-ref" href="#fn:panache"&gt;1&lt;/a&gt;&lt;/sup&gt;  In this article, I
talk about how I continued to get my confidence back by resolving …&lt;/p&gt;</summary><content type="html">
&lt;h2 id="summary"&gt;Summary&lt;a class="headerlink" href="#summary" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;In my
&lt;a href="https://jackdewinter.github.io/2020/06/29/markdown-linter-rabbit-hole-3-trying-to-dig-myself-out/"&gt;last article&lt;/a&gt;,
I talked about how I was pulling myself out of the rabbit hole that I dug myself into,
by finding a small task, and completing it with panache.&lt;sup id="fnref:panache"&gt;&lt;a class="footnote-ref" href="#fn:panache"&gt;1&lt;/a&gt;&lt;/sup&gt;  In this article, I
talk about how I continued to get my confidence back by resolving items on the issues
list while increasing the quality of the project.&lt;/p&gt;
&lt;h2 id="introduction"&gt;Introduction&lt;a class="headerlink" href="#introduction" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;At the
&lt;a href="https://jackdewinter.github.io/2020/06/29/markdown-linter-rabbit-hole-3-trying-to-dig-myself-out/#what-was-my-experience-so-far"&gt;end of the last article&lt;/a&gt;,
I talked about how I was starting to get out of the negative headspace that I found
myself in, making progress with the project at the same time.  The project’s
progress was a good thing, but it was my emotions towards the project that I was more
concerned with.  I have seen people stop working on their passion projects for
varied reasons, and I just did not want a momentary lapse of
confidence on my part to be the reason that I stopped working on this project.&lt;/p&gt;
&lt;p&gt;When I was pulling myself up out of my rabbit hole, I came to the realization that part
of the reason that my confidence took a bit of a hit, were the contents of the issues
list. While I am pretty sure that not every item on the list is an actual issue, until I
debug and verify each one, each item on that list is a potential bug.  And each
one of those potential bugs represented a bit of uncertainty that lowered my confidence.
Given that realization, taking some time to go through and “weed” the project’s issue
list seemed like a good idea!&lt;/p&gt;
&lt;h2 id="what-is-the-audience-for-this-article"&gt;What Is the Audience for This Article?&lt;a class="headerlink" href="#what-is-the-audience-for-this-article" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;While detailed more eloquently in
&lt;a href="https://jackdewinter.github.io/2020/04/05/what-is-the-audience-for-my-blog/#what-is-the-audience-for-my-blog"&gt;this article&lt;/a&gt;,
my goal for this technical article is to focus on the reasoning behind my solutions,
rather that the solutions themselves.  For a full record of the solutions presented in
this article, please go to this project’s GitHub repository and consult the
commits between
&lt;a href="https://github.com/jackdewinter/pymarkdown/commit/fdd7349a3473bda8a5644bead48396542919ec09"&gt;16 Jun 2020&lt;/a&gt; and
&lt;a href="https://github.com/jackdewinter/pymarkdown/commit/4312898343a31e382e9f5fe105374cbbde5ebbff"&gt;26 Jun 2020&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id="starting-out-easy"&gt;Starting Out Easy&lt;a class="headerlink" href="#starting-out-easy" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;The first three tasks on my list were simple things to resolve, little things that
I kept on meaning to do when I had some time. Completing them to get me warmed up
for the issues list was a good, solid plan.&lt;/p&gt;
&lt;p&gt;The first item on
my list was some simple refactoring of the &lt;code&gt;assert_token_consistency&lt;/code&gt; function in the
&lt;code&gt;utils.py&lt;/code&gt; module.  I had added some decent functionality to it in the last couple of
weeks, and it was time to make sure that the module was returned to its normal, properly
organized state.  The needed changes were simple. Start with a bit of extracting code
into functions, then add some function and variable renaming, and finally test the
changes to make sure I did not break anything.  While nothing changed in the source
code for the project, it felt good knowing that the test code was just &lt;em&gt;that&lt;/em&gt; much
cleaner.&lt;/p&gt;
&lt;p&gt;The next item was also a simple task: add reporting of leading whitespace to the next
list item token (&lt;code&gt;li&lt;/code&gt;).  When I was adding the code to handle leading whitespace for the
list start tokens, somehow, I forgot the new list item token in that work.  I noticed
this when I went to verify the next list item tokens in the consistency checks, and
there was no indication of the leading whitespace, other than the &lt;code&gt;indent_level&lt;/code&gt;
variable. For the sake of those consistency checks, this needed to be addressed.&lt;/p&gt;
&lt;p&gt;Adding this support into the consistency checks with the new list item tokens
modifications in place was almost trivial.
The &lt;em&gt;do not do new list item token until fixed&lt;/em&gt; check was removed and replaced with a
simple calculation of the &lt;code&gt;init_ws&lt;/code&gt; variable, in keeping with the handling of the list
start tokens.  To complete those changes, I also added some code in the
&lt;code&gt;__maintain_block_stack&lt;/code&gt; function to guarantee that new list item tokens were 
properly added and removed from the stack.&lt;/p&gt;
&lt;p&gt;Finally, I decided to use PyCharm and its enhanced code analysis tools to take a look
at the project, fixing things where possible.  I have
&lt;a href="https://jackdewinter.github.io/2020/04/20/markdown-linter-adding-image-links-and-simple-cleanup/#simple-cleanup-3-pycharm-static-code-analysis"&gt;talked before&lt;/a&gt;
about how PyCharm, while not a good development environment for me, is a product I
definitely like to use as a tool on a current project.  For me, the most useful of these
tools is a comprehensive look at what arguments and variables are used, and whether
they are needed.  In addition, PyCharm has a project dictionary that allows
me to search for typos in comments and variable names while maintaining a custom
dictionary that allows me to remove often used terms and abbreviations.
Combined, I feel that using PyCharm as a tool just adds an extra level of quality
and cleanliness to the project.&lt;/p&gt;
&lt;p&gt;While none of these tasks were big issues to tackle, they were small tasks that were
easily resolved and crossed off my mental “when I get time” list. And one less item
on that list is one less thing to worry about!&lt;/p&gt;
&lt;h2 id="verifying-issues"&gt;Verifying Issues&lt;a class="headerlink" href="#verifying-issues" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;h3 id="scenario-86a-indented-code-blocks"&gt;Scenario 86a: Indented Code Blocks&lt;a class="headerlink" href="#scenario-86a-indented-code-blocks" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;There are times when I look at an issue and I know exactly why I put that issue onto the
issues list.  This was not one of those times.  The notes I have for this one clearly
state that scenario 86a is a modification of
&lt;a href="https://github.github.com/gfm/#example-86"&gt;scenario 86&lt;/a&gt;
, but with 9 leading spaces
before the indented code block.  Those same notes are even clear that the reason I
added this new scenario was because I was concerned that scenario 86 only tested a case
where the length of the extracted whitespace equaled the length of the remaining
whitespace.  What I did not know was why I thought this was an issue.&lt;/p&gt;
&lt;p&gt;I did some due diligence here and found nothing.  I temporarily added some extra debug
code around the indented code block code but did not find anything useful.  After
making a mental note to myself to write better notes on why I added items to the issues
list, I removed it from the issues list and moved on.&lt;/p&gt;
&lt;h3 id="scenario-87-more-fun-with-indented-code-blocks"&gt;Scenario 87: More Fun with Indented Code Blocks&lt;a class="headerlink" href="#scenario-87-more-fun-with-indented-code-blocks" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;When I was doing the initial work to add the line/column number to the tokens back in
May, I wrote an issue to myself as a question:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;087 - shouldn’t it be inside of the indented code block?&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Unlike the issue with scenario 86a, it was easy to see why I wrote that question.  If
you look at the example by itself, the blank line before the reported start of the
indented code block is also indented by 4 space characters.  However, when I looked at
the example within the context of the GFM specification for
&lt;a href="https://github.github.com/gfm/#example-87"&gt;example 87&lt;/a&gt;,
the line before the example reads:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Blank lines preceding or following an indented code block are not included in it:&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;An honest question, an honest and researched answer, and an issue that was quickly
resolved.  Next!&lt;/p&gt;
&lt;h3 id="scenarios-235-236-252-and-255-indented-code-blocks-and-lists"&gt;Scenarios 235, 236, 252, and 255: Indented Code Blocks and Lists&lt;a class="headerlink" href="#scenarios-235-236-252-and-255-indented-code-blocks-and-lists" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;In each of these four cases, every scenario had to do with something
that may look like an indented code block being started from within a list. Like
scenario 87 in the last section, I could see how these scenario tests raised
questions.  For each one of these examples, from a quick glance it is hard to tell if
the number of spaces is correct from the example.&lt;/p&gt;
&lt;p&gt;In the case of
&lt;a href="https://github.github.com/gfm/#example-235"&gt;scenario 235&lt;/a&gt;
, my first inclination was that I had coded something wrong.
The &lt;code&gt;-&lt;/code&gt; character is followed by 4 spaces, so &lt;code&gt;one&lt;/code&gt; should be in an indented code block.
Right?  Almost.  The actual start sequence for the list is not &lt;code&gt;-&lt;/code&gt;, but &lt;code&gt;-{space}&lt;/code&gt;. As
such, the list starts with the &lt;code&gt;-&lt;/code&gt; character at column number 2, the space character at
column number 3, followed by 3 space characters for a total indent to column number 6.
The blank line
then ends the list on line number 2, and line 3 with 5 leading spaces is picked up as
an indented code block.  The scenario test was correct. Yes!&lt;/p&gt;
&lt;p&gt;The general math for
&lt;a href="https://github.github.com/gfm/#example-236"&gt;scenario 236&lt;/a&gt;
is the same, but because the text &lt;code&gt;two&lt;/code&gt; is indented 6 spaces
instead of scenario 237’s 5 spaces, it counts as a continuation of the original list.
&lt;a href="https://github.github.com/gfm/#example-252"&gt;Scenario 252&lt;/a&gt; and
&lt;a href="https://github.github.com/gfm/#example-255"&gt;scenario 255&lt;/a&gt;
are just variations of this, with and without the indented code blocks confusing the
issue.  In each case, the scenario tests were correct.  But I felt good that I had
questioned whether they were correct, and it was solidly answered in the positive.&lt;/p&gt;
&lt;p&gt;However, even though I did not find an immediate issue, I did find a future issue.  In
each of these cases, the &lt;code&gt;indent_level&lt;/code&gt; associated with the list is assumed to be
comprised of
space characters.  This assumption is fine for now, as the current consistency
checks explicitly ignore checking tests that contain tabs.  But when the tab character
support is enabled in the consistency checks, extra calculations will need to be added
to ensure the column numbers remain accurate.  This was not something I needed to
deal with now, but it would be an issue later.&lt;/p&gt;
&lt;h3 id="blank-lines-and-html-blocks"&gt;Blank Lines and HTML Blocks&lt;a class="headerlink" href="#blank-lines-and-html-blocks" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;I initially thought that this one was an open-and-shut case; the issue being noted down
as:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;blanks lines, if starts with 2 ws, is it (x,1) or (x,3)?&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The obvious answer is that it is always 1, as I indicated in the commit message for
removing the issue:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Answered question: blank lines always start at 1, as do HTML blocks.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;To verify this, I did a a quick scan of the test code for the text &lt;code&gt;html-block&lt;/code&gt; and
the text &lt;code&gt;BLANK&lt;/code&gt;, looking for the string values of their respective tokens in the
scenario test output.  As expected, each of those tokens contained a column number
of 1.  Until they didn’t.  &lt;/p&gt;
&lt;p&gt;The HTML block token and the blank line token always start at the start of the line, and
hence have a column number of 1.  But when those leaf block tokens are created within a
container block, the start of the line is where the
container block says it is.  Therefore, for blank lines created within a list block,
their column number becomes the indent level for the container block.&lt;/p&gt;
&lt;p&gt;The good news here is that I had an issue with the commit message, not the source
code.  If I could go back and correct the commit message&lt;sup id="fnref:doNotRebase"&gt;&lt;a class="footnote-ref" href="#fn:doNotRebase"&gt;2&lt;/a&gt;&lt;/sup&gt; to make it more
correct, I would have changed it to:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Answered question: blank lines always start at 1, as do HTML blocks, except when enclosed by a container block.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;After a bit of double checking, those scenarios and their tokens were also verified.
Another quick issue to resolve and get off the list!&lt;/p&gt;
&lt;h3 id="scenarios-197-257-and-262-blank-lines-and-lists"&gt;Scenarios 197, 257, and 262: Blank Lines and Lists&lt;a class="headerlink" href="#scenarios-197-257-and-262-blank-lines-and-lists" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;This issue was logged in order to explore whether or not there were issues with lists
that started with a blank line, as in
&lt;a href="https://github.github.com/gfm/#example-257"&gt;scenario 257&lt;/a&gt;
and
&lt;a href="https://github.github.com/gfm/#example-262"&gt;scenario 262&lt;/a&gt;.
To start with a baseline for blank lines, the example for
&lt;a href="https://github.github.com/gfm/#example-197"&gt;scenario 197&lt;/a&gt;
is as follows:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;\&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="err"&gt;\&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;

&lt;span class="n"&gt;aaa&lt;/span&gt;
&lt;span class="err"&gt;\&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="err"&gt;\&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;

&lt;span class="o"&gt;#&lt;/span&gt; &lt;span class="n"&gt;aaa&lt;/span&gt;

&lt;span class="err"&gt;\&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="err"&gt;\&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;(&lt;strong&gt;Aside:&lt;/strong&gt; Due to previous issues with me missing spaces in the examples, I had
previously replaced the spaces in this example with the character sequence &lt;code&gt;\a&lt;/code&gt;, making
the space character more visible.  Then, before passing this string to the test code,
the string is processed this string by invoking &lt;code&gt;.replace("\a", " ")&lt;/code&gt; on the resultant
string, transforming it into an accurate representation of the example.  This greatly
reduced the number of times that I missed trailing whitespace to zero!)&lt;/p&gt;
&lt;p&gt;In the scenario test for scenario 197, the tokens for the 1st, 4th, and 8th lines,
includes the leading whitespace while maintaining a column number of 1.  For example,
the token for the blank line on line 4 is:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;[BLANK(4,1):  ]
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Therefore, I compared that behavior to the blank line’s behavior inside of a
simple list block, such as with this Markdown for scenario 257:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="err"&gt;\&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="err"&gt;\&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="err"&gt;\&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;
  &lt;span class="n"&gt;foo&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;and the differences were clear:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;[BLANK(1,5):]
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;There are two differences between this token and the uncontained token above.  The
first is
that unlike scenario 197, the leading whitespace that was removed is not stored in the
token.  The second is that the column number is 5, when it should be 2.  Based on my
experience with blank lines in the last section, it was easy to see that the column
number should be 2, given the unordered list start character &lt;code&gt;-&lt;/code&gt; and the mandatory
space that followed it.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://github.github.com/gfm/#example-262"&gt;Scenario 262&lt;/a&gt;
was a far easier issue to deal with.  Its Markdown is:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Simple.  An unordered list start token, by itself in a document.  Thanks to the work
I did on scenario 257, this one was easily verified.  If scenario 257 should produce a
blank line token that contains 3 leading space characters, then scenario 262 should
contain a blank line token with no leading space characters.&lt;/p&gt;
&lt;p&gt;As this was just researching the issue, I resolved the existing issue and added more
specific issues to be properly addressed later. One issue to do with recording
whitespace for blank lines in a container, and the other issue for correcting the
column number of that same blank line in a container.&lt;/p&gt;
&lt;h3 id="scenarios-extra001-and-extra002-checking-for-correctness"&gt;Scenarios Extra001 and Extra002: Checking for Correctness&lt;a class="headerlink" href="#scenarios-extra001-and-extra002-checking-for-correctness" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Looking at how
&lt;a href="https://github.github.com/gfm/#blank-lines"&gt;blank lines&lt;/a&gt;
are defined in the GFM specification, from a purely transform-to-HTML point of view,
it is obvious that a document that only contains whitespace will produce an
empty HTML document.  This is mainly due to the stipulations:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Blank lines between block-level elements are ignored&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;and&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Blank lines at the beginning and end of the document are also ignored.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;But for those blank lines to be ignored, it stands to reason that from a tokenization
point of view, there must be a blank line token to ignore.  And as the linter operates
on tokens, the scenario tests &lt;code&gt;test_extra_001&lt;/code&gt; and &lt;code&gt;test_extra_002&lt;/code&gt; were added to
make sure the right blank tokens are produced.&lt;/p&gt;
&lt;p&gt;After the previous work in the above sections with blank lines, verifying these
scenario tests was quick and painless.  In reverse order, the text for scenario test
&lt;code&gt;test_extra_002&lt;/code&gt; was a simple document with 3 spaces, hence it needed to produce a
single blank line token with 3 spaces.  With that test solidly in place, it logically
follows that remove those 3 spaces for scenario test &lt;code&gt;test_extra_001&lt;/code&gt; would produce a
blank line token with no spaces, which is what the test expects.&lt;/p&gt;
&lt;p&gt;While this may have seemed like a trivial test, it is often the trivial cases and
&lt;a href="https://en.wikipedia.org/wiki/Edge_case#Software_engineering"&gt;edge cases&lt;/a&gt; that trip
up projects.  With everyone on the project worried how a big complex example will be
resolved, sometimes it is those little examples that slip through the crack out into
the wild.&lt;/p&gt;
&lt;p&gt;Honestly, even though they are trivial, I just felt better knowing that these trivial
cases were double-checked and covered.&lt;/p&gt;
&lt;h3 id="scenarios-559-and-560-link-reference-definitions"&gt;Scenarios 559 and 560: Link Reference Definitions?&lt;a class="headerlink" href="#scenarios-559-and-560-link-reference-definitions" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;I almost felt embarrassed when I read this one, as the answer was right in the
scenarios themselves.  The function comments for 559 (and with one small modification,
560) are as follows:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;test_reference_links_559&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
    &lt;span class="sd"&gt;"""&lt;/span&gt;
&lt;span class="sd"&gt;    Test case 559:  (part 1) A link label must contain at least one non-whitespace character:&lt;/span&gt;
&lt;span class="sd"&gt;    """&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Using scenario 559 as a benchmark, its Markdown is as follows:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;[]&lt;/span&gt;

&lt;span class="p"&gt;[]:&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;uri&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;and the Markdown for scenario 560 is almost the same, except for added whitespace:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;
 &lt;span class="p"&gt;]&lt;/span&gt;

&lt;span class="p"&gt;[&lt;/span&gt;
 &lt;span class="p"&gt;]:&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;uri&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;As it is hard to argue with the GFM specification’s definition of a
&lt;a href="https://github.github.com/gfm/#link-label"&gt;link label&lt;/a&gt;,
I resolved this and moved on.  In both cases, there just was not any whitespace
in the link label.&lt;/p&gt;
&lt;p&gt;But I still did due diligence: verified the example, checked the tokens, and after
a slight &lt;a href="https://en.wikipedia.org/wiki/Facepalm"&gt;face-palm&lt;/a&gt;, I resolved the issue
and moved on.&lt;/p&gt;
&lt;h3 id="changing-the-markdowntokens-constructor"&gt;Changing the MarkdownToken’s Constructor?&lt;a class="headerlink" href="#changing-the-markdowntokens-constructor" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Starting to ramp down on the project work, I hoped that this was a simple issue to
look at and resolve.  I had logged a simple question in the issue list:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;for all of the tokens that used position_marker, do we need =None any more?&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;This was an interesting question in that, except for the &lt;code&gt;MarkdownToken&lt;/code&gt; class itself,
none of the child classes have &lt;code&gt;position_marker&lt;/code&gt; as an optional argument!  From
that point of view, it would be quick to resolve it.  But I did not feel that I was
doing a complete job, so I decided to run with that idea a bit and find out where it
led me to.&lt;/p&gt;
&lt;p&gt;Doing a quick search over the &lt;code&gt;MarkdownToken&lt;/code&gt; class and its children, the breakdown
of how the &lt;code&gt;MarkdownToken&lt;/code&gt; constructor was called from the child classes were as
follows:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;line_number&lt;/code&gt; and &lt;code&gt;column_number&lt;/code&gt; arguments used: 3&lt;/li&gt;
&lt;li&gt;&lt;code&gt;position_marker&lt;/code&gt; argument used: 10&lt;/li&gt;
&lt;li&gt;none of the above arguments used: 11&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For the “none of the above” case, most of those child classes were for inline tokens
that do not have line/column support yet.  But if the trend of the current statistics
continues, this change may be something to revisit in the future.  Knowing more about
this issue, I was good resolving this issue now, possibly exploring this again in the
future when line/column numbers are added to inline elements.&lt;/p&gt;
&lt;h3 id="renaming-the-setext-tokens-whitespace-variable"&gt;Renaming the SetExt Token’s Whitespace Variable&lt;a class="headerlink" href="#renaming-the-setext-tokens-whitespace-variable" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;I was finally at the end of my planned issues list, and I was
glad that I was ending on another simple one.  When I was writing my first pass of the
&lt;a href="https://jackdewinter.github.io/2020/06/22/markdown-linter-rabbit-hole-2-losing-my-way/#fixing-the-easy-failures"&gt;consistency checker&lt;/a&gt;,
I noted that I had to special case the SetExt heading tokens, as the member variable
that is consistently named &lt;code&gt;extracted_whitespace&lt;/code&gt; for other tokens was mysteriously
named &lt;code&gt;remaining_line&lt;/code&gt; for this token.&lt;/p&gt;
&lt;p&gt;After performing due diligence to find out where the variable &lt;code&gt;remaining_line&lt;/code&gt; was
referenced and what was depending on it, there was no reason to keep this difference
around.  It just made more sense to change the name to the more consistent
&lt;code&gt;extracted_whitespace&lt;/code&gt;.  In addition to a simple search-and-replace, this change
allowed me to reduce the complexity of the &lt;code&gt;__calc_initial_whitespace&lt;/code&gt; function.&lt;/p&gt;
&lt;p&gt;Another small change, but another small step to a cleaner code base!&lt;/p&gt;
&lt;h2 id="why-was-this-work-important-to-me"&gt;Why Was This Work Important to Me?&lt;a class="headerlink" href="#why-was-this-work-important-to-me" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;From my personal and professional experience, the longer you let an issue sit
unexplored, the more uncertainty exists with respect to the team’s confidence in a
project.  At the time when I resolved those issues, I was at a more emotional place
than normal, where those uncertainties were weighing more heavily on my confidence.
While it took some time to work through them, it just felt right doing the proper due
diligence on each issue and resolving it.&lt;/p&gt;
&lt;p&gt;And the results of resolving these issues were very positive.  With the exception of
adding the proper encapsulation of leading whitespace for new list item tokens, no
other source code was measurably changed.&lt;sup id="fnref:defineMeasurable"&gt;&lt;a class="footnote-ref" href="#fn:defineMeasurable"&gt;3&lt;/a&gt;&lt;/sup&gt;
With respect to the test code, there were a couple of net-neutral changes for code
quality, but the other changes only added extra tests cases, not changing existing
tests.  Basically, while the work done in this time frame did not change the project’s
code base significantly, it did increase my confidence in the project by eliminating a
few of the existing questions.&lt;/p&gt;
&lt;h2 id="what-was-my-experience-so-far"&gt;What Was My Experience So Far?&lt;a class="headerlink" href="#what-was-my-experience-so-far" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;As far as recoveries go, I was feeling better after this stint of work.  By going
through the issues list, resolving 9 of those issues, and doing some code cleanup, my
confidence was back on track to be where it was before.  In any project, people
encounter circumstances that force them to evaluate if they have made the right project
decisions up to that point.  Depending on how hard those circumstances hit them and how
hard they hit them, people will decide to continue with the project, abandon it, or
take a wait-and-see approach.  While I was shaken for a bit, I was now back firmly in
the continue with the project camp.&lt;/p&gt;
&lt;p&gt;According to
&lt;a href="https://www.merriam-webster.com/dictionary/confidence"&gt;Webster&lt;/a&gt;,
confidence is:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;a feeling or consciousness of one’s powers or of reliance on one’s circumstances&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Confidence is an emotion, not logic.  It is not a light switch and it is not something
that listens to reason.  Confidence it fickle, hence the expression:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;One bad apple spoils the barrel.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;I could have resolved 29 issues, but if I found just one issue that looked
like a showstopper, those circumstances could be completely different. Who knows?&lt;/p&gt;
&lt;p&gt;Whether it was something substantial or something more lightweight, I knew that I
needed to do some work to try and influence my confidence in a positive direction.  In
this case, resolving several items off of the issues list was needed, and it paid
off.  It was not a guarantee, but a gamble that paid off.&lt;/p&gt;
&lt;p&gt;Someone once told me:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Marriage is made up with a whole bunch of days.  You have good days, you have bad days, and you have so-so days.  The sign of a good marriage is that you have more good days that the other two combined.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;A similar concept applies to working on passion projects, like me and my PyMarkdown
project.  It was just a matter of finding the right thing to do on the project that
would reignite my confidence, and therefore passion, for the project.&lt;/p&gt;
&lt;h2 id="what-is-next"&gt;What is Next?&lt;a class="headerlink" href="#what-is-next" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Having done some decent cleanup, I decided it was time to get back to work on the
consistency checker.  While I realized it was not going to be able to be 100% complete
until I started handling tab characters, I wanted to make a good effort towards getting
it more complete.  And that started with proper accounting of whitespace.&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr/&gt;
&lt;ol&gt;
&lt;li id="fn:panache"&gt;
&lt;p&gt;Per &lt;a href="https://www.merriam-webster.com/dictionary/panache"&gt;Webster’s&lt;/a&gt; “dash or flamboyance in style and action”. &lt;a class="footnote-backref" href="#fnref:panache" title="Jump back to footnote 1 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:doNotRebase"&gt;
&lt;p&gt;Yes, I know you can &lt;a href="https://docs.github.com/en/github/committing-changes-to-your-project/changing-a-commit-message"&gt;change a commit message&lt;/a&gt;, but the price is usually too high to pay for anything other than your very last commit. &lt;a class="footnote-backref" href="#fnref:doNotRebase" title="Jump back to footnote 2 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:defineMeasurable"&gt;
&lt;p&gt;For the sake of this sentence, I define a measurable change as a change that changes the requirements for input or the actual output of the project, with the exception of adding or modifying log messages. &lt;a class="footnote-backref" href="#fnref:defineMeasurable" title="Jump back to footnote 3 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</content><category term="Software Quality"></category><category term="markdown linter"></category><category term="core linter"></category></entry><entry><title>Markdown Linter - Rabbit Hole 3 - Trying To Dig Myself Out</title><link href="https://jackdewinter.github.io/2020/06/29/markdown-linter-rabbit-hole-3-trying-to-dig-myself-out/" rel="alternate"></link><published>2020-06-29T00:00:00-07:00</published><updated>2020-06-29T00:00:00-07:00</updated><author><name>Jack De Winter</name></author><id>tag:jackdewinter.github.io,2020-06-29:/2020/06/29/markdown-linter-rabbit-hole-3-trying-to-dig-myself-out/</id><summary type="html">
&lt;h2 id="summary"&gt;Summary&lt;a class="headerlink" href="#summary" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;In my
&lt;a href="https://jackdewinter.github.io/2020/06/22/markdown-linter-rabbit-hole-2-losing-my-way/"&gt;last article&lt;/a&gt;,
I talked about how I quickly found myself descending into a rabbit hole while
addressing an issue with my PyMarkdown project.  From experience, that behavior is a
pattern that I personally must work hard at to avoid.  In this article I talk about
mentally digging …&lt;/p&gt;</summary><content type="html">
&lt;h2 id="summary"&gt;Summary&lt;a class="headerlink" href="#summary" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;In my
&lt;a href="https://jackdewinter.github.io/2020/06/22/markdown-linter-rabbit-hole-2-losing-my-way/"&gt;last article&lt;/a&gt;,
I talked about how I quickly found myself descending into a rabbit hole while
addressing an issue with my PyMarkdown project.  From experience, that behavior is a
pattern that I personally must work hard at to avoid.  In this article I talk about
mentally digging myself out of that hole while extending the consistency checks for the
PyMarkdown linter to tokens beyond the initial token.&lt;/p&gt;
&lt;h2 id="introduction"&gt;Introduction&lt;a class="headerlink" href="#introduction" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;At the
&lt;a href="https://jackdewinter.github.io/2020/06/22/markdown-linter-rabbit-hole-2-losing-my-way/#what-was-my-experience-so-far"&gt;end of the last article&lt;/a&gt;,
I talked about how I started chasing a feature down multiple rabbit holes, noticing that
behavior a good 4-5 days after I felt that I should have noticed it.  As part of who I
am, I find certain types of puzzles very hard to put down and almost addictive in
nature.  During the development of the PyMarkdown
project, I have had my share of these puzzles, so I have had to
be very vigilant that I take a measured approach when solving each issue in an
attempt to keep that behavior in check.&lt;/p&gt;
&lt;p&gt;As this was the first time during this project that I have travelled down this route so
completely, I was slightly proud of myself.  Usually, for a project of this complexity
and duration, I would have expected to descend to those depths an extra 2-3 more times,
if not more. From experience, I find that it is during those times that I
lose my perspective on a project, and either go for perfection, give up the project
that I am working on, or both.  I am not sure, but my current belief is that by taking
a look at the bigger picture, and looking at it frequently, I have mostly mitigated my
desire for perfection by moderating it with other grounding concepts like feasibility.&lt;/p&gt;
&lt;p&gt;Having noticed that I dug myself into that hole, it was now time to try and figure
out what to do.  Stay where I was? Go forward? Go backward?  It really was my choice
on how I handled that situation.&lt;/p&gt;
&lt;h2 id="what-is-the-audience-for-this-article"&gt;What Is the Audience for This Article?&lt;a class="headerlink" href="#what-is-the-audience-for-this-article" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;While detailed more eloquently in
&lt;a href="https://jackdewinter.github.io/2020/04/05/what-is-the-audience-for-my-blog/#what-is-the-audience-for-my-blog"&gt;this article&lt;/a&gt;,
my goal for this technical article is to focus on the reasoning behind my solutions,
rather that the solutions themselves.  For a full record of the solutions presented in
this article, please go to this project’s GitHub repository and consult the
commit of
&lt;a href="https://github.com/jackdewinter/pymarkdown/commit/4bb4034ec69bc0aa67552f08c986ff94632e1e82"&gt;14 Jun 2020&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id="mental-and-emotional-stuff-is-important-too"&gt;Mental and Emotional Stuff Is Important Too&lt;a class="headerlink" href="#mental-and-emotional-stuff-is-important-too" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;I am not one for using excuses when something does not work out, but I am also not one
to keep on knocking someone down for failing.  Keep in mind the saying I
&lt;a href="https://jackdewinter.github.io/2020/02/10/markdown-linter-adding-html-blocks/#changing-the-narrative"&gt;have adopted&lt;/a&gt;:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Stuff happens, pick yourself up, dust yourself off, and figure out what to do next.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;For me and my family, there are two parts of that statement are important to
realize: the trying part and the figure out/learning part.&lt;/p&gt;
&lt;p&gt;In all honesty, I have every reason to not write this blog or work on this project.
I could spend more time interacting with my family,
fiddling around with home automation (how this blog started), watching movies (the more
b-movie or “hard” sci-fi the better), reading books (see movies), or any number of other
things.  At the time that I am writing this article, it is just shy of 4 months that I
have been working from home, due to
&lt;a href="https://www.cdc.gov/coronavirus/2019-ncov/index.html"&gt;COVID-19&lt;/a&gt;.  There is the
stress related to thinking about the 500,000 fatalities and 10 million infected
people worldwide.  Let’s face it.  The mere thoughts of that scale of death and
disease are somewhat crippling to me on good days. Add to that the normal stress of
making sure I am being a good worker, colleague, husband, and father.  Pick any 1 or 2
of those reason, and most people would understand my reasons if I said “I started
writing a blog, but I stopped when…”&lt;/p&gt;
&lt;p&gt;But I continue writing this blog and continue developing the project.  I have good days
and I have bad days, and I also have just, well, days.  But I keep on trying.
I know I am not going to get the blog right each time, but I try, and I improve.
I know I am not going to get the PyMarkdown project right on the first try,
and I am probably at my tenth or eleventh try if I add all the small tries
together.  But I keep on trying.&lt;/p&gt;
&lt;p&gt;And that is where the second half of the saying comes into play: figure out what to do
next.  There is a great quote that may or may not be attributed to
&lt;a href="https://quoteinvestigator.com/2017/03/23/same/"&gt;Albert Einstein&lt;/a&gt;:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Insanity is doing the same thing over and over again and expecting different results.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Figuring out what to do next for me is learning from what just happened, trying to avoid
the same mistakes in the future.  Does it always work? Nope.  Sometimes it takes a
couple of times for me to figure things out.  Sometimes I do not figure them out and
have to ask for help on how to deal with those mistakes or how to prevent them.  And
in some rare cases, I just need to let them be.  But that is also learning: learning
what I can do, what I cannot do, and trying to understand the effort required for each.&lt;/p&gt;
&lt;h2 id="how-does-this-relate-to-my-current-situation"&gt;How Does This Relate to My Current Situation?&lt;a class="headerlink" href="#how-does-this-relate-to-my-current-situation" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;I went down a rabbit hole and lost 4-5 days of productive work, only to realize that
when I was completely obsessed with the solution.  While I did struggle to find some
positive spin on the situation, it was
a rough break to deal with. Mentally, it took me about a week to get over the “oh no, I
went there
again” thoughts in my head.  Emotionally, I was hard on myself because I had “let
myself” not pay attention and lost my way.  Then add the weight of the elements in
my environment that were going on around the world at that time.  It took me a bit to
work through that quagmire.&lt;/p&gt;
&lt;p&gt;But I do not believe on giving up on something without a good reason.  I have learned a
lot about Python, writing, and myself by working on the PyMarkdown project and writing
about it in this blog.  The things that I have learned are in all sorts of areas, not
just the technical areas that I expected.  And personally, I have committed to this
path: to learning and helping others learn.  Basically, I have too many good reasons
to keep going, and not many reasons to give up.&lt;/p&gt;
&lt;p&gt;And yes, it was hard to push myself forward for the first couple of
weeks, through all the emotional and mental debris in the way.  I did a lot of
falling in that time, deciding each time to pick myself up.  There were times when the
words flew out of my fingers, and times where I could not type the next line in either
the project or the blog.  But I had confidence that I would work through it, and that
I would not give up.  This was something I knew I could do, I just had to push through
some bad stuff to get there.&lt;/p&gt;
&lt;h2 id="where-to-start"&gt;Where to Start?&lt;a class="headerlink" href="#where-to-start" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;I knew that I had to push forward with something positive, but what to do?  After a
bit of thinking, hoping to get myself back into the writing mood, I decided that I
would make some enhancements to the work already done.
In the last article, I described how I added code to validate the initial token in the
token stream.  This was done by only adding logic into the function for the cases where
the &lt;code&gt;last_token&lt;/code&gt; variable was &lt;code&gt;None&lt;/code&gt; for any block tokens.  The plan for this
enhancement was to keep the focus on block tokens, but to focus on the other block
tokens in the arrays. That is, focus on the cases where the the &lt;code&gt;last_token&lt;/code&gt; variable
was not &lt;code&gt;None&lt;/code&gt;.&lt;/p&gt;
&lt;h3 id="keeping-the-scope-small"&gt;Keeping the Scope Small&lt;a class="headerlink" href="#keeping-the-scope-small" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;After being burnt by the events documented in the previous article, I wanted to be extra
careful by setting myself up for success.  If I started with a small scope and found
that I was able to get it working quickly, I could always do more work on a subsequent
enhancement.  Knowing how I work; I knew that it would be far more difficult for me to
reduce the work’s scope once I had started it.  Especially when my confidence needed
a boost, I needed a solid, yet achievable, goal that I could complete with confidence.&lt;/p&gt;
&lt;p&gt;The question was where to start?  I had a feeling that dealing with leaf blocks which
started on the same line as container blocks were going to be a headache, so I removed
them from the scope.  I knew that I had issues with tab characters from the last
enhancement, so I removed them as well.  Was there anything else I could remove?&lt;/p&gt;
&lt;p&gt;Looking over the scenario tests and their data while scribbling some notes for myself,
I quickly came to two conclusions.
The first was that verifying the consistency of list-related objects would be relatively
easy, as the token contained all the necessary data.  Because of the presence of the
&lt;code&gt;indent_level&lt;/code&gt; variable and extracted whitespace in those tokens, I was able to quickly
figure out how to check their consistency.  After a couple of mental dry runs with my
solution and the real test data, I had confidence I could complete those checks.&lt;/p&gt;
&lt;p&gt;The second conclusion was that handling the block quote tokens were going to be
a completely different issue. Those tokens did not have a concept like
an &lt;code&gt;indent_level&lt;/code&gt; that could be generally applied, nor any memory of the whitespace
that they extracted from the line.  Supporting consistency checking with block quotes
was going to take some decent changes to the block quote tokens, something that was
going to take a lot of time and planning to properly execute.&lt;/p&gt;
&lt;p&gt;With these considerations in mind, I decided that
this enhancement would not address any token arrays with block
quote tokens or tab characters.  To keep things more manageable, I would restrict
any checking to leaf block tokens on new lines.  With this in place, it was good to go!
But I needed to add one thing first: a consistency token stack.&lt;/p&gt;
&lt;h3 id="adding-the-consistency-token-stack"&gt;Adding the Consistency Token Stack&lt;a class="headerlink" href="#adding-the-consistency-token-stack" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;The necessity for adding this stack to the consistency check was not a surprise to me.
To allow the parser to maintain a proper understanding of what the scope of the active
container blocks was, I added a stack to the parser explicitly for those container
blocks.  With the task of validating the consistency of the tokens and without access
to that internal stack, I knew that I needed to replicate some of the functionality
of that stack.&lt;/p&gt;
&lt;p&gt;Before any of the serious checking of the tokens took place, I needed a simple
stack that would track which container tokens were currently active.  The first pass at
this was really simple, with the
&lt;a href="https://en.wikipedia.org/wiki/Pseudocode"&gt;pseudocode&lt;/a&gt;
being as follows:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;for each token:
  if the token is a container block:
    add the token to the stack
  else if the token ends a container block:
    remove the last item from the stack

  do the rest of the processing
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This pseudocode is part of my mental algorithm repository that I lovingly refer to as
Parser 101.  Except in the case
of very simple parsers, almost every other parser I have written has had to maintain
some manner of stack to track context.  While the consistency checker is not a
full-fledged parser, it is operating on the tokens generated by a legitimate
full-fledged parser.  As such, it made sense that some of my parser experience would
assist me with this enhancement.&lt;/p&gt;
&lt;p&gt;The first pass at implementing this algorithm was a simple translation of the above
pseudocode fragment into Python code.  The &lt;em&gt;if the token is a container block&lt;/em&gt;
translation was simple, due to a previous refactoring:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;current_token&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;token_class&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;MarkdownTokenClass&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;CONTAINER_BLOCK&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;and the &lt;em&gt;add the token to the stack&lt;/em&gt; part of the translation was just as simple:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;    &lt;span class="n"&gt;container_block_stack&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;current_token&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The &lt;em&gt;if the token ends a container block&lt;/em&gt; part of the translation was a bit more
tedious to implement.  This was primarily due to end tokens not having any concept of
the token that started that block, only the name.  As such, after adding a comment and
a note to improve this, the following code was written to figure out if the container
block was ending:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;    &lt;span class="k"&gt;elif&lt;/span&gt; &lt;span class="nb"&gt;isinstance&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;current_token&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;EndMarkdownToken&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="n"&gt;token_name_without_prefix&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;current_token&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;token_name&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;
            &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;EndMarkdownToken&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;type_name_prefix&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="p"&gt;]&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;token_name_without_prefix&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;
            &lt;span class="n"&gt;MarkdownToken&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;token_block_quote&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
            &lt;span class="n"&gt;MarkdownToken&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;token_unordered_list_start&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
            &lt;span class="n"&gt;MarkdownToken&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;token_ordered_list_start&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
            &lt;span class="n"&gt;MarkdownToken&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;token_new_list_item&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="p"&gt;):&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Finally, the &lt;em&gt;remove the last item from the stack&lt;/em&gt; was translated into:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;            &lt;span class="k"&gt;assert&lt;/span&gt; &lt;span class="n"&gt;container_block_stack&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;token_name&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;token_name_without_prefix&lt;/span&gt;
            &lt;span class="k"&gt;del&lt;/span&gt; &lt;span class="n"&gt;container_block_stack&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;After all that was added, I quickly ran the tests and… tests were failing all over
the place.  But why?&lt;/p&gt;
&lt;h3 id="getting-the-stack-code-working"&gt;Getting the Stack Code Working&lt;a class="headerlink" href="#getting-the-stack-code-working" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Looking at the stack code, something became obvious almost immediately. If my
observation was correct, the processing of the &lt;code&gt;EndMarkdownToken&lt;/code&gt; was never being
invoked. A couple of quick debug statements verified that observation.  Doing a bit
more digging, I found out that I had set the class of the &lt;code&gt;EndMarkdownToken&lt;/code&gt; to
&lt;code&gt;INLINE_BLOCK&lt;/code&gt;.  This meant at the start of the consistency check loop, the code:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;current_token&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;token_class&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;MarkdownTokenClass&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;INLINE_BLOCK&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;would prevent the &lt;code&gt;EndMarkdownToken&lt;/code&gt; from ever getting through.  A quick fix changed
that statement to:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;
            &lt;span class="n"&gt;current_token&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;token_class&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;MarkdownTokenClass&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;INLINE_BLOCK&lt;/span&gt;
            &lt;span class="ow"&gt;and&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="nb"&gt;isinstance&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;current_token&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;EndMarkdownToken&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="p"&gt;):&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;and the test all ran… er… not fine?  With echoes of “what now?” ringing through
my ears, and debugging some more, the answer took a while to find.  Using extra
debug statements, I was able to pull some additional information out of the tests.
It became apparent that the second half
of the function had many issues with those end tokens.  However, addressing that
issue was easy, by adding the following code:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="nb"&gt;isinstance&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;current_token&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;EndMarkdownToken&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
            &lt;span class="k"&gt;continue&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;after the stack code and before the remaining code.  A couple of extra test runs, both
with and without debug statements and… everything was working with the new stack code.
On to the next issue!&lt;/p&gt;
&lt;h3 id="removing-block-quotes"&gt;Removing Block Quotes&lt;a class="headerlink" href="#removing-block-quotes" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;With the stack code in place and running cleanly, I needed to add the code to
prevent checking for the consistency for block quotes.  As previously decided, block
quotes were outside the scope of the current enhancement, and as such the following
code was added to check for block quotes:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;            &lt;span class="n"&gt;found_block_quote&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;False&lt;/span&gt;
            &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;container_block_stack&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;token_name&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;MarkdownToken&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;token_block_quote&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                    &lt;span class="n"&gt;found_block_quote&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;True&lt;/span&gt;
            &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;found_block_quote&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="n"&gt;last_token&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;current_token&lt;/span&gt;
                &lt;span class="k"&gt;continue&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;While this code may seem flawed, it was written this way on purpose.  I did not want
to have to validate any tokens that were contained within a block quote block, but I
did not want to remove the validation of the non-contained tokens either.  The above
block of code simply checks to see if there is a block quote on the container block
stack, skipping over any token while that condition is true.  This allows for any
block quote contained tokens to be avoided, while still validating any other tokens
present in that test sample.&lt;/p&gt;
&lt;h3 id="ignoring-tabs-for-now"&gt;Ignoring Tabs for Now&lt;a class="headerlink" href="#ignoring-tabs-for-now" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;The other big thing to take care of was to ignore any tabs that occurred in the
initial whitespace for any of the block tokens.  This was accomplished by changing the
return value of &lt;code&gt;__calc_initial_whitespace&lt;/code&gt; to be a pair of values, the first being the
same &lt;code&gt;indent_level&lt;/code&gt; as before and the second was a new &lt;code&gt;had_tab&lt;/code&gt; variable.  By setting
this variable, it was then possible to change this assert:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;            &lt;span class="k"&gt;assert&lt;/span&gt; &lt;span class="n"&gt;current_position&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;index_number&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;init_ws&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;to:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;            &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="n"&gt;had_tab&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="k"&gt;assert&lt;/span&gt; &lt;span class="n"&gt;current_position&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;index_number&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;init_ws&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;As I knew tabs were going to be a problem until they are properly and thoroughly
addressed, this change circumvented the assert statement when a tab was encountered.&lt;/p&gt;
&lt;h2 id="adding-the-basic-enhancement"&gt;Adding the Basic Enhancement&lt;a class="headerlink" href="#adding-the-basic-enhancement" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;With those changes in place and the tests passing, it felt that it was the right time
to add the code for the planned enhancement.  The basic part of this change was
easy, adding an else statement that followed the &lt;em&gt;same line number&lt;/em&gt; check, as such:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;            &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;last_position&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;line_number&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;current_position&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;line_number&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="k"&gt;assert&lt;/span&gt; &lt;span class="n"&gt;last_token&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;token_class&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;MarkdownTokenClass&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;CONTAINER_BLOCK&lt;/span&gt;
                &lt;span class="k"&gt;assert&lt;/span&gt; &lt;span class="n"&gt;current_position&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;index_number&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;last_position&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;index_number&lt;/span&gt;
            &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="n"&gt;init_ws&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;had_tab&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;__calc_initial_whitespace&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;current_token&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
                &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="n"&gt;had_tab&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                    &lt;span class="k"&gt;assert&lt;/span&gt; &lt;span class="n"&gt;current_position&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;index_number&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;init_ws&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This part of the algorithm makes clear sense.  Leaf blocks always start on a new
line, except for when they are started on the same line as a container block. As such,
the token starts right after any leading whitespace.  Since this enhancement focuses
solely on leaf block tokens on a new line, and due to the previous work to ignore any
tabs in the consistency checks, this code was kept simple.&lt;/p&gt;
&lt;p&gt;Testing this code out in my head, it was all sound except for when the token was in
a container block.  While
block quote blocks were excluded, that still left list blocks.  As such, when I ran the
tests this time, I expected failures to occur with leaf blocks that are started on their
own line but are contained within a list block.  As I went through the test run
failures, it was affirming to see that each of the failures that were now showing up
were squarely within those parameters.&lt;/p&gt;
&lt;h3 id="going-through-the-failures"&gt;Going Through the Failures&lt;a class="headerlink" href="#going-through-the-failures" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;As I went through the failures from the last set of code changes, I scribbled down notes
about the failure patterns that I saw.  The big pattern that I observed is, what I felt,
was a very obvious one.
When a leaf block was created within a list block, the reported column number was
always one more than the &lt;code&gt;indent_level&lt;/code&gt; variable for the list token.  That pattern does
make sense, as the list block contains the new leaf block, calculated from the indent
level of the list.&lt;/p&gt;
&lt;p&gt;The first pass at modifying the check to take this into account was the following:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;                &lt;span class="n"&gt;top_block&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;container_block_stack&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
                &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;
                    &lt;span class="n"&gt;top_block&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;token_name&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;MarkdownToken&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;token_unordered_list_start&lt;/span&gt;
                    &lt;span class="ow"&gt;or&lt;/span&gt; &lt;span class="n"&gt;top_block&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;token_name&lt;/span&gt;
                    &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;MarkdownToken&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;token_ordered_list_start&lt;/span&gt;
                    &lt;span class="ow"&gt;or&lt;/span&gt; &lt;span class="n"&gt;top_block&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;token_name&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;MarkdownToken&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;token_new_list_item&lt;/span&gt;
                &lt;span class="p"&gt;):&lt;/span&gt;
                    &lt;span class="n"&gt;init_ws&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="n"&gt;top_block&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;indent_level&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This code almost worked but reported errors with the first line.  That was quickly
addressed with a simple change to the code, checking to make sure that the
&lt;code&gt;container_block_stack&lt;/code&gt; variable containing the container stack is not empty:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;                &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;
                    &lt;span class="n"&gt;container_block_stack&lt;/span&gt;
                &lt;span class="p"&gt;):&lt;/span&gt;
                    &lt;span class="n"&gt;top_block&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;container_block_stack&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
                    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;
                        &lt;span class="n"&gt;top_block&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;token_name&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;MarkdownToken&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;token_unordered_list_start&lt;/span&gt;
                        &lt;span class="ow"&gt;or&lt;/span&gt; &lt;span class="n"&gt;top_block&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;token_name&lt;/span&gt;
                        &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;MarkdownToken&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;token_ordered_list_start&lt;/span&gt;
                        &lt;span class="ow"&gt;or&lt;/span&gt; &lt;span class="n"&gt;top_block&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;token_name&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;MarkdownToken&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;token_new_list_item&lt;/span&gt;
                    &lt;span class="p"&gt;):&lt;/span&gt;
                        &lt;span class="n"&gt;init_ws&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="n"&gt;top_block&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;indent_level&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h3 id="dealing-with-consistency-and-lists"&gt;Dealing with Consistency and Lists&lt;a class="headerlink" href="#dealing-with-consistency-and-lists" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;At this point, the only tests that were failing were tests related to list blocks.
Most of those tests were either contained in the &lt;code&gt;test_markdown_list_blocks.py&lt;/code&gt; module
or the &lt;code&gt;test_markdown_lists.py&lt;/code&gt; module.  Doing a bit more digging, the reason for a lot
of the failures was visible within seconds of looking at the failing scenario tests.
To make sure that lists and their inevitable sublists can be controlled properly, the
&lt;code&gt;indent_level&lt;/code&gt; variable contains the required indentation from the beginning of the
line, not since the end of the last list block.  To
complement this, any whitespace that occurs before that list block is saved within
the list block token.  The effect of this is that both ordered and unordered list
start tokens did not require any further modification, containing all the required
information within their own token.&lt;/p&gt;
&lt;p&gt;To address this, the check for adjusting the calculation if the token is in a list
was changed to:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;                &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;
                    &lt;span class="n"&gt;container_block_stack&lt;/span&gt;
                    &lt;span class="ow"&gt;and&lt;/span&gt; &lt;span class="n"&gt;current_token&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;token_name&lt;/span&gt;
                    &lt;span class="o"&gt;!=&lt;/span&gt; &lt;span class="n"&gt;MarkdownToken&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;token_unordered_list_start&lt;/span&gt;
                    &lt;span class="ow"&gt;and&lt;/span&gt; &lt;span class="n"&gt;current_token&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;token_name&lt;/span&gt;
                    &lt;span class="o"&gt;!=&lt;/span&gt; &lt;span class="n"&gt;MarkdownToken&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;token_ordered_list_start&lt;/span&gt;
                &lt;span class="p"&gt;):&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Furthermore, on additional examination, blank lines were in a similar situation.  Blank
lines contain complete information on how they were derived, so no manipulation of the
token’s column number was required.  Hence, another slight modification of the check
resulted in the code:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;                &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;
                    &lt;span class="n"&gt;container_block_stack&lt;/span&gt;
                    &lt;span class="ow"&gt;and&lt;/span&gt; &lt;span class="n"&gt;current_token&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;token_name&lt;/span&gt; &lt;span class="o"&gt;!=&lt;/span&gt; &lt;span class="n"&gt;MarkdownToken&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;token_blank_line&lt;/span&gt;
                    &lt;span class="ow"&gt;and&lt;/span&gt; &lt;span class="n"&gt;current_token&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;token_name&lt;/span&gt;
                    &lt;span class="o"&gt;!=&lt;/span&gt; &lt;span class="n"&gt;MarkdownToken&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;token_unordered_list_start&lt;/span&gt;
                    &lt;span class="ow"&gt;and&lt;/span&gt; &lt;span class="n"&gt;current_token&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;token_name&lt;/span&gt;
                    &lt;span class="o"&gt;!=&lt;/span&gt; &lt;span class="n"&gt;MarkdownToken&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;token_ordered_list_start&lt;/span&gt;
                &lt;span class="p"&gt;):&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h3 id="almost-there"&gt;Almost There&lt;a class="headerlink" href="#almost-there" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Running the tests again, the number of failures remaining was now a much smaller set of
tests.  Once again doing my due diligence,
I discovered an interesting issue with the new list item token: I had left out an
important field out of the token.  Unlike the ordered and unordered list start tokens,
the contents of
the new list item
token only had the &lt;code&gt;indent_level&lt;/code&gt; field, with the &lt;code&gt;extracted_whitespace&lt;/code&gt; field being
added to try and solve the failures.  But without the proper values for the
&lt;code&gt;extracted_whitespace&lt;/code&gt; field, it was not a proper solution to the problem.  I even
made modifications to the container block stack to properly deal with the new list
tokens. But even with those two changes in place, it just was not enough to solve all
the issues.&lt;/p&gt;
&lt;p&gt;Once I determined that it was not enough, I knew that I had to fix this properly at a
later date and close out this enhancement.  To accomplish that, I made a small change
to the code as part of the main consistency check: &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;            &lt;span class="k"&gt;elif&lt;/span&gt; &lt;span class="n"&gt;current_token&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;token_name&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;MarkdownToken&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;token_new_list_item&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="c1"&gt;# TODO later&lt;/span&gt;
                &lt;span class="k"&gt;pass&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;I did not feel that it was a great solution, but it was a decent stop-gap until I
could address those tokens.&lt;/p&gt;
&lt;h2 id="the-inevitable-bug-fixes"&gt;The Inevitable Bug Fixes&lt;a class="headerlink" href="#the-inevitable-bug-fixes" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Along the way, there were some small issues that were uncovered in the parser code,
fixed almost immediately due to their small nature.  There was a small fix made to the
&lt;code&gt;list_in_process&lt;/code&gt; function to make sure that the line was adjusted properly in some
edge cases.  There was another fix to the &lt;code&gt;__adjust_for_list_start&lt;/code&gt; function to make
sure that it returned an indication of whether it processed the list start index or not.
And finally, even though the tabs were not part of the enhancement, there was a bit
of cleanup to do in the area of the dual-purpose code used to handle list indents and
block quotes.  None of these were big bugs, but little issues that the consistency
checker was uncovering, and getting dealt with up front before they became a larger
issue.&lt;/p&gt;
&lt;p&gt;And that is where I stopped.  I knew that if I started trying to get more of the tab
code to work, it would be another rabbit hole.  Reminding myself of the big picture and
the current goals for the enhancement, I backed off.  And after a couple of minutes,
I felt good about it.  Tabs would wait for another enhancement, and then I would spend
a good amount of time working on tabs.  But for now, it could wait.&lt;/p&gt;
&lt;h2 id="importance-of-starting-small"&gt;Importance of Starting Small&lt;a class="headerlink" href="#importance-of-starting-small" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;I needed this enhancement to be a win, and I think I achieved that by keeping my
goals in mind. Rather than trying to do everything and having my effort be scattered,
I kept my work focused within the boundaries of a simple goal, one that I had
confidence that I would be able to achieve.  With this progress, I felt more confident
about myself and the project, and I knew I was on my way back to building a solid and
stable foundation that I could build further on.&lt;/p&gt;
&lt;p&gt;While my previous experience guided me towards this approach as I needed a win, it is
a solid approach regardless.  One of my managers at a previous company used to say:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;It is better to under promise and over perform than the other way around.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;I prefer another quote that was relayed to me by a friend at my current company:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Having a conversation with someone about resetting expectations is always troubling for me.  I would rather my reports take small bites of work and get better estimates on those bites of work, than take huge chunks of works and get lost and need help finding their way.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Those words have stayed with me for a long while, and I have tried to live up to the
essence of that quote.  I cannot tell anyone when the PyMarkdown linter is going to be
ready.  The scope is big enough that I cannot accurately judge that span of time.  But
I can let people know what my next 3 items on the issue list are, and approximately how
long it will take to complete them.  Those items are my small bites, something I can
solidly analyze and realistically figure out a time frame for their completion.&lt;/p&gt;
&lt;p&gt;For me, I feel that it is better to complete 10 tasks that work together than to
complete 1 task that will not work until it is completely done.  There just is no
comparison in my mind.  And having just completed one of those smaller tasks, my
confidence was returning.&lt;/p&gt;
&lt;h2 id="what-was-my-experience-so-far"&gt;What Was My Experience So Far?&lt;a class="headerlink" href="#what-was-my-experience-so-far" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;After my experience with the rabbit hole called &lt;em&gt;Tabs&lt;/em&gt;, I was worried that I was
going to focus more on the negative aspects of the project, rather than making
some good progress.  Would I repeat the behavior that I documented in my last article,
or would I correct that behavior and move the project forward?  While the
enhancements I made to the consistency checking were small, I was convinced that they
were solid enhancements.  That was exactly the type of win that I needed.&lt;/p&gt;
&lt;p&gt;This enhancement was not about technical feasibility, it was about getting myself out of
a negative headspace.  I believe it is true of most people that we are own worst
enemies, as we are privy to those thoughts and emotions that we keep private.  I know
that I am my own worst enemy for those reasons.  And while I did try hard with the
last enhancement, I know I was harder on myself that others would have been.  Not for
going down the rabbit hole, but because I did not notice I had slipped down there and
needed to get out of there before getting lost.&lt;/p&gt;
&lt;p&gt;I started this enhancement trying to get rid of the “oh no, here we go again” mindset.
Based on where my confidence was at finishing this enhancement, I am proud to report a
lot of positive work has been done.  My confidence was by no means back to where it
should be, but I was on my way there.  I developed a plan, made certain limitations,
and stuck by those limitations while delivering a well thought out enhancement.&lt;/p&gt;
&lt;p&gt;This was definitely a step in the right direction.&lt;/p&gt;
&lt;h2 id="what-is-next"&gt;What is Next?&lt;a class="headerlink" href="#what-is-next" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Having added a few issues to my issues log, mostly to verify certain scenarios I tested
or wrote about, I knew that I had some technical debt building up.  Along with the
new list item token issue, I felt it was a good time to build up some more confidence
by knocking some more of those issues out of the way.&lt;/p&gt;</content><category term="Software Quality"></category><category term="markdown linter"></category><category term="core linter"></category></entry><entry><title>Markdown Linter - Rabbit Hole 2 - Losing My Way</title><link href="https://jackdewinter.github.io/2020/06/22/markdown-linter-rabbit-hole-2-losing-my-way/" rel="alternate"></link><published>2020-06-22T00:00:00-07:00</published><updated>2020-06-22T00:00:00-07:00</updated><author><name>Jack De Winter</name></author><id>tag:jackdewinter.github.io,2020-06-22:/2020/06/22/markdown-linter-rabbit-hole-2-losing-my-way/</id><summary type="html">
&lt;h2 id="summary"&gt;Summary&lt;a class="headerlink" href="#summary" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;In my
&lt;a href="https://jackdewinter.github.io/2020/06/15/markdown-linter-rabbit-hole-1-adding-consistency-checks/"&gt;last article&lt;/a&gt;,
I talked about starting to add consistency checks for the line/column numbers by
adding simple line number checks.  In this article, I document the work that I
performed to add column checks to the project in a similar fashion to.  While I would
like …&lt;/p&gt;</summary><content type="html">
&lt;h2 id="summary"&gt;Summary&lt;a class="headerlink" href="#summary" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;In my
&lt;a href="https://jackdewinter.github.io/2020/06/15/markdown-linter-rabbit-hole-1-adding-consistency-checks/"&gt;last article&lt;/a&gt;,
I talked about starting to add consistency checks for the line/column numbers by
adding simple line number checks.  In this article, I document the work that I
performed to add column checks to the project in a similar fashion to.  While I would
like to say that the required effort was simple and the work was quickly accomplished,
as the title of the article implies, there were issues along the way that I could have
handled better.&lt;/p&gt;
&lt;h2 id="introduction"&gt;Introduction&lt;a class="headerlink" href="#introduction" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;At the
&lt;a href="https://jackdewinter.github.io/2020/06/15/markdown-linter-rabbit-hole-1-adding-consistency-checks/#adding-in-more-line-number-checks"&gt;end of the last article&lt;/a&gt;,
I talked about how I felt that the right move at that time was to move from the basic
consistency checking of line numbers to adding  a similar level
of checks for column
numbers.  My main argument for switching was that, from experience, it was
easier to track the line numbers when I manually verified the line/column numbers
than it was to track the column numbers.&lt;/p&gt;
&lt;p&gt;For line numbers, unless it was a list block
or a block quote block, a new block always meant a new line, which was easy to keep
track of.  For those two container blocks,
I had to check to see if a new block followed the container block, but the calculation
was still relatively simple.&lt;/p&gt;
&lt;p&gt;The calculation of column numbers was more detailed, and therefore more difficult
for me to accurately
calculate on-the-fly.  If not contained within a list block or a block quote block, I
looked at the whitespace at the start of the token and adjusted the column based
on the amount of whitespace.  If it was within a container block, I looked at the amount
of indent imparted by the container block and adjusted from there.  And while these
calculations may seem straightforward and easy, I initially double and triple checked
these values before moving on.  Even then, when I was checking the consistency of the
line numbers, I know that I got a decent handful of column numbers wrong.&lt;/p&gt;
&lt;p&gt;In the end, after getting some proper perspective, I believe that the
situation became an easy one to resolve.  I had the
easy cases for line numbers done, and that was good enough for a while.  I needed to get
the column numbers to a confidence level where I felt comfortable going back to the
line numbers and finishing off those checks.  Even though I was nervous about the
mistakes that I would find, I buckled down and started to work.&lt;/p&gt;
&lt;h2 id="what-is-the-audience-for-this-article"&gt;What Is the Audience for This Article?&lt;a class="headerlink" href="#what-is-the-audience-for-this-article" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;While detailed more eloquently in
&lt;a href="https://jackdewinter.github.io/2020/04/05/what-is-the-audience-for-my-blog/#what-is-the-audience-for-my-blog"&gt;this article&lt;/a&gt;,
my goal for this technical article is to focus on the reasoning behind my solutions,
rather that the solutions themselves.  For a full record of the solutions presented in
this article, please go to this project’s GitHub repository and consult the
commits after
&lt;a href="https://github.com/jackdewinter/pymarkdown/commit/9a2196b4dfd9948ef188e40c2619346bc4e673be"&gt;30 May 2020&lt;/a&gt; up to
&lt;a href="https://github.com/jackdewinter/pymarkdown/commit/19b4a2e6c26588370a2bab063b5cb1583d45f7d1"&gt;11 Jun 2020&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id="in-case-you-did-not-notice"&gt;In Case You Did Not Notice&lt;a class="headerlink" href="#in-case-you-did-not-notice" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Looking at the dates in the previous section, the duration between the start of the
column number work and the end of the column number work was 12 days.  To be clear,
this was not all the column number work, just the easy parts of the column numbers.
The batch of work documented in this article took a lot longer than my normal 5-day
to 7-day work time.&lt;/p&gt;
&lt;p&gt;It was for reasons like this situation that I named the articles in this part of the
series as “rabbit hole” articles.  Using that term at work a lot, it was amusing to
looking around for a good definition of what “rabbit hole” really means.  After some
fun research, I settled on this specific part of the article at
&lt;a href="https://www.dictionary.com/e/slang/rabbit-hole/"&gt;dictionary.com’s slang dictionary&lt;/a&gt;:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;But as Kathryn Schulz observed for The New Yorker in 2015, rabbit hole has further evolved in the information age: “These days…when we say that we fell down the rabbit hole, we seldom mean that we wound up somewhere psychedelically strange. We mean that we got interested in something to the point of distraction—usually by accident, and usually to a degree that the subject in question might not seem to merit.”&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;That really does capture what happened here.  But I do not want to spoil the story too
much.  Just continue reading and keep this in mind.&lt;/p&gt;
&lt;h2 id="keeping-it-simple-to-start"&gt;Keeping It Simple to Start&lt;a class="headerlink" href="#keeping-it-simple-to-start" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;As with all good tales, the work started off with good intentions.  As stated above, I
simply wanted to replicate for column numbers, the extra confidence that I achieved
with line numbers.  To that extent, the first stipulation that I made was that, if
possible, I was going to leave the container blocks until later.  Container
blocks were going to easily make things more confusing, so leaving them out would free
my mind up to concentrate solely on the leaf blocks.
While I was not sure what impact that rule would make, I hoped that it would reduce
the large amount of work that I was anticipating.&lt;/p&gt;
&lt;h2 id="taking-time-to-come-up-with-a-plan"&gt;Taking Time to Come Up With A Plan&lt;a class="headerlink" href="#taking-time-to-come-up-with-a-plan" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;With container block tokens (via the previous section) and inline tokens (as noted in
previous articles) excluded, I was able to concentrate all my effort on the leaf blocks.
While it was tempting to dive right into the work and to “clean everything up”, I knew
that I needed more of a plan than “clean everything up”
or “check all leaf blocks”.  I needed to take a good survey of the existing tokens and
their resultant HTML and determine what the intent of the token is and how it translates
into HTML.&lt;/p&gt;
&lt;p&gt;How did I know to do that?  When I was going through the different scenario tests while
implementing the consistency checks for
the line numbers, I noticed that there seemed to be 2 different classes of column
numbers for leaf tokens: one class where the whitespace occurs before the token and one
class where the whitespace seems to be part of the token.  It took a bit of research
and looking again at the tests, but I did verify that there were at least 2 classes of
leaf tokens.&lt;/p&gt;
&lt;p&gt;Confused?  Let me help!&lt;/p&gt;
&lt;h3 id="organizing-classes-of-blocks-by-their-intent"&gt;Organizing Classes of Blocks By Their Intent&lt;a class="headerlink" href="#organizing-classes-of-blocks-by-their-intent" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Fenced code blocks are blocks where any whitespace that occurs before the token is
recorded in the token, placing it solidly in the &lt;code&gt;before&lt;/code&gt; class.  Looking at the
Markdown for
&lt;a href="https://github.github.com/gfm/#example-105"&gt;example 105&lt;/a&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;```&lt;/span&gt;
&lt;span class="n"&gt;aaa&lt;/span&gt;
  &lt;span class="o"&gt;```&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;and the Markdown for &lt;a href="https://github.github.com/gfm/#example-106"&gt;example 106&lt;/a&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;   &lt;span class="o"&gt;```&lt;/span&gt;
&lt;span class="n"&gt;aaa&lt;/span&gt;
  &lt;span class="o"&gt;```&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;in the GFM specification, both fenced code block Markdown fragments produce the exact
same HTML output:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;pre&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;code&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;aaa
&lt;span class="p"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;code&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;pre&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Note that any whitespace before the code block starts is removed and does not appear in
the output.  While I need to add that whitespace back in to validate the column numbers
properly, it makes no difference to the HTML that is output.  As all the whitespace
occurs before the token itself starts, I decided to call this class of leaf blocks
the &lt;code&gt;before&lt;/code&gt; class.&lt;/p&gt;
&lt;p&gt;On the other hand,
&lt;a href="https://github.github.com/gfm/#example-86"&gt;example 86&lt;/a&gt;
shows Markdown text for an indented code block:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;        &lt;span class="n"&gt;foo&lt;/span&gt;
    &lt;span class="n"&gt;bar&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;that produces the following HTML:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;pre&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;code&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;    foo
bar
&lt;span class="p"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;code&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;pre&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;In this case, the indented code block is more aware of the whitespace that occurs
before the block starts, putting it firmly in the &lt;code&gt;contains&lt;/code&gt; class.  Specifically,
this class of blocks is for any leaf block where the whitespace makes up even a small
part of the block itself.  This is obvious with this block as the whitespace starts
at column 1 but continues in the produced HTML within the &lt;code&gt;&amp;lt;pre&amp;gt;&amp;lt;code&amp;gt;&lt;/code&gt; block.&lt;/p&gt;
&lt;p&gt;To prove that these leaf blocks are in the correct classes, I replicated the above
examples, but deleted a single space character from the initial whitespace for each
code block.  That change did not make any difference to the fenced code block, but
that change precipitated the removal of one space character from the HTML output for
the indented code block.  Due to that simple behavior, it was simple to place every leaf
block type into one of the two classes, allowing the blocks to be mostly handled as a
group of blocks instead of as individual blocks.&lt;/p&gt;
&lt;h3 id="aside"&gt;Aside&lt;a class="headerlink" href="#aside" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;To keep things above board, there technically is a third class, but it is mostly hidden.
In the case of blank lines and link reference definitions, the actual HTML output for
both elements is that they are ignored.  Therefore, technically the third class is for
&lt;em&gt;ignored&lt;/em&gt; tokens, but for the purposes of this classification, I assume they are in
neither class.&lt;/p&gt;
&lt;h3 id="classifying-the-blocks"&gt;Classifying the Blocks&lt;a class="headerlink" href="#classifying-the-blocks" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;With that newly acquired information in mind, I walked through similar examples and
assigned each of the leaf tokens to one of these three classes: before, contains, or
ignored.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;thematic breaks: before, see &lt;a href="https://github.github.com/gfm/#example-17"&gt;example 17&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;atx headings: before, see &lt;a href="https://github.github.com/gfm/#example-38"&gt;example 38&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;setext headings: before, see &lt;a href="https://github.github.com/gfm/#example-54"&gt;example 54&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;indented code block: contains, see &lt;a href="https://github.github.com/gfm/#example-86"&gt;example 86&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;fenced code block: before, see &lt;a href="https://github.github.com/gfm/#example-106"&gt;example 106&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;HTML block: contains, see &lt;a href="https://github.github.com/gfm/#example-120"&gt;example 120&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;link reference definition: ignored, see &lt;a href="https://github.github.com/gfm/#example-162"&gt;example 162&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;paragraphs: before, see &lt;a href="https://github.github.com/gfm/#example-192"&gt;example 192&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;blank lines: ignored, but treated as contains, see &lt;a href="https://github.github.com/gfm/#example-197"&gt;example 197&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="keeping-things-consistent"&gt;Keeping Things Consistent&lt;a class="headerlink" href="#keeping-things-consistent" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;In looking at how whitespace was handled for each of the leaf block tokens, one thing
did indeed stand out: I was not storing whitespace for each of the tokens in the token
itself.  While it was being passed down to the base class, there was not an explicit
variable named &lt;code&gt;extracted_whitespace&lt;/code&gt; for each token that stored this information.
Some tokens had that variable, some did not.&lt;/p&gt;
&lt;p&gt;While I could calculate this information on a token by token basis, it seemed simpler
to add the following line:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;    &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;extracted_whitespace&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;extracted_whitespace&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;to each of the constructors that were not assigning the argument to a member variable.
Specifically, the tokens for block quotes, list starts, indented code blocks, html
blocks, and thematic breaks needed this change, and it was a very quick change to
perform.  The important thing about this change was that, going forward, each of the
non-ignored tokens contained a
variable that explicitly was there to contain any extracted whitespace.  As this
variable was now in most block tokens, I hoped that the group of tokens could now be
processed largely as one group, instead of 11 distinct block tokens.&lt;/p&gt;
&lt;h2 id="player-enter-rabbit-hole-level-1"&gt;Player, Enter Rabbit Hole Level 1&lt;a class="headerlink" href="#player-enter-rabbit-hole-level-1" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;When I implemented the column numbers to begin with, I honestly thought there was only
one class of tokens, and therefore I treated them all as if they were in the &lt;em&gt;before&lt;/em&gt;
class.  To that extent, when I calculated each of the column numbers for the leaf
tokens, I started with the number 1 at the first position in the line and incremented
by 1 for each space character present in the data.  Effectively, I used the formula:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;    &lt;span class="n"&gt;column_number&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;token&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;extracted_whitespace&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;But now that I knew there was also a &lt;em&gt;contains&lt;/em&gt; class, it meant adjusting the formula
slightly.  Additionally, based on further observations, it looked like the HTML blocks
and the indented code blocks were going to need slightly different formulas.&lt;/p&gt;
&lt;p&gt;HTML blocks were the easiest one to observe and determine the pattern for.  Based on
the Markdown from
&lt;a href="https://github.github.com/gfm/#example-120"&gt;example 120&lt;/a&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;div&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
  &lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;hello&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;
         &lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;foo&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;it was obvious to me that the Markdown produces output that is exactly what is
contained within the block, namely:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt; &lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;div&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
  *hello*
         &lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;foo&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;a&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Based on the transformation, an
&lt;a href="https://en.wikipedia.org/wiki/Identity_transform"&gt;identity transformation&lt;/a&gt;
to be exact, it made sense that the formula for HTML blocks is:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;    &lt;span class="n"&gt;column_number&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The reasoning for this simple calculation is based on the observation of the transformed
HTML.  As any text that is part of the Markdown HTML block is part of the resultant
HTML, I interpreted that to mean that the block itself starts at the start of the line,
hence a column number of 1.&lt;/p&gt;
&lt;p&gt;Following a similar line of investigation, I looked at a good example of an indented
code block, the Markdown for
&lt;a href="https://github.github.com/gfm/#example-86"&gt;example 86&lt;/a&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;        &lt;span class="n"&gt;foo&lt;/span&gt;
    &lt;span class="n"&gt;bar&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;and its resultant HTML:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;pre&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;code&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;    foo
bar
&lt;span class="p"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;code&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;pre&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Based on this transformation, after the first 4 spaces are removed from the start of
each line, those lines are inserted into the HTML output, with a &lt;code&gt;&amp;lt;pre&amp;gt;&lt;/code&gt; &lt;code&gt;&amp;lt;code&amp;gt;&lt;/code&gt;
around them.
As the first 4 spaces are removed from each line, they are effectively part of the
token, but in a weird way.  In the above example, the first 4 spaces are swallowed while
the remaining spaces are left intact.  Based on this behavior, I interpreted that to
mean that the block itself starts after the 4th space, even though there are more spaces
before the non-space text starts.  Given that, the formula is:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;    &lt;span class="n"&gt;column_number&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;but with a special provision that any unused text is added to the start of the text
token that follows the indented code block token.&lt;/p&gt;
&lt;p&gt;Now that I had the behavior down, it was on to implementing the code for the
consistency check.&lt;/p&gt;
&lt;h2 id="congratulations-player-now-enter-rabbit-hole-level-2"&gt;Congratulations Player, Now Enter Rabbit Hole Level 2&lt;a class="headerlink" href="#congratulations-player-now-enter-rabbit-hole-level-2" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Having a solid idea of the behavior that I expected from each &lt;em&gt;contains&lt;/em&gt; token and the
group of &lt;em&gt;begins&lt;/em&gt; tokens, it was time to write the consistency check.
To allow for an easy computation of what the initial positioning was, I created
the &lt;code&gt;__calc_initial_whitespace&lt;/code&gt; function, starting it off with the equivalent
of:&lt;sup id="fnref:every"&gt;&lt;a class="footnote-ref" href="#fn:every"&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;__calc_initial_whitespace&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;calc_token&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;

    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;calc_token&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;token_name&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt; &lt;span class="sb"&gt;`every token`&lt;/span&gt; &lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;indent_level&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;calc_token&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;extracted_whitespace&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;assert&lt;/span&gt; &lt;span class="bp"&gt;False&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;By isolating all the various formula into one function, I was to be able to
use this simple code to implement the check itself:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;    &lt;span class="n"&gt;init_ws&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;__calc_initial_whitespace&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;current_token&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;assert&lt;/span&gt; &lt;span class="n"&gt;current_position&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;index_number&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;init_ws&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h3 id="fixing-the-easy-failures"&gt;Fixing the Easy Failures&lt;a class="headerlink" href="#fixing-the-easy-failures" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;After running the scenario tests with this new code in place, there were a lot of
successes,
but also failures that I needed to deal with.  The first set of failures
was with
various tokens that did not have a properly implemented &lt;code&gt;extracted_whitespace&lt;/code&gt; member
variable: HTML blocks,
blank lines, and SetExt headings.&lt;/p&gt;
&lt;p&gt;The HTML blocks were the easiest to deal with, as the formula from the previous section
always returns a column number of 1.  I added code to always return an index of 0 for
the length of the initial whitespace, resulting in a column position of 1 once the
above code was applied.  From there, blank lines were equally easy. While there are
good arguments for having blank lines denote the start or the end of the line, I picked
the start of the line to keep things simple. This made the coding easy, as these tokens
ended up returning 0, the same value as for HTML blocks.&lt;/p&gt;
&lt;p&gt;That left an oddball: SetExt headings.  For some reason that is lost to me, SetExt
headings use the &lt;code&gt;remaining_line&lt;/code&gt; member variable instead of
&lt;code&gt;extracted_whitespace&lt;/code&gt;.  While it felt weird, it was easy to do a quick check for that,
returning the length of that variable when SetExt headings tokens were encountered.
I also added an issue to my list to check this out in the future, as it is an
unnecessary complication that does not add any benefit.&lt;/p&gt;
&lt;p&gt;Running that scenario tests again, most of the issues were dealt with easily, following
the above rules, and adjusting the column numbers to the newly corrected values after
additional manual verification.
It was only a small handful of
errors that showed up, mostly in the HTML block scenario tests and the indented code
block scenario tests.  As those two blocks were ones that I placed into the
&lt;em&gt;contains&lt;/em&gt; class, these failures were expected and quickly addressed, applying changes
to the scenario tests to resolve those failures in short order.&lt;/p&gt;
&lt;h3 id="paragraphs-were-a-bit-more-work"&gt;Paragraphs Were a Bit More Work&lt;a class="headerlink" href="#paragraphs-were-a-bit-more-work" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;The next group of failures were easily grouped together as scenario tests that deal
explicitly with paragraphs.  On closer examination, it seemed that the failures occurred
only in a couple of specific cases.  After a couple of observations, it became obvious
that the failures were
restricted to multiline paragraphs.  In those multiline paragraphs, all the
whitespace stripped from the start of each line in the paragraph is added to the
token, not just the first line.  To address that, I made some quick changes to the code
for dealing with multiline paragraph tokens:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt; &lt;span class="k"&gt;elif&lt;/span&gt; &lt;span class="n"&gt;calc_token&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;token_name&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;MarkdownToken&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;token_paragraph&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;calc_token&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;extracted_whitespace&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;indent_level&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;calc_token&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;extracted_whitespace&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;index&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;indent_level&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;calc_token&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;extracted_whitespace&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;With the paragraph tokens dealt with, the column numbers now lined up nicely between
my calculated numbers and the consistency check numbers.  Other than tabs, the only
outlying scenario tests were two tests for indented code blocks inside of list blocks.&lt;/p&gt;
&lt;h3 id="another-rabbit-hole"&gt;Another Rabbit Hole&lt;a class="headerlink" href="#another-rabbit-hole" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;To be honest, during the writing of this article, getting a firm understanding of the
status of these two scenario tests took a couple of passes.  I had that understanding
when I completed the tests, then forgot it before I wrote the article.  When I started
to write article, I figured it out again, then forgot it while focusing on other
aspects of the article.  Finally, when I found the correct answer again, before I
forgot the explanation yet again, I quickly jotted down notes for this section.&lt;/p&gt;
&lt;p&gt;Yes, column numbers can be confusing.  Keep good notes.  Trust me on this.&lt;/p&gt;
&lt;p&gt;The two list block scenario tests that I had issues with were
&lt;a href="https://github.github.com/gfm/#example-235"&gt;example 235&lt;/a&gt; and
&lt;a href="https://github.github.com/gfm/#example-252"&gt;example 252&lt;/a&gt;.  For example 235:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;    &lt;span class="n"&gt;one&lt;/span&gt;

     &lt;span class="n"&gt;two&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;due to the extra indentation, the top paragraph starts at column number 7.  However,
as the lower paragraph does not have enough spaces to match that start column, it is
instead interpreted as an indented code block.&lt;sup id="fnref:see236"&gt;&lt;a class="footnote-ref" href="#fn:see236"&gt;2&lt;/a&gt;&lt;/sup&gt;  As such, that indented code
block starts at column 5, per established rule from above, and contains text that
starts with the 1 extra space.  As the column number in the test was 6, it was adjusted
to the now correct value of 5, with manual verification and consistency check
verification in place.  From personal experience, it was easy to forget that the
indented code block starts after the 4 space indent, making the calculation look
wrong.&lt;/p&gt;
&lt;p&gt;For &lt;a href="https://github.github.com/gfm/#example-252"&gt;example 252&lt;/a&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;      &lt;span class="n"&gt;indented&lt;/span&gt; &lt;span class="n"&gt;code&lt;/span&gt;

   &lt;span class="n"&gt;paragraph&lt;/span&gt;

       &lt;span class="k"&gt;more&lt;/span&gt; &lt;span class="n"&gt;code&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;it was more &lt;em&gt;fun&lt;/em&gt; with lists, but this time it was an unordered list that
contained a valid indented code block, unlike the example above.  In this case, the
list start sequence does not have any whitespace before it and is a simple 1 digit
list start.  From a calculation point of view, that means start with 0, add 0 to
that total for leading whitespace for the list start, 2 to that total for characters
in the list start sequence, and then add 1 to that total for the mandatory
list-to-content whitespace separator.  That means that the earliest that any content
can start in the list is at index 3, matching the list’s &lt;code&gt;indent_level&lt;/code&gt; member
variable.  As the
next token is an indented code block, adding 4 to that total results in an index of 7
or a position/column of 8 where the content for the code block starts.
  As the column number in the test was 9, it was adjusted
to the now correct value of 8, with manual verification and consistency check
verification in place.&lt;/p&gt;
&lt;p&gt;As I mentioned in my introduction to this article, the calculation for column numbers
were more detailed.  It was not until I wrote down the formulas for the calculation,
as outlined above, that I was able to confirm that I had made the right choice.&lt;/p&gt;
&lt;p&gt;And with that, all the scenario tests were passing except for tabs.&lt;/p&gt;
&lt;p&gt;Yeah, tabs again.&lt;/p&gt;
&lt;h2 id="be-wary-player-now-enter-rabbit-hole-level-3-tabs"&gt;Be Wary Player, Now Enter Rabbit Hole Level 3: Tabs&lt;a class="headerlink" href="#be-wary-player-now-enter-rabbit-hole-level-3-tabs" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;As I looked at the code, dreading a lot of changes to the code to support tabs, there
was both good
news and bad news.  The first part of the good news was that
except for the tab scenarios, the rest of the code was solid.  I had found a couple of
issues so far, but otherwise column numbers looked good.  The second part of the good
news
was that anything to fix with respect to tabs at the start of a line would be
largely restricted to the indented code blocks.  Until I started testing with container
blocks, any blocks that started with any combination of tabs and spaces would always
trigger the 4 whitespace minimum required to start an indented code block.&lt;/p&gt;
&lt;p&gt;The bad news?  This was not going to be fun.   As I documented in
&lt;a href="https://jackdewinter.github.io/2020/04/27/markdown-linter-reducing-the-parsers-technical-debt/#refactor-2-more-fun-with-tabs"&gt;More Fun With Tabs&lt;/a&gt;,
Markdown uses tab characters as tab stops.  To remove the complexity of handling those
tabs at the start of every block, I did the necessary computations to translate tab
characters into the correct number of spaces, based on the current index in the Markdown
document.  From that point on, any leading whitespace was tab-free and easy to work
with and manipulate for the transformation into HTML.&lt;/p&gt;
&lt;p&gt;But then I got to validating tokens for consistency with respect to column numbers.
After clearing away all the
other failures, only 13 failures remained, and all them dealt with tabs and
specifically with tabs in indented code blocks.  How bad could it be to reverse the
change and pass the initial whitespace through?  I started working the problem.&lt;/p&gt;
&lt;p&gt;Three days later, I determined that it would be very difficult.  After 2 restarts, there
was just too much code already in place to handle that relied on all leading whitespace
being space characters.
Replacing it would require more time to just get it to a good starting point, not even
to the point of having the tests passing.  Resetting for a third time, I decided to
just focus on the initial case of having a tab in the starting whitespace that caused
an indented code block.  Instead of working to reset the tab in all the code,
I focused on reconstructing the leading whitespace to determine what the proper handling
of the tab should be.&lt;/p&gt;
&lt;p&gt;Another three days later, and the code was complete.  When the initial whitespace is
encountered, a check is made against the initial line to be parsed to see if that line
contains a tab.  If so, further progressing is done to extract the original whitespace
that directly corresponds to the initial whitespace that caused the indented code block
to be started.  Once the original whitespace fragment was recovered, the extracted
whitespace in the indented code block token was adjusted, placing the proper portions
of the leading whitespace in the code block token and the following text block token.
And it also provisionally supported lists and block quotes.&lt;/p&gt;
&lt;h3 id="why-did-i-need-to-do-this"&gt;Why Did I Need to Do This?&lt;a class="headerlink" href="#why-did-i-need-to-do-this" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Basically, before this work, the whitespace that
was in the leaf block tokens did not have to be correct as it was largely ignored. As
such, only the extracted whitespace stored in the enclosed text block had to be
correct, as that whitespace is directly exposed when rendering the token into HTML.  To
make this more evident, consider the Markdown text for
&lt;a href="https://github.github.com/gfm/#example-7"&gt;example 7&lt;/a&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;-&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;tab&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;tab&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;foo&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;where &lt;code&gt;&amp;lt;tab&amp;gt;&lt;/code&gt; is a tab character.  As the specification explains, there is a bit of
calculation trickery in this area.  The list start character &lt;code&gt;-&lt;/code&gt; must be followed by
a space, so when the first tab character is encountered, 2 spaces must be emitted to
replace the tab stop.  When the next tab character is encountered, we are already at
a tab stop, so that tab is replaced with 4 characters, for a total initial whitespace
of 6 characters.&lt;/p&gt;
&lt;p&gt;Why was this important?  Because I had to make sure the right whitespace was being
placed in the right token, otherwise either the HTML validation would fail, or the
new consistency checks would fail.  Before this consistency check, if I
placed the needed 2 characters in the HTML text, the test passed.  Due to the check,
I now had to also properly calculate the whitespace to put in the indented code block
tokens itself.&lt;/p&gt;
&lt;p&gt;As I finished up work on the changes, I looked at the calendar… and noticed that
instead of my usual one week of work, it was 12 days later.  What I had budgeted 5
days for had taken 12 days.&lt;/p&gt;
&lt;h2 id="what-went-wrong"&gt;What went wrong?&lt;a class="headerlink" href="#what-went-wrong" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Looking back, I simply messed up. To me, there is nothing wrong with messing
up with something like this, if I learn something and grow.  So, it is just a
matter of taking a good look at what happened, and being honest with myself.&lt;/p&gt;
&lt;p&gt;The big thing that happened is that I believe that when I saw that it was going to
be a lot of additional work to support tabs, I should have stopped to re-evaluate
what needed to be done.  Instead, I kept on pressing forward instead of evaluating
whether tabs were worth it at that time.  As I personally do not use tabs, and many
of the documents that I surveyed do not have tabs in them, I could have sidelined tabs
for another day.&lt;/p&gt;
&lt;p&gt;In addition, once I started to work on implementing the proper tab support for the
tokens, I ignored additional warning signs.  Thinking back, I believe that I
kept on thinking “just around the next corner” and “one more line”, instead of being
honest about the work.  Essentially, I let my pride get in the way.  Instead of
being okay with leaving a partially implemented solution or resetting the work, I
was convinced that it was just another 5 minutes away… even after 5 days.&lt;/p&gt;
&lt;p&gt;On top of that, I mostly ignored my rule about leaving container blocks out of the
current block of work.  To get to this point with the tabs, I had to write extra
code that is specifically in place to deal with indented code blocks within container
blocks that contain tabs in the leading whitespace.  That is doubling down on dealing
with container blocks, not leaving them for later.&lt;/p&gt;
&lt;p&gt;I need to think about things.  How did I feel about all this?&lt;/p&gt;
&lt;h2 id="what-was-my-experience-so-far"&gt;What Was My Experience So Far?&lt;a class="headerlink" href="#what-was-my-experience-so-far" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;As I have
&lt;a href="https://jackdewinter.github.io/2020/02/10/markdown-linter-adding-html-blocks/#changing-the-narrative"&gt;mentioned before&lt;/a&gt;:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Stuff happens, pick yourself up, dust yourself off, and figure out what to do next.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Yeah, I messed up.  Stuff happened.  Instead of doing what I normally do, I went down
the rabbit hole
and got lost in trying to get the column numbers right, not just “good enough”. Even
after I started implementing the tab support, I did not pay attention to my own
warning signs that were telling me to reset and regroup.&lt;/p&gt;
&lt;p&gt;As for the dusting myself off, I realized that there was some good news out of all
this work.  Good news from all this? Really?&lt;/p&gt;
&lt;p&gt;The biggest part of the good news is this is the first time that this kind of thing
has happened on this project.  Yeah, I was
&lt;a href="https://en.wikipedia.org/wiki/Hyperfocus"&gt;hyperfocused&lt;/a&gt;
on getting the
work done, and did not pay attention to anything else.  But unlike other projects where
this happened multiple times throughout the same project, this was the first time for
this project.  One instance of this for a project that has lasted 8 months… not bad!
This is not just me making
&lt;a href="https://www.idiomeanings.com/make-lemonade-out-of-lemons/"&gt;lemons out of lemonade&lt;/a&gt;,
I was genuinely happy.  Granted, it took me a bit of self-reflection to get there,
but I got there.&lt;/p&gt;
&lt;p&gt;And on the way there, I did notice things.  One thing that I am confident about is that
even though having to take this route
with the tab characters is painful, it would have been more painful to have to deal
with those tabs in multiple places.  The current implementation for leading whitespace
removes the tabs, only adding them back in for the few cases where they are needed.
Another thing is that although I needed to address a couple of issues with 2 classes
of leaf blocks, the calculations for the column numbers were mostly spot on.  I still
want to make sure remain consistent by having consistency checks, but I am more
confident that I calculated the column numbers correctly.&lt;/p&gt;
&lt;p&gt;Sure, I got distracted.  It happens to everyone, especially with projects that we are
all passionate about.  I sincerely wanted to do the right thing, and that is not bad,
just counterproductive at this time.  Right now, I need “good enough”, not “perfect”.
While this was indeed a setback, it was a relatively small setback, one that I can
easily recover from.&lt;/p&gt;
&lt;p&gt;Overall, I was a bit bruised from following tabs down the rabbit hole, but I was
okay with it.  Not proud of it, but also not blaming myself and flogging myself for
it either.  Just okay with it.  And while I did go overboard, I did get the initial
scope of work done.  In the end, all is good.&lt;/p&gt;
&lt;h2 id="what-is-next"&gt;What is Next?&lt;a class="headerlink" href="#what-is-next" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;After focusing a lot of time on went wrong, it took a bit for me to realize that the
consistency checks were working as planned.  But on further examination, with possible
influence from my issues with hyperfocusing, I decided that I was not yet at the
point where I could switch back to line numbers.  As such, my next article will talk
about how I continued this work verifying column numbers.&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr/&gt;
&lt;ol&gt;
&lt;li id="fn:every"&gt;
&lt;p&gt;The text &lt;code&gt;every token&lt;/code&gt; is not meant to be taken literally.  Instead of listing each of the 11 tokens, I just felt it was more compact to use a figurative value. &lt;a class="footnote-backref" href="#fnref:every" title="Jump back to footnote 1 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:see236"&gt;
&lt;p&gt;The case where the second paragraph’s column matches the indent of the list item is tested in &lt;a href="https://github.github.com/gfm/#example-236"&gt;example 236&lt;/a&gt;. &lt;a class="footnote-backref" href="#fnref:see236" title="Jump back to footnote 2 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</content><category term="Software Quality"></category><category term="markdown linter"></category><category term="core linter"></category></entry><entry><title>Markdown Linter - Rabbit Hole 1 - Adding Consistency Checks</title><link href="https://jackdewinter.github.io/2020/06/15/markdown-linter-rabbit-hole-1-adding-consistency-checks/" rel="alternate"></link><published>2020-06-15T00:00:00-07:00</published><updated>2020-06-15T00:00:00-07:00</updated><author><name>Jack De Winter</name></author><id>tag:jackdewinter.github.io,2020-06-15:/2020/06/15/markdown-linter-rabbit-hole-1-adding-consistency-checks/</id><summary type="html">
&lt;h2 id="summary"&gt;Summary&lt;a class="headerlink" href="#summary" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;At the end of my
&lt;a href="https://jackdewinter.github.io/2020/06/08/markdown-linter-adding-line-and-column-support/"&gt;last article&lt;/a&gt;,
I talked about how I felt a lack of confidence in the work that I had just completed,
primarily due to the large number of scenario tokens that I added line/column numbers
to. This article documents the work to increase my …&lt;/p&gt;</summary><content type="html">
&lt;h2 id="summary"&gt;Summary&lt;a class="headerlink" href="#summary" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;At the end of my
&lt;a href="https://jackdewinter.github.io/2020/06/08/markdown-linter-adding-line-and-column-support/"&gt;last article&lt;/a&gt;,
I talked about how I felt a lack of confidence in the work that I had just completed,
primarily due to the large number of scenario tokens that I added line/column numbers
to. This article documents the work to increase my confidence in those line/column
numbers
by starting to add consistency checks to all the scenario tests.  Additionally, I talk
about the bad line/column numbers that were found by the new consistency checks and how
I addressed those issues.&lt;/p&gt;
&lt;h2 id="introduction"&gt;Introduction&lt;a class="headerlink" href="#introduction" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Why am I referring to this work as a
&lt;a href="https://www.merriam-webster.com/dictionary/rabbit%20hole"&gt;rabbit hole&lt;/a&gt;?
It is because this kind of verification can be easy, but if things are not done right,
the verification itself can be very messy and seemingly endless.  As with many things
in this project, whether or not to do this is a balancing act between the risk of doing
(or not doing) it, the
cost of doing it, and the impact if the risk comes to pass. The risk of not doing this
type of verification is that I may have miscalculated one of the line number/column
number pairs for one of the tokens in the 700+ examples that make up the scenario
tests. The cost of doing this is a small amount of code for the verification part of
the code, but it could also add tons of code to the actual parser to track additional
elements.  The impact is even more difficult to pin down.&lt;/p&gt;
&lt;p&gt;While part of the impact is measurable, namely the number of line number and column
number errors found, the other part of the impact is not measurable: confidence.
There is my confidence that I have those numbers right and there is the confidence of
any users that I have those numbers right.  And if I do not reach the minimum confidence
level for any users of the project, I am certain that I will lose those users.  It will
be a balancing act that I will need to be aware of, and to monitor going forward, even
after this work is finished.&lt;/p&gt;
&lt;h2 id="what-is-the-audience-for-this-article"&gt;What Is the Audience for This Article?&lt;a class="headerlink" href="#what-is-the-audience-for-this-article" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;While detailed more eloquently in
&lt;a href="https://jackdewinter.github.io/2020/04/05/what-is-the-audience-for-my-blog/#what-is-the-audience-for-my-blog"&gt;this article&lt;/a&gt;,
my goal for this technical article is to focus on the reasoning behind my solutions,
rather that the solutions themselves.  For a full record of the solutions presented in
this article, please go to this project’s GitHub repository and consult the
commits after
&lt;a href="https://github.com/jackdewinter/pymarkdown/commit/9a2196b4dfd9948ef188e40c2619346bc4e673be"&gt;30 May 2020&lt;/a&gt; up to
&lt;a href="https://github.com/jackdewinter/pymarkdown/commit/4bb4034ec69bc0aa67552f08c986ff94632e1e82"&gt;14 Jun 2020&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id="a-quick-aside"&gt;A Quick Aside&lt;a class="headerlink" href="#a-quick-aside" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Yes, one of these again!  I have been trying to figure out a good way to talk about
the line number and column numbers as a pair, trying out various combinations over
the last article and during the writing of this article.  The most descriptive and most
compact wording that I believe captures the information is: line/column number.  It
both indicates that they are a pair and that the pair has two distinct parts.  From
this point forward, I am going to strive to consistently use this format.&lt;/p&gt;
&lt;h2 id="starting-with-some-refactoring"&gt;Starting with Some Refactoring&lt;a class="headerlink" href="#starting-with-some-refactoring" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;I am always looking for ways to make the project better, and this was no exception.
During the addition of the &lt;code&gt;position_marker&lt;/code&gt; variables throughout the parsing code,
I noticed there were four variables that were usually getting passed around together:
&lt;code&gt;token_stack&lt;/code&gt;, &lt;code&gt;token_document&lt;/code&gt;, &lt;code&gt;close_open_blocks_fn&lt;/code&gt; and &lt;code&gt;handle_blank_line_fn&lt;/code&gt;.
While these variables might have slightly different names in the functions that used
them, their usage pattern was very consistent.  In each case, they were defined once in
the &lt;code&gt;TokenizedMarkdown&lt;/code&gt; class, and passed without change down throughout the rest of the
parser.  If Python had a good concept of a read-only variable, I would have used that
concept to decorate these variables.  Another alternative was to make these variables
static variables, but it did not feel right to me to make them into 4 different
static variables.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;ParserState&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="sd"&gt;"""&lt;/span&gt;
&lt;span class="sd"&gt;    Class to provide for an encapsulation of the high level state of the parser.&lt;/span&gt;
&lt;span class="sd"&gt;    """&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="fm"&gt;__init__&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;token_stack&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;token_document&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;close_open_blocks_fn&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;handle_blank_line_fn&lt;/span&gt;
    &lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;token_stack&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;token_stack&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;token_document&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;token_document&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;close_open_blocks_fn&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;close_open_blocks_fn&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;handle_blank_line_fn&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;handle_blank_line_fn&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;As I did want to reduce the overhead of passing these around, I created a new class
&lt;code&gt;ParserState&lt;/code&gt;, initialized an instance of it in the &lt;code&gt;__parse_blocks_pass&lt;/code&gt; function of
the &lt;code&gt;TokenizedMarkdown&lt;/code&gt; class, and added those four variables to that class as member
variables.  Then I worked my way through the parser, passing that object down further
and further into the parser.  Along the way, where possible, I removed PyLint
&lt;code&gt;too-many-arguments&lt;/code&gt; warnings and a couple of &lt;code&gt;too-many-locals&lt;/code&gt; warnings as well.  To
me, it just left things a bit cleaner, and ready for the next
step: starting to add the consistency checks.&lt;/p&gt;
&lt;h3 id="why-not-static-variables"&gt;Why not static variables?&lt;a class="headerlink" href="#why-not-static-variables" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Perhaps it is my object-oriented background or perhaps it is
my test automation background, but both of those backgrounds note that static variables
are bad.  From the object-oriented point of view, static variables cause issues because
you must be very aware of what is changing and observing those variables at every
moment.  From the test automation point of view, static variables are just hard to
test.  Because
everything in the project that uses that static variable has access to it, it can be
the result of a direct or indirect change from almost anywhere in that project.  If it
is only accessible from a static method, then there are problems with clearing out the
value of that variable so it can be properly tested under all circumstances.  Basically,
most of my experience tells me to stay away from static variables if possible.&lt;/p&gt;
&lt;h2 id="starting-with-the-plumbing"&gt;Starting with the Plumbing&lt;a class="headerlink" href="#starting-with-the-plumbing" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;With any sort of verification code, it is always a good idea to start with something
simple, slowly building on top of that work.  As this was just normal verification code,
the first thing I did was to add this function to the &lt;code&gt;utils.py&lt;/code&gt; module:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;assert_token_consistency&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;source_markdown&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;expected_tokens&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;pass&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Just a simple function that could be called from each of the scenario tests, starting
out with a skeleton function that does nothing.  With that in place, I started the
laborious task of going to each of the &lt;code&gt;test_markdown_*.py&lt;/code&gt; files and changing the
tests at the end of each scenario test from:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;    &lt;span class="c1"&gt;# Assert&lt;/span&gt;
    &lt;span class="n"&gt;assert_if_lists_different&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;expected_tokens&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;actual_tokens&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;assert_if_strings_different&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;expected_gfm&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;actual_gfm&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;to:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;    &lt;span class="c1"&gt;# Assert&lt;/span&gt;
    &lt;span class="n"&gt;assert_if_lists_different&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;expected_tokens&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;actual_tokens&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;assert_if_strings_different&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;expected_gfm&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;actual_gfm&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;assert_token_consistency&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;source_markdown&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;actual_tokens&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This was a simple task, but by making sure it was completed, I was able to go ahead
and add in any consistency checks between the Markdown and the tokens without wondering
if I had missed any of the tests.  And yes, I was paranoid and double checked all
the scenario tests at least one more time to make sure I did not miss any of the tests.&lt;/p&gt;
&lt;p&gt;Why did I take such a small step?  While other people’s mileage may vary, I find that
adding multiple consistency checks in a single step compounds the errors that
can occur if you get that check wrong.  Unless I can avoid it, I choose small changes
to the verification that I can easily validate manually, getting those changes addressed
solidly before moving on.  The base calculus that I am betting on is that the time
taken to complete multiple steps independently is less than the time taken to combine
them together.  Based on my experience, including implementing, testing, debugging, and
maintenance as factors into that equation usually favors the independent steps.&lt;/p&gt;
&lt;h2 id="verifying-the-line-numbers-start-at-1"&gt;Verifying the Line Numbers Start At 1&lt;a class="headerlink" href="#verifying-the-line-numbers-start-at-1" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;I was sure that verifying column numbers was going to be messy, but I was confident
that verifying line numbers would be more simplistic.  When it comes down to it, the
base part of verifying line numbers is making sure that each block token starts on
its own new line, except for a block that is within a container block.  In those cases,
and only those cases, can the line number be the same.&lt;/p&gt;
&lt;p&gt;But even before I started down that path, the first verification that I wanted to do
was to make sure that each array of tokens started with a block token on line 1.  It
was the simplest verification that I could think of, and from previously discovered
issues, I knew there were at least a couple of reported issues in this area.  If I
coded it properly, not only would I validate that the verification was working, but
I could also detect and fix an issue or two at the same time.&lt;/p&gt;
&lt;h3 id="classifying-the-tokens"&gt;Classifying the Tokens&lt;a class="headerlink" href="#classifying-the-tokens" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Up to this point in the project, I had little need to classify any of the Markdown
tokens as anything other than Markdown tokens.  When I addressed a block of tokens,
those tokens were always as a single token or as a small group of 2-3 tokens.  But,
to verify the line numbers properly, I was going to need to group the tokens on a
larger scale.  To accomplish that, I was going to have to add classification to the
tokens.&lt;/p&gt;
&lt;p&gt;In re-reading the verification steps outlined at the start of the previous section, I
realized at the minimum I was going to need to add the concept of each token belonging
to a specific class of token.
In this context, I was defining the class of the token as the grouping assigned to the
Markdown element in the GFM specification.  Using that as a template, along with some
previous work with Python enumerations, I was able to quickly set up this enumeration:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;MarkdownTokenClass&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Enum&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="sd"&gt;"""&lt;/span&gt;
&lt;span class="sd"&gt;    Enumeration to provide guidance on what class of token the token is.&lt;/span&gt;
&lt;span class="sd"&gt;    """&lt;/span&gt;

    &lt;span class="n"&gt;CONTAINER_BLOCK&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;
    &lt;span class="n"&gt;LEAF_BLOCK&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
    &lt;span class="n"&gt;INLINE_BLOCK&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;While Python supports four types of enumerations, I was confident that the simple
type of enumeration was the right fit to solve this issue.  I did not need the
enumeration to do anything fancy, just provide a simple property value for each token
that specifies what the class of that token is: container block, leaf block, or inline.
With the enumeration in place, it was a simple task to go through all the tokens in the
&lt;code&gt;markdown_token.py&lt;/code&gt; module and associate each token with its respective class. Using
the GFM specification as a guide, each token was matched up to its owning element and
assigned the proper class instance for that element.&lt;/p&gt;
&lt;h3 id="adding-the-first-verification"&gt;Adding the First Verification&lt;a class="headerlink" href="#adding-the-first-verification" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;With each token classified, the first part of the token verification was to only focus
on the blocks, as inline line/column numbers were not yet implemented.  Using the new
classification variable &lt;code&gt;token_class&lt;/code&gt; this was easily accomplished by adding a simple
loop over all the non-inline tokens:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;current_token&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;expected_tokens&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;current_token&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;token_class&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;MarkdownTokenClass&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;INLINE_BLOCK&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="k"&gt;continue&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Next, this was expanded to remember the last token, as such:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;    &lt;span class="n"&gt;last_token&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;None&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;current_token&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;expected_tokens&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;current_token&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;token_class&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;MarkdownTokenClass&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;INLINE_BLOCK&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="k"&gt;continue&lt;/span&gt;

        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;last_token&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="k"&gt;pass&lt;/span&gt;
        &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="k"&gt;assert&lt;/span&gt; &lt;span class="n"&gt;current_token&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;line_number&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;

        &lt;span class="n"&gt;last_token&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;current_token&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;While these were not big changes, it was a good start.  It made sure that the first
token in the document was always positioned on line number 1, which it should always
be.  If not,
the verification code asserts on the failure.  Simple.  And while I could have added
more
checks, I decided that was complex enough for now, and stopped there.  As I mentioned
above, taking small steps with the verification is a far safer bet.  And as I would
soon discover, it was already bearing fruit!&lt;/p&gt;
&lt;h3 id="looking-for-issues-link-reference-definitions"&gt;Looking for Issues - Link Reference Definitions&lt;a class="headerlink" href="#looking-for-issues-link-reference-definitions" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;When implementing the line/column numbers for each block tokens, as documented in the
&lt;a href="https://jackdewinter.github.io/2020/06/08/markdown-linter-adding-line-and-column-support/#lather-rinse-repeat"&gt;last article&lt;/a&gt;,
I noted down scenario
tests that looked dodgy for later examination.  At that time, I tagged the scenario
tests for examples 166 and 168 as being incorrect as they started off with an
extra blank line that started on line 2.  With this new verification code in place, when
those scenario tests were executed again, those new verification tests failed right
away.&lt;/p&gt;
&lt;p&gt;The output of the test was not an issue, as the HTML output for a blank line token in
the current output formatter is to output nothing.  However, when I added in the
line/column number check, it failed as it was the first block token in the output, and
it reported that it started on line 2.  The blank line was indeed on line 2, but the
token was being output at the start of the token array, and then again in the middle of
the &lt;code&gt;actual_tokens&lt;/code&gt; array.&lt;/p&gt;
&lt;p&gt;After some digging, I was able to find the error. During the processing of the blank
line, the parser checks to see whether there is an active link reference definition,
and if so, stops the definition.  However, regardless of whether a definition
was found, that blank line token is appended to the &lt;code&gt;token_document&lt;/code&gt; array.  With any
other token, this would be the correct thing to do.  However, as the processing of
the link reference definition
&lt;a href="https://jackdewinter.github.io/2020/04/06/markdown-linter-adding-link-reference-definitions/#hitting-implementation-issues"&gt;requires rewinding on failures&lt;/a&gt;,
the blank line was output, the parsing was rewound for the failed link reference
definition, and then the blank line was output again.  Once I figured out what the
problem was, it was easily remedied by seeing if a rewind was in progress by checking
the &lt;code&gt;force_ignore_first_as_lrd&lt;/code&gt; variable, and only emitting the token if it was not set.&lt;/p&gt;
&lt;p&gt;After some double checking, the scenario tests for example 166 and 168 were executed
again, verifying that they were indeed fixed.  I then ran the tests again to see what
other tests were failing, and it was a mass of SetExt heading failures that caught
my eye right away.&lt;/p&gt;
&lt;h3 id="looking-for-issues-setext-headings"&gt;Looking For Issues - SetExt Headings&lt;a class="headerlink" href="#looking-for-issues-setext-headings" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;It was very evident that more than half of the SetExt heading tests were failing
from the scenario test summary line.  Performing a quick count of the failing tests,
there were 13 SetExt heading tests failures out of a total 25 scenario tests.  As I
have put significant time into making sure that both the SetExt and Atx headings are
working properly, I was surprised to see that there were any verification failures, let
alone 13 of them.&lt;/p&gt;
&lt;p&gt;Within seconds of looking at the first of those tests, it was easy to see why the
verification was failing.  In the scenario test for example 50, the first part of
the Markdown text is:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;Foo&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;bar&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;
&lt;span class="o"&gt;=========&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;but the tokens being output by that block of Markdown text was:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;        "[setext(2,1):=:]",
        "[text:Foo :]",
        "[emphasis:1]",
        "[text:bar:]",
        "[end-emphasis::1]",
        "[end-setext::]",
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;From an HTML point of view, the tokens were correct, as the HTML output for that text:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;h1&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;Foo &lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;em&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;bar&lt;span class="p"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;em&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;h1&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;was correct.  But it was also obvious that the line/column number for the first token
was wrong.  As the first token, it should start on line 1, not line 2.  Even more
interesting is that if you visually look at the Markdown, it is obvious that it indeed
is the first Markdown element in the document.&lt;/p&gt;
&lt;p&gt;Starting to debug this scenario test, the answer was quick to come.  In the processing
of a SetExt heading, as
&lt;a href="https://jackdewinter.github.io/2020/06/01/markdown-linter-taking-time-to-evaluate/#adjusting-the-parsing-of-whitespace-in-setext-tokens"&gt;talked about previously&lt;/a&gt;,
the Markdown for a SetExt heading occurs after a paragraph has completed, transforming
that paragraph into a SetExt heading.  At the time that the SetExt heading token is
added to the markdown token array, the position that is associated with the token is
the start of the SetExt Markdown indicator.  As such, that is the position that is used
for the token.  And it does make sense that for every token, the position should
indicate where that token occurs.&lt;/p&gt;
&lt;h3 id="adapting-the-token-to-properly-represent-its-data"&gt;Adapting the Token to Properly Represent Its Data&lt;a class="headerlink" href="#adapting-the-token-to-properly-represent-its-data" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Despite the token position being technically correct, from a line/column number
verification point of view it did not make sense, and line/column numbers were what
was being verified.  As I thought about this, I vacillated between
representing the token with the position of the SetExt Markdown element and
the position of the block of text contained within the SetExt heading.  To me, there
just was not a good answer.  They both had a valid use and a valid reason to be the
one position that represented the token.&lt;/p&gt;
&lt;p&gt;Battling back and forth, I finally came to the realization that I needed to break out
of my current thinking that a token must have only one position.  While it is
not a feature I want to use frequently, this was an honest case where the token
should contain two positions: the primary position to contain the location of the
SetExt element itself and the secondary position to contain the location of the block
of text contained within the SetExt heading.&lt;/p&gt;
&lt;p&gt;To accomplish this, I added two new variables to the &lt;code&gt;SetExtHeadingMarkdownToken&lt;/code&gt; class:
&lt;code&gt;original_line_number&lt;/code&gt; and &lt;code&gt;original_column_number&lt;/code&gt;.  These two variables would be used
independently of the &lt;code&gt;line_number&lt;/code&gt; and &lt;code&gt;column_number&lt;/code&gt; variables to track the position
of the block of text contained within the SetExt heading.  I wired up the necessary
code to pass in the correct values for the two new variables, included adjusting the
&lt;code&gt;__str__&lt;/code&gt; function to present them as part of the token.&lt;/p&gt;
&lt;p&gt;When I reran the scenario test for example 50, I was pleasantly greeted with the
following new set of tokens:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;        "[setext(2,1):=::(1,1)]",
        "[text:Foo :]",
        "[emphasis:1]",
        "[text:bar:]",
        "[end-emphasis::1]",
        "[end-setext::]",
&lt;/pre&gt;&lt;/div&gt;
&lt;h3 id="changing-the-scenario-tests"&gt;Changing the Scenario Tests&lt;a class="headerlink" href="#changing-the-scenario-tests" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Now that the SetExt heading token contained a good set of information, I needed to
change the scenario tests to understand the new information.  Without any change, those
tests would still only know about the primary position.  To address this issue, I added
the following code:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;__calc_adjusted_position&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;markdown_token&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;markdown_token&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;token_name&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;MarkdownToken&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;token_setext_heading&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;line_number&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;markdown_token&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;original_line_number&lt;/span&gt;
        &lt;span class="n"&gt;index_number&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;markdown_token&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;original_column_number&lt;/span&gt;
    &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;line_number&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;markdown_token&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;line_number&lt;/span&gt;
        &lt;span class="n"&gt;index_number&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;markdown_token&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;column_number&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;PositionMarker&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;line_number&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;index_number&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;""&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;While it may seem like overkill to some people, the purpose of this function is to
keep the addition of this new logic contained within a single function.  This
encapsulation came in useful when I added it in to the consistency function:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;    &lt;span class="n"&gt;last_token&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;None&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;current_token&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;expected_tokens&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;current_position&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;__calc_adjusted_position&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;current_token&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;current_token&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;token_class&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;MarkdownTokenClass&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;INLINE_BLOCK&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="k"&gt;continue&lt;/span&gt;

        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;last_token&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;last_position&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;__calc_adjusted_position&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;last_token&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="k"&gt;assert&lt;/span&gt; &lt;span class="n"&gt;current_position&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;line_number&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;

        &lt;span class="n"&gt;last_token&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;current_token&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Used for both the &lt;code&gt;current_token&lt;/code&gt; and the &lt;code&gt;last_token&lt;/code&gt;, the new function easily provides
the right position for both tokens, with only a small change to the target function. In
addition, the adding of the &lt;code&gt;last_position&lt;/code&gt; variable gave me a bit of a reminder of the
direction that I needed to go in with the consistency checks.  More on that in a minute.&lt;/p&gt;
&lt;p&gt;Refocusing myself on the work directly ahead of me, running all the scenario tests
yielded 20 test failures, the original 13 tests plus another 7 tests that contained
SetExt heading tokens, just not at the start of the array.  For each of those 20 tests,
I manually checked the new tokens against the Markdown sample, and once I was satisfied
that they were accurate, I adjusted the expected tokens for that test to match the new
tokens.&lt;/p&gt;
&lt;p&gt;And this time, when I ran all the scenario tests, I was greeted with a clean slate
of no test failures.&lt;/p&gt;
&lt;h3 id="before-going-on"&gt;Before Going On&lt;a class="headerlink" href="#before-going-on" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Up to this point, when adding the consistency checks, I was mostly invoking the
tests with the following line:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;pipenv run pytest -m gfm
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;As the new consistency checks were only concerned with the scenario tests, this was
the fastest method to run all those tests.  However, before continuing, I wanted
to make sure those changes did not have any adverse side effects, so I ran the all
the tests in the project using:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;pipenv run pytest
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;While running all the tests may not have been necessary, I wanted to run them to
be confident that I did not introduce any bad side effects.  As the complete group of
tests can be executed in less than half a minute, the cost of the little bit of extra
confidence was easy for me to justify.&lt;/p&gt;
&lt;h2 id="adding-more-consistency-checks"&gt;Adding More Consistency Checks&lt;a class="headerlink" href="#adding-more-consistency-checks" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;With the SetExt heading tokens addressed and all the scenario tests passing again,
it was time to add more consistency checking.  As alluded to in the last section,
now that the line numbers are being verified for the first token, it was time to
add verification of container blocks and leaf blocks on the same line.&lt;/p&gt;
&lt;p&gt;In this case, the smallest step I could take was to check for two blocks that had the
same line number.  When this condition is true, the previous block must be a container
block, otherwise some error has just occurred.  In addition, without worrying about
column number accuracy yet, I can also state that that the current position must be to
the right of the enclosing block.  Adding those changes into the consistency checking
was therefore just as easy as its description:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;last_token&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;last_position&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;__calc_adjusted_position&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;last_token&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;last_position&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;line_number&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;current_position&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;line_number&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="k"&gt;assert&lt;/span&gt; &lt;span class="n"&gt;last_token&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;token_class&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;MarkdownTokenClass&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;CONTAINER_BLOCK&lt;/span&gt;
                &lt;span class="k"&gt;assert&lt;/span&gt; &lt;span class="n"&gt;current_position&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;index_number&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;last_position&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;index_number&lt;/span&gt;
        &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="k"&gt;assert&lt;/span&gt; &lt;span class="n"&gt;current_position&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;line_number&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;While this was not checking everything yet, it was a good step forward.  While I was
certain that I did not mess anything up with the container tokens, it was
good to have the validation that I did not miss anything.  It was to my surprise
that when ran the scenario tests again, two failures were reported.&lt;/p&gt;
&lt;h3 id="duplicated-tokens"&gt;Duplicated Tokens&lt;a class="headerlink" href="#duplicated-tokens" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;After I got over my surprise at there being two possible container block failures, I
started to investigate those two tests.  It was with relief that I noticed that both
tests, 218 and 219, were noted as being suspicious during the work from my last
article. From a quick glance at the test output, it was easy to spot that the check
was not failing due to container block issues, but due to almost duplicate blank line
tokens present in the
&lt;code&gt;actual_tokens&lt;/code&gt; array.  Because the line number was the same in both tokens,
it looked like a case of a leaf block within a leaf block instead of a duplicated
token.&lt;/p&gt;
&lt;p&gt;Debugging through this, it took me a while to figure this issue out.  After a lot
of head scratching, I finally had added enough debug information that I noticed that
in the code for the &lt;code&gt;parse_line_for_container_blocks&lt;/code&gt; function, once the calling of the
&lt;code&gt;handle_block_quote_block&lt;/code&gt; function was completed, the blank line had already been
handled, but the processing continued.  After verifying this a couple of times, I tried
removing the first call to process the blank line, but some of the other cases where
I handled blank lines stopped working.  While it did seem a bit of a kludge&lt;sup id="fnref:kludge"&gt;&lt;a class="footnote-ref" href="#fn:kludge"&gt;1&lt;/a&gt;&lt;/sup&gt;,
on the return from the &lt;code&gt;handle_block_quote_block&lt;/code&gt; function, I simply verified that the
blank line process was handled already.  If that, then the tokens were added to the
markdown token array, and the function was returned from.&lt;/p&gt;
&lt;p&gt;As the scenario test for example 261 was also flagged in the same line as 218 and 219,
I took a similar look at the output, of that, but did not notice any issues.  I even
tried some variations on the data to see if there was an error that was previously
exposed, and now fixed, and I was not able to reproduce it.  Confident that 218 and 219
were fixed and that I could not reproduce 261, I removed those issues from my
issues list.&lt;/p&gt;
&lt;p&gt;Once again, I re-ran the scenario tests, and all the test passed.  Executing the
entire batch of tests for the project, I was also greeted with a clean set of tests,
each one of them passing.  Now to figure out what to do next.&lt;/p&gt;
&lt;h2 id="adding-in-more-line-number-checks"&gt;Adding in More Line Number Checks?&lt;a class="headerlink" href="#adding-in-more-line-number-checks" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Taking a good look at adding more line number verification, I had a hard choice to
make.  Either I could try and add more line number verification, or I could start
working on column number verification.  There were good reasons for both paths, but
I had to make a choice.&lt;/p&gt;
&lt;p&gt;I went back and forth on this decision before taking another look at the existing
scenario tests, trying to figure out what I was most concerned about.  I decided that
while
it would be nice to get the line numbers completed, I was more concerned about the
column numbers.  In the token array for each scenario tests, I was able to track
the lines and line numbers more easily that I was able to track the column numbers.
In the end, that one observation is what affected my decision: I needed to start
verifying the column numbers next.&lt;/p&gt;
&lt;h2 id="what-was-my-experience-so-far"&gt;What Was My Experience So Far?&lt;a class="headerlink" href="#what-was-my-experience-so-far" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;For any consistency checking being implemented, it is often useful to have a handful
of issues that you know should fail, and then see the new consistency logic
failing.  The new checks passed that part of the test.  In addition, the
consistency checks add so far pointed out an issue with how I assigned line/column
numbers to the SetExt heading token.  Having caught and
reported failures on those issues, I was confident that adding consistency checking
for the line/column numbers was a good thing to do.  Seeing as the cost was still
very low, it seemed that the cost:benefit ratio was still heavily in favor of
continuing, so that is what I decided to do.&lt;/p&gt;
&lt;p&gt;Going back to my main issue regarding my confidence with line/column numbers and
their accuracy, if anything, I think I believed that I had lost ground.  With each
check finding something, it was both an affirmation that I was right to question
my manual verification abilities and a challenge to find more issues with more
consistency checking.  Basically, it was both “good job” and “what else ya got?” in
the same sentence.&lt;/p&gt;
&lt;p&gt;If I am honest, I felt it was a bit of a setback.  I had hoped it was going to lift
my confidence a bit, instead of a give-and-take that balanced each other out.  I
knew I needed to do something to boost my confidence, and I just hoped that adding
column number consistency checks would be the key to that.&lt;/p&gt;
&lt;h2 id="what-is-next"&gt;What is Next?&lt;a class="headerlink" href="#what-is-next" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Having reached a good point in my verification for line numbers, it was time to proceed
further down the
&lt;a href="https://www.merriam-webster.com/dictionary/rabbit%20hole"&gt;rabbit hole&lt;/a&gt;
that is consistency checking by starting to verify the column numbers.  And what a
rabbit hole it would end up being!&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr/&gt;
&lt;ol&gt;
&lt;li id="fn:kludge"&gt;
&lt;p&gt;According to Merriam-Webster: “a haphazard or makeshift solution to a problem and especially to a computer or programming problem” &lt;a class="footnote-backref" href="#fnref:kludge" title="Jump back to footnote 1 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</content><category term="Software Quality"></category><category term="markdown linter"></category><category term="core linter"></category></entry><entry><title>Markdown Linter - Adding Line and Column Support</title><link href="https://jackdewinter.github.io/2020/06/08/markdown-linter-adding-line-and-column-support/" rel="alternate"></link><published>2020-06-08T00:00:00-07:00</published><updated>2020-06-08T00:00:00-07:00</updated><author><name>Jack De Winter</name></author><id>tag:jackdewinter.github.io,2020-06-08:/2020/06/08/markdown-linter-adding-line-and-column-support/</id><summary type="html">
&lt;h2 id="introduction"&gt;Introduction&lt;a class="headerlink" href="#introduction" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;As I documented at the
&lt;a href="https://jackdewinter.github.io/2020/06/01/markdown-linter-taking-time-to-evaluate/#what-is-next"&gt;end of the previous article&lt;/a&gt;,
having arrived at the decision to improve the linter’s foundation,
it was time to tackle the largest issue on the stack: missing support for line numbers
and column numbers.
While at the time I thought of it as …&lt;/p&gt;</summary><content type="html">
&lt;h2 id="introduction"&gt;Introduction&lt;a class="headerlink" href="#introduction" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;As I documented at the
&lt;a href="https://jackdewinter.github.io/2020/06/01/markdown-linter-taking-time-to-evaluate/#what-is-next"&gt;end of the previous article&lt;/a&gt;,
having arrived at the decision to improve the linter’s foundation,
it was time to tackle the largest issue on the stack: missing support for line numbers
and column numbers.
While at the time I thought of it as a glaring omission (see
&lt;a href="https://jackdewinter.github.io/2020/05/11/markdown-linter-rules-the-first-three/#line-numbers-and-column-numbers"&gt;this article for more&lt;/a&gt;
), the passage of time since that discovery has helped me see that omission in a
better light.  On its own, the process of getting the tokenization correct was a large
enough task but adding the determination of each token’s line number and column
number to that task would have made that task unbearably larger.
Knowing myself as I do, even if I had discovered that requirement during the design
phase, there is a really good chance that I would have relegated the determination of
each token’s original position into its own task.  Regardless of what happened in the
past, it was obvious that I needed to start working on that task now.&lt;/p&gt;
&lt;p&gt;Starting to think about this issue, I had no doubt it was going to be a tough task to
complete, and I knew that I needed to find a way to break things down even further.
As I figured that
adding line numbers and column numbers to every token was going to be too much, I
reduced the scope even further by deciding to limit the scope to only block tokens.  As
every inline element is rooted in
a block element, I had
confidence that this would ensure that the line number and column numbers would be solid
in each block elements before adding the inline elements into the mix.  It was also a
solid dividing line for the task that just made sense to me.&lt;/p&gt;
&lt;p&gt;With those decisions on scope dealt with, it was time to delve into the depths of
line numbers and column numbers.&lt;/p&gt;
&lt;h2 id="what-is-the-audience-for-this-article"&gt;What Is the Audience for This Article?&lt;a class="headerlink" href="#what-is-the-audience-for-this-article" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;While detailed more eloquently in
&lt;a href="https://jackdewinter.github.io/2020/04/05/what-is-the-audience-for-my-blog/#what-is-the-audience-for-my-blog"&gt;this article&lt;/a&gt;,
my goal for this technical article is to focus on the reasoning behind my solutions,
rather that the solutions themselves.  For a full record of the solutions presented in
this article, please go to this project’s GitHub repository and consult the
commits between
&lt;a href="https://github.com/jackdewinter/pymarkdown/commit/628d6848029c3a2b02c755611455301fdf0fced4"&gt;26 May 2020&lt;/a&gt; and
&lt;a href="https://github.com/jackdewinter/pymarkdown/commit/1eb3677506dcefe7562f72082bed5374761f21cc"&gt;16 May 2020&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id="why-was-reducing-the-scope-good"&gt;Why Was Reducing the Scope Good?&lt;a class="headerlink" href="#why-was-reducing-the-scope-good" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Each of the implemented and enabled parser test functions includes the list variable
&lt;code&gt;expected_tokens&lt;/code&gt; and the string variable &lt;code&gt;expected_gfm&lt;/code&gt;.  The &lt;code&gt;expected_tokens&lt;/code&gt;
variable
is used to ensure that the tokens that are expected from the Markdown document are
emitted by the parser.  The &lt;code&gt;expected_gfm&lt;/code&gt; variable is used to ensure that those tokens
can use a simple algorithm&lt;sup id="fnref:simpleAlg"&gt;&lt;a class="footnote-ref" href="#fn:simpleAlg"&gt;1&lt;/a&gt;&lt;/sup&gt; to transform themselves into the HTML required by
the specification.  Prior to this work, their focus was simple: enable that forward
translation from Markdown into HTML.&lt;/p&gt;
&lt;p&gt;Adding in support for line numbers and column numbers was going to be a lot of work,
but it was working in a different direction: backwards towards the original Markdown
document.  There was no denying that this was a difficult task to complete, but
due to circumstances, the reduction in scope would leave me with a far simpler problem
to solve.  In addition, to protect the work already done in the forward direction, the
existing battery of tests remained in place, diligently guarding that work.&lt;/p&gt;
&lt;p&gt;With protection for the already completed work in place, and a clear definition of the
work to be done in mind, it was time for me to figure out how to start the process off.&lt;/p&gt;
&lt;h2 id="where-to-start"&gt;Where to start?&lt;a class="headerlink" href="#where-to-start" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;To help me keep track of things,
I added each of the block element names to the
&lt;code&gt;readme.md&lt;/code&gt; document where I track my issues.  As I needed to represent
every Markdown block, I moved the question in the issue document regarding the adding
of a Link Reference Definition token to the start of this new section and transformed
it into a statement.  As each block element in the
Markdown document needed to be tagged with its position, it was a necessity that
Link Reference Definition tokens be added, even if they did not result in any HTML
output.&lt;/p&gt;
&lt;p&gt;Having all the blocks elements listed in that document, I then needed to somehow
pick a good place to start. I was aware that wherever I decided to start, that token
was going to have a lot more work
associated with it as I tested out and implemented the foundation used to add line
numbers and column numbers to the other tokens.  Whatever process and code I used
for that first block element; the plan was to repeat it in some closely related form
for each of the other 10 block elements in the list.  But which one to pick?&lt;/p&gt;
&lt;p&gt;In the end, I decided to start with Atx headings.  Unfortunately, I did not keep any
notes as to why I picked this block element to start. My best guess is that after
having a lot of exposure to heading code while implementing the last group of rules, I
figured headings would be a good place to
start.  Following that line of thought, I believe that I also would have guessed that
SetExt headings were going to be the more difficult token to change, leaving Atx
headings as the best place to start.  Either that, or I decided to go alphabetic and
‘a’ is the first letter of the alphabet.  Either way, Atx headings were first, and it
was going to be a &lt;em&gt;fun&lt;/em&gt; ride.&lt;/p&gt;
&lt;h2 id="adding-in-position-markers"&gt;Adding in Position Markers&lt;a class="headerlink" href="#adding-in-position-markers" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Taking a good look at the Atx headings and the information that was being passed around,
the first thing that caught my eye was a good opportunity to refactor.  As I was letting
parts of the parser grow organically, many functions included the argument
&lt;code&gt;line_to_parse&lt;/code&gt; along with an argument that was usually named &lt;code&gt;start_index&lt;/code&gt;.  This
organic pairing made sense in a lot of places, allowing for the easy manipulation of
the current index, and occasionally the &lt;code&gt;line_to_parse&lt;/code&gt;.  However, when adding in
support for line numbers, I was going to have to pass in a third variable, meaning it
was time to refactor this.  As I have said
&lt;a href="https://jackdewinter.github.io/2020/05/04/markdown-linter-core-pre-rule-improvements/#source-providers"&gt;previously&lt;/a&gt;:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Write it once, write it neat.  Write it twice, think about extracting it.  Write it three times, extract it without a second thought.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;And that is where I started to work on replacing the &lt;code&gt;line_to_parse&lt;/code&gt; variable and the
&lt;code&gt;start_index&lt;/code&gt; like variables with the &lt;code&gt;position_marker&lt;/code&gt; variable and the
&lt;code&gt;PositionMarker&lt;/code&gt; class.  This class was, and remains, very simple:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;PositionMarker&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="sd"&gt;"""&lt;/span&gt;
&lt;span class="sd"&gt;    Class to provide an encapsulation of the location within the Markdown document.&lt;/span&gt;
&lt;span class="sd"&gt;    """&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="fm"&gt;__init__&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;line_number&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;index_number&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;text_to_parse&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;line_number&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;line_number&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;index_number&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;index_number&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;text_to_parse&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;text_to_parse&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;index_indent&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The &lt;code&gt;line_to_parse&lt;/code&gt; variable was replaced by the &lt;code&gt;text_to_parse&lt;/code&gt; member variable, the
index-type variable was replaced with the &lt;code&gt;index_number&lt;/code&gt; member variable, with the
&lt;code&gt;line_number&lt;/code&gt; member variable being introduced.  As I knew I would have to support
“indented” text, such as text after a block quote character or a list start sequence,
I added &lt;code&gt;index_indent&lt;/code&gt; at the same time.&lt;/p&gt;
&lt;p&gt;And with that, the easy stuff was ended.  It was time to move on to the tougher stuff.&lt;/p&gt;
&lt;h3 id="creating-the-marker"&gt;Creating the marker&lt;a class="headerlink" href="#creating-the-marker" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Wanting to start at the beginning, I made some modifications to the
&lt;code&gt;__parse_blocks_pass&lt;/code&gt; function in the &lt;code&gt;TokenizedMarkdown&lt;/code&gt; class to track the line
number.  As I did not have to deal with Link Reference Definition tokens yet
(spoilers!), this was a straight forward change, with the local &lt;code&gt;line_number&lt;/code&gt; variable
being initialized
before the main loop and that same variable being incremented at the end of the loop.
To encapsulate this information, I created a new position marker as follows:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;position_marker&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;PositionMarker&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;line_number&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;token_to_use&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Instead of passing &lt;code&gt;token_to_use&lt;/code&gt; to the &lt;code&gt;parse_line_for_container_blocks&lt;/code&gt; function, I
instead passed in the expression &lt;code&gt;position_marker.text_to_parse&lt;/code&gt;.  While I wanted to
pass in &lt;code&gt;position_marker&lt;/code&gt; by itself, I knew I had some important work to do before
getting that would be possible.&lt;/p&gt;
&lt;h3 id="stage-1-integrating-the-marker-locally"&gt;Stage 1 - Integrating the Marker Locally&lt;a class="headerlink" href="#stage-1-integrating-the-marker-locally" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Using my knowledge of the project, I knew that the path between the
&lt;code&gt;__parse_blocks_pass&lt;/code&gt; function in the &lt;code&gt;TokenizedMarkdown&lt;/code&gt; class and the
&lt;code&gt;parse_atx_headings&lt;/code&gt; function in the &lt;code&gt;LeafBlockProcessor&lt;/code&gt; class was going to go through
a number of functions in the &lt;code&gt;ContainerBlockProcessor&lt;/code&gt; class.  Instead of
using a lot of guesswork to determine what that path was, I decided to start at the
&lt;code&gt;parse_atx_headings&lt;/code&gt; function itself and work my way backwards to the
&lt;code&gt;parse_line_for_container_blocks&lt;/code&gt; function.&lt;/p&gt;
&lt;p&gt;In the place of adapting the entire function in one pass, I decided to start with
focusing
on the passing of the position marker into the function.  To facilitate this decision,
in the &lt;code&gt;parse_atx_headings&lt;/code&gt; function, I wrote some simple
&lt;a href="https://en.wikipedia.org/wiki/Glue_code"&gt;glue code&lt;/a&gt; to interface between the old style
code and the new style code. Before the change, the code looked like this:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;parse_atx_headings&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="n"&gt;line_to_parse&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;start_index&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;extracted_whitespace&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;close_open_blocks_fn&lt;/span&gt;
    &lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="sd"&gt;"""&lt;/span&gt;
&lt;span class="sd"&gt;        Handle the parsing of an atx heading.&lt;/span&gt;
&lt;span class="sd"&gt;        """&lt;/span&gt;
        &lt;span class="n"&gt;new_tokens&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;After the change, the code looked like this:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;parse_atx_headings&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;position_marker&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;extracted_whitespace&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;close_open_blocks_fn&lt;/span&gt;
    &lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="sd"&gt;"""&lt;/span&gt;
&lt;span class="sd"&gt;        Handle the parsing of an atx heading.&lt;/span&gt;
&lt;span class="sd"&gt;        """&lt;/span&gt;
        &lt;span class="n"&gt;line_to_parse&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;position_marker&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;text_to_parse&lt;/span&gt;
        &lt;span class="n"&gt;start_index&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;position_marker&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;index_number&lt;/span&gt;
        &lt;span class="n"&gt;new_tokens&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;In the &lt;code&gt;__parse_line_for_leaf_blocks&lt;/code&gt; function where the &lt;code&gt;parse_atx_headings&lt;/code&gt; function
was called from, I created a new &lt;code&gt;PositionMarker&lt;/code&gt; instance named &lt;code&gt;temp_marker&lt;/code&gt;, with
the information from the local function.  That new &lt;code&gt;temp_marker&lt;/code&gt; variable was then
passed into the &lt;code&gt;parse_atx_headings&lt;/code&gt; function instead of the previously used
&lt;code&gt;line_to_parse&lt;/code&gt; and &lt;code&gt;start_index&lt;/code&gt; arguments.&lt;/p&gt;
&lt;p&gt;I knew from the start that this approach was going to be more work.  However, by
isolating the change
to the function’s signature, I knew I could keep the parser stable and usable at any
point.  By keeping the parser in that good state, I knew I could depend on the
large bank of tests used by the project to verify any change was a successful change
with no unintended side effects.  The process was indeed slower than some other
methods, but it was a process that I had absolute confidence that I could rely on.&lt;/p&gt;
&lt;h3 id="stage-2-integrating-the-marker-up-the-stack"&gt;Stage 2 - Integrating the Marker Up the Stack&lt;a class="headerlink" href="#stage-2-integrating-the-marker-up-the-stack" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;In this stage, the process that was applied to the &lt;code&gt;parse_atx_headings&lt;/code&gt; function was
applied again and again until the &lt;code&gt;__parse_blocks_pass&lt;/code&gt; function was
reached.  With every step going back towards that function, I repeated the same actions
that I performed in stage 1, but with the calling function: add glue code, change
function arguments, create a temporary position marker, and pass that position marker
into the newly changed function.&lt;/p&gt;
&lt;p&gt;The almost continuous execution of tests at this point was essential.  As with any
parser, even slight changes in the content or interpretations of the content can cause
small ripples in the output that may escape detection if not quickly located and
addressed.  While I was doing my best to try and ensure that all changes were kept as
isolated as possible, it was only the rapid battery of tests that kept my confidence
high that I was going in the right direction with no ripples.&lt;/p&gt;
&lt;p&gt;Another thing that helped me immensely was using Git’s staging ability.  To facilitate
clean commits, Git has a nice feature called a
&lt;a href="https://git-scm.com/about/staging-area"&gt;staging area&lt;/a&gt;,
with the moving changes into this area being commonly referred to as staging.  The nice
part about Git staging is that,
&lt;a href="https://www.freecodecamp.org/forum/t/how-to-discard-unstaged-changes-in-git/13214"&gt;as this article describes&lt;/a&gt;,
it is very easy to discard any changes made to your local files in favor of the state of
that file with any committed changes and staged changes applied.  As such, each time I
applied this process to another function, I ensured that once the tests were all
passing that I staged those changes in the repository.  In the cases where I made
mistakes, which did happen frequently, I had the knowledge that I was able to revert
the relevant files back to their pre-change states, and resume work from there.  When
it was time to commit those changes, they were already isolated in the staging area,
ready to be committed.&lt;/p&gt;
&lt;h3 id="stage-3-cleaning-up-going-back-down"&gt;Stage 3 - Cleaning up Going back down&lt;a class="headerlink" href="#stage-3-cleaning-up-going-back-down" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Once I reached the &lt;code&gt;__parse_blocks_pass&lt;/code&gt; function, I was able to connect
with the real &lt;code&gt;position_marker&lt;/code&gt; variable, using that variable instead of creating a
new &lt;code&gt;temp_marker&lt;/code&gt; variable.  I then started working back towards the
&lt;code&gt;parse_atx_headings&lt;/code&gt; function, replacing &lt;code&gt;temp_marker&lt;/code&gt; with &lt;code&gt;position_marker&lt;/code&gt; as
I went.&lt;/p&gt;
&lt;p&gt;When I got to the
&lt;code&gt;parse_atx_headings&lt;/code&gt; function, I then proceeded to replace instances of &lt;code&gt;line_to_parse&lt;/code&gt;
within that function with &lt;code&gt;position_marker.text_to_parse&lt;/code&gt; and instances of &lt;code&gt;start_index&lt;/code&gt;
with &lt;code&gt;position_marker.index_number&lt;/code&gt;.  As these changes were localized, they were
easy to make, but I still ran frequent test passes just to make sure I was making
the right changes.  I do acknowledge that some of those test passes were executed out
of paranoia, but in my mind, if running the
tests an extra time allowed me to step forward with no reservations, it was worth it.&lt;/p&gt;
&lt;p&gt;Finally, at the end of all this process, I removed the &lt;code&gt;line_to_parse&lt;/code&gt; variable and
the &lt;code&gt;start_index&lt;/code&gt; variable from the function, as they were no longer being used.
There was no benefit to keeping those two variables around, so I just removed them.
I now had a solid function to parse for Atx headings, referencing the line number and
index number in a nice compact object.  In addition, I was able to easily trace this
compact object from the main processing line of the parser directly to the function
itself. The only thing left to complete the change was to wire up the token.&lt;/p&gt;
&lt;h3 id="stage-4-wiring-up-the-token"&gt;Stage 4 - Wiring up the Token&lt;a class="headerlink" href="#stage-4-wiring-up-the-token" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Now that I had the &lt;code&gt;position_marker&lt;/code&gt; object being passed properly into the
&lt;code&gt;parse_atx_headings&lt;/code&gt; function, I needed to pass that object into the token’s
constructor.&lt;/p&gt;
&lt;p&gt;The first change I made was to the base &lt;code&gt;MarkdownToken&lt;/code&gt; object, changing its constructor
to allow the passing in of a &lt;code&gt;line_number&lt;/code&gt; argument and a &lt;code&gt;column_number&lt;/code&gt; argument to be
stored in the instance.  To complement this change, I made some
modifications to the &lt;code&gt;__str__&lt;/code&gt; method to add the line number and column number to
the returned string, but only if at least one of those two numbers was not 0.  The
benefit of this slight change was that the line number/column number pair would only
show up in the function’s output if that information were provided.  As that information
was only provided once I added support for that type of token, I only
had to worry about the token output changing for the tokens I had already changed.&lt;/p&gt;
&lt;p&gt;The second change was to modify the constructor for the &lt;code&gt;AtxHeadingMarkdownToken&lt;/code&gt;
class to accept a &lt;code&gt;position_marker&lt;/code&gt; argument.  That code was implemented as such:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;    &lt;span class="n"&gt;line_number&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;
    &lt;span class="n"&gt;column_number&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;position_marker&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;line_number&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;position_marker&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;line_number&lt;/span&gt;
        &lt;span class="n"&gt;column_number&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;
            &lt;span class="n"&gt;position_marker&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;index_number&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;position_marker&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;index_indent&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
        &lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Basically, if the &lt;code&gt;position_marker&lt;/code&gt; variable was not present, the default value of 0
was used for the &lt;code&gt;line_number&lt;/code&gt; and &lt;code&gt;column_number&lt;/code&gt; variables.
If the &lt;code&gt;position_marker&lt;/code&gt; variable was present, the &lt;code&gt;line_number&lt;/code&gt; was be moved over
from its &lt;code&gt;position_marker&lt;/code&gt; object into the function’s &lt;code&gt;line_number&lt;/code&gt; variable.  For
the &lt;code&gt;column_number&lt;/code&gt; variable was assigned the sum of the &lt;code&gt;index_number&lt;/code&gt; member variable,
the &lt;code&gt;index_indent&lt;/code&gt; variable (at this point, always 0), and &lt;code&gt;1&lt;/code&gt;.  As index values are
always 0 based and column numbers are always 1 based, the addition of &lt;code&gt;1&lt;/code&gt; to the index
number ensured it was based properly.&lt;/p&gt;
&lt;p&gt;Finally, these newly calculated values for the &lt;code&gt;line_number&lt;/code&gt; and the &lt;code&gt;column_number&lt;/code&gt;
were passed into the newly retooled &lt;code&gt;MarkdownToken&lt;/code&gt; object constructor.  This was the
point that I was preparing for, where everything came together.  It was now time
to see how close I got to the actual test results.  If memory serves, I believe I
actually closed my eyes after saving my changes and started the execution of
the tests.&lt;/p&gt;
&lt;h3 id="stage-5-addressing-test-results"&gt;Stage 5 - Addressing Test Results&lt;a class="headerlink" href="#stage-5-addressing-test-results" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Prior to the very end of the previous step, the most frequent test command line that I
used was:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;pipenv run pytest -m gfm
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This executed only the parser’s scenario tests, reducing the test area to only those
tests that were tagged as being part of the &lt;code&gt;gfm&lt;/code&gt; group.  As I was running the tests
with each change, it was important to keep the scope, and therefore execution time,
of the tests to a minimum.  And up to this point, it worked well, and the tests were
solid, passing every time.&lt;/p&gt;
&lt;p&gt;But as I made the connection between the &lt;code&gt;AtxHeadingMarkdownToken&lt;/code&gt; token’s constructor
calling the &lt;code&gt;MarkdownToken&lt;/code&gt; token’s constructor, I knew that everything that I had
just changed was just a good guess.  I hoped that I had wired things up correctly, but
at that point, I only knew 2 things for sure:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;due to the tests, I had not disrupted any of the parsed tokens for the test cases, including their order and content&lt;/li&gt;
&lt;li&gt;I was passing some transformation of the base &lt;code&gt;position_marker&lt;/code&gt; into the token’s constructor&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;With everything wired up, I used the above command line multiple times, each time
picking off one of the failed tests to validate.  With each test, I first calculated
what I thought the line/column pair should be, noting it down in the function’s
comments section.  I then validated it against the test results, trying my hardest
to not peek at the test results before I did my calculations. Once
I had all those tests cleaned up, I did an extra pass through the changed tokens,
manually recalculating the line/column pair and checking to make sure they were right.
Only after all that was addressed did I change the module in the above command
line from &lt;code&gt;gfm&lt;/code&gt; to &lt;code&gt;rules&lt;/code&gt;, cleaning up any test failures caused by line/column pairs
that were now being displayed as part of the output.&lt;/p&gt;
&lt;h3 id="the-importance-of-good-tests"&gt;The Importance of Good Tests&lt;a class="headerlink" href="#the-importance-of-good-tests" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;While I can talk at length about good practices with respect to tests, I hope I can
convey the
sincere importance that I associate with having good tests and good test coverage
on a project.  It is true that I can often “eyeball” a simple change to a project,
figuring out whether that change is correct.  But in my mind, anything beyond a
simple change requires solid, repeatable testing.  Without that testing in place, you
are betting against the risk of something going wrong with your project.&lt;/p&gt;
&lt;p&gt;Testing is not about finding bugs as much as it is about risk management.  If you have
a small project that rolls various forms of dice for a Dungeons and Dragons campaign,
the impact of that risk failing is very light.  Any person I know that would
use such a project would also have some backup dice for “just in case”.  For the
PyMarkdown project, the end goal is to have a tool that website owners can trust to keep
their website’s Markdown documents in a proscribed format and style.  The impact of
too many failures is a loss of trust in the project, with a certain level of loss in
trust being associated with those website owners dropping their use of the project.  By
having good testing of various forms embedded within the project, I can hopefully
mitigate some amount of the loss of trust that any failure brings with it.&lt;/p&gt;
&lt;p&gt;Since I have worked so hard to get the project to this state, I did not want to take
any unnecessary risk to the project’s stability.  The tests are a solid tool that
I use frequently to keep any such risk to a minimum, and especially during refactoring,
where I rely on them heavily.  And as I rely on them heavily, I am also continuously
looking for better ways to test the projects that those tests are in.&lt;/p&gt;
&lt;h2 id="lather-rinse-repeat"&gt;Lather-Rinse-Repeat&lt;a class="headerlink" href="#lather-rinse-repeat" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;I honestly tried to find another heading for this section.  Try as I might, no other
section heading seemed to convey the repetition that I went through other than the
phrase:
&lt;a href="https://en.wikipedia.org/wiki/Lather,_rinse,_repeat"&gt;Lather, Rinse, and Repeat&lt;/a&gt;
.  For each of the 10 remaining tokens, the 5 steps outlined above for Atx heading
were repeated, with only a few changes to the process.  Those changes are outlined
in the following sections.  Please note that the following sections are ordered with
respect to the amount of work needed to resolve them, rather than my usual
chronological ordering.&lt;/p&gt;
&lt;p&gt;When I encountered questions with respect to whether something with respect to that
token was done properly or not, those questions were added as action items to the
&lt;code&gt;readme.md&lt;/code&gt; file to be examined later.  I knew this was going to be a
&lt;a href="https://www.merriam-webster.com/dictionary/slog"&gt;slog&lt;/a&gt;, and a hard slog at that.
It just seemed more efficient to me to note them and move on, circling back to deal
with them later.&lt;/p&gt;
&lt;h3 id="html-blocks-setext-heading-blocks-and-code-blocks"&gt;HTML Blocks, SetExt Heading Blocks and Code Blocks&lt;a class="headerlink" href="#html-blocks-setext-heading-blocks-and-code-blocks" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;There were no changes introduced to the process for these elements.&lt;/p&gt;
&lt;h3 id="thematic-breaks"&gt;Thematic Breaks&lt;a class="headerlink" href="#thematic-breaks" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;There was only one small change to the process for this element.  That change was
the delaying of the cleanup stage until a later time, as I wanted to get more breadth
of tokens implemented to ensure I had the right foundation for the change.&lt;/p&gt;
&lt;p&gt;The other change that I made was to the &lt;code&gt;MarkdownToken&lt;/code&gt; class, thereby affecting all
the other tokens.  For this change, I moved the code to calculate the &lt;code&gt;line_number&lt;/code&gt;
variable and
the &lt;code&gt;column_number&lt;/code&gt; variable from the &lt;code&gt;AtxHeadingMarkdownToken&lt;/code&gt; class to the base
&lt;code&gt;MarkdownToken&lt;/code&gt; class.  Once this code was proven, it just made more sense to keep
it in the base class than repeating it for each token.&lt;/p&gt;
&lt;h3 id="blank-line-token"&gt;Blank Line Token&lt;a class="headerlink" href="#blank-line-token" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;The change required to process the blank line token was not with the token itself, but
with the processing of block quote blocks.  The &lt;code&gt;__handle_blank_line&lt;/code&gt; function was
changed in the &lt;code&gt;TokenizedMarkdown&lt;/code&gt; class to accommodate the &lt;code&gt;position_marker&lt;/code&gt; argument,
starting the change for all calls to this function requiring that argument.  Other than
that change, everything else was normal.&lt;/p&gt;
&lt;h3 id="block-quote-blocks-and-list-blocks"&gt;Block Quote Blocks and List Blocks&lt;a class="headerlink" href="#block-quote-blocks-and-list-blocks" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Strangely enough, I thought these two types of blocks would take the most amount of
work to address, but due to the way they were implemented, only a couple of small
changes were required.  In both cases, the block start algorithms have to deal with
with the possibility of a tab character (often denoted as &lt;code&gt;\t&lt;/code&gt;) being used as the
whitespace between the block start sequence and the rest of the block’s data.&lt;/p&gt;
&lt;p&gt;Having already dealt with tab stops versus tab characters and
&lt;a href="https://jackdewinter.github.io/2020/04/27/markdown-linter-reducing-the-parsers-technical-debt/#refactor-2-more-fun-with-tabs"&gt;fixing that issue&lt;/a&gt; once,
I really did not want to fix it again.  I just needed to ensure that the current fix
and the previous fix were compatible with each other.  To ensure that happened
correctly, the modified line text and index numbers were passed to a newly created
&lt;code&gt;PositionMarker&lt;/code&gt; instance, created after the processing of the Block Quote block and
the List blocks.  This ensured that any line text modified by the processing of
either container block would be retained, while adding the now normal processing
using the &lt;code&gt;PositionMarker&lt;/code&gt; class.&lt;/p&gt;
&lt;h3 id="paragraph-blocks"&gt;Paragraph Blocks&lt;a class="headerlink" href="#paragraph-blocks" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;As the catch-all element for Markdown documents, I had a feeling that these blocks
would end up near the top of the “most effort” list, although I will admit that I
guessed the reason
wrong.  I thought that it would have something to do with lists and block quotes,
while the actual reason is due to Link Reference Definitions.  More precisely, the
reason is due to failed or partially failed Link Reference Definitions.&lt;/p&gt;
&lt;p&gt;Due to its composition, it is impossible to properly determine if a Link Reference
Definition is valid without reading the next line.  As documented in the article
&lt;a href="https://jackdewinter.github.io/2020/04/06/markdown-linter-adding-link-reference-definitions/"&gt;Adding Link Reference Definitions&lt;/a&gt;, its multiline
nature and use of various forms of quoted sections mean that unless the parser
encounters the end of the closing section or a blank line, it does not know if it
had reached the end of the Link Reference Definition.  If it reaches the end and
for any reason that Link Reference Definition is not valid, the logic in the parser
starts adding lines back on to a list of lines that need to be reparsed without
them being misinterpreted as a Link Reference Definition.&lt;/p&gt;
&lt;p&gt;It is precisely that requeuing logic that I needed to alter to work properly with the
new &lt;code&gt;PositionMarker&lt;/code&gt; class.  While the &lt;code&gt;index_number&lt;/code&gt; remained untouched, I had to
make sure that the &lt;code&gt;line_number&lt;/code&gt; variable was properly reset to account for the
length of the &lt;code&gt;lines_to_requeue&lt;/code&gt; variable when any requeuing occurred.  I had a
bit of a problem with the initial implementation of this code, so I wanted to take
extra time and really boost my confidence that I was handling the change for this
token properly.&lt;/p&gt;
&lt;h3 id="link-reference-definitions"&gt;Link Reference Definitions&lt;a class="headerlink" href="#link-reference-definitions" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;This one should be very obvious… I needed to add the token itself!  When designing
the parser, I did not see any need for a token that literally has no impact on
the output, so I did not add a token for it.  While a link element that refers to a
link reference definition will show up as a link in the HTML output, the link reference
definition itself is not added to the HTML in any form.  However, now that I was
adding support for all markdown block elements, I found myself in the position of
adding the token in to the parser.&lt;/p&gt;
&lt;p&gt;Adding the token itself was not too difficult. That was accomplished by the usual
process of finding the right method, the &lt;code&gt;__stop_lrd_continuation&lt;/code&gt; method in this case,
creating a new instance of the new &lt;code&gt;LinkReferenceDefinitionMarkdownToken&lt;/code&gt; class in
that function, and properly populating it.  Then the process of adding the support for
the &lt;code&gt;PositionMarker&lt;/code&gt; class kicked in, and quickly I had a case of a wired-up
token with the proper data.&lt;/p&gt;
&lt;p&gt;And then I went to test it… and I noticed that the tests failed in the transformation
of the tokens into HTML.  Looking, I quickly determined that I needed to make
some additional changes to the &lt;code&gt;TransformToGfm&lt;/code&gt; module.  This was a simple change, as
by definition, Link Reference Definitions have no effect on the output.  To accommodate
the new token, a simple handler was registered for that token that simply returns the
same string that was given to the handler.&lt;/p&gt;
&lt;p&gt;And then I went to test it… and the line number and column numbers were incorrect.
In about half of the tests, the pair of numbers seemed to be widely different than I had
manually calculated.  Double checking my numbers, I then noticed a pattern.  The
numbers being reported were for the last line of the Link Reference Definition.
Because of its multiline nature, the values associated with the &lt;code&gt;position_marker&lt;/code&gt;
variable were the ones used when that Link Reference Definition was considered both
valid and complete.  Avoiding the passing of a single use variable around, I added
the starting position to the &lt;code&gt;LinkDefinitionStackToken&lt;/code&gt; instance at the top of the
stack, and things looked better.&lt;/p&gt;
&lt;p&gt;As I looked at the token and its &lt;code&gt;__str__&lt;/code&gt; function output, it looked very lean.  Based
on other tokens, I expected a lot more information to be stored in that token, to be
analyzed later.  Slowly going through the information gathered during the processing
of the token, I ended up figuring out how to properly represent the token.  Between the
various whitespace
sequences between parts of the definition, the various parts of the definition
themselves, and both uninterpreted and interpreted parts, the data called for a
class with 11 member variables.&lt;/p&gt;
&lt;p&gt;Slowly but surely, I started working through each of the Link Reference Definition
scenario tests, starting with the easier  ones and working my way to the more difficult
ones.  It took me a while to work through each scenario and validate it, but I breathed
a sigh of relief when I finished going through
all the tests. In the end, it had taken 2 days to complete, along with countless
executions of the scenario tests.&lt;/p&gt;
&lt;p&gt;It was not until I looked at my notes that I remembered something: I had delayed some
of the cleanup.&lt;/p&gt;
&lt;h2 id="cleaning-up"&gt;Cleaning Up&lt;a class="headerlink" href="#cleaning-up" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Before calling this round of changes done, there was a decent amount of delayed cleanup
to be performed.  As part of Stage 3 of the process, there were quite a few times where
that cleanup was delayed for one reason or another.  As I was about to move on to
another issue, I wanted to make sure that cleanup was performed.&lt;/p&gt;
&lt;p&gt;That cleanup itself was easy, as I had repeated the “change-test-check” process
so many times that I believe I could perform it while sleeping.  Following a variation
of that same process, the code was cleaned up in short order.&lt;/p&gt;
&lt;h2 id="what-was-my-experience-so-far"&gt;What Was My Experience So Far?&lt;a class="headerlink" href="#what-was-my-experience-so-far" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;As I finished the cleanup, I was happy to have the work of adding in the line numbers
and column numbers behind me.  After 10 days of work, it was now a large task
that I knew was not on my task list anymore.  But while I was
happy, I was also concerned about the 20 new issues that I had added to my issues list.
I was aware that at least a few of those items would be checked out and determined to
be false alarms, but that probably left somewhere between 16 to 18 issues to research
and triage.&lt;/p&gt;
&lt;p&gt;On top of that, there was also the fact that each line number/column number
pair for the tokens was determined manually by me.  While I have faith that I can
count accurately for small sets of numbers, I do know that I make mistakes.  Some
of those mistakes I had already caught while going over the test cases before committing
the changes for each of the elements.  But it was entirely possible, and indeed
probable, that I had missed at least 1 or 2 mistakes.  This was not due to lack of
confidence, but due to a sense of reality.  I know that the project has great coverage
and great scenarios, but I also know that I do not have every scenario represented,
just the really important ones.&lt;/p&gt;
&lt;p&gt;That got me thinking.  If I found that many errors, was there a way to remove the need
for me to manually count those values?  Could I automate it?  Would it be worth it?
Would I find anything?&lt;/p&gt;
&lt;p&gt;The more I thought about those questions, the more I realized that I needed to explore
this area.  If nothing else, I wanted to make sure I had not missed anything.  But after
thinking about it for a while, I realized that I did not want to risk that I had missed
anything important.&lt;/p&gt;
&lt;h2 id="what-is-next"&gt;What is Next?&lt;a class="headerlink" href="#what-is-next" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;And here ladies and gentlemen is where I begin to go down the
&lt;a href="https://www.merriam-webster.com/dictionary/rabbit%20hole"&gt;rabbit hole&lt;/a&gt;
.&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr/&gt;
&lt;ol&gt;
&lt;li id="fn:simpleAlg"&gt;
&lt;p&gt;At the current moment, the &lt;code&gt;transform_to_gfm.py&lt;/code&gt; module is approximately 900 lines long.  About 30% of that module is processing overhead, with about 18% dedicated to handling the &lt;em&gt;somewhat complex&lt;/em&gt; issue of list looseness. The remaining 52% is consumed with the simple &lt;code&gt;handle_*&lt;/code&gt; methods used to translate each token’s start and end tokens into HTML.  While the calculation of list looseness does add some complexity to the translation, the algorithm and implementation are both relatively simple. &lt;a class="footnote-backref" href="#fnref:simpleAlg" title="Jump back to footnote 1 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</content><category term="Software Quality"></category><category term="markdown linter"></category><category term="core linter"></category></entry><entry><title>Markdown Linter - Taking Time To Evaluate</title><link href="https://jackdewinter.github.io/2020/06/01/markdown-linter-taking-time-to-evaluate/" rel="alternate"></link><published>2020-06-01T00:00:00-07:00</published><updated>2020-06-01T00:00:00-07:00</updated><author><name>Jack De Winter</name></author><id>tag:jackdewinter.github.io,2020-06-01:/2020/06/01/markdown-linter-taking-time-to-evaluate/</id><summary type="html">
&lt;h2 id="introduction"&gt;Introduction&lt;a class="headerlink" href="#introduction" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;I have been busy at work on the PyMarkdown project since December 2019, November 2019
if you include project pre-planning.  During that time, I have established a very
consistent schedule for planning the next weeks’ worth of work. Normally I start
planning the next article a couple of days …&lt;/p&gt;</summary><content type="html">
&lt;h2 id="introduction"&gt;Introduction&lt;a class="headerlink" href="#introduction" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;I have been busy at work on the PyMarkdown project since December 2019, November 2019
if you include project pre-planning.  During that time, I have established a very
consistent schedule for planning the next weeks’ worth of work. Normally I start
planning the next article a couple of days before I write the rough outline for the
current article, ensuring continuity between the two articles.  This occurs
concurrently with the last couple of days of development work for the week, so I usually
have a very healthy picture of where the project is and where the project is going.&lt;/p&gt;
&lt;p&gt;This week was very different.  For the first time since I started the project, I was
unsure of the right direction to take.  As I stated at the
&lt;a href="https://jackdewinter.github.io/2020/05/25/markdown-linter-rules-headings-part-2/#what-is-next"&gt;end of the previous article&lt;/a&gt;,
I needed to answer one important question: should I write more rules or should I fix
more issues?&lt;/p&gt;
&lt;p&gt;While I did arrive at a final answer, it would eventually take me almost 2 weeks
before I was able to properly answer that question.  In addition to spending some time
to take a good look at the project, I decided to use that time to knock some of the low
priority issues off the technical debt list, hoping to gain some useful insight on
how to answer the question along the way.&lt;/p&gt;
&lt;h2 id="what-is-the-audience-for-this-article"&gt;What Is the Audience for This Article?&lt;a class="headerlink" href="#what-is-the-audience-for-this-article" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;While detailed more eloquently in
&lt;a href="https://jackdewinter.github.io/2020/04/05/what-is-the-audience-for-my-blog/#what-is-the-audience-for-my-blog"&gt;this article&lt;/a&gt;,
my goal for this technical article is to focus on the reasoning behind my solutions,
rather that the solutions themselves.  For a full record of the solutions presented in
this article, please go to this project’s GitHub repository and consult the
commits between
&lt;a href="https://github.com/jackdewinter/pymarkdown/commit/2517d271dc7b79b76683ff5cce7bb573f22fab7a"&gt;15 May 2020&lt;/a&gt; and
&lt;a href="https://github.com/jackdewinter/pymarkdown/commit/1fbcfcb8185fcb8d7dcb6b70adb7309b0225f8da"&gt;08 May 2020&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id="how-did-i-get-here"&gt;How Did I Get Here?&lt;a class="headerlink" href="#how-did-i-get-here" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;I believe that questions such as features versus issues are important questions
for any project maintainers to ask of themselves and their project team.  Even more
important to me is the policy that any such questions and answers regarding a project
must occur with full transparency to team members and other people interested in the
project.  I know I am not the first person to get stuck on an issue like this in their
project, and I will not be the last. Because of that desire for transparency and
openness, I wanted to document how I arrived at an answer, with explanations along the
way to help others with their decisions regarding similar questions. Basically, I
consider everyone reading this article to be an honorary team member.&lt;/p&gt;
&lt;p&gt;As I alluded to in the introduction, most of my articles start off as ideas that I
get while I am working on the project.  When I am trying to figure out the direction
that
I want to go with on the project, I consider both my ability to code and test any
changes along with how I am going to document those changes in an article.  By the
time the end of the “project week” starts to roll around, I have usually started to
transition from having an idea of where I want the project to go, into a plan of what
to do for the project in the next week, and how I will write the article about the
execution of the plan the week after.&lt;/p&gt;
&lt;p&gt;When I get to the last day of the week, three things happen one after the other.
First, I perform a small project retrospective to figure out what parts
of the last week went well, and where I can improve, being as honest with myself as
I can.  Secondly, I scan over my commits and notes from that week and come up with a
good unifying theme for that week’s outline and sketch out a very rough outline for
the future article.  If things went well, that theme matches
the project direction from a week before.  If not, I just adjust as I go.  Finally,
I use both of those pieces of information to compose a plan on what needs to be done
in the next week with respect to the project.&lt;/p&gt;
&lt;p&gt;I have found this process very healthy as it asks three very important questions for
the project. How did you do? What did you do? What do you plan to do?  More
specifically, by asking the questions in that order, my plan for the next week can
be an informed plan, incorporating any “where can I improve” action items into the
next weeks work, while they are still fresh from the retrospective.&lt;/p&gt;
&lt;h2 id="where-did-this-process-fall-apart"&gt;Where Did This Process Fall Apart?&lt;a class="headerlink" href="#where-did-this-process-fall-apart" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;The current issue that I had with this process started when I asked myself the rules
versus issues
question because of one of those retrospectives.  I remember sitting down at my
desk, starting to type out a couple of notes to myself as part of my retrospective.
There were two main
themes that were a part of that retrospective.  What went well was the writing of the
rules and my belief that I had developed the right framework.  What needed improving
was that my confidence in the framework was at a high level, but was it was high enough
for me to continue developing rules?  I did not feel comfortable moving forward
on the project without answering that question. But after a long period of time, I
had not made any progress on answering it.  I silently hoped that moving on to my next
task would help.&lt;/p&gt;
&lt;p&gt;Despite my hope, skipping to creating a rough outline of that week’s work did not help
me to answer that question either.  The prior few weeks had all been about proving that
I had done
enough work on the project that linting rules were both possible and easy to write.  I
sincerely believed that I have succeeded with that goal with room to spare.  Mission
achieved!
But with that important question solidly answered in the positive, it did not help
me move forward on answering the question on whether the project would benefit
more from more rules or less issues.&lt;/p&gt;
&lt;p&gt;I then tried to force the issue by coming up with a plan for the next week, hoping it
would
jar something in my head that would “magically” resolve the issues I had with the
retrospective and outline.  It did not work. I just sat there and paused for a long time
while staring at the screen.  I tried bouncing between the retrospective, the outline,
and the planning, but the results did not change.  I was at a bit of an impasse.
As far as I could figure, the scales seemed equally balanced.  If the questions had to
do with some manner of data-driven metric, it would have been easy for me to come up
with a
&lt;a href="https://en.wikipedia.org/wiki/Go/no_go"&gt;go-no-go&lt;/a&gt;
threshold that I could rely on.  This decision was not going to be data-driven, but
emotion-driven.  That would make the go-no-go decision a lot more difficult to pin
down to an answer that I felt good with.&lt;/p&gt;
&lt;p&gt;After making a good-faith effort to arrive at an answer, I decided to choose neither
answer.
Instead, I decided to do two things.  The first thing was to take a good look at the
code over a few days, hoping to get extra insight as to where I felt the project
was and how to better answer that question.  The second thing was to fix some low-level
issues that I had noticed and wanted to address.  Nothing too earth-shattering, just
some small cleanup issues that never seemed to get picked up in one of the
other refactoring efforts.  I hoped that this two-pronged approach would help me to pick
up some other information that would tip the scales one way or the other.&lt;/p&gt;
&lt;p&gt;In my mind, while it was not much of a plan, it was moving forward.  It was taking a
step forward in the hope of getting more information.  At the very least, the project
would benefit by a few issues being removed from the technical debt list.  That
was level of success criteria for the week that was lower that I was used to, but I
was fine with it.  That is, if I figured out how to properly answer that question!&lt;/p&gt;
&lt;h2 id="taking-time-is-not-taking-it-easy"&gt;Taking Time Is Not Taking It Easy&lt;a class="headerlink" href="#taking-time-is-not-taking-it-easy" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;While it is true that I have written every line of code in the project
so far, I rarely have time to take a step back and see how things all fit together.  To
quote a professor of mine from university:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Sometimes you cannot see the forest because the trees get in the way.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;As I was looking through the code, I was taking notes, mostly questions for myself.
In all honesty, a couple of them were “does this really work?” which I resolved to
answer for myself by the end of the week.  Most of them though were simply me
wondering out loud if there was a better way to do something or whether I could
change something in a function to make it more readable or maintainable.&lt;/p&gt;
&lt;p&gt;In the end, as would befit my university professor, I think I was better able to see
both the forest and the trees after those couple of days.  But while I had hoped that
it would nudge me one way or the other in answering my main question, I remained
at an impasse.  I was able to answer all the questions I had asked myself as I was
looking
through the code, but none of those answers signified that I had done something wrong.
They only suggested small improvements on how I wrote the code.  By no means were any
of those answers better enough to tip the scales.&lt;/p&gt;
&lt;h2 id="fixing-issues"&gt;Fixing Issues&lt;a class="headerlink" href="#fixing-issues" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;With one of my two paths not providing any information to sway the answer either way,
it was time to switch to the second path: fixing issues.&lt;/p&gt;
&lt;h3 id="better-logging-command-line-support"&gt;Better Logging Command Line Support&lt;a class="headerlink" href="#better-logging-command-line-support" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;One of the first things on my “never got around to it”&lt;sup id="fnref:roundTuit"&gt;&lt;a class="footnote-ref" href="#fn:roundTuit"&gt;1&lt;/a&gt;&lt;/sup&gt; list was to make sure
that PyMarkdown has proper command line logging support.  This level of logging
support was already available through the test framework but adding that same support
to the command line support seemed to always get pushed off.  It was time to change
that.&lt;/p&gt;
&lt;p&gt;Adding that support was extremely simple, especially since I have added support like
this to many command line programs.  From experience, the two parts to adding this
feature are adding the ability to control the default log level and adding the ability
to redirect any logs that are produced to a file.&lt;/p&gt;
&lt;p&gt;The actual core code to implement this feature was just 7 lines long, with the
interpretation of the command line arguments being the bulk of this change.  The
existing interpretation code, to handle command line argument parsing through the
&lt;code&gt;argparse&lt;/code&gt; library, was changed to include support for the
&lt;code&gt;--log-level&lt;/code&gt; and &lt;code&gt;--log-file&lt;/code&gt; options, including a default setting of &lt;code&gt;CRITICAL&lt;/code&gt; for
the log level.  To round out these changes, the &lt;code&gt;log_level_type&lt;/code&gt; function was added to
verify that any specified log level is a valid log level.&lt;/p&gt;
&lt;p&gt;Those 7 core lines to add the logging itself may change from language to language, but
they almost always are simple modifications of a common pattern.  The first part of
that pattern is dealing with
writing to the console.  As many logging frameworks will do this by default, the
customization here is to ensure that the desired logging level is applied to the
console log handler.  The second
part of that pattern is to add support for logging to a log file, usually requiring 2
to 3 discrete actions to customize the file logging to the proper settings for the
application.  As these are the two most frequently used logging modes
for command line programs, most languages include good solid templates on how to add
this for that specific language.&lt;/p&gt;
&lt;p&gt;The fun part for me is always in making sure that a change like this is tested properly,
and this was not an exception.  As this is a new set of command line options, existing
tests that listed existing command line options were updated.  Additional tests were
added to &lt;code&gt;test_main.py&lt;/code&gt; to specifically test the new options, including tests
specifically around specifying invalid options.&lt;/p&gt;
&lt;p&gt;I am not sure if it felt good to have this issue taken care of as much as I felt like
I should have got to this one before that moment.  Being such of a core fixture
in other command line applications I have written, I just felt like this should have
been addressed a lot sooner.  Still, it was good to get it out of the way.&lt;/p&gt;
&lt;h3 id="better-logging-support"&gt;Better Logging Support&lt;a class="headerlink" href="#better-logging-support" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;This change was a small-ish change, but it was one that I was overdue to explore.  Back
at the start of May, in my article on
&lt;a href="https://jackdewinter.github.io/2020/05/04/markdown-linter-core-pre-rule-improvements/#side-note"&gt;pre-rule improvements&lt;/a&gt;
I noted that while I might be able to get away with a single static logger variable
at the top of my modules, I had not seen any good documentation on the “right” way
to do it.  When I looked at various examples, such as
&lt;a href="https://pythonspot.com/logging/"&gt;this example&lt;/a&gt;
at Python Spot, the examples seemed to always show logging within a single module
application, and not within a multiple module application like PyMarkdown. As such,
I decided to add localized &lt;code&gt;logger&lt;/code&gt; variables until I could do some
research and figure out the proper way to add logging to each module.&lt;/p&gt;
&lt;p&gt;It was not until I got the time to do more thorough research that I was able to find a
good example of how to log with multiple modules.  While the
&lt;a href="https://docs.python.org/3/howto/logging.html"&gt;Python logging docs&lt;/a&gt;
has a good section on “Logging from multiple modules”, it was actually the section
titled
&lt;a href="https://docs.python.org/3/howto/logging.html#advanced-logging-tutorial"&gt;Advanced Logging Tutorial&lt;/a&gt;
that gave me the information I was looking for.  While not an example, the guidance that
is given near the top of this section is quite clear:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;A good convention to use when naming loggers is to use a module-level logger, in each module which uses logging, named as follows:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;Python
logger = logging.getLogger(__name__)&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;This means that logger names track the package/module hierarchy, and it’s intuitively obvious where events are logged just from the logger name.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Yes!  After searching for some clear guidance for weeks on this, I finally found
something that was both authoritative and definitive.  Even more, the last sentence
contained a good, solid explanation of why this process should be followed.&lt;/p&gt;
&lt;p&gt;In the grand scheme of things, this change took very little time.  Instead of having a
logger instance declared as &lt;code&gt;logger&lt;/code&gt; within various classes and static methods, a new
instance &lt;code&gt;LOGGER&lt;/code&gt; was created at the top of each file per the instructions quoted above.
The change from &lt;code&gt;logger&lt;/code&gt; to &lt;code&gt;LOGGER&lt;/code&gt; was a simple search-and-replace tasks for each
file, quickly accomplished.  The hard part here was removing any &lt;code&gt;logger&lt;/code&gt; arguments
that were being passed into functions in favor of the &lt;code&gt;LOGGER&lt;/code&gt; instance declared at the
top of the file. Testing was also simple, as all I had to do was execute all of the
tests again, and make sure I did not miss anything.&lt;/p&gt;
&lt;p&gt;It felt good to get this one off the issues list and committed to the repository.
If I had to guess, I think this one never made it into any of my refactoring lists
because things were
working okay, with no loss functionality in PyMarkdown because of it.  At the
same time, there was this persistent nagging when looking at the issues list that I
really need to figure out the “right” way to do this… and now I know what that is.&lt;/p&gt;
&lt;p&gt;But did this help me figure out the answer to my question? Nope.  Taking some time
to go back and look at my half-written notes, I was still at that same impasse.
Nothing had changed.  Hopefully, that would soon change.&lt;/p&gt;
&lt;h3 id="adjusting-the-parsing-of-whitespace-in-setext-tokens"&gt;Adjusting the Parsing of Whitespace in SetExt Tokens&lt;a class="headerlink" href="#adjusting-the-parsing-of-whitespace-in-setext-tokens" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Like the other issues that I addressed at this time, the effort to address
this issue was small. Found during the development of
&lt;a href="rule-3.md#rule-md023-headings-must-start-at-the-beginning-of-the-line"&gt;rule MD023&lt;/a&gt;,
this was a rare case where I felt that code added to a rule could
have been positioned better in the core framework.  While the added code in the rule was
only a small amount of code, it was a case where I knew a better way of handling this
whitespace was possible, as it was already being done for the related Paragraph token.&lt;/p&gt;
&lt;p&gt;The two tokens that the SetExt heading token is related to are the Atx heading token
and the Paragraph token.  The SetExt heading token is related to the Atx heading token
in that they are both heading tokens.  The SetExt heading token is related to the
Paragraph token as a SetExt
token is created by changing an eligible Paragraph token with SetExt markings after it
into a SetExt token.  As such, when I wrote the code for rule MD023, I was surprised
that the logic for detecting whitespace at the start of a Paragraph token was trivial
but the similar logic for a SetExt token was more involved.&lt;/p&gt;
&lt;p&gt;Digging into why those tokens were handled differently, I quickly determined that it
was only a couple of small changes that separated the handling of those two tokens.
Addressing these differences required a few simple changes during the coalesce
phase and the
inline processing phase, both ensuring that the processing afforded to Paragraph tokens
was also being applied to its kindred SetExt tokens.  That was immediately followed up
by adding a
couple of tests to make sure this change stuck, and then by a change to rule MD023 to
make use of a more trivial calculation of leading whitespace.&lt;/p&gt;
&lt;p&gt;Looking back at my notes while I am writing this article, I believe this was the start
of me mentally tipping the scales towards spending time working on the issues.  While
this was not a big change, I believe that it represented a larger set of smaller things
that I wanted to get right before moving on.  I believe the change that was occurring
was a subtle change in how I was weighing the various categories of issues.&lt;/p&gt;
&lt;p&gt;That weighing was starting to put more emphasis on fixing issues, specifically issues
with the parser.  The previous two issues that were addressed, both dealing with
logging, did not seem to affect my decision at all.  This issue, dealing with the
parser, moved the weighing enough that I noticed it.  While it was only barely
noticeable at this point, that feeling was going to get stronger as I addressed
the next issue.&lt;/p&gt;
&lt;h3 id="properly-grouping-hard-line-break-whitespace"&gt;Properly Grouping Hard Line Break Whitespace&lt;a class="headerlink" href="#properly-grouping-hard-line-break-whitespace" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;One of the things that I noticed when fixing the previous issue was that where
hard line breaks were concerned, they did not have any leading whitespace embedded
within them.  It was not a big issue. If I was not looking at the test cases
for the previous issue, I would not have seen this issue.  It was just silently
waiting to be discovered.&lt;/p&gt;
&lt;p&gt;It may seem like a small thing, but I have a “rule” that any whitespace before any
non-text token goes with the token that follows it.  Just before I started
writing rules, I noticed that many of the tokens were following this rule, so
I decided to apply this pattern as a blanket rule over  all the tokens.  The benefit
to this approach is that I have a consistent expectation of where the leading
whitespace will be placed after it is extracted.  That benefit allows me to write
better, more consistent rules where I always know where to look for that whitespace.&lt;/p&gt;
&lt;p&gt;The fix for this issue was almost trivial.  For the most part, it was adding another
parameter to the &lt;code&gt;HeadBreakMarkdownToken&lt;/code&gt; constructor, passing it either the
line continuation character &lt;code&gt;\&lt;/code&gt; or the leading whitespace that caused the hard line
break to occur.  A bit of cleaning up with the resultant variables, and it was done.
But as with the previous issue, I could feel the weighing of my priorities changing.
This was another small thing, so small that it went undetected until I chanced upon
it.  But the thing was, it started me thinking: If I was able to find this issue, what
other issues were lurking in the parser, waiting to be discovered?&lt;/p&gt;
&lt;h3 id="consistently-using-the-word-heading"&gt;Consistently Using the Word “Heading”&lt;a class="headerlink" href="#consistently-using-the-word-heading" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;While I was very aware that this was a non-code related task, I felt that it was a good
time to get it out of the way.  During my documentation of
&lt;a href="https://jackdewinter.github.io/2020/05/11/markdown-linter-rules-the-first-three/#a-quick-aside"&gt;the first three rules&lt;/a&gt;,
I decided to choose “heading” of “header” for the reasons outlined in
that article.  However, even though I had made that change in my articles&lt;sup id="fnref:notThat"&gt;&lt;a class="footnote-ref" href="#fn:notThat"&gt;2&lt;/a&gt;&lt;/sup&gt;,
I had not
made the accompanying changes in the PyMarkdown source.&lt;/p&gt;
&lt;p&gt;This was a quick search-and-replace, followed by running of tests to make sure things
were good.  Experiencing no bumps and no typos, everything went fine.  While purely
cosmetic, it felt good to make sure that the blog and the source code were in sync
with each other.  Making sure they were in sync just felt good.&lt;/p&gt;
&lt;h3 id="removing-setextheadingendmarkdowntoken"&gt;Removing &lt;code&gt;SetExtHeadingEndMarkdownToken&lt;/code&gt;&lt;a class="headerlink" href="#removing-setextheadingendmarkdowntoken" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;I have long since got rid of the notes I used during the early days of writing the
parser for PyMarkdown, so any attempt at figuring out why I added this class near the
start of the project on 29 January 2020 is probably going to fail.  My best guess, based
on what I can see in the GitHub repository, is that perhaps I believed that having a
specific end token for each start token type was the way to go.  Regardless, since that
time I have adopted an approach with a single &lt;code&gt;EndMarkdownToken&lt;/code&gt; that refers to its
starting &lt;code&gt;MarkdownToken&lt;/code&gt; by name.  This approach has proven to be quite practical as
most of the operations that rely on &lt;code&gt;EndMarkdownToken&lt;/code&gt; instances do not need any
contextual information except for the starting tokens’s name.  As such, the
practicality of having a specific
&lt;code&gt;EndMarkdownToken&lt;/code&gt; instance that matches each start Markdown token feels overpowered to
me, with little benefits to show for the added complexity.&lt;/p&gt;
&lt;p&gt;Removing this token was easy.  The class was removed from the &lt;code&gt;markdown_token.py&lt;/code&gt; module
and the &lt;code&gt;leaf_block_processor.py&lt;/code&gt; module was changed to add an &lt;code&gt;EndMarkdownToken&lt;/code&gt;
instance for the related SetExt heading.  The rest of the changes in the commit for this
change were holdovers from the previous changes, where I had forgot to do a
clean build and record the changes.&lt;/p&gt;
&lt;p&gt;This change was cosmetic, but like other issues detailed in this article, it changed
the weighing of the issues even more.  Once again, the change was not a dramatic one,
but it was enough that at this point, it was noticeable.&lt;/p&gt;
&lt;h2 id="what-was-my-choice"&gt;What Was My Choice?&lt;a class="headerlink" href="#what-was-my-choice" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Having addressed a good handful of small issues that did not make the big lists for
refactorings, the balance between the two scales had shifted enough that I knew that
I had a good solid answer: fix more issues.  I did not feel that I would be wrong in
adding more rules, just that I wanted to focus on ensuring that a number of the smaller
issues were given some focus to ensure they were resolved properly.  It also did not
feel like I had lost any confidence in writing rules, that was still at a healthy level.&lt;/p&gt;
&lt;p&gt;In the end, I believe it came down to a solid understanding that if I was going to
write more rules with this framework, I wanted to make sure that any obvious issues
were dealt with.  The largest of those issues that needed to be addressed was adding
the proper line number and column number support to the tokens.  But it also meant
working through the issues that I found during the first 12 rules and either verifying
they are issues and addressing them or explaining why they were okay.&lt;/p&gt;
&lt;h2 id="what-was-my-experience-so-far"&gt;What Was My Experience So Far?&lt;a class="headerlink" href="#what-was-my-experience-so-far" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;I strongly believe that the process of taking my time and working through those low
priority issues gave me some valuable insight into the project that I had missed
before.  While the primary catalyst for being able to properly answer the question
were the parser issues that I resolved, I do not discount the insights provided by
looking at the source code at a higher level than usual.  I believe that by allowing
myself time to absorb the project code at a higher level, it opened some doors in my
mind that allowed me to be better influenced by the issues I fixed.  I cannot prove
that of course, but as with all feelings, it just is.&lt;/p&gt;
&lt;p&gt;And while it was initially irritating that I could not answer the features versus
issues question, I now believe it was inevitable.  Especially since I am the only
one working on this project, I do not have anyone to remind me to stop looking at
the trees and focus on the forest.  That change in perspective really helped me to
get a clearer picture, and for that reminder, I am grateful.&lt;/p&gt;
&lt;p&gt;One thing that I did not expect was that the answering of this question taking almost
2 weeks.  I started the planning for this block of work on 02 May and it was 16 May
before I had the planning in place for the next block of work.  The thing is, at no
time during the process did I want to
&lt;a href="https://en.wikipedia.org/wiki/Timeboxing"&gt;timebox&lt;/a&gt;
this process.  It took 2 weeks because that is what I needed to properly answer this
question.  And I was fine with that.&lt;/p&gt;
&lt;p&gt;For the large part, I am also okay with spending some time making sure I get the
parser right before moving on to authoring more rules.  Sure, it means I am extending
the development cycle out by at least a couple of weeks, but I think that the time
will be well spent.&lt;/p&gt;
&lt;h2 id="what-is-next"&gt;What is Next?&lt;a class="headerlink" href="#what-is-next" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Having answered the question of rules vs foundation, it was time to tackle one of the
big issues that I had listed: line numbers and column numbers.  I knew this was not
going to be an easy change, but that just told me I should make sure I do it right the
first time!&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr/&gt;
&lt;ol&gt;
&lt;li id="fn:roundTuit"&gt;
&lt;p&gt;Not &lt;a href="https://www.bing.com/search?q=round+tuit"&gt;one of these&lt;/a&gt; which was actually given to me by my family one time. &lt;a class="footnote-backref" href="#fnref:roundTuit" title="Jump back to footnote 1 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:notThat"&gt;
&lt;p&gt;I rarely go back and change anything in previous articles, except for bad grammar.  Since I wrote that article, I have endeavored to be consistent in my use of “heading” over “header”. &lt;a class="footnote-backref" href="#fnref:notThat" title="Jump back to footnote 2 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</content><category term="Software Quality"></category><category term="markdown linter"></category><category term="core linter"></category></entry><entry><title>Markdown Linter - Rules - Headings - Part 2</title><link href="https://jackdewinter.github.io/2020/05/25/markdown-linter-rules-headings-part-2/" rel="alternate"></link><published>2020-05-25T00:00:00-07:00</published><updated>2020-05-25T00:00:00-07:00</updated><author><name>Jack De Winter</name></author><id>tag:jackdewinter.github.io,2020-05-25:/2020/05/25/markdown-linter-rules-headings-part-2/</id><summary type="html">
&lt;h2 id="introduction"&gt;Introduction&lt;a class="headerlink" href="#introduction" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;For any readers that have been waiting with bated breath since last week when I posted
my article titled “Markdown Linter - Rules - Headings - Part 1”, I will now break the
suspense.  This week’s article is titled… drum roll please…&lt;/p&gt;
&lt;p&gt;“Markdown Linter - Rules - Headings - Part 2”.&lt;/p&gt;
&lt;p&gt;Yeah, I know …&lt;/p&gt;</summary><content type="html">
&lt;h2 id="introduction"&gt;Introduction&lt;a class="headerlink" href="#introduction" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;For any readers that have been waiting with bated breath since last week when I posted
my article titled “Markdown Linter - Rules - Headings - Part 1”, I will now break the
suspense.  This week’s article is titled… drum roll please…&lt;/p&gt;
&lt;p&gt;“Markdown Linter - Rules - Headings - Part 2”.&lt;/p&gt;
&lt;p&gt;Yeah, I know, the title is terribly unoriginal, but like the previous article, there is
nothing special about this article except that it details the second group of
heading rules that I am creating.&lt;/p&gt;
&lt;p&gt;With this group of rules completed, except for the two rules mentioned in
&lt;a href="https://jackdewinter.github.io/2020/05/18/markdown-linter-rules-headings-part-1/#what-about-those-two-rules-that-were-left-out"&gt;the previous article&lt;/a&gt;,
every rule in the initial heading rules group will be completed.  Even though I know
these rules will not be the last group of rules that I write, the writing of these
rules serves an important purpose.  The process of writing these rules will help to
paint a reliable picture of the stability of the project at this point.  This picture
will then allow me to determine whether writing more rules or fixing some issues is the
best course of action for the project.&lt;/p&gt;
&lt;p&gt;To be clear, I am not pro-rules nor am I pro-issues, I am pro-project.  If the
picture that emerges gives me a level of confidence with which to write more rules, so
be it.  If that level of confidence is not achieved, then I will address any issues
that I feel are getting in the way of me being able to add more rules with confidence.
Basically, the tests and the issues provide me data, and I will interpret that data to
determine the proper next step.  Simple.&lt;/p&gt;
&lt;h2 id="what-is-the-audience-for-this-article"&gt;What Is the Audience for This Article?&lt;a class="headerlink" href="#what-is-the-audience-for-this-article" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;While detailed more eloquently in
&lt;a href="https://jackdewinter.github.io/2020/04/05/what-is-the-audience-for-my-blog/#what-is-the-audience-for-my-blog"&gt;this article&lt;/a&gt;,
my goal for this technical article is to focus on the reasoning behind my solutions,
rather that the solutions themselves.  For a full record of the solutions presented in
this article, please go to this project’s GitHub repository and consult the
commits between
&lt;a href="https://github.com/jackdewinter/pymarkdown/commit/006eed187e212bb2c425ebebe1202193be327708"&gt;28 April 2020&lt;/a&gt; and
&lt;a href="https://github.com/jackdewinter/pymarkdown/commit/816a1fb5fcf07c765ee3858e5d9292129800478c"&gt;02 May 2020&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id="dealing-with-an-omission"&gt;Dealing with An Omission&lt;a class="headerlink" href="#dealing-with-an-omission" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;As I started to write this article, I went over the 15 different rules that I know
contain headings: 3 in the
&lt;a href="https://jackdewinter.github.io/2020/05/11/markdown-linter-rules-the-first-three/"&gt;“First Three” article&lt;/a&gt;,
5 in
&lt;a href="https://jackdewinter.github.io/2020/05/18/markdown-linter-rules-headings-part-1/"&gt;the last article&lt;/a&gt;,
2 rules
&lt;a href="https://jackdewinter.github.io/2020/05/18/markdown-linter-rules-headings-part-1/#what-about-those-two-rules-that-were-left-out"&gt;to skip&lt;/a&gt;,
and 4 rules in this article.  Huh?  I double checked my numbers, and as far as my math
is concerned, 3 + 5 + 2 + 4 = 14.  Where did the missing rule go?&lt;/p&gt;
&lt;p&gt;At the end of implementing the last rule group, I determined that the development of
&lt;a href="https://github.com/DavidAnson/markdownlint/blob/master/doc/Rules.md#md025---multiple-top-level-headings-in-the-same-document"&gt;rule MD025&lt;/a&gt;
needed to be put on hold, for the same reasons as
&lt;a href="https://github.com/DavidAnson/markdownlint/blob/master/doc/Rules.md#md041---first-line-in-file-should-be-a-top-level-heading"&gt;rule MD041&lt;/a&gt;:
YAML front matter.  Rule MD025 exists to make sure that there is one and only one
top-level heading present in each document. The description for rule MD041 allows that
top-level heading to be specified in the metadata for the file, and the plan for rule
MD025 is to follow that same pattern.  As rule MD041 was put on hold until that
metadata support is added, it only makes sense that rule MD025 is also put on hold
pending the addition of that same metadata support.&lt;/p&gt;
&lt;h2 id="and-now-more-rules"&gt;And Now, More Rules&lt;a class="headerlink" href="#and-now-more-rules" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;With this group of 4 rules, the total number of implemented heading rules will
be 12.  I believe that is a good sampling of rules with which to decide whether to
fix more issues or create new rules.  To that extent, let’s go!&lt;/p&gt;
&lt;h2 id="rule-md023-headings-must-start-at-the-beginning-of-the-line"&gt;Rule MD023 - Headings must start at the beginning of the line&lt;a class="headerlink" href="#rule-md023-headings-must-start-at-the-beginning-of-the-line" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;This section describes the initial implementation of PyMarkdown’s
&lt;a href="https://github.com/jackdewinter/pymarkdown/blob/master/pymarkdown/plugins/rule_md_023.py"&gt;Rule MD023&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id="why-does-this-rule-make-sense"&gt;Why Does This Rule Make Sense?&lt;a class="headerlink" href="#why-does-this-rule-make-sense" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;For this rule, the first answer that popped into my mind was the usual answer:
consistency. According to the GFM specification, there is no syntactic difference
between:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;#&lt;/span&gt; &lt;span class="n"&gt;Heading&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;and&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;   &lt;span class="o"&gt;#&lt;/span&gt; &lt;span class="n"&gt;Heading&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;As they are equivalent, just like with previous rules, it makes sense to use the simpler
form of the heading to keep things consistent.&lt;/p&gt;
&lt;p&gt;However, on a more thorough examination, a better purpose for this rule is
compatibility.  While I recognize that the initial parser features and tests are based
on the
&lt;a href="https://github.github.com/gfm/"&gt;GFM specification&lt;/a&gt;,
knowing where other parsers diverge from that specification allows me to start thinking
about future “tunings” for the project.  I do not know how possible it is, but I am
wondering if I can tune PyMarkdown’s output based on a profile set up for a given
Markdown parser being used.  While this is still in the “far-future thinking” stage,
one of the pieces of data I need to understand for that endeavor is how far from my
chosen base specification are the specifications for those other parsers.&lt;/p&gt;
&lt;p&gt;To get an idea of how compatible a normal Atx heading is across parsers, I submitted
the text &lt;code&gt;# Heading 1&lt;/code&gt; to
&lt;a href="https://johnmacfarlane.net/babelmark2/?text=%23+Heading+1%0A%0A"&gt;Babelmark&lt;/a&gt;&lt;sup id="fnref:Babelmark"&gt;&lt;a class="footnote-ref" href="#fn:Babelmark"&gt;1&lt;/a&gt;&lt;/sup&gt;.
Except for the presence of an &lt;code&gt;id&lt;/code&gt; attribute in the &lt;code&gt;h1&lt;/code&gt; tag (and that
attribute’s value varying only slightly), the results were the same across all the
parsers,
indicating wide compatibility. When I added 2 spaces at the start of the text and
submitted that text to
&lt;a href="https://johnmacfarlane.net/babelmark2/?text=++%23+Heading+1%0A%0A"&gt;Babelmark&lt;/a&gt;,
only 12 out of the 31 available parsers interpreted the line as an Atx heading.  With
only 39% of the parsers at Babelmark recognizing the changed text as an Atx heading,
it was far from being widely compatible.&lt;/p&gt;
&lt;p&gt;Based on those results, for the sake of compatibility, it made sense to create a rule
to recommend the removal of
any whitespace at the start of an Atx heading line.  While a standard GFM
Markdown parser will treat it properly, with less than half of the sampled parsers
handling it properly, it just made sense to avoid that extra
whitespace.  If PyMarkdown tuning is a feature that I add in the future, I can always
revisit this rule and make it aware of the added tuning.  As that feature is currently
only a maybe, a current, solid rule for headings means no spaces at the start of
heading lines.&lt;/p&gt;
&lt;h3 id="adding-the-rule"&gt;Adding the Rule&lt;a class="headerlink" href="#adding-the-rule" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Adding the code to implement this rule was trivial.  The rule simply looks at the
&lt;code&gt;extracted_whitespace&lt;/code&gt; field of the Atx heading token where the captured whitespace
from before the start of the Atx heading is stored.  If the value of
&lt;code&gt;extracted_whitespace&lt;/code&gt; is not empty, whitespace is present, and the rule fails.&lt;/p&gt;
&lt;p&gt;Using the process from the previous section to test Markdown samples with multiple
parsers, I then tested variations of SetExt headings like:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;My&lt;/span&gt; &lt;span class="n"&gt;heading&lt;/span&gt;
&lt;span class="c1"&gt;----------&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;where there was extra spacing at the start of the first line, the second line, or both
lines.  In each of those cases, the results showed that there was at least one parser
that did not recognize it as a proper SetExt heading.  If I want a linter that can
be useful for a wide variety of parsers, the failure of one parser to recognize
the above text as a SetExt heading is still somewhat of a failure.&lt;/p&gt;
&lt;p&gt;To deal with whitespace before SetExt headings, only a small amount of extra parsing
was required above what was added for the Atx headings.  When the SetExt token is
observed, that token is stored in the
&lt;code&gt;setext_start_token&lt;/code&gt; variable, with the storing of the presence of any leading
whitespace in the &lt;code&gt;any_leading_whitespace_detected&lt;/code&gt; variable.  As Text tokens are
observed, if the
&lt;code&gt;any_leading_whitespace_detected&lt;/code&gt; variable has not already been set, a simple
decomposition of the text is performed to look for leading whitespace on each line, the
&lt;code&gt;any_leading_whitespace_detected&lt;/code&gt; variable being set to &lt;code&gt;True&lt;/code&gt; if any whitespace is
found.  Finally, when the SetExt’s end token is observed, one final check is made
against the end token for whitespace.  When that is complete, if any whitespace was
detected in any of these three phases, the rule fails with the value stored in the
&lt;code&gt;setext_start_token&lt;/code&gt; variable being used as the failure token.&lt;/p&gt;
&lt;p&gt;The code for implementing this rule, the tests, and test data were all trivial.  Once I
understood the constraints that I needed for the rule, it was easy to
translate those constraints into test data and source code.  Perhaps I am a bit jaded
in my viewpoint, but after implementing 8 other rules for headings, adding this rule
was just easy.&lt;/p&gt;
&lt;p&gt;The real interesting part about implementing this rule was using Babelmark and looking
at the output from the various parsers.  Seeing the different HTML variations that
arose from the different interpretations of a single Markdown element made it clearer to
me why the GFM specification was written.  If there is not a single, clear picture of
how parsers translate Markdown into HTML, the authors start to get confused, tailoring
their use of Markdown to a specific parser and its output. Seeing that Babelmark output
just really drove that point home for me.&lt;/p&gt;
&lt;h2 id="rule-md024-multiple-headings-with-the-same-content"&gt;Rule MD024 - Multiple headings with the same content&lt;a class="headerlink" href="#rule-md024-multiple-headings-with-the-same-content" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;This section describes the initial implementation of PyMarkdown’s
&lt;a href="https://github.com/jackdewinter/pymarkdown/blob/master/pymarkdown/plugins/rule_md_024.py"&gt;Rule MD024&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id="why-does-this-rule-make-sense_1"&gt;Why Does This Rule Make Sense?&lt;a class="headerlink" href="#why-does-this-rule-make-sense_1" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;If the parser is following the GFM specification exactly or is a bare bones parser,
this rule does not make any sense.  When presented with Markdown such as:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;## &lt;span class="k"&gt;Next&lt;/span&gt; &lt;span class="nv"&gt;Heading&lt;/span&gt;

&lt;span class="nv"&gt;some&lt;/span&gt; &lt;span class="nv"&gt;text&lt;/span&gt;

## &lt;span class="k"&gt;Next&lt;/span&gt; &lt;span class="nv"&gt;Heading&lt;/span&gt;

&lt;span class="nv"&gt;some&lt;/span&gt; &lt;span class="nv"&gt;text&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;the parser will generate HTML that is close to the following:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;h2&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;Next Heading&lt;span class="p"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;h2&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
&lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;p&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;some text&lt;span class="p"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;p&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
&lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;h2&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;Next Heading&lt;span class="p"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;h2&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
&lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;p&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;some text&lt;span class="p"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;p&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;However, either through its own configuration or through a plugin, most Markdown
parsers allow for a
mode in which some transformation of the heading text is added to the &lt;code&gt;&amp;lt;h2&amp;gt;&lt;/code&gt; tag,
usually in an &lt;code&gt;id&lt;/code&gt; attribute.  Some parsers go
further than that, providing an anchor point allowing the reader to navigate directly
to the heading by using a full URL with the contents of the &lt;code&gt;href&lt;/code&gt; attribute after the
normal part of the URL.&lt;/p&gt;
&lt;p&gt;Once such example is this HTML, which was rendered by one of the parsers for the
first heading in the previous sample:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;h2&lt;/span&gt; &lt;span class="na"&gt;id&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;"h2-next-heading"&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
&lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;a&lt;/span&gt; &lt;span class="na"&gt;id&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;"user-content-next-heading"&lt;/span&gt; &lt;span class="na"&gt;class&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;"anchor"&lt;/span&gt; &lt;span class="na"&gt;href&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;"#next-heading"&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
Next Heading
&lt;span class="p"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;a&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
&lt;span class="p"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;h2&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This kind of generated HTML output is popular for two main reasons.  First, various
combinations
of the heading tag’s &lt;code&gt;id&lt;/code&gt; attribute, the anchor tag’s class, and the anchor tag’s &lt;code&gt;id&lt;/code&gt;
attribute allow for stylesheets to be applied to the generated page in a clean and
unambiguous manner.
Secondly,
assuming that the normal URL to the page is &lt;code&gt;https://www.website.com/that-page.html&lt;/code&gt;,
since the &lt;code&gt;href&lt;/code&gt; attribute for the anchor tag is specified as &lt;code&gt;#next-heading&lt;/code&gt;, the
reader can go directly to that section on the page by using the URL
&lt;code&gt;https://www.website.com/that-page.html#next-heading&lt;/code&gt;.  This concept is so useful that
multiple “Table of Contents” plugins that I looked at required another plugin to
already be enabled that provides this information that is the repurposed by the Table
of Contents plugin.&lt;/p&gt;
&lt;p&gt;Specifically related to this rule, the part that I want to focus on is the generation
of the &lt;code&gt;id&lt;/code&gt; attributes and the
&lt;code&gt;href&lt;/code&gt; attribute.  If a naïve generator implementation is used, the heading text
&lt;code&gt;Next Heading&lt;/code&gt; will always be reduced to some form of the text &lt;code&gt;next-heading&lt;/code&gt;, without
any regard for duplicates.  When a more advanced implementation is used, the plugin
remembers that it has already generated the text &lt;code&gt;next-heading&lt;/code&gt; for the current
document.  To avoid any duplication, when the parser goes to generate another instance
of a heading &lt;code&gt;id&lt;/code&gt; based on the text &lt;code&gt;Next Heading&lt;/code&gt;, it generates it as normal but also
appends a suffix to the generated text, usually something like &lt;code&gt;-1&lt;/code&gt; to keep the
generated ids unique.&lt;/p&gt;
&lt;p&gt;Because Markdown parsers are not guaranteed to perform the proper, advanced generator
implementation, this rule plays it safe by failing when it detects heading text that is
duplicated.  However, to provide further configuration for more compliant parsers,
this rule
can also be set to only fail the rule in cases where sibling heading elements have
the same name.  While it is not stated, my guess is that some parsers include extra
information in their generated ids that only causes duplication issues when sibling
headings have the same text.&lt;/p&gt;
&lt;h3 id="adding-the-rule_1"&gt;Adding the Rule&lt;a class="headerlink" href="#adding-the-rule_1" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Using the default configuration, the evaluation for this rule is
very simple.  When an Atx heading token or a SetExt heading token is observed, the
rule starts collecting the text until it encounters the appropriate end token.  At
that point, one of two things happen.  If this is the first time that text has been
seen, it is saved in a dictionary that is cleared at the start of each document.  If it
is not the first time that the text has been seen, the rule fails.  Simple and clear
cut.&lt;/p&gt;
&lt;p&gt;If this rule’s configuration is changed to only search for duplicates in siblings,
a small amount of a change is required in the algorithm, but not much.  The first
change is that each of the 6 levels of headings must have its own dictionary. Instead
of looking up the collected text in a single dictionary, the text is looked for in the
dictionary assigned to its heading level.  Basically, if a heading is a level
2 heading, then it needs to verify against the level 2 heading dictionary, and so on.
As the heading level that determines which dictionary to use is an integer, it made
sense to create an
array that contains 6 dictionaries, one for each heading level and initialized to an
empty dictionary for each new document.&lt;/p&gt;
&lt;p&gt;With those changes in place, a bit of working through multiple scenarios provided the
rest of the answers. For the increasing heading level case, consider the general case
of:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;##&lt;/span&gt; &lt;span class="k"&gt;Level&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;
&lt;span class="o"&gt;###&lt;/span&gt; &lt;span class="k"&gt;Level&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;While it is appropriate to only increase the heading level by 1, hence the creation of
&lt;a href="https://jackdewinter.github.io/2020/05/11/markdown-linter-rules-the-first-three/#rule-md001-incrementing-heading-levels"&gt;rule MD001&lt;/a&gt;,
the general case for this rule applies to any increase in heading levels.  When
going to the new heading level, the level’s dictionary must be cleared to ensure that
any previous headings do not pollute the rule’s sense of duplication.  If multiple
levels are involved, it makes logical  sense to clear all the dictionaries up to and
including the new heading level.&lt;/p&gt;
&lt;p&gt;The other case to consider is where the heading levels decrease, such as with:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;###&lt;/span&gt; &lt;span class="k"&gt;Level&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;
&lt;span class="o"&gt;##&lt;/span&gt; &lt;span class="k"&gt;Level&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Once again, the general case for this applies to any decrease in heading levels.  As
the new &lt;code&gt;Level 2&lt;/code&gt; heading is separated from any previous level 2 headings by the
&lt;code&gt;### Level 3&lt;/code&gt; heading, those headings are no longer considered siblings.  As such,
when moving to the lower levels, the dictionaries must be cleared down to and including
the new heading level.&lt;/p&gt;
&lt;p&gt;Other than figuring out the logic for this rule, and taking a while to do it, the rest
of the coding for this rule went smoothly.  While the new algorithm based on that logic
took longer to figure out than I hoped it would, it was useful to be able to have the
test data and test cases on hand from VSCode’s output.  Taking the information from
the &lt;code&gt;Problems&lt;/code&gt; window of that editor saved a lot of time when coded into my tests for
this rule.  I did have a couple of false starts but knowing that the algorithm passed
the tests using the VSCode derived test data really increased my confidence that I got
the algorithm right.&lt;/p&gt;
&lt;h2 id="rule-md026-trailing-punctuation-in-heading"&gt;Rule MD026 - Trailing punctuation in heading&lt;a class="headerlink" href="#rule-md026-trailing-punctuation-in-heading" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;This section describes the initial implementation of PyMarkdown’s
&lt;a href="https://github.com/jackdewinter/pymarkdown/blob/master/pymarkdown/plugins/rule_md_026.py"&gt;Rule MD026&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id="why-does-this-rule-make-sense_2"&gt;Why Does This Rule Make Sense?&lt;a class="headerlink" href="#why-does-this-rule-make-sense_2" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;This rule seems to be largely derived from Ciro Santilli’s
&lt;a href="https://cirosantilli.com/markdown-style-guide#punctuation-at-the-end-of-headers"&gt;Markdown Style Guide&lt;/a&gt;.
In this document, Ciro claims that headings are not complete sentences, and as such,
should not
end with punctuation.  Specifically, his examples show very good cases for
not ending a heading with the &lt;code&gt;:&lt;/code&gt; character or the &lt;code&gt;.&lt;/code&gt; character.  My best guess is
that David Anson, when creating his rule based on that document, wanted to allow his
linter’s users to be able to extend this concept to include any headings that end
with a set of common punctuation characters. As such, the default for David’s rule is
to fail the rule if any heading ends with any of the &lt;code&gt;.,;:!?。，；：！？&lt;/code&gt; characters,
and that set of characters can be easily changed with configuration.&lt;/p&gt;
&lt;p&gt;While I do not completely agree with this rule, I do agree with the premise
behind the rule: headings should never be considered complete sentences.  To properly
describe that statement and how it applies to various headings, I needed to
brush up on my English grammar rules.  Even though it has been a few years since I
was in high school, I was quickly able to find a good solid definition:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;a complete sentence starts with a capital letter, ends with a punctuation character, and expresses a complete thought.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Using that definition as a rubric, I feel it is useful to demonstrate how that rule
applies to the headings in my own documents.  For this comparison, I used the layout
of the current section of this article as a good example of how to conceptually apply
this rule.&lt;/p&gt;
&lt;p&gt;For each rule in this section, the level 2 heading is always the id of the
rule followed by the description.  In the case of this rule, that heading is
&lt;code&gt;Rule MD026 - Trailing punctuation in heading&lt;/code&gt;.  That heading is not a valid
sentence because it is not a complete thought and does not end with punctuation.
The level 3 heading following this section is &lt;code&gt;Adding the Rule&lt;/code&gt;.  There is a bit more
nuance involved with that heading, as I can easily argue that it can be interpreted as
a complete sentence, just a very weak one.  The saving grace for that heading is that
it does not end with punctuation, so it is not advertising itself as a complete
sentence.&lt;/p&gt;
&lt;p&gt;That leaves the heading for this section which is &lt;code&gt;Why Does This Rule Make Sense?&lt;/code&gt;. When
I first looked at my grammar references for this, it seemed to fail at every point.
It starts with a capital letter, ends with punctuation, and looks like a complete
sentence.  Yes, I said “looks”… and it took me a bit to get there as well.  Remember
above when I said that a complete sentence expresses a complete thought?  That is where
context comes in.  Without the context imposed by this document, the obvious question
to ask is “What rule?”.  Because I tied the context of the heading to document’s
structure, it is not a complete thought unless it remains in the document. As it is not
a complete thought on its own, it narrowly fails the complete sentence test.&lt;/p&gt;
&lt;h4 id="aside-so-why-keep-it-like-that"&gt;Aside: So, Why Keep It Like That?&lt;a class="headerlink" href="#aside-so-why-keep-it-like-that" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;I know that using partial questions as headings is not a popular choice, and I know it
narrowly fails the complete sentence test.  So why keep it?&lt;/p&gt;
&lt;p&gt;For me, it all boils down to using my own voice in my writing, and the authenticity of
my writing in that voice.  For each of these rules, if I were reading someone else’s
document, I would ask two questions:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Why is it good to do this?&lt;/li&gt;
&lt;li&gt;What did it take to do this?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Wording the second question as a statement is relatively easy.  Instead of “What did it
take to do this?” I used the heading “Adding the Rule”.  It is not glamourous, but it
concisely and accurately conveys the image that I want to convey for that section.&lt;/p&gt;
&lt;p&gt;For the first question, I struggled for a long while trying to rephrase that question
as anything other than a question, and it just did not seem correct.  It either was
missing something, or it just felt like something that I would not say unless I was
prompted to.  So instead of
settling for something that I was not confident about, I opted for using a question that
did capture the essence that I wanted in a heading for that section.&lt;/p&gt;
&lt;p&gt;And yes, I purposefully worded the heading of this section to emphasize that point.
That, and it is the kind of question I would ask myself if I was reading someone else’s
article.&lt;/p&gt;
&lt;h3 id="adding-the-rule_2"&gt;Adding the Rule&lt;a class="headerlink" href="#adding-the-rule_2" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;At this point in the development of heading rules, I believe the term “ditto” is
appropriate.  Like a fair number of the rules before this one, any text that
is seen between either the Atx heading token or the SetExt heading token is collected
for later examination.  As that process of collecting the heading text has been
well documented in the other rules, I will avoid documenting it from here on out,
assuming that avid readers already know it fairly well, instead focusing on the
unique bits and differences in the algorithms.&lt;/p&gt;
&lt;p&gt;Once the heading text is collected and the heading’s end token is encountered, 
the rule’s comparison logic is then activated.  Quite simply, when the end token is
encountered, the
last text character of the collected text is checked against the configured set of
punctuation characters.  If there is a match, the rule fails.  If configuration is
provided to change the set of punctuation characters to check against, the check
is simply performed against that list of characters instead of the default list.&lt;/p&gt;
&lt;p&gt;At first, I was a bit let down that I saw this as being a simple rule, as the both
the code and testing for this rule were very trivial.  While I was initially
disappointed, after a while I was able to see it as a good thing. One benefit that I
started to see is that if these rules are performing a consistent action, it reduces
the chance that I am going to get the logic wrong.  Perhaps more obvious to me is the
benefit that if the logic is indeed very similar, it may be encapsulated into a base
class or helper class in a future refactoring, thereby reducing the maintenance costs.&lt;/p&gt;
&lt;p&gt;When I realized what those benefits were, I became okay with this rule being a mundane
rule to write.  Mundane equals refactorable equals lower maintenance.&lt;/p&gt;
&lt;h2 id="rule-md036-emphasis-used-instead-of-a-heading"&gt;Rule MD036 - Emphasis used instead of a heading&lt;a class="headerlink" href="#rule-md036-emphasis-used-instead-of-a-heading" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;This section describes the initial implementation of PyMarkdown’s
&lt;a href="https://github.com/jackdewinter/pymarkdown/blob/master/pymarkdown/plugins/rule_md_036.py"&gt;Rule MD036&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id="why-does-this-rule-make-sense_3"&gt;Why Does This Rule Make Sense?&lt;a class="headerlink" href="#why-does-this-rule-make-sense_3" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;This rule is another rule that was largely derived from Ciro Santilli’s
&lt;a href="https://cirosantilli.com/markdown-style-guide#emphasis-vs-headers"&gt;Markdown Style Guide&lt;/a&gt;.
If I had to guess, it seems that Ciro had seen cases where people were using
emphasis as headings in Markdown documents, something that is confusing.  Doing a bit
of easy research, most Markdown tutorial sites, such as
&lt;a href="https://www.markdowntutorial.com/"&gt;Markdown Tutorial&lt;/a&gt;,
address headings in their first 3 lessons.   For people who may ignore tutorials and
go straight to cheat sheets, both
&lt;a href="https://www.markdownguide.org/cheat-sheet"&gt;Markdown Guide’s Cheat Sheet&lt;/a&gt; and
&lt;a href="https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet"&gt;Adam Pritchard’s Cheatsheet&lt;/a&gt; deal with headings on their first page where they are immediately
visible. From this research alone, it is hard to figure out why someone would use
emphasis over headings.  However, I started wondering if perhaps there were historical
reasons for this rule?&lt;/p&gt;
&lt;p&gt;If you start looking at the tutorials and cheat sheets from a different angle,
perhaps the historical angle to justify this rule does make sense.  Perhaps these
distinct sources put
headings near the start of their documents because people were not using headings
properly at the time that those documents were written.
Thinking as an author, by putting headings near the start of the tutorial or cheat
sheet, I would expect that placement to strongly hint that they are important and
should be looked at before going with the rest of the document.&lt;/p&gt;
&lt;p&gt;To explore that concept further, I assumed that I did not know about headings, forcing
me to theorize on how to make a heading-like element would work.  Trying to forget
about this rule, I started working on a list of the elements that I could use.
With headings out of the picture, and every one of the other blocks having a very
distinct purpose, that left only inline elements.  Line breaks are not immediately
visible, and links are really meant for navigation, so they were removed from the
possibilities list early on.  That left backslashes, character references, code spans,
and emphasis. Out of those 4, only the emphasis made sense to use to draw attention to
some text.&lt;/p&gt;
&lt;p&gt;Based on those restrictions, the best heading-like element that I came up with was this
example:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;My&lt;/span&gt; &lt;span class="k"&gt;Not&lt;/span&gt; &lt;span class="n"&gt;So&lt;/span&gt; &lt;span class="n"&gt;Heading&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;

&lt;span class="k"&gt;More&lt;/span&gt; &lt;span class="nb"&gt;text&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;What a surprise! That is exactly what this rule is looking for.  In particular:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;the paragraph is a single line, surrounded by emphasis&lt;/li&gt;
&lt;li&gt;the contents of the paragraph are only simple text, no inline Markdown except for the surrounding emphasis&lt;/li&gt;
&lt;li&gt;for the same reasons as
&lt;a href="https://jackdewinter.github.io/2020/05/25/markdown-linter-rules-headings-part-2/#rule-md026-trailing-punctuation-in-heading"&gt;rule MD026&lt;/a&gt;,
the text does not end with a punctuation character&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Basically, if the only action I do is to remove the emphasis around the text, instead
prefixing the line with the text &lt;code&gt;#&lt;/code&gt;, it should become a valid heading.&lt;/p&gt;
&lt;p&gt;As I now had a working theory on why this rule may have been created and what a good
justification was for it, it was time to start writing the rule.&lt;/p&gt;
&lt;h3 id="adding-the-rule_3"&gt;Adding the Rule&lt;a class="headerlink" href="#adding-the-rule_3" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;While the logic for the rules has been somewhat simple before the point, even a simple
glance at this rule led me to believe that the logic for this rule was going to need
some heft to it.  As it often is with many complex parsing scenarios, it was
time to use a Finite State Machine.  While there are many good articles on Finite
State Machines, such as this decently complete one at
&lt;a href="https://en.wikipedia.org/wiki/Finite-state_machine"&gt;Wikipedia&lt;/a&gt;, these complex
machines boil down to this simple statement:  the machine has a finitely small number
of states and for each state there are 0 or more transitions from that state to other
states.&lt;/p&gt;
&lt;p&gt;From my experience, there is a certain level in parsing or pattern recognition where a
simple comparison is not enough, and a formal Finite State Machine is required.  The
inverse of this is also true, where the formality and setup required for a proper
Finite State Machine may get in the way of a small, efficient algorithm. Consider the
algorithm and code for
&lt;a href="https://jackdewinter.github.io/2020/05/25/markdown-linter-rules-headings-part-2/#rule-md026-trailing-punctuation-in-heading"&gt;rule MD026&lt;/a&gt;
in the previous section.  A simple &lt;code&gt;if&lt;/code&gt; statement was used to look for 3 types of
tokens: a start heading token, any contained text tokens, and an end heading token.
While not called out as such, this algorithm was a small state machine with
clear states and clear transitions between states.  Once the contents of the heading
were collected, then rule MD026 did an analysis on it, and determined whether
to fail the rule based on that analysis.&lt;/p&gt;
&lt;p&gt;Breaking that logic out into a full-fledged Finite State Machine had little benefit,
as the simple logic was able to complete the task without less than 5 states and
without any complicated transition logic.  On the other hand, the logic for this
rule as defined in the last section reveals that this rule’s algorithm requires 5
distinct states:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;look for a paragraph start token&lt;/li&gt;
&lt;li&gt;look for an emphasis start token&lt;/li&gt;
&lt;li&gt;look for a text token&lt;/li&gt;
&lt;li&gt;look for an emphasis end token&lt;/li&gt;
&lt;li&gt;look for a paragraph end token&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;If at any point the next token that we encounter is not the type of token required to
go to the next state, the machine resets back to state 1 and the machine starts to look
for a new paragraph.  While the transition logic remained simple, I felt that
the “large” number of different states made using a Finite State Machine the best
alternative.&lt;/p&gt;
&lt;p&gt;Once I had the states and transitions figured out, the writing of the rule was
trivial.  The states were represented by a simple set of &lt;code&gt;if&lt;/code&gt; statements, each one
clearly looking for the correct condition to move the state machine to the next state.
If that condition is not found,
the current state is reset to state 1, causing it to look for the initial condition
again.  If the Finite State Machine gets past the final state, the rule fails and the
current state is again reset back to state 1, looking for another candidate paragraph
to evaluate.&lt;/p&gt;
&lt;h2 id="what-was-my-experience-so-far"&gt;What Was My Experience So Far?&lt;a class="headerlink" href="#what-was-my-experience-so-far" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;From the viewpoint of adding new rules, this was a good experience.  My feelings,
as expressed in
&lt;a href="https://jackdewinter.github.io/2020/05/18/markdown-linter-rules-headings-part-1/##what-was-my-experience-so-far"&gt;the last article&lt;/a&gt;,
were easily extended to cover this set of rules as well.  While I still want to jump
ahead sometimes, my confidence in the process of writing rules and the framework in
which I write those rules is getting deeper with the authoring of each rule. A good
part of that confidence boost is that when I create new rules, the bulk of the time used
to author those rules is focused on the rules themselves, and not on how to wring the
required data from the framework.  It is only the rare exception where I need to figure
out how to get some data from the framework.&lt;/p&gt;
&lt;p&gt;But it is those exceptions that caused me to pause and think when trying to answer the
question that I posed at the start of the article: write more rules or fix more issues?
This answer is a difficult one for me to arrive at, as there is good data to support
both sides.  Writing more rules would round out the framework some more, while focusing
on the framework will fix known issues with the framework, allowing future rules to
be written with less friction.&lt;/p&gt;
&lt;p&gt;This choice was also complicated by the arrival of new ideas for the project as I am
implementing the rules.  A good example of this is the Markdown parser “tunings” that
I briefly talked about back in the documentation for
&lt;a href="http://localhost:8000/2020/05/25/markdown-linter-rules-headings-part-2/#rule-md023-headings-must-start-at-the-beginning-of-the-line"&gt;rule MD023&lt;/a&gt;.
While it is nice to think about these concepts and how they could make the project
better, doing anything more than thinking about them at this stage would be
distracting.  Even worse, it could derail the project by having me follow that
concept down the
&lt;a href="https://www.merriam-webster.com/dictionary/rabbit%20hole"&gt;rabbit hole&lt;/a&gt;.  If I want
to be able to explore concepts such as “tunings”, which of the two options would
allow me to get there faster while maintaining my require level of quality?&lt;/p&gt;
&lt;p&gt;In the end, I determined that I wanted some more time to think about this.  There
are a few issues in my backlog, and fixing those issues will give me some more
time to determine the best course of action.  Sometimes, the best decision is not to
decide, but to collect more information.  I firmly believe that this is one of those
cases.  And if I am wrong?  It just means the foundation for the project will be
that much cleaner and stronger than it was before.&lt;/p&gt;
&lt;h2 id="what-is-next"&gt;What is Next?&lt;a class="headerlink" href="#what-is-next" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;As I mentioned in the previous section, I feel that the best course of action is to do
some refactoring.  While it is not a glorious task, it will give me some time
to determine if whether to choose line/column support in the parser or adding more
rules.&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr/&gt;
&lt;ol&gt;
&lt;li id="fn:Babelmark"&gt;
&lt;p&gt;Babelmark is a useful online tool that converts a given piece of Markdown text into HTML using a wide variety of Markdown parsers.  I find tools like this very useful in exploring possibilities for how to solve issues that I have. &lt;a class="footnote-backref" href="#fnref:Babelmark" title="Jump back to footnote 1 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</content><category term="Software Quality"></category><category term="markdown linter"></category><category term="linter rules"></category></entry><entry><title>Markdown Linter - Rules - Headings - Part 1</title><link href="https://jackdewinter.github.io/2020/05/18/markdown-linter-rules-headings-part-1/" rel="alternate"></link><published>2020-05-18T00:00:00-07:00</published><updated>2020-05-18T00:00:00-07:00</updated><author><name>Jack De Winter</name></author><id>tag:jackdewinter.github.io,2020-05-18:/2020/05/18/markdown-linter-rules-headings-part-1/</id><summary type="html">
&lt;h2 id="introduction"&gt;Introduction&lt;a class="headerlink" href="#introduction" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;After setting up a good, easy process for
&lt;a href="https://jackdewinter.github.io/2020/05/11/markdown-linter-rules-the-first-three/#adding-the-rule"&gt;writing new rules&lt;/a&gt;,
it was now time to make some headway on the task of writing those new rules.  While the
title “Headings - Part 1” is not glamorous, it is a very apt description for the way
that I planned out …&lt;/p&gt;</summary><content type="html">
&lt;h2 id="introduction"&gt;Introduction&lt;a class="headerlink" href="#introduction" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;After setting up a good, easy process for
&lt;a href="https://jackdewinter.github.io/2020/05/11/markdown-linter-rules-the-first-three/#adding-the-rule"&gt;writing new rules&lt;/a&gt;,
it was now time to make some headway on the task of writing those new rules.  While the
title “Headings - Part 1” is not glamorous, it is a very apt description for the way
that I planned out the development of this group of rules dealing with Markdown
headings. In
&lt;a href="https://github.com/DavidAnson/markdownlint"&gt;David Anson’s MarkDownLint&lt;/a&gt;,
there are a total of 15 linter rules that specifically deal with headings.
The first 3 of those rules were used as examples in the previous article, leaving
12 rules to implement.  For reasons I will follow up on, I decided to leave the
implementation of rules MD041 and MD043 for later, reducing the number of rules to
a nice manageable 10.&lt;/p&gt;
&lt;p&gt;Without any unnecessary embellishment, the article’s title simply denotes that I am
going to talk about the implementation of the first half of those rules.  Sure, I could
come up with a name like “The 5 Most Important Rules for Headings!” or “5 Rules
for Headings That You Cannot Live Without!”, but the truth is that they were simply the
next group of rules.  Nothing fancy, nothing misleading, just the plain truth.&lt;/p&gt;
&lt;h2 id="what-is-the-audience-for-this-article"&gt;What Is the Audience for This Article?&lt;a class="headerlink" href="#what-is-the-audience-for-this-article" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;While detailed more eloquently in
&lt;a href="https://jackdewinter.github.io/2020/04/05/what-is-the-audience-for-my-blog/#what-is-the-audience-for-my-blog"&gt;this article&lt;/a&gt;,
my goal for this technical article is to focus on the reasoning behind my solutions,
rather that the solutions themselves.  For a full record of the solutions presented in
this article, please go to this project’s GitHub repository and consult the
commits between
&lt;a href="https://github.com/jackdewinter/pymarkdown/commit/c07dd31cf85db9905693191fb022705b4d641305"&gt;24 April 2020&lt;/a&gt; and
&lt;a href="https://github.com/jackdewinter/pymarkdown/commit/1c4a87c88f45417ddc70c537a3c598a4349ed7ad"&gt;26 April 2020&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id="what-about-those-two-rules-that-were-left-out"&gt;What About Those Two Rules That Were Left Out?&lt;a class="headerlink" href="#what-about-those-two-rules-that-were-left-out" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Just to get this out of the way: because it was expedient.&lt;/p&gt;
&lt;p&gt;I started to look at rule MD041 when I was implementing rule MD002, as documented in
&lt;a href="https://jackdewinter.github.io/2020/05/11/markdown-linter-rules-the-first-three/#rule-md002-deprecated-first-heading-should-be-top-level"&gt;the last article&lt;/a&gt;.
At that time, I looked at rule MD041 to determine if I could just include the work for
MD041 with the work to write rule MD002.  While the only difference between the two
rules is the inclusion of “YAML front matter” into the rule, I felt that the
difference was a large one at that stage of the project.  I knew that I needed to
added metadata support to the parser as a requirement for my use of the linter.  But
the overriding question I had to answer was: Was this the right time to add this
new feature to the parser?&lt;/p&gt;
&lt;p&gt;After a decent amount of back and forth on the subject, I decided against adding it at
that moment. From my point of view, at that time it was better to focus on additional
linter rules for the project rather than focus on additional features for the parser.
While it would be fun to add more functionality to the parser to allow for MD041 to be
implemented, I made a judgement call that it could wait a bit.&lt;/p&gt;
&lt;p&gt;For rule MD043, my decision was based on a combination of the
complexity of the feature and the usefulness of the feature to me.  Without a deep dive
into the rule, it looks like there will be a fair number of edge cases that I will have
to consider for rule MD043, easily increasing its complexity.  From the usefulness
point of view, while I can
see how it may be useful, this is not a feature that I see myself using a lot.  While I
took a different path to the judgement call, the result was the same: Rule MD043 could
wait for later.&lt;/p&gt;
&lt;h2 id="why-is-this-group-of-rules-important"&gt;Why Is This Group of Rules Important?&lt;a class="headerlink" href="#why-is-this-group-of-rules-important" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;While I didn’t think about it at the time, I needed this group of rules to prove
two important things to myself: that I had chosen the right base framework to write
linter rules with, and that I had chosen a good development process with which to
write and test those rules.  It was only after the development was completed and
I was writing this article that I was able to recognize their importance in proving
or disproving those two things to myself.&lt;/p&gt;
&lt;h2 id="rule-md018-no-space-after-hash-on-atx-style-heading"&gt;Rule MD018 - No space after hash on atx style heading&lt;a class="headerlink" href="#rule-md018-no-space-after-hash-on-atx-style-heading" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;This section describes the initial implementation of PyMarkdown’s
&lt;a href="https://github.com/jackdewinter/pymarkdown/blob/master/pymarkdown/plugins/rule_md_018.py"&gt;Rule MD018&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id="why-does-this-rule-make-sense"&gt;Why Does This Rule Make Sense?&lt;a class="headerlink" href="#why-does-this-rule-make-sense" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;This rule is all about catching a
&lt;a href="https://www.merriam-webster.com/dictionary/typo"&gt;typo&lt;/a&gt;.
This rule surmises that when someone types:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;#&lt;/span&gt;&lt;span class="n"&gt;Heading&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;they probably forgot to add a space and really meant to type this:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;#&lt;/span&gt; &lt;span class="n"&gt;Heading&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;While it is possible that the author intended to start a new line with the text
&lt;code&gt;#Heading&lt;/code&gt;, I believe that it is far more likely that a typo occurred.&lt;/p&gt;
&lt;h3 id="adding-the-rule"&gt;Adding the Rule&lt;a class="headerlink" href="#adding-the-rule" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;The two important parts of adding this rule were recognizing that it can take place
in a normal paragraph and that it can occur at the start of any line in that paragraph.&lt;/p&gt;
&lt;p&gt;While I did consider the possibility of text like &lt;code&gt;#Heading&lt;/code&gt; being
captured as part of another block element, my experimentation with the CommonMark
parser did not reveal any case that causes another block element to stop
capturing on a line like &lt;code&gt;# Heading&lt;/code&gt;.  As such, by default the text ends up being
captured within a paragraph block using a text token. As is shown in
&lt;a href="https://github.github.com/gfm/#example-47"&gt;example 47&lt;/a&gt;,
an Atx heading can interrupt other blocks, but more importantly, it can interrupt a
paragraph block.  With these two constraints understood, I was ready to start
coding the rule.&lt;/p&gt;
&lt;p&gt;Leveraging the first constraint allowed me to add code to the &lt;code&gt;next_token&lt;/code&gt;
function to consider any text token within a paragraph block eligible for further
examination.  From there, I applied the second constraint by enhancing the
rule to look for an Atx heading-like pattern at the start of each line within those
eligible text tokens.
This was accomplished by breaking down each text token into separate lines and checking
them against a
&lt;a href="https://docs.python.org/3/howto/regex.html"&gt;Python regular expression&lt;/a&gt;.
By carefully reading the GFM specification’s section on
&lt;a href="https://github.github.com/gfm/#atx-headings"&gt;Atx headings&lt;/a&gt;,
I was able to construct the regular expression &lt;code&gt;^\s{0,3}#{1,6}\S&lt;/code&gt;, which breaks down
into the following components:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;^&lt;/code&gt; - start matching at the start of the line&lt;/li&gt;
&lt;li&gt;&lt;code&gt;\s{0,3}&lt;/code&gt; - look for between 0 and 3 whitespace characters&lt;/li&gt;
&lt;li&gt;&lt;code&gt;#{1,6}&lt;/code&gt; - look for between 1 and 6 &lt;code&gt;#&lt;/code&gt; characters&lt;/li&gt;
&lt;li&gt;&lt;code&gt;\S&lt;/code&gt; - look for one non-whitespace character&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I needed the regular expression to be a form of the regular expression to recognize the
proper GRM specification form but modified to look for the specific case that I wanted
to look for.  In this instance, I was looking for heading-like text that is missing
at least one space after the starting &lt;code&gt;#&lt;/code&gt; characters.  To satisfy this constraint I
used the &lt;code&gt;\S&lt;/code&gt; sequence,
matching any single non-whitespace character, at the end of the regular expression
specifically looking for no whitespace characters at the end of the expression. Using my
favorite online &lt;a href="https://pythex.org/"&gt;Python regular expression tester&lt;/a&gt;, I was able to
verify that I had the correct regular expression right away.&lt;/p&gt;
&lt;p&gt;The rigorous testing for this rule involved more testing of cases where the rule should
not fail than cases where it should fail.  But when I boiled all those tests down into
what was relevant, there were a couple of patterns that I just needed to test.  In
testing, this is referred to as equivalence class testing.&lt;/p&gt;
&lt;p&gt;While sites like
&lt;a href="https://www.professionalqa.com/equivalence-class-testing"&gt;this one&lt;/a&gt;
go on and on about what it is, it breaks down into one statement.  Unless there
is something special (usually around boundary conditions), entire groups of tests can
be considered equivalent and be represented by a single test, if their relevant
behavior is consistent across that entire group.  Consider a simple calculator
application that allows for the addition of 2 integers together.  The testing of that
application does not need to test every single integer added to every single integer.
Just thinking about the work required for that is exhausting!  Instead, the testing can
be broken down into representative
groups such as “any integer added to 0 equals that integer”, drastically reducing the
number of tests required to cover a specific component.&lt;/p&gt;
&lt;p&gt;Applying this concept to the test cases for this rule, I was able to reduce over 20
tests down to a more reasonable 8 tests.  Some of these groups were making sure
the rule does not fail if eligible text is in any of the text-containing leaf blocks
except for the paragraph block, in which it should fail.  The rest of the groups were
simple cases based on variations of the regular expression above, that regular
expression a reflection of the specification.&lt;/p&gt;
&lt;p&gt;Confident that I had covered all the conditions for this rule, it was time to move
on to the next one!&lt;/p&gt;
&lt;h2 id="rule-md019-multiple-spaces-after-hash-on-atx-style-heading"&gt;Rule MD019 - Multiple spaces after hash on atx style heading&lt;a class="headerlink" href="#rule-md019-multiple-spaces-after-hash-on-atx-style-heading" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;This section describes the initial implementation of PyMarkdown’s
&lt;a href="https://github.com/jackdewinter/pymarkdown/blob/master/pymarkdown/plugins/rule_md_019.py"&gt;Rule MD019&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id="why-does-this-rule-make-sense_1"&gt;Why Does This Rule Make Sense?&lt;a class="headerlink" href="#why-does-this-rule-make-sense_1" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Like a fair number of the other rules that are defined, this rule is about
consistency.  While the opening paragraph for the GFM specification for
&lt;a href="https://github.github.com/gfm/#atx-headings"&gt;Atx headings&lt;/a&gt;
does allow for more than one space after the initial set of &lt;code&gt;#&lt;/code&gt; characters, it also
specifies that those leading spaces are stripped before the rest of the line is
parsed as inline content.  Essentially:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;#&lt;/span&gt; &lt;span class="n"&gt;Heading&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;and&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;#&lt;/span&gt;                                            &lt;span class="n"&gt;Heading&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;are syntactically equivalent.  As they are equivalent, it makes sense to use the simpler
form of the heading to keep things consistent.&lt;/p&gt;
&lt;h3 id="adding-the-rule_1"&gt;Adding the Rule&lt;a class="headerlink" href="#adding-the-rule_1" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;The code to evaluate this rule was very simple.  When the content of the Atx heading is
parsed into a text token, any spaces that are stripped from that token are kept as part
of the text token in a separate part specifically reserved for stripped whitespace.  To
check for multiple spaces, I simply added code that checked to see if a
text token existed within an Atx heading, and if so checked to see if that token
contained more than one space in that stripped whitespace area of the token.&lt;/p&gt;
&lt;p&gt;As the code was simple, the tests themselves were simple.  The examples from the
&lt;a href="https://github.com/DavidAnson/markdownlint/blob/master/doc/Rules.md#md019---multiple-spaces-after-hash-on-atx-style-heading"&gt;MD019 rule description page&lt;/a&gt;
were used verbatim as the only cases needed as that is how simple this rule is.  At
least it was that simple until I looked more closely at the next two rules.&lt;/p&gt;
&lt;h2 id="rules-md020-and-md021"&gt;Rules MD020 and MD021&lt;a class="headerlink" href="#rules-md020-and-md021" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;This section describes the initial implementation of PyMarkdown’s
&lt;a href="https://github.com/jackdewinter/pymarkdown/blob/master/pymarkdown/plugins/rule_md_020.py"&gt;Rule MD020&lt;/a&gt; and
&lt;a href="https://github.com/jackdewinter/pymarkdown/blob/master/pymarkdown/plugins/rule_md_021.py"&gt;Rule MD021&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id="these-rules-look-very-familiar"&gt;These Rules Look Very Familiar&lt;a class="headerlink" href="#these-rules-look-very-familiar" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;While preparing for the work detailed in
&lt;a href="https://jackdewinter.github.io/2020/05/11/markdown-linter-rules-the-first-three/"&gt;the last article&lt;/a&gt;,
I quickly read through the list of rules before starting that work.  I believe that
because I was focusing on those first 3 rules, I missed an interesting
piece of information on rules MD020 and MD021.  The piece of information is that
rules MD020 and MD021 are variations of the rules for MD018 and MD019 that apply
specifically to Atx headings with the
&lt;a href="https://jackdewinter.github.io/2020/05/11/markdown-linter-rules-the-first-three/#atx-headings-vs-atx_closed-headings"&gt;Atx_Closed style&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;That information was both good news and bad news.  The good news part was that since I
had the code and tests already written for the previous two rules, I could repurpose a
lot of that code for these new rules.  The bad news part was that I was going to have
to rewrite parts of those two previous rules to exclude cases where the latter two rules
will fail.  However, I believe that the good news here definitely outweighs the bad
news, so on to the coding!&lt;/p&gt;
&lt;h3 id="adjusting-the-old-rules"&gt;Adjusting the Old Rules&lt;a class="headerlink" href="#adjusting-the-old-rules" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;The first part of adding these new rules was modifying the old rules to not fail if an
Atx_Closed style of Atx heading is found.  Rule Md019 was the easiest one to adjust,
requiring only a small change. As part of the normal Atx heading parsing, the number of
trailing &lt;code&gt;#&lt;/code&gt; characters in the heading is collected in the Atx heading’s
&lt;code&gt;remove_trailing_count&lt;/code&gt; variable.  The small change I made was to only fail rule MD019
if that variable was zero, an easy change in anyone’s viewpoint.
The change for rule MD018 was only slightly more difficult, adding an additional check
for the regular expression &lt;code&gt;#\s*$&lt;/code&gt;&lt;sup id="fnref:closeAtx"&gt;&lt;a class="footnote-ref" href="#fn:closeAtx"&gt;1&lt;/a&gt;&lt;/sup&gt; to the existing condition.  In both
cases, simple test cases were added to expressly test the rule to make sure they did
not fail if presented with an Atx_Closed style heading.&lt;/p&gt;
&lt;p&gt;Simple changes, and simple tests to verify those changes.&lt;/p&gt;
&lt;h3 id="adding-the-new-rules"&gt;Adding the New Rules&lt;a class="headerlink" href="#adding-the-new-rules" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Adjusting rule MD019 to fit the parameters of rule MD021 was interesting, but not too
difficult.  The original check for spaces was modified to set the variable
&lt;code&gt;is_left_in_error&lt;/code&gt; instead of failing immediately.  When the end token for the Atx
heading token is seen, it checks to see if that &lt;code&gt;is_left_in_error&lt;/code&gt; was set or if the
closing &lt;code&gt;#&lt;/code&gt;
count is greater than 1, failing if either part is true.  Checking the end token was
required as the parser’s pattern is that any leading spaces are applied to the token
that follows those spaces, meaning that those spaces before the closing &lt;code&gt;#&lt;/code&gt; characters
is stored with the Atx heading’s end token.&lt;/p&gt;
&lt;p&gt;Making similar changes to rule MD020 proved to be a bit more difficult.  The
constraints from rule MD018 were still present, but rule MD020 added the constraint of
looking for bad spacing before the closing set of &lt;code&gt;#&lt;/code&gt; characters.  Starting with the
previous regular expression for finding normal Atx headings in paragraphs
(&lt;code&gt;^\s{0,3}#{1,6}\S&lt;/code&gt;) and merging it together with the the regular expression
for excluding Atx_Closed line failures from rule MD019 (&lt;code&gt;#\s*$&lt;/code&gt;), I ended up with the
expression &lt;code&gt;^\s{0,3}#{1,6}.*#+\s*$&lt;/code&gt;.  To merge the two expression together, I made two
small changes.  The &lt;code&gt;\S&lt;/code&gt; expression used to indicate the matching of any character that
is not whitespace was replaced with the &lt;code&gt;.*&lt;/code&gt; expression to match zero or
more instances of any character.  The &lt;code&gt;#&lt;/code&gt; character used to indicate a single &lt;code&gt;#&lt;/code&gt;
character was then replaced with the &lt;code&gt;#+&lt;/code&gt; expression to match 1 or more &lt;code&gt;#&lt;/code&gt; characters,
allowing for any number of closing &lt;code&gt;#&lt;/code&gt; characters in the Atx heading.  &lt;/p&gt;
&lt;p&gt;Before adding any extra test cases, I used my favorite
&lt;a href="https://pythex.org/"&gt;Python regular expression tester&lt;/a&gt; to do some extensive testing
on the regular expression.  I am happy to report that except for a simple
typo, I got the regular expression right on the first try!&lt;/p&gt;
&lt;p&gt;With the regular expression
verification concluding successfully, I moved to add the test cases for both rules.
For both rules, I started by adding copies of the test cases from the original rules
but modified each one to represent missing spaces at the start of the Atx_Closed style
headings instead of normal Atx style headings.  From there, I added test cases where
spaces were
missing from both the start and the end of the Atx heading as well as where spaces
were only missing from the end of the Atx_Closed style headings.  It was there that I
ran into an interesting case.&lt;/p&gt;
&lt;h3 id="is-this-really-a-failure"&gt;Is This Really A Failure?&lt;a class="headerlink" href="#is-this-really-a-failure" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;While the original rules do not specifically identify this as a distinct case, consider
the following Markdown:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;#&lt;/span&gt; &lt;span class="n"&gt;Heading&lt;/span&gt;&lt;span class="o"&gt;#&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;While this obviously qualifies as an Atx heading, I can credibly argue that it should
be included in MD020’s definition of a typo in an Atx_Closed styled heading.  While I
could have left it out, I felt strongly that this was most likely a typo and the rule
should fail on this input as well.  &lt;/p&gt;
&lt;p&gt;Adding this into the rule for MD020 was easy.  If the last token is a text token and the
rule is currently looking at an end Atx heading token, the rule checks to see if that
previous text token ends with a &lt;code&gt;#&lt;/code&gt; character.  If the &lt;code&gt;#&lt;/code&gt; character is found, it fails
the rule.&lt;/p&gt;
&lt;p&gt;After adding the code for this newly discovered case, I spent some time exploring
different possible combinations, making sure that I had the right equivalence classes
for all 4 new rules.  When I was satisfied that I had not missed anything, I move on
to the next rule.&lt;/p&gt;
&lt;h2 id="rule-md022-headings-should-be-surrounded-by-blank-lines"&gt;Rule MD022 - Headings should be surrounded by blank lines&lt;a class="headerlink" href="#rule-md022-headings-should-be-surrounded-by-blank-lines" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;This section describes the initial implementation of PyMarkdown’s
&lt;a href="https://github.com/jackdewinter/pymarkdown/blob/master/pymarkdown/plugins/rule_md_022.py"&gt;Rule MD022&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id="why-does-this-rule-make-sense_2"&gt;Why Does This Rule Make Sense?&lt;a class="headerlink" href="#why-does-this-rule-make-sense_2" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;While I could stay with the consistency answer I used for MD019, a better answer for
this rule is  compatibility and readability.  Speaking to compatibility,
there are some Markdown parsers that will not recognize Atx headings unless they are
preceded by a blank line or followed by a blank line.  To keep things simple, having
at least one blank line on either side of the Atx heading keeps the options for parser
choices open.&lt;/p&gt;
&lt;p&gt;From a readability point of view, hopefully it is obvious that:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nv"&gt;Lorem&lt;/span&gt; &lt;span class="nv"&gt;ipsum&lt;/span&gt; &lt;span class="nv"&gt;dolor&lt;/span&gt; &lt;span class="nv"&gt;sit&lt;/span&gt; &lt;span class="nv"&gt;amet&lt;/span&gt;, &lt;span class="nv"&gt;consectetur&lt;/span&gt; &lt;span class="nv"&gt;adipiscing&lt;/span&gt;.

## &lt;span class="k"&gt;Next&lt;/span&gt; &lt;span class="nv"&gt;Section&lt;/span&gt;

&lt;span class="nv"&gt;Morbi&lt;/span&gt; &lt;span class="nv"&gt;dictum&lt;/span&gt; &lt;span class="nv"&gt;tortor&lt;/span&gt; &lt;span class="nv"&gt;a&lt;/span&gt; &lt;span class="nv"&gt;diam&lt;/span&gt; &lt;span class="nv"&gt;volutpat&lt;/span&gt;, &lt;span class="nv"&gt;ut&lt;/span&gt;.
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;is a lot easier to read than:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nv"&gt;Lorem&lt;/span&gt; &lt;span class="nv"&gt;ipsum&lt;/span&gt; &lt;span class="nv"&gt;dolor&lt;/span&gt; &lt;span class="nv"&gt;sit&lt;/span&gt; &lt;span class="nv"&gt;amet&lt;/span&gt;, &lt;span class="nv"&gt;consectetur&lt;/span&gt; &lt;span class="nv"&gt;adipiscing&lt;/span&gt;.
## &lt;span class="k"&gt;Next&lt;/span&gt; &lt;span class="nv"&gt;Section&lt;/span&gt;
&lt;span class="nv"&gt;Morbi&lt;/span&gt; &lt;span class="nv"&gt;dictum&lt;/span&gt; &lt;span class="nv"&gt;tortor&lt;/span&gt; &lt;span class="nv"&gt;a&lt;/span&gt; &lt;span class="nv"&gt;diam&lt;/span&gt; &lt;span class="nv"&gt;volutpat&lt;/span&gt;, &lt;span class="nv"&gt;ut&lt;/span&gt;.
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Between the coloring of the Atx heading in my editor and the spacing around the Atx
heading, it is easy to find the different sections.  Without that spacing, I know it
takes me a lot more effort to find headings, especially in a large document.&lt;/p&gt;
&lt;p&gt;In addition to these reasons, I believe that different people have varying requirements
on what is acceptable or proper amounts of spacing before and after a heading.  I
personally know of a few people with visual impairments that find it easier to
acknowledge the change in sections if accompanied by extra spacing.  To support varying
requirements like these, rule MD022 has the &lt;code&gt;lines_above&lt;/code&gt; and &lt;code&gt;lines_below&lt;/code&gt;
configuration values that allows the user to alter the required number of blank lines
before and after each heading element.  From my point of view, the benefit provided
by allowing the user to configure this rule easily outweighs the work that was
required to add it.&lt;/p&gt;
&lt;h3 id="adding-the-rule_2"&gt;Adding the Rule&lt;a class="headerlink" href="#adding-the-rule_2" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;In documenting the previous 4 rules, I noticed that I almost always talk about
testing as a final step, which is far from my practice.  As such, I thought it would
be useful to use this rule’s development as an example of my normal development
process.&lt;/p&gt;
&lt;h4 id="testing-done-right"&gt;Testing Done Right&lt;a class="headerlink" href="#testing-done-right" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;As I documented in &lt;a href="https://jackdewinter.github.io/2020/05/11/markdown-linter-rules-the-first-three/"&gt;my last post&lt;/a&gt;,
my usual process for developing a new rule is:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Creating a New Rule&lt;/li&gt;
&lt;li&gt;Creating the Initial Tests&lt;/li&gt;
&lt;li&gt;Implementing the Rule&lt;/li&gt;
&lt;li&gt;Thorough Rule Validation&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I usually talk about running the tests after I talk about creating a rule, because it
is in the “Thorough Rule Validation” phase that most of the interesting things happen.
In this case, it was the “Creating the Initial Tests” phase that was interesting.&lt;/p&gt;
&lt;p&gt;Creating a new rule is a task that I can now perform while sleeping, as I have done it
enough times that adding a new rule to the project only requires a little bit of my
attention to accomplish correctly.  I was then wakened out of slumber when I proceeded
to the next step and started going through the initial combinations of test data for
this rule.  Honestly, keeping all that data in my head caused me to get confused
somewhat quickly.  There were simply too many
combinations to keep in my head with any degree of confidence.  As such, I started
creating the initial test cases for rule MD022, adding
one test case per file just like normal.  Working through each set of combinations,
I was surprised that at the end of that exercise, I had 22 test files ready to go for
testing.  Reviewing the variations of text block types, SetExt/Atx headings,
valid/invalid spacing, and alternate spacing configurations, it did seem justified that
22 test files were required to properly test the rule. And that number was kept low as
I cheated a little bit, leaving any combinations with container blocks (block quotes
and list blocks) out of the
equation until I could do a bit more research and thinking on them.&lt;/p&gt;
&lt;h4 id="writing-the-rule"&gt;Writing the Rule&lt;a class="headerlink" href="#writing-the-rule" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;Having so many test cases, I was concerned that the logic was going to be incredibly
complex, but I was able to boil it down to two simple metrics: the number of blank lines
before a heading and the number of blank lines after a heading.  The count
of lines before any heading is equal to the number of blank lines after a leaf block
completes and the heading block starts.  The count of lines after any heading is equal
to the number of blank lines after the end of the heading until the next leaf block
starts.  This is where excluding the container blocks paid off, as adding those blocks
in to this rule with their containing conditions and ending conditions would have
complicated those calculations by a fair amount.&lt;/p&gt;
&lt;p&gt;Given the calculations as specified in the last paragraph, the code to determine these
values was simple, but required some thinking.  The &lt;code&gt;blank_line_count&lt;/code&gt; variable is
incremented if it is not
&lt;code&gt;None&lt;/code&gt; and is greater than zero.  At the start of the document, the &lt;code&gt;blank_line_count&lt;/code&gt;
variable is set to &lt;code&gt;-1&lt;/code&gt; to make sure it does not fail for a heading at the very start of
the document.  Whenever the end of a leaf block is encountered, the &lt;code&gt;blank_line_count&lt;/code&gt;
variable is set to &lt;code&gt;0&lt;/code&gt; to allow the counting of blank lines to commence.  The end token
for anything other than leaf blocks is not important to this rule, so in that case, the
&lt;code&gt;blank_line_count&lt;/code&gt; is set to &lt;code&gt;None&lt;/code&gt; to stop counting until the next qualifying end token
starts it again.&lt;/p&gt;
&lt;p&gt;Once I had the calculation of &lt;code&gt;blank_line_count&lt;/code&gt; worked out properly, the rest was a
matter of perspective.  The before count is simply the value of &lt;code&gt;blank_line_count&lt;/code&gt; at
the time that the Atx heading is encountered.  Likewise, the after count is the value
of &lt;code&gt;blank_line_count&lt;/code&gt; at the time that the next leaf block is encountered.  But what
if there is no next leaf block?  What if the heading block is the last block in the
document?  That is where the &lt;code&gt;completed_file&lt;/code&gt; function comes in handy. Added
to the plugin manager for cases like this, this function is called after all the
line and token processing for the Markdown has completed.  When the
&lt;code&gt;completed_file&lt;/code&gt; function is called for this rule, it performs the usual check for
closing conditions, failing the rule if the conditions are right.&lt;/p&gt;
&lt;p&gt;With the 22 test cases identified at the start of the development for this rule,
the testing was simple, with almost no errors in the implementation of the rule
itself, just the normal semantic and typo stuff.  I do feel that I must acknowledge
that I believe part of the reason this went off so cleanly was because the container
blocks are not yet implemented.  I do think those 2 blocks alone will easily
&lt;a href="https://idioms.thefreedictionary.com/throw+a+wrench+in+the+works"&gt;throw a monkey wrench&lt;/a&gt;
into the works.  But for now, it is a good place to stop with development of this rule.&lt;/p&gt;
&lt;h2 id="what-was-my-experience-so-far"&gt;What Was My Experience So Far?&lt;a class="headerlink" href="#what-was-my-experience-so-far" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;After the stress of adding the first three rules, as documented in
&lt;a href="https://jackdewinter.github.io/2020/05/11/markdown-linter-rules-the-first-three/"&gt;the previous article&lt;/a&gt;,
adding these rules to PyMarkdown was comparatively easy.  While I still had to contend
with the line numbers and column numbers not being reported&lt;sup id="fnref:yes"&gt;&lt;a class="footnote-ref" href="#fn:yes"&gt;2&lt;/a&gt;&lt;/sup&gt;, everything else in
my “rule development process” was working fine.  There are times that I want to skip
the tests and get to the development of the rule and have fun, as I am only human.
But if there is anything that
my experience as a developer has taught me, it is that having a clear picture of what
you want to do before your write the code is essential to shaping the code.  If you
start with a poor picture for what your code will do, you get poor results.  I find it
almost always pays off to take the time to draw that good picture, getting together
solid test cases and manually calculating their anticipated results once executed
against the project.&lt;/p&gt;
&lt;p&gt;While the ease of rule development is nice, it is the solid nature and usefulness of the
core rule engine that is making me happy.  In implementing this batch of 5 rules, I
did not have to make any changes to the core rule engine.  At the same time, the
development of the rules was easy, my focus centering on the particulars of the rule
itself, and not the infrastructure required to support the rule.  While I am not sure
if it is happiness or pride, it is a good
feeling that the work to get the project to this point is paying off.  And while I
do know refactoring is needed in some areas, I also have a growing collection of
proof that my approach to this project is solid and should be continued.&lt;/p&gt;
&lt;p&gt;Based on those observations, I believe that any earlier questions about whether I
had chosen the right framework and the right development process were answered
positively.  As an added benefit, I also sincerely believe that my early choices to do
things “this way” are paying off for the project.  While not 100% frictionless,
the minimal effort that I require to write new rules is challenging but not difficult,
increasing the “fun quotient” for the project.&lt;/p&gt;
&lt;p&gt;I honestly couldn’t wait to keep the progress going with the next set of rules.&lt;/p&gt;
&lt;h2 id="what-is-next"&gt;What is Next?&lt;a class="headerlink" href="#what-is-next" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Without much fanfare, since this first group of 5 heading rules was accomplished
with ease, next on the list if the second group of 5 rules.  I do hope that I
will have a similar result with those rules!&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr/&gt;
&lt;ol&gt;
&lt;li id="fn:closeAtx"&gt;
&lt;p&gt;Look for any &lt;code&gt;#&lt;/code&gt; character followed by any number of whitespace characters, anchored to the end of the line. &lt;a class="footnote-backref" href="#fnref:closeAtx" title="Jump back to footnote 1 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:yes"&gt;
&lt;p&gt;Yes, I am still kicking myself over that, just not as much. &lt;a class="footnote-backref" href="#fnref:yes" title="Jump back to footnote 2 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</content><category term="Software Quality"></category><category term="markdown linter"></category><category term="linter rules"></category></entry><entry><title>Markdown Linter - Rules - The First Three</title><link href="https://jackdewinter.github.io/2020/05/11/markdown-linter-rules-the-first-three/" rel="alternate"></link><published>2020-05-11T00:00:00-07:00</published><updated>2020-05-11T00:00:00-07:00</updated><author><name>Jack De Winter</name></author><id>tag:jackdewinter.github.io,2020-05-11:/2020/05/11/markdown-linter-rules-the-first-three/</id><summary type="html">
&lt;h2 id="introduction"&gt;Introduction&lt;a class="headerlink" href="#introduction" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;With some solid refactoring work completed, it was time for me to write the first set
of rules based on all that hard work.  To start things off, I planned to work on 2-3
rules that would verify that I had created an acceptable framework for writing and
evaluating …&lt;/p&gt;</summary><content type="html">
&lt;h2 id="introduction"&gt;Introduction&lt;a class="headerlink" href="#introduction" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;With some solid refactoring work completed, it was time for me to write the first set
of rules based on all that hard work.  To start things off, I planned to work on 2-3
rules that would verify that I had created an acceptable framework for writing and
evaluating Markdown linting rules.  As
&lt;a href="https://github.com/DavidAnson/markdownlint"&gt;David Anson’s MarkDownLint&lt;/a&gt;
plugin for VSCode already has a number of rules defined, it made sense to pick a
handful of rules from there as a starting point.  This choice was also fitting, as
David’s NPM-based project was the inspiration for my Python-based project.&lt;/p&gt;
&lt;p&gt;But how to pick the rules to start with?  One of my criteria was that whatever
set of rules that I picked, I wanted to be able to extend the set  of rules naturally
once I finished proving the first few rules were able to be clearly written.  The other
criteria that I wanted was for those initial rules to be a good cross-section of what to
expect in the other rules.&lt;/p&gt;
&lt;p&gt;Based on those criteria and some quick thinking on my part, it took me less than 2
minutes to realized that the first three rules in David’s check list would do just fine!&lt;/p&gt;
&lt;h2 id="why-is-this-article-so-long"&gt;Why Is This Article So Long?&lt;a class="headerlink" href="#why-is-this-article-so-long" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;To be honest, this article got away from me.  Without breaking down this article into
3 articles, each one focusing on its own rule, I couldn’t see any intermediate
solutions for breaking up the article.  These are the first three rules I wrote for the
project, and as such, they laid the foundation for all the other rules.  It just
did not seem right to artificially break up the article.&lt;/p&gt;
&lt;h2 id="what-is-the-audience-for-this-article"&gt;What Is the Audience for This Article?&lt;a class="headerlink" href="#what-is-the-audience-for-this-article" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;While detailed more eloquently in
&lt;a href="https://jackdewinter.github.io/2020/04/05/what-is-the-audience-for-my-blog/#what-is-the-audience-for-my-blog"&gt;this article&lt;/a&gt;,
my goal for this technical article is to focus on the reasoning behind my solutions,
rather that the solutions themselves.  For a full record of the solutions presented in
this article, please go to this project’s GitHub repository and consult the
commits between
&lt;a href="https://github.com/jackdewinter/pymarkdown/commit/c9e487dcf47b9fce0bdf4ccf6e5af26507a06c65"&gt;17 April 2020&lt;/a&gt; and
&lt;a href="https://github.com/jackdewinter/pymarkdown/commit/2425a81be8b95ed891cb210e8bdfa4d7de126f6a"&gt;23 April 2020&lt;/a&gt;, except for the commit from
&lt;a href="https://github.com/jackdewinter/pymarkdown/commit/562600457654234aa7cabefa8e2a6b56665d936c"&gt;18 April 2020&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id="why-the-first-three-rules"&gt;Why the First Three Rules?&lt;a class="headerlink" href="#why-the-first-three-rules" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Given that David Anson’s work was the inspiration for this project, it made sense to
start with those rules,
&lt;a href="https://github.com/DavidAnson/markdownlint/blob/master/doc/Rules.md#rules"&gt;outlined here&lt;/a&gt;.
The first three of those rules easily meet the first criteria, as all three rules deal
with examining the headings in a Markdown document.  Doing a quick count of all the
rules that dealt with headings, I counted 15 such rules.  Definitely qualifies as
extensible.&lt;/p&gt;
&lt;p&gt;As for the second criteria, the first rule is a standard rule, the second rule is a
disabled rule, and the third rule has configuration that affects how the rule is
measured.  Between the three of them, I had a lot of confidence that together they
would represent a good cross-section of all rules, and therefore satisfy the
second criteria nicely.&lt;/p&gt;
&lt;p&gt;With the three rules selected and a confirmation that these three rules satisfied my
criteria, it was time to move forward with implementation.&lt;/p&gt;
&lt;h2 id="a-quick-aside"&gt;A Quick Aside&lt;a class="headerlink" href="#a-quick-aside" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Are they &lt;code&gt;headings&lt;/code&gt; or &lt;code&gt;headers&lt;/code&gt;?  While some of my cheat sheet resources like the
&lt;a href="https://www.markdownguide.org/cheat-sheet"&gt;Markdown Guide’s Cheat Sheet&lt;/a&gt;
refer to them as &lt;code&gt;headings&lt;/code&gt;, other resources like
&lt;a href="https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet"&gt;Adam Pritchard’s Cheatsheet&lt;/a&gt;
refer to them as &lt;code&gt;headers&lt;/code&gt;.  Even the
&lt;a href="https://spec.commonmark.org/0.29/#atx-headings"&gt;CommonMark specification&lt;/a&gt;
refers to them as &lt;code&gt;headings&lt;/code&gt;, but then include a couple of times where the term
&lt;code&gt;header&lt;/code&gt; is used instead of &lt;code&gt;heading&lt;/code&gt;.  So which one is right?&lt;sup id="fnref:cheatSheet"&gt;&lt;a class="footnote-ref" href="#fn:cheatSheet"&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;p&gt;To keep things simple, I am going to use the term &lt;code&gt;heading&lt;/code&gt; in this article and my
other articles that deal with headings going forward.  That term seems to be the one
that is most dominant in the specification, and I believe that the authors of the
specification had a good reason for specifically using the term &lt;code&gt;heading&lt;/code&gt;.  Even if
that reason is not documented.&lt;/p&gt;
&lt;h2 id="rule-md001-incrementing-heading-levels"&gt;Rule MD001 - Incrementing Heading Levels&lt;a class="headerlink" href="#rule-md001-incrementing-heading-levels" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;This section describes the initial implementation of PyMarkdown’s
&lt;a href="https://github.com/jackdewinter/pymarkdown/blob/master/pymarkdown/plugins/rule_md_001.py"&gt;Rule MD001&lt;/a&gt;.  Feel free to examine the code at your convenience.&lt;/p&gt;
&lt;h3 id="why-does-this-rule-make-sense"&gt;Why Does This Rule Make Sense?&lt;a class="headerlink" href="#why-does-this-rule-make-sense" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;This rule is simple: when using headings, the heading level should at most
increase by one.  Based largely on the
&lt;a href="https://www.w3.org/WAI/tutorials/page-structure/headings/"&gt;W3C’s Accessibility Guidelines&lt;/a&gt;,
this rule just makes sense even without those accessibility guidelines.  If you have a
heading, and you want subsections under that heading, you use a heading level that is
one below the current one.  Consider this example:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;# &lt;span class="nv"&gt;What&lt;/span&gt; &lt;span class="nv"&gt;I&lt;/span&gt; &lt;span class="nv"&gt;Did&lt;/span&gt; &lt;span class="nv"&gt;On&lt;/span&gt; &lt;span class="nv"&gt;My&lt;/span&gt; &lt;span class="nv"&gt;Summer&lt;/span&gt; &lt;span class="nv"&gt;Vacation&lt;/span&gt;

&lt;span class="nv"&gt;I&lt;/span&gt; &lt;span class="nv"&gt;did&lt;/span&gt; &lt;span class="nv"&gt;a&lt;/span&gt; &lt;span class="nv"&gt;lot&lt;/span&gt; &lt;span class="nv"&gt;of&lt;/span&gt; &lt;span class="nv"&gt;things&lt;/span&gt;.

## &lt;span class="nv"&gt;July&lt;/span&gt;

&lt;span class="nv"&gt;July&lt;/span&gt; &lt;span class="nv"&gt;is&lt;/span&gt; &lt;span class="nv"&gt;when&lt;/span&gt; &lt;span class="nv"&gt;it&lt;/span&gt; &lt;span class="nv"&gt;started&lt;/span&gt;.

### &lt;span class="nv"&gt;The&lt;/span&gt; &lt;span class="nv"&gt;Pool&lt;/span&gt;

&lt;span class="nv"&gt;I&lt;/span&gt; &lt;span class="nv"&gt;went&lt;/span&gt; &lt;span class="nv"&gt;to&lt;/span&gt; &lt;span class="nv"&gt;the&lt;/span&gt; &lt;span class="nv"&gt;pool&lt;/span&gt; &lt;span class="nv"&gt;every&lt;/span&gt; &lt;span class="nv"&gt;day&lt;/span&gt;.

#### &lt;span class="nv"&gt;Swim&lt;/span&gt; &lt;span class="nv"&gt;Classes&lt;/span&gt;

&lt;span class="nv"&gt;Mom&lt;/span&gt; &lt;span class="nv"&gt;made&lt;/span&gt; &lt;span class="nv"&gt;me&lt;/span&gt; &lt;span class="k"&gt;do&lt;/span&gt; &lt;span class="nv"&gt;this&lt;/span&gt;, &lt;span class="nv"&gt;again&lt;/span&gt;&lt;span class="o"&gt;!&lt;/span&gt;

## &lt;span class="nv"&gt;August&lt;/span&gt;

&lt;span class="nv"&gt;This&lt;/span&gt; &lt;span class="nv"&gt;is&lt;/span&gt; &lt;span class="nv"&gt;when&lt;/span&gt; &lt;span class="nv"&gt;everything&lt;/span&gt; &lt;span class="nv"&gt;seemed&lt;/span&gt; &lt;span class="nv"&gt;repetitive&lt;/span&gt;.

### &lt;span class="nv"&gt;The&lt;/span&gt; &lt;span class="nv"&gt;Pool&lt;/span&gt;

&lt;span class="nv"&gt;I&lt;/span&gt; &lt;span class="nv"&gt;got&lt;/span&gt; &lt;span class="nv"&gt;really&lt;/span&gt; &lt;span class="nv"&gt;sick&lt;/span&gt; &lt;span class="nv"&gt;of&lt;/span&gt; &lt;span class="nv"&gt;the&lt;/span&gt; &lt;span class="nv"&gt;pool&lt;/span&gt;.
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;While it does accurately detail most of my summer vacations as a kid, I believe that it
is also a decent example of a report with the various highlights of each section
organized under their own headings.  It makes sense to
begin the document with the level 1 heading describing what the document is all about.
From there, it logically follows that to break the document up, there should be level 2
headings with the month names, each heading containing text specific to that month.
As going to the local pool was the major part of each summer, it therefore follows that
each of the months has its own level 3 heading under which I talk about what I did at
the pool during that month.  Finally, swim classes were deemed mandatory by my mother,
so me and my siblings took at least one session of swim classes each summer.  Detailing
those classes in the month they happened, under a level 4 heading, just seems to be the
right thing to do.  As a matter of fact, this example reminds me a lot of the
“returning to school” report that my mother made us right just before school started,
just to ensure that our waterlogged brains still remembered how to write properly.
Thanks Mom!&lt;/p&gt;
&lt;p&gt;Putting my reminiscing about summers as a kid aside, take another look at the headings
and the text, observing the natural progression for heading levels, as detailed in the
last paragraph.  For me, the headings and their levels just feel right, their flow is
natural and not jarring.  When I need to get more specific with information in each
section, I used a new heading one level down from the current heading and added that
more specific information under the new heading.  From my point of view, it just worked,
and I really did not need to think about why it worked… it just did.&lt;/p&gt;
&lt;p&gt;Specifically looking at the heading levels themselves, while there is a case where the
heading levels decrease by more than 1, there are no cases where the heading level
does not increase by 1.  As an author, it just made sense to author the report like
that, adding more detail with a lower heading and a lower subsection, and then popping
back up to the right level to continue.   While there may have been a scenario in which
the &lt;code&gt;Swim Classes&lt;/code&gt; section was followed by a level 3 heading and more text, it was not
required.  In fact, I believe that my freedom to not follow up that section with a
“garbage” level 3 heading and section text are what makes the flow of the headings
work as they do.&lt;/p&gt;
&lt;p&gt;While I might have taken the long way around in describing my theory behind this rule,
to me it simply just makes sense both as an author and as a reader.&lt;/p&gt;
&lt;h3 id="adding-the-rule"&gt;Adding the Rule&lt;a class="headerlink" href="#adding-the-rule" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;This was my first rule using the built-in parser, so I wanted to make sure to lay down
some good patterns for myself to repeat going forward.&lt;/p&gt;
&lt;h4 id="pattern-test-format"&gt;Pattern: Test Format&lt;a class="headerlink" href="#pattern-test-format" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;The first pattern I wanted to set in stone is the pattern to specify how to execute
tests for a given rule. After experimenting with different formats and combinations,
it was the proven test format that I chose
&lt;a href="https://github.com/jackdewinter/pymarkdown/commit/04222e24fdfb4c0f2d5c0e768516590a0140bb63#diff-0f4bc6824d3dcdb712fd4a5305ff4e4f"&gt;back in November&lt;/a&gt;
that won out.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;test_md0047_good_description&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
    &lt;span class="sd"&gt;"""&lt;/span&gt;
&lt;span class="sd"&gt;    Test to make sure...&lt;/span&gt;
&lt;span class="sd"&gt;    """&lt;/span&gt;

    &lt;span class="c1"&gt;# Arrange&lt;/span&gt;
    &lt;span class="n"&gt;scanner&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;MarkdownScanner&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="n"&gt;suppplied_arguments&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;"test/resources/rules/md047/some_test_file.md"&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;

    &lt;span class="n"&gt;expected_return_code&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;
    &lt;span class="n"&gt;expected_output&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;""&lt;/span&gt;
    &lt;span class="n"&gt;expected_error&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;""&lt;/span&gt;

    &lt;span class="c1"&gt;# Act&lt;/span&gt;
    &lt;span class="n"&gt;execute_results&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;scanner&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;invoke_main&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;arguments&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;suppplied_arguments&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="c1"&gt;# Assert&lt;/span&gt;
    &lt;span class="n"&gt;execute_results&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;assert_results&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="n"&gt;expected_output&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;expected_error&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;expected_return_code&lt;/span&gt;
    &lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This format keeps things simple: a descriptive function name, a decent function
description, and simple boiler-plate code for the function that can be applied to most
tests.  Even in cases where I had to add some extra code, such as adding a
configuration file for the linter
to read in and use, those changes were always applied on top of this template code,
not instead of it.
And except for those additions, only the variables &lt;code&gt;supplied_arguments&lt;/code&gt;,
&lt;code&gt;expected_return_code&lt;/code&gt;, &lt;code&gt;expected_output&lt;/code&gt;, and
&lt;code&gt;expected_error&lt;/code&gt; were ever changed for any of the tests, even to this day.&lt;/p&gt;
&lt;p&gt;Basically, my plan was to create the template once, put it through a trial of fire to
test it, and then reuse it endlessly once proven.  Keep it effective by keeping it
simple.  As Isaac Newton said:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Truth is ever to be found in the simplicity, and not in the multiplicity and confusion of things.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4 id="pattern-creating-a-new-rule"&gt;Pattern: Creating a New Rule&lt;a class="headerlink" href="#pattern-creating-a-new-rule" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;Translating the logic described under the section
&lt;a href="https://jackdewinter.github.io/2020/05/11/markdown-linter-rules-the-first-three/#why-does-this-rule-make-sense"&gt;Why Does This Rule Make Sense?&lt;/a&gt;
into Python code was easy.  First, I created the tests cases described above, and
examined the debug information output for those cases, specifically looking at what the
final sequence of tokens was.  As all the information for the rules was contained
within the instances of the &lt;code&gt;AtxHeaderMarkdownToken&lt;/code&gt; or
the &lt;code&gt;SetextHeaderMarkdownToken&lt;/code&gt;&lt;sup id="fnref:here"&gt;&lt;a class="footnote-ref" href="#fn:here"&gt;2&lt;/a&gt;&lt;/sup&gt;, those were the only two tokens I had to worry
about.&lt;/p&gt;
&lt;p&gt;With that knowledge in hand, it was time to move to the second pattern that I wanted to
repeat: creating a new
rule.  While the content of each rule changes, this process is always consistent.
First, I pick a test to clone from and copy its contents into a new file.  In this
initial case, I copied the file &lt;code&gt;rule_md_047.py&lt;/code&gt; into the file
&lt;code&gt;rule_md_001.py&lt;/code&gt;.  Any initialization for each rule is performed in the
&lt;code&gt;starting_new_file&lt;/code&gt; function, so that function is cleaned out except for the comment.
Finally, the &lt;code&gt;next_token&lt;/code&gt; is cleaned out in the same way, to provide for a clean slate
to start writing the rule with.  For this rule, &lt;code&gt;rule_md_047.py&lt;/code&gt; used the &lt;code&gt;next_line&lt;/code&gt;
function, so that needed to be changed to override the &lt;code&gt;next_token&lt;/code&gt; function instead,
as this rule is specifically token based.  Except for this one special case, this
pattern has now been replicated for each rule in the project.&lt;/p&gt;
&lt;h4 id="pattern-creating-the-initial-tests"&gt;Pattern: Creating the Initial Tests&lt;a class="headerlink" href="#pattern-creating-the-initial-tests" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;The third pattern that I wanted to get in place was specifying a good set of initial
test cases for the rule, prior to writing the rule itself.  A strong proponent of
test-driven development, I believe that before writing the source code, at least a
rough outline of the test code and test data should be written.&lt;/p&gt;
&lt;p&gt;A common misconception of test-driven development is that before you write any code,
you write all the tests.  The process is an iterative process, one
that grows over time.  While this entire process is the pattern that I want to
enshrine in this project, the important part that I want to tackle at this point is
coming up with a good set of tests and test data to start with.&lt;/p&gt;
&lt;p&gt;For this project, this initial set of tests and test data are made easy by the
existing MarkdownLint rules
&lt;a href="https://github.com/DavidAnson/markdownlint/blob/master/doc/Rules.md#rules"&gt;outlined here&lt;/a&gt;.
While the rules outlined there do not always have a comprehensive set of Markdown
documents to test that rule, they always document at least one good
Markdown document and one bad Markdown document.  If there was something obvious that
is missing, I also try and add it at this point, just to save iterations later. But
just in case I miss something, I have another pattern,
&lt;a href="https://jackdewinter.github.io/2020/05/11/markdown-linter-rules-the-first-three/#pattern-thorough-rule-validation"&gt;Thorough Rule Validation&lt;/a&gt;,
that I will talk about later to try and catch those missed cases.&lt;/p&gt;
&lt;h4 id="implementing-the-rule"&gt;Implementing the Rule&lt;a class="headerlink" href="#implementing-the-rule" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;Once things were setup, it was time to add the logic.  A false failure is not desired
when a new document is started, so I added a reset of the &lt;code&gt;last_header_count&lt;/code&gt; class
variable in the &lt;code&gt;starting_new_file&lt;/code&gt; function.  In the &lt;code&gt;next_token&lt;/code&gt; function, I then
added some simple code to test whether the token was one of the two heading tokens, and
if so, set the &lt;code&gt;hash_count&lt;/code&gt; variable to a non-None value.  At this point, I added some
debug to the function and ran each of the test cases against the rule, checking to see
whether what I expected to happen, did happen.&lt;/p&gt;
&lt;p&gt;As this rule implements simple logic, the initial logic was validated on my first try.
Removing the debug statements, I added some logic to filter out any cases where
&lt;code&gt;last_header_count&lt;/code&gt; was not set (initial case) or where &lt;code&gt;header_count&lt;/code&gt; was not greater
than &lt;code&gt;last_header_count&lt;/code&gt; (not increasing).  With those cases filtered out, it was
simple to
check for an increase of 1 and to fail if the increase was more than 1.  A quick
call to &lt;code&gt;report_next_token_error&lt;/code&gt; to report the failure, and the basic case was
completed.&lt;/p&gt;
&lt;p&gt;From there, I circled back to the test data, and looked to see if there were any
obvious cases that I was missing.  It was then that I noticed that the text’s
description specified headings, but had no test data for SetExt headings, just
Atx headings.  I quickly crafted some data that mixed a SetExt heading followed by
a valid and invalid Atx heading and iterated through the process again.  It was
only after I was sure that I had not missed anything obvious that I proceeded
to the next pattern: Thorough Rule Validation.&lt;/p&gt;
&lt;h4 id="pattern-thorough-rule-validation"&gt;Pattern: Thorough Rule Validation&lt;a class="headerlink" href="#pattern-thorough-rule-validation" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;The final pattern that I wanted to put into place was to be thorough in my rule
validation, using both internal data sources and external data sources.&lt;/p&gt;
&lt;p&gt;The validation against the internal data sources was easy, as I had just finished the
source code
and the tests code for that rule.  However, I put that aside and instead ignored the
source code in favor of the the definition of the rule’s scenario along with the
test data.  Based on those two factors alone, I predicted what the outcome of the test
should be, then executed the test to verify that prediction.&lt;/p&gt;
&lt;p&gt;If I encountered an error, the first step I took was to recheck the expected output
more rigorously against the rule’s scenario and the test data.  Whenever doing this, I
rechecked the output multiple times just to make sure I had the right answer.  From
my experience, unless I try very hard, it is unlikely that I will make the same mistake
twice.  If there was an error in the output, I corrected the error and executed the
tests again, as if from the beginning of this section.  If there was an error in the
rule itself, I would add some debug to the rule and run further tests to check what
refinements I needed to make, before restarting all the tests in this section.&lt;/p&gt;
&lt;p&gt;For this initial rule, I had errors in the test data and the rule, and this attention
to detail helped me spot them quickly.  After a few iterations, I was confident
that the validation against internal data sources was completed, and I needed to move
on to an external data source.  As the MarkDownLint implementation of the rules was
done as a VSCode plugin, it made sense to use VSCode + MarkDownLint as the external
validation source.&lt;/p&gt;
&lt;p&gt;It was with great confidence that I I loaded up the sample files into VSCode to check
against MarkDownLint.  It was when I looked at VSCode’s Problems tab that I got a big
surprise.  I had forgotten something important: line numbers and column numbers.&lt;/p&gt;
&lt;h4 id="line-numbers-and-column-numbers"&gt;Line Numbers and Column Numbers&lt;a class="headerlink" href="#line-numbers-and-column-numbers" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;To say this hit me like a ton of bricks would not do it justice.  I was floored.
I was so focused on getting the parsing of the tokens done accurately, I completely
forgot to design and implement a way to place the location of the element in the
Markdown document into their tokens.  It was hard to miss the issue:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;MD001/heading-increment/header-increment:
  Heading levels should only increment by one level at a time
  [Expected: h3; Actual: h4] markdownlint(MD001) [4,1]
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Honestly, I took me a bit to get over this.  It was so obvious to me that I should
have seen this ahead of time.  When you are reporting any type of linting failure, you
need to specify the location of that failure so that the user can fix it.  Without
that information, the rule is somewhat useless.&lt;/p&gt;
&lt;p&gt;In the present as I am writing this article, I can better understand what happened
and how I missed those number.  However, at the time I struggled to find an interim
solution until I could start to tackle this properly.  I needed to focus on the
first cohort of rules, so I tried to put this mishap out of my mind.  It was after
some a couple of frustrating hours that I added two fields to track the line number and
column number of the tokens, setting both to 0.&lt;/p&gt;
&lt;p&gt;After some additional “yelling” at my monitor, I decided to close out that first rule,
and moved one to the second rule, confident that I (mostly) had set up some solid
patterns to focus on for the future rules.&lt;/p&gt;
&lt;h2 id="rule-md002-deprecated-first-heading-should-be-top-level"&gt;Rule MD002 - (Deprecated) First Heading Should Be Top Level&lt;a class="headerlink" href="#rule-md002-deprecated-first-heading-should-be-top-level" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;This section describes the initial implementation of PyMarkdown’s
&lt;a href="https://github.com/jackdewinter/pymarkdown/blob/master/pymarkdown/plugins/rule_md_002.py"&gt;Rule MD002&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id="why-does-this-rule-not-make-sense"&gt;Why Does This Rule (Not) Make Sense?&lt;a class="headerlink" href="#why-does-this-rule-not-make-sense" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Note the slightly different wording of the heading.  As documented on the
&lt;a href="https://github.com/DavidAnson/markdownlint/blob/master/doc/Rules.md#md002---first-heading-should-be-a-top-level-heading"&gt;MarkdownLint site&lt;/a&gt;,
this rule has been replaced by
&lt;a href="https://github.com/DavidAnson/markdownlint/blob/master/doc/Rules.md#md041---first-line-in-file-should-be-a-top-level-heading"&gt;rule MD041&lt;/a&gt;.
The important difference between the two rules is that MD002 looks at Atx headings
and SetExt headings, while rule MD041 also looks at the metadata at the start of the
document, often referred to as YAML front matter.  Because there is an improved rule,
this rule is disabled by default in favor of that rule.&lt;/p&gt;
&lt;p&gt;Whether in rule MD002 or rule MD047, the reasoning for both rules is consistent: each
document should contain a clean title.  For both rules, this is achieved by looking at
the first Atx heading or SetExt heading in the document and verifying that the first
heading is a level 1 heading.  For rule MD047, the only difference from rule MD002 is
that it additionally looks for a specific metadata field that can take the place of an
explicit level 1 heading.&lt;/p&gt;
&lt;p&gt;A good example of rule MD002 is the standard &lt;code&gt;readme.md&lt;/code&gt; file that I usually add at
the base of a GitHub project.  Typically, I start with a file that looks like this:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;#&lt;/span&gt; &lt;span class="n"&gt;ReadMe&lt;/span&gt;

&lt;span class="n"&gt;This&lt;/span&gt; &lt;span class="n"&gt;file&lt;/span&gt; &lt;span class="n"&gt;describes&lt;/span&gt; &lt;span class="n"&gt;what&lt;/span&gt; &lt;span class="n"&gt;the&lt;/span&gt; &lt;span class="n"&gt;project&lt;/span&gt; &lt;span class="n"&gt;does&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;who&lt;/span&gt; &lt;span class="k"&gt;to&lt;/span&gt; &lt;span class="n"&gt;contact&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;etc&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;While the title is simplistic, it does present a clear indication of what the title and
purpose of the document is.  If, on the other hand, you see a Markdown document like:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;Lorem&lt;/span&gt; &lt;span class="n"&gt;ipsum&lt;/span&gt; &lt;span class="n"&gt;dolor&lt;/span&gt; &lt;span class="n"&gt;sit&lt;/span&gt; &lt;span class="n"&gt;amet&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;consectetur&lt;/span&gt; &lt;span class="n"&gt;adipiscing&lt;/span&gt; &lt;span class="n"&gt;elit&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt; &lt;span class="n"&gt;Phasellus&lt;/span&gt; &lt;span class="n"&gt;felis&lt;/span&gt; &lt;span class="n"&gt;lacus&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;finibus&lt;/span&gt;
&lt;span class="n"&gt;eget&lt;/span&gt; &lt;span class="n"&gt;gravida&lt;/span&gt; &lt;span class="n"&gt;eget&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dapibus&lt;/span&gt; &lt;span class="n"&gt;vel&lt;/span&gt; &lt;span class="n"&gt;lacus&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt; &lt;span class="n"&gt;Phasellus&lt;/span&gt; &lt;span class="n"&gt;placerat&lt;/span&gt; &lt;span class="n"&gt;nisi&lt;/span&gt; &lt;span class="n"&gt;enim&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;eu&lt;/span&gt; &lt;span class="n"&gt;maximus&lt;/span&gt; &lt;span class="n"&gt;ipsum&lt;/span&gt;
&lt;span class="n"&gt;congue&lt;/span&gt; &lt;span class="n"&gt;nec&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt; &lt;span class="nb"&gt;Integer&lt;/span&gt; &lt;span class="n"&gt;sollicitudin&lt;/span&gt; &lt;span class="n"&gt;metus&lt;/span&gt; &lt;span class="n"&gt;urna&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;quis&lt;/span&gt; &lt;span class="n"&gt;iaculis&lt;/span&gt; &lt;span class="n"&gt;ligula&lt;/span&gt; &lt;span class="n"&gt;condimentum&lt;/span&gt; &lt;span class="n"&gt;eu&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;it is hard to figure out what this document is for.  Simply by adding a title heading,
this can be cleared up.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;# &lt;span class="k"&gt;Random&lt;/span&gt; &lt;span class="nv"&gt;Test&lt;/span&gt; &lt;span class="nv"&gt;Paragraphs&lt;/span&gt;

&lt;span class="nv"&gt;Lorem&lt;/span&gt; &lt;span class="nv"&gt;ipsum&lt;/span&gt; &lt;span class="nv"&gt;dolor&lt;/span&gt; &lt;span class="nv"&gt;sit&lt;/span&gt; &lt;span class="nv"&gt;amet&lt;/span&gt;, &lt;span class="nv"&gt;consectetur&lt;/span&gt; &lt;span class="nv"&gt;adipiscing&lt;/span&gt; &lt;span class="nv"&gt;elit&lt;/span&gt;. &lt;span class="nv"&gt;Phasellus&lt;/span&gt; &lt;span class="nv"&gt;felis&lt;/span&gt; &lt;span class="nv"&gt;lacus&lt;/span&gt;, &lt;span class="nv"&gt;finibus&lt;/span&gt;
&lt;span class="nv"&gt;eget&lt;/span&gt; &lt;span class="nv"&gt;gravida&lt;/span&gt; &lt;span class="nv"&gt;eget&lt;/span&gt;, &lt;span class="nv"&gt;dapibus&lt;/span&gt; &lt;span class="nv"&gt;vel&lt;/span&gt; &lt;span class="nv"&gt;lacus&lt;/span&gt;. &lt;span class="nv"&gt;Phasellus&lt;/span&gt; &lt;span class="nv"&gt;placerat&lt;/span&gt; &lt;span class="nv"&gt;nisi&lt;/span&gt; &lt;span class="nv"&gt;enim&lt;/span&gt;, &lt;span class="nv"&gt;eu&lt;/span&gt; &lt;span class="nv"&gt;maximus&lt;/span&gt; &lt;span class="nv"&gt;ipsum&lt;/span&gt;
&lt;span class="nv"&gt;congue&lt;/span&gt; &lt;span class="nv"&gt;nec&lt;/span&gt;. &lt;span class="nv"&gt;Integer&lt;/span&gt; &lt;span class="nv"&gt;sollicitudin&lt;/span&gt; &lt;span class="nv"&gt;metus&lt;/span&gt; &lt;span class="nv"&gt;urna&lt;/span&gt;, &lt;span class="nv"&gt;quis&lt;/span&gt; &lt;span class="nv"&gt;iaculis&lt;/span&gt; &lt;span class="nv"&gt;ligula&lt;/span&gt; &lt;span class="nv"&gt;condimentum&lt;/span&gt; &lt;span class="nv"&gt;eu&lt;/span&gt;.
&lt;/pre&gt;&lt;/div&gt;
&lt;h3 id="adding-the-rule_1"&gt;Adding the Rule&lt;a class="headerlink" href="#adding-the-rule_1" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Having previously explained my process for
&lt;a href="https://jackdewinter.github.io/2020/05/11/markdown-linter-rules-the-first-three/#adding-the-rule"&gt;adding new rules&lt;/a&gt;,
I’ll leave that content out from here on, and just concentrate on what has changed.&lt;/p&gt;
&lt;p&gt;The logic for this rule is almost exactly the same as for the previously implemented
rule
&lt;a href="https://jackdewinter.github.io/2020/05/11/markdown-linter-rules-the-first-three/#rule-md001-incrementing-heading-levels"&gt;MD001&lt;/a&gt;,
except that instead of checking for an increase in the heading level,
it simply looks to see if the first heading it encounters has a heading level of 1.
The implementation of this rule introduced two new concepts: rule configuration and
disabling a rule by default.  While the next rule,
&lt;a href="https://jackdewinter.github.io/2020/05/11/markdown-linter-rules-the-first-three/#rule-md003-heading-style"&gt;MD003&lt;/a&gt;,
will properly deal with the configuration aspect, the main focus of this rule is the
ability to add a rule that is disabled by default.&lt;/p&gt;
&lt;p&gt;To provide options to the user, adding a rule that is disabled has merit.  In this
case, a new rule was added that is more comprehensive than this rule. However, rather
than removing this rule and possibly breaking the configuration of some users, the
original rule was preserved for users that are not comfortable updating their linting
to use the more comprehensive rule.  In addition, there is also a good
argument to be made for new rules to be added in a disabled state, allowing people who
are upgrading to a new version of the project to control which new features they want.
As both examples illustrate, having a rule be disabled by default is a useful feature
to have.&lt;/p&gt;
&lt;p&gt;The code to allow for a rule to be disabled by default was added back in November when
I was testing out the plugin manager concept.  While there was a good test of the
disable feature at that time, it was now time to really test its functionality with
this rule.  This testing was achieved by looking back at the test data for MD001 and
noticing that the first heading in the file &lt;code&gt;improper_setext_header_incrementing.md&lt;/code&gt; is
a level 2 heading.  That means that if rule MD002 is enabled and executed for that
Markdown file, I would expect a failure to occur.  Therefore, when I executed the
MD001 tests again, with rule MD002 in its default disabled state, I expected that no
additional failures would be reported.  I executed that tests, and this behavior is
exactly what I saw in the results.  For me, that was enough proof that the rule was
disabled by default.  &lt;/p&gt;
&lt;p&gt;To properly test this disabled rule, only a slight change to my normal process of
testing rules was required.  In addition to the normal information supplied by
the test in the &lt;code&gt;supplied_arguments&lt;/code&gt; variable of the test, the start of that array
was modified to include the elements &lt;code&gt;-e&lt;/code&gt; and &lt;code&gt;MD002&lt;/code&gt;.  As PyMarkdown allows for rules
to be enabled and disabled on the command line, those two additions simply told the
command line to enable (&lt;code&gt;-e&lt;/code&gt;) rule MD002 (&lt;code&gt;MD002&lt;/code&gt;).&lt;/p&gt;
&lt;p&gt;With those changes made to the tests, the rest of the testing went by without incident.&lt;/p&gt;
&lt;h2 id="rule-md003-heading-style"&gt;Rule MD003 - Heading Style&lt;a class="headerlink" href="#rule-md003-heading-style" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;This section describes the initial implementation of PyMarkdown’s
&lt;a href="https://github.com/jackdewinter/pymarkdown/blob/master/pymarkdown/plugins/rule_md_003.py"&gt;Rule MD003&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id="why-does-this-rule-make-sense_1"&gt;Why Does This Rule Make Sense?&lt;a class="headerlink" href="#why-does-this-rule-make-sense_1" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;In a single word: consistency.  I am sure I would not want to read a Markdown document
that had multiple heading styles, such as:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;#&lt;/span&gt; &lt;span class="n"&gt;ATX&lt;/span&gt; &lt;span class="n"&gt;style&lt;/span&gt; &lt;span class="n"&gt;H1&lt;/span&gt;

&lt;span class="o"&gt;##&lt;/span&gt; &lt;span class="n"&gt;Closed&lt;/span&gt; &lt;span class="n"&gt;ATX&lt;/span&gt; &lt;span class="n"&gt;style&lt;/span&gt; &lt;span class="n"&gt;H2&lt;/span&gt; &lt;span class="o"&gt;##&lt;/span&gt;

&lt;span class="n"&gt;Setext&lt;/span&gt; &lt;span class="n"&gt;style&lt;/span&gt; &lt;span class="n"&gt;H1&lt;/span&gt;
&lt;span class="o"&gt;===============&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;It would be a confusing mess!  If I were reviewing that document for someone, I would
tell them to
keep it simple, pick a heading style, and stick to it.  By picking a single, simple
style, it would help any readers know what to expect.&lt;/p&gt;
&lt;p&gt;In terms of styles, there are 6 styles to choose from.  The obvious style, the default
&lt;code&gt;consistent&lt;/code&gt; style, simply looks at the first header and assumes that the style
of that heading will be used for the entire document, &lt;code&gt;atx&lt;/code&gt;, &lt;code&gt;atx_closed&lt;/code&gt; or &lt;code&gt;setext&lt;/code&gt;.
If the user wants to be more
specific about the style, there are two variations on Atx headings styles, and three
variations on SetExt headings styles to choose from.  They take a bit of getting used
to, so let me walk through them.&lt;/p&gt;
&lt;h4 id="atx-headings-vs-atx_closed-headings"&gt;Atx Headings vs Atx_Closed Headings&lt;a class="headerlink" href="#atx-headings-vs-atx_closed-headings" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;For Atx headings, the two variations that are available are &lt;code&gt;atx&lt;/code&gt; and &lt;code&gt;atx_closed&lt;/code&gt;,
demonstrated in the follow example:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;##&lt;/span&gt; &lt;span class="n"&gt;Atx&lt;/span&gt;

&lt;span class="o"&gt;##&lt;/span&gt; &lt;span class="n"&gt;Atx&lt;/span&gt; &lt;span class="n"&gt;Closed&lt;/span&gt; &lt;span class="o"&gt;##&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The only difference between these two variations are that &lt;code&gt;atx_closed&lt;/code&gt; style includes
&lt;code&gt;#&lt;/code&gt; characters at the end of the heading as well as at the beginning.  While the
&lt;a href="https://github.github.com/gfm/"&gt;GFM specification&lt;/a&gt;
has strict requirements that there can only be 1 to 6 &lt;code&gt;#&lt;/code&gt; characters at the start of the
Atx heading, the only requirement for the closing &lt;code&gt;#&lt;/code&gt; characters is that there is at
least one valid &lt;code&gt;#&lt;/code&gt; character.  For any stricter requirements on the closing &lt;code&gt;#&lt;/code&gt;
characters, a new rule would have to be written to add more stringent requirements for
any Markdown documents with the &lt;code&gt;atx_closed&lt;/code&gt; style.&lt;/p&gt;
&lt;h4 id="setext-headings-vs-setext_with_42-headings"&gt;SetExt Headings vs SetExt_With_* Headings&lt;a class="headerlink" href="#setext-headings-vs-setext_with_42-headings" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;For documents that use the SetExt headings, the obvious issue is what to do if the
document requires a level 3 heading, as SetExt headings only support a level 1 and a
level 2 heading.  To handle this case, the &lt;code&gt;setext_with_atx&lt;/code&gt; style is used to specify
that level 1 and level 2 headings remain SetExt, while level 2 to 6 headings are to
use Atx headings, as in the following example:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="gh"&gt;Setext style H1&lt;/span&gt;
&lt;span class="gh"&gt;===============&lt;/span&gt;

&lt;span class="gh"&gt;Setext style H2&lt;/span&gt;
&lt;span class="gh"&gt;---------------&lt;/span&gt;

### ATX style H3
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Without specifying a heading style of &lt;code&gt;setext_with_atx&lt;/code&gt; and relying on an implicitly
or defaulted setting of &lt;code&gt;setext&lt;/code&gt;, the rule would fail on the heading labeled
&lt;code&gt;ATX style H3&lt;/code&gt;.  To round things out, there is also a style variation
&lt;code&gt;setext_with_atx_closed&lt;/code&gt; which has the same behavior as the above example, except using
the &lt;code&gt;atx_closed&lt;/code&gt; style instead of the &lt;code&gt;atx&lt;/code&gt; style.&lt;/p&gt;
&lt;h3 id="adding-the-rule_2"&gt;Adding the Rule&lt;a class="headerlink" href="#adding-the-rule_2" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Back in the description for
&lt;a href="https://jackdewinter.github.io/2020/05/11/markdown-linter-rules-the-first-three/#adding-the-rule_1"&gt;rule MD002&lt;/a&gt;,
I mentioned that I would cover the configuration aspect later, focusing at that
time on the disabling of rules by default.  Having completed the discussion about that
rule, it is now time to talk configuration.  For any readers following along with the
commits in the project’s repository, note that the work for rule configuration was
performed in changes introduced in the commits for both rules MD002 and MD003.&lt;/p&gt;
&lt;h4 id="configuration"&gt;Configuration&lt;a class="headerlink" href="#configuration" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;Configuration was the last component of the rules that I needed to have implemented and
tested thoroughly before implementing more rules.  It was important to me to get
configuration right, as just over half of the initial rules contains some element
of configuration.&lt;/p&gt;
&lt;p&gt;The main part of accepting configuration was to change the &lt;code&gt;main.py&lt;/code&gt; command line
interface to accept a configuration file in the JSON format, verifying that it
was a proper JSON file by parsing it into a simple Python &lt;code&gt;dict&lt;/code&gt; object before
continuing.  Just before the files were scanned, a call was introduced to the new
&lt;code&gt;__load_configuration_and_apply_to_plugins&lt;/code&gt; function, that function performing the
required work to call the &lt;code&gt;initialize_from_config&lt;/code&gt; function in each plugin.  At that
point, if the plugin requires any configuration, it calls the plugin’s
&lt;code&gt;get_configuration_value&lt;/code&gt; function to see if a value of the requested type is present in
the map.&lt;/p&gt;
&lt;p&gt;That might seem like a lot of work, but that work done can be summarized
as: load the configuration, let the plugins know about it, and then let the plugin
retrieve the configuration if required.  Almost everything else surrounding those
actions were either making sure errors were handled properly or making sure that the
correct information was passed properly to the plugin manager.&lt;/p&gt;
&lt;p&gt;Before checking the configuration code in for MD002, and then again for MD003, I
changed various parts of the plugins to request different information from the
configuration store.  It was this extra testing that allowed me to simplify rule MD003.
The initial code for the rule raised an exception if the configuration value did not
match one of the required values.  Based on that testing, I changed it to use the
default value in that case instead.  It just seemed like the right thing to do in
that case.&lt;/p&gt;
&lt;h4 id="the-rule-and-the-tests"&gt;The Rule and The Tests&lt;a class="headerlink" href="#the-rule-and-the-tests" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;Once the configuration was in place, the rest of the development went smoothly.  A
slight change to the Atx heading token was required to report the number of trailing
&lt;code&gt;#&lt;/code&gt; characters, but other than that, the core rules engine was stabilizing with no
other changes.&lt;/p&gt;
&lt;p&gt;The rule itself was somewhat simple but reducing the complexity of the check was a
daunting task.  At first, I wrote the rule with everything in the &lt;code&gt;next_token&lt;/code&gt;
function, which worked decently well.  The first part of that function was a block
of code that figured out two important attributes: the type of heading (&lt;code&gt;atx&lt;/code&gt;,
&lt;code&gt;atx_closed&lt;/code&gt;, or &lt;code&gt;setext&lt;/code&gt;) if the token was a heading token and whether that token
contained a level 1 or level 2 heading token.&lt;/p&gt;
&lt;p&gt;Based on that information, the rest of the code worked out cleanly.  If it was not a
heading token, exit quickly.  If the style was &lt;code&gt;consistent&lt;/code&gt; and this was the first
heading token to be seen, set the style to the heading type of the current token.
With all that out of the way, the actual checking of the styles started.  If the
style was one of the 3 basic styles, a simple comparison determined if the rule
failed or not.  In the &lt;code&gt;*with*&lt;/code&gt; variations for SetExt, the logic was a little more
complicated, mostly dealing with checking the level of the heading. A certain amount
of playing around with the code was required to get all the rules validating
the Markdown in a clean and simple manner.&lt;/p&gt;
&lt;p&gt;The tests themselves were simple as well.  Before starting on the rule, I had
created one test input file
with a positive example for each of the style types.  By changing the configured
style type to apply to the rule, I was able to cover all combinations very quickly.
What were negative cases for some tests became positive tests for other cases, and
vice versa.  The reusability of the data for testing this rule ended up being a big
win.  Instead of 3-5 test documents for each style, the tests only use a total of
5 documents, not including the &lt;code&gt;empty.md&lt;/code&gt; file.  Pretty efficient!&lt;/p&gt;
&lt;p&gt;It was with that battery of tests in place that I worked to reduce the complexity of
the rule.  I won’t try and say I got everything right on the first try. I didn’t.
But having those tests in place helped me figure out where I went wrong and helped
me determine the next changes to make.  Having a good set of tests is pivotal in
being able to refactor any algorithm, and that includes one the project’s rules.&lt;/p&gt;
&lt;h4 id="resolving-conflicts-between-rule-test-data"&gt;Resolving Conflicts Between Rule Test Data&lt;a class="headerlink" href="#resolving-conflicts-between-rule-test-data" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;The one thing that I had to start watching out with this rule was the test data for one
rule raising an error on a previously written rule.  In each of the tests that I wrote,
I specifically wanted to narrow down the testing to that specific rule,
to keep the test more relevant to the rule.  With rules MD001 and MD002 being in the
same area, it was only luck that they did not cause any interference with each other.
For rule &lt;code&gt;MD003&lt;/code&gt;, it caused interference with the test data for the previous 2 rules,
where a consistent style for the input data was not a priority.&lt;/p&gt;
&lt;p&gt;To remove the interference, the PyMarkdown’s disable rule feature was used, the
opposite to the enable rule used in the testing of rule MD002.  Instead of adding the
&lt;code&gt;-e&lt;/code&gt; and &lt;code&gt;MD002&lt;/code&gt;
values to the &lt;code&gt;supplied_arguments&lt;/code&gt; variable, the values &lt;code&gt;--disable-rules&lt;/code&gt; and &lt;code&gt;MD003&lt;/code&gt;
were added.  In the tests for rule MD002, rule MD002 was enabled from the
command line at the same time that rule MD003 was disabled from the command line.&lt;/p&gt;
&lt;p&gt;By applying &lt;code&gt;--disable-rules&lt;/code&gt; and &lt;code&gt;MD003&lt;/code&gt; to the tests for MD001 and MD002, I was
able to resolve the interference from rule MD003 cleanly, getting nice consistent
test results.&lt;/p&gt;
&lt;h2 id="what-was-my-experience-so-far"&gt;What Was My Experience So Far?&lt;a class="headerlink" href="#what-was-my-experience-so-far" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;The first part of my experience that I want to talk about is change and how I handle it.
Specifically, I want to talk about the line and column numbers.  While it was painfully
obvious after comparing the output in VS Code with my output, it really hadn’t crossed
my mind before then.  I was more concerned with the ability to write a solid rule, and
not concerned with the content that would be displayed when that rule detected a
violation.  Sure, I felt like I should have caught that in the design process, and I
gave myself somewhere between 5 minutes and 5 hours to deal with that.&lt;/p&gt;
&lt;p&gt;After that, I noted it in my “to do” document as technical debut, and I just put it
behind me.  That was not an easy thing to do, and my failure to account for that in
my design haunted me for a bit.  In the end, what helped me get over it was looking at
what I did accomplish.  I know it sounds cliché, but in this case, it helped me get
a better perspective on the issue.  What I forgot to do was add support for line numbers
and column numbers. What I did not forget was to build a strong parser that has over
800 test cases that it is passing without fail.  That parser also has a simple
translation layer that can be plugged in to the parser to generate GFM specification
compliant HTML code.  Accomplishing those two feats was not easy.&lt;/p&gt;
&lt;p&gt;On top of accomplishing those two feats was another, more obvious one.  I started in
2019 November with an idea of writing a Markdown linter in Python.  With the three
initial rules that I had just created, I proved to myself that I had made the right
choice in selecting to build a parser for Markdown.  The successful rules just proved
that.  The third feat was writing a parser-based linter for Markdown in Python.&lt;/p&gt;
&lt;p&gt;Yeah, I still feel a bit like a fool for missing something that was obvious, but with
those things in my head, it became easier to let it go.  Instead of focusing on the 1%
that was that design flaw, I made sure to refocus myself on the 99% of the project that
was not a design flaw… and moved forward.&lt;/p&gt;
&lt;h2 id="what-is-next"&gt;What is Next?&lt;a class="headerlink" href="#what-is-next" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Having completed the first set of rules, I decided that it was more important for me
to keep my momentum in creating new rules than to add line numbers and column numbers
to the parser.  Truth be told, I thought that getting some distance from that problem
would help me so it more clearly.  With both reasons in place, I started work on
the next group of heading based rules.&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr/&gt;
&lt;ol&gt;
&lt;li id="fn:cheatSheet"&gt;
&lt;p&gt;To avoid the same issue with “cheat sheet” versus “cheatsheet”, &lt;a href="https://www.dictionary.com/browse/cheat-sheet?s=t"&gt;dictionary.com&lt;/a&gt; says the correct answer is “cheat sheet”. &lt;a class="footnote-backref" href="#fnref:cheatSheet" title="Jump back to footnote 1 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:here"&gt;
&lt;p&gt;It was not until the writing of this article that I formally decided to go with heading over header.  There is now an item in my backlog to make this change throughout the source code. &lt;a class="footnote-backref" href="#fnref:here" title="Jump back to footnote 2 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</content><category term="Software Quality"></category><category term="markdown linter"></category><category term="linter rules"></category></entry><entry><title>Markdown Linter - Core - Pre-Rule Improvements</title><link href="https://jackdewinter.github.io/2020/05/04/markdown-linter-core-pre-rule-improvements/" rel="alternate"></link><published>2020-05-04T00:00:00-07:00</published><updated>2020-05-04T00:00:00-07:00</updated><author><name>Jack De Winter</name></author><id>tag:jackdewinter.github.io,2020-05-04:/2020/05/04/markdown-linter-core-pre-rule-improvements/</id><summary type="html">
&lt;h2 id="introduction"&gt;Introduction&lt;a class="headerlink" href="#introduction" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Way back in 2019 November, I started this project with a bare-bones framework using a
simple dynamic plugin loader.  It was a simple proof of concept to determine whether I
could create the basis for an extensible linter framework in Python.  Once I verified
that I could write that …&lt;/p&gt;</summary><content type="html">
&lt;h2 id="introduction"&gt;Introduction&lt;a class="headerlink" href="#introduction" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Way back in 2019 November, I started this project with a bare-bones framework using a
simple dynamic plugin loader.  It was a simple proof of concept to determine whether I
could create the basis for an extensible linter framework in Python.  Once I verified
that I could write that framework, I implemented a very simple case to test against:
checking to make sure the provided Markdown text ends with an empty line.  While that
rule was easy to implement, it was when I looked for another rule to implement that
I determined that to properly lint Markdown text, I needed a Markdown tokenizing
parser.  From my viewpoint, unless I had a parser that
emitted tokens that were a good representation of the Markdown to lint, the linting
rules that I wanted to write would require too much guess work for my own liking.  If I
wanted to write good, solid rules, I needed to have the right information
available for those rules to act upon.  I needed a Markdown parser that emits Markdown
tokens that I had confidence would be the required, correct information for the rules.&lt;/p&gt;
&lt;p&gt;Having now written such a parser against the
&lt;a href="https://github.github.com/gfm/"&gt;Github Flavored Markdown specification&lt;/a&gt;,
it was time to move on to the next part of the project: writing rules.  However, since
almost 5 months had passed since the project started, there were a few changes
that were required in the linter’s core before I could continue.&lt;/p&gt;
&lt;h2 id="what-is-the-audience-for-this-article"&gt;What Is the Audience for This Article?&lt;a class="headerlink" href="#what-is-the-audience-for-this-article" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;While detailed more eloquently in
&lt;a href="https://jackdewinter.github.io/2020/04/05/what-is-the-audience-for-my-blog/#what-is-the-audience-for-my-blog"&gt;this article&lt;/a&gt;,
my goal for this technical article is to focus on the reasoning behind my solutions,
rather that the solutions themselves.  For a full record of the solutions presented in
this article, please go to this project’s GitHub repository and consult the
commits between
&lt;a href="https://github.com/jackdewinter/pymarkdown/commit/51bb1cf945ad5171bd1c41829a48beceb95a3ab0"&gt;12 April 2020&lt;/a&gt; and
&lt;a href="https://github.com/jackdewinter/pymarkdown/commit/c8ee25446a425cabf9886b65ad1d4922949bbf44"&gt;16 April 2020&lt;/a&gt;, and the commit from
&lt;a href="https://github.com/jackdewinter/pymarkdown/commit/562600457654234aa7cabefa8e2a6b56665d936c"&gt;18 April 2020&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id="source-providers"&gt;Source Providers&lt;a class="headerlink" href="#source-providers" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;In my experience, following the
&lt;a href="https://en.wikipedia.org/wiki/Rule_of_three_(computer_programming)"&gt;threefold rule for refactoring&lt;/a&gt;
is usually a good idea, as its wisdom has borne out true in my projects many times.
While not a
literal copy of the threefold rule, I choose to remember the rule as follows:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Write it once, write it neat.  Write it twice, think about extracting it.  Write it three times, extract it without a second thought.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The original text of “three strikes and you refactor” always seemed a little too harsh
for me with its negative connotation. In addition, I feel that it does not provide good
enough guidance on what to do in the first two cases, just the third one.  My
version of the rule still adheres to the spirit of the original rule, while
fixing the specific issues that I perceive with it.&lt;/p&gt;
&lt;p&gt;Source providers for the parser are a concept that fits that refactoring pattern very
well.  When the
original framework for the parser was written, it was designed to parse a line at a
time to conserve memory.  In the parser tests, this information is provided to the
&lt;code&gt;TokenizedMarkdown&lt;/code&gt; class as a single string, with the internal functions of the
&lt;code&gt;TokenizedMarkdown&lt;/code&gt; class breaking down that data
into individual lines for further processing. With the exception of a single
feature’s error case&lt;sup id="fnref:linkReferenceDefinitionError"&gt;&lt;a class="footnote-ref" href="#fn:linkReferenceDefinitionError"&gt;1&lt;/a&gt;&lt;/sup&gt;, this design has proven to be very
useful in reducing the complexity of the parser.
It made sense to me to refactor this section of code when considering how to
add support for the second source of Markdown data: Markdown files.&lt;/p&gt;
&lt;h3 id="starting-with-the-inmemorysourceprovider"&gt;Starting with the InMemorySourceProvider&lt;a class="headerlink" href="#starting-with-the-inmemorysourceprovider" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Now that the project was moving into the rule-development phase, it was necessary to
ensure that it was just as easy to feed the parser information from a string as it was
to feed it information from a file.  As the initial development
kept things neat, it was relatively simple to take the logic for grabbing the next line
and encapsulate it within the &lt;code&gt;InMemorySourceProvider&lt;/code&gt; class as follows:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;InMemorySourceProvider&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="sd"&gt;"""&lt;/span&gt;
&lt;span class="sd"&gt;    Class to provide for a source provider that is totally within memory.&lt;/span&gt;
&lt;span class="sd"&gt;    """&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="fm"&gt;__init__&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;source_text&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;next_token&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;source_text&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;split&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;get_next_line&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="sd"&gt;"""&lt;/span&gt;
&lt;span class="sd"&gt;        Get the next line from the source provider.&lt;/span&gt;
&lt;span class="sd"&gt;        """&lt;/span&gt;
        &lt;span class="n"&gt;token_to_use&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;None&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;next_token&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;next_token&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="n"&gt;token_to_use&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;next_token&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
                &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;next_token&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;next_token&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;split&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="k"&gt;assert&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;next_token&lt;/span&gt;
                &lt;span class="n"&gt;token_to_use&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;next_token&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
                &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;next_token&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;None&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;token_to_use&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This class contains very simple logic.  When the instance of the class is initialized,
it starts by breaking down the input text into a tuple.  The first element of the
resultant tuple contains the next line to be parsed and the second element of that same
tuple contains the input text to be parsed in the immediate future.  Once that
calculation has been performed, the rest of the processing is relatively simple.
If &lt;code&gt;get_next_line&lt;/code&gt; is called and the tuple contains 2 elements, the first element is
returned as the next line, and the &lt;code&gt;next_token&lt;/code&gt; variable (for next time) is
recalculated using the same expression as was used in the &lt;code&gt;__init__&lt;/code&gt; function.
When the &lt;code&gt;get_next_line&lt;/code&gt; is called at the end of the file, the tuple contains only 1
element.  At that point, that singular element is returned as the next line to be
parsed, and
the &lt;code&gt;next_token&lt;/code&gt; variable is set to &lt;code&gt;None&lt;/code&gt; to make sure we end the processing
properly.  Finally, when &lt;code&gt;get_next_line&lt;/code&gt; is called and the tuple is set to &lt;code&gt;None&lt;/code&gt;,
there is nothing left to parse and &lt;code&gt;None&lt;/code&gt; is returned, signaling that the provider has
reached the end of its available text.&lt;/p&gt;
&lt;p&gt;To be clear, this is the exact code that was in place for the duration of the parser
testing, just repackaged to be in a more reusable form.  Its interface is plain and
simple: it either returns the next line as a string, or it
returns a &lt;code&gt;None&lt;/code&gt; object if there are no more lines.  Nothing fancy as a class either,
just a simple interface: one function to create the instance and get it setup, and one
function to read the next line.&lt;/p&gt;
&lt;h3 id="continuing-with-the-filesourceprovider"&gt;Continuing with the FileSourceProvider&lt;a class="headerlink" href="#continuing-with-the-filesourceprovider" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;By keeping things simple, creating the class &lt;code&gt;FileSourceProvider&lt;/code&gt; was almost as simple
as the refactoring to create the &lt;code&gt;InMemorySourceProvider&lt;/code&gt; class.  While I want to keep
options open for future performance experimentation, I just needed something simple
for reading a file from the file system.  Based on those qualifications, I came up with
this:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;FileSourceProvider&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="sd"&gt;"""&lt;/span&gt;
&lt;span class="sd"&gt;    Class to provide for a source provider that is on media as a file.&lt;/span&gt;
&lt;span class="sd"&gt;    """&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="fm"&gt;__init__&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;file_to_open&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="nb"&gt;open&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;file_to_open&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;encoding&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;"utf-8"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;file_to_parse&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;file_as_lines&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;file_to_parse&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;readlines&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read_lines&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read_index&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;
        &lt;span class="n"&gt;did_line_end_in_newline&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;True&lt;/span&gt;
        &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;next_line&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;file_as_lines&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;did_line_end_in_newline&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;next_line&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;endswith&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;did_line_end_in_newline&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="n"&gt;next_line&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;next_line&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
            &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read_lines&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;next_line&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;did_line_end_in_newline&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read_lines&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;""&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Basically, open the file, read in the lines, and process the lines into the format
that we expect.  The only tricky bit with the class’s &lt;code&gt;__init__&lt;/code&gt; function was handling
line terminators properly.  In fact, that is the only
purpose for the &lt;code&gt;did_line_end_in_newline&lt;/code&gt; variable, remembering if the current line
ended with a newline character before it is removed.  Based on independent unit testing
of the class, I had problems with the characters at the end of the file, which adding
that variable and the final &lt;code&gt;if&lt;/code&gt; statement resolved cleanly.  I am not sure if I feel
that the &lt;code&gt;did_line_end_in_newline&lt;/code&gt; variable is a kludge or not, but I do feel that it
was the right thing to do in order to maintain the fidelity of the data being read in
from the file.&lt;/p&gt;
&lt;p&gt;Because care was taken in the provider’s &lt;code&gt;__init__&lt;/code&gt; function to do all the necessary
processing, the &lt;code&gt;get_next_line&lt;/code&gt; function is very basic:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;get_next_line&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="sd"&gt;"""&lt;/span&gt;
&lt;span class="sd"&gt;        Get the next line from the source provider.&lt;/span&gt;
&lt;span class="sd"&gt;        """&lt;/span&gt;
        &lt;span class="n"&gt;token_to_use&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;None&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read_index&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read_lines&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
            &lt;span class="n"&gt;token_to_use&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read_lines&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read_index&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
            &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read_index&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;token_to_use&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;While this function could be more complicated (or simplified depending on your
viewpoint), I feel that this is a good example of keeping things basic.  The provider
reads the information into an array of strings during the &lt;code&gt;__init__&lt;/code&gt; function, and this
function simply uses an index to iterate through and return each element of that
array.  Nothing fancy for now, just some code that
is very functional.  Fancy code can always be added later.&lt;/p&gt;
&lt;h3 id="testing-the-source-providers"&gt;Testing the Source Providers&lt;a class="headerlink" href="#testing-the-source-providers" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;To make sure both providers are adhering to the interface in the same way, I
added a decent number of tests in the &lt;code&gt;test_source_providers.py&lt;/code&gt; file.  In all the
tests, the big thing that is being tested is if the source providers return the correct
lines given the correct input.  If there are 2 line terminators in the input, each
provider must return 3 lines, even if the last one is empty.  Every test is a variation
on that, thoroughly exercising each provider to ensure that both adhere to the
interface flawlessly.  After all, if the parser gets bad input to tokenize, it cannot
help but to produce bad output, even if is only off by a line terminator.&lt;/p&gt;
&lt;h2 id="replacing-print-with-log"&gt;Replacing Print with Log&lt;a class="headerlink" href="#replacing-print-with-log" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;This improvement was a long time coming: replacing all of the &lt;code&gt;print&lt;/code&gt; statements in the
parser with &lt;code&gt;log.debug&lt;/code&gt; statements.  When I was developing the parser, adding a simple
Python &lt;code&gt;print&lt;/code&gt; statement was the easiest way to add extra debug to the output of the
tests.  This information was pivotal in my ability to debug the parser and quickly
add new features to the parser with confidence.  And in the cases where there were
problems with those features, those same &lt;code&gt;print&lt;/code&gt; statements were also pivotal in
helping me ensure the flow of each function was as I had designed it.&lt;/p&gt;
&lt;p&gt;Why did I avoid using &lt;code&gt;log.debug&lt;/code&gt; statements from the beginning of development, and
instead use &lt;code&gt;print&lt;/code&gt; statements?  I am honestly not sure.  I do recall an early
experiment in which I used both types of statements, to see which one worked better for
me.  I remember the experiment, I remember choosing &lt;code&gt;print&lt;/code&gt; statements, but I cannot
remember why I chose them, knowing I would have to replace them later. I even checked
my notes from back then, and nothing about logging vs print.  Interesting.&lt;/p&gt;
&lt;p&gt;Regardless of why I did it, the time to fix it was now.  It was a mostly painless
transition and didn’t take that long to accomplish.  To the start of most files, I
added the following import:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;logging&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;and at the start of many blocks of processing, I added the following line:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;    &lt;span class="n"&gt;logger&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;logging&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;getLogger&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="vm"&gt;__name__&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Then, for each time I called the print function, like this example:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;        &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"Line:"&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;line_to_parse&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="s2"&gt;":"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;I replaced it with the exact same arguments, just changing the name of the called
function from &lt;code&gt;print&lt;/code&gt; to &lt;code&gt;logger.debug&lt;/code&gt; as follows:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;        &lt;span class="n"&gt;logger&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;debug&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"Line:"&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;line_to_parse&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="s2"&gt;":"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;After the initial changes to replace &lt;code&gt;print&lt;/code&gt; with &lt;code&gt;log.debug&lt;/code&gt;, everything looked okay
until I ran the normal &lt;code&gt;clean&lt;/code&gt; script that I use with the project.  This script is a
simple script to execute the
&lt;a href="https://pypi.org/project/black/"&gt;black&lt;/a&gt;
code formatter, the
&lt;a href="https://pypi.org/project/flake8/"&gt;Flake8&lt;/a&gt;
and
&lt;a href="https://www.pylint.org/"&gt;PyLint&lt;/a&gt;
linters, and the full set of tests for the project.  When the script got to PyLint,
it seemed to go crazy and was emitting lots or warning lines, each line essentially
being the same.&lt;/p&gt;
&lt;p&gt;Reading the warnings carefully and looking at the source code, PyLint seemed to be
complaining about each logging function call that
involved concatenation.  In each case where I was concatenating strings to arrive at
what I wanted to log, PyLint raised a warning that I wasn’t doing it right.  According
to PyLint, the proper way to log a message for the above example is:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;        &lt;span class="n"&gt;logger&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;debug&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"Line:&lt;/span&gt;&lt;span class="si"&gt;%s&lt;/span&gt;&lt;span class="s2"&gt;:"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;line_to_parse&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Doing a bit more research, the reason for the warning is because the logging library
was purposefully created to be lazy.  If the log level for a given call is not high
enough to cause the string to be logged, doing any kind of formatting or concatenation
on that string is wasted effort.  Following that logic, the logger follows the same
conventions that are used with the percent character (&lt;code&gt;%&lt;/code&gt;) as the
&lt;a href="https://docs.python.org/3/library/stdtypes.html?highlight=interpolation#printf-style-string-formatting"&gt;string interpolation operator&lt;/a&gt;,
delaying the evaluation of the actual string until the logger determines
whether the specified string is actually going to be logged.  Once a positive
determination has been made, the format and the arguments are applied to each other,
a resolved string is produced, and that string that is then logged.&lt;/p&gt;
&lt;p&gt;It took a while to go through each of those messages. I had to examine each
concatenation sequence, break it down into its component parts, and verify my changes.
Each string that was concatenated needed to be represented in either the format string
or the arguments passed to the logger.  It was slow and pedantic work, but in the end,
I was happy to have a logging solution that was more performant than before.&lt;/p&gt;
&lt;h3 id="side-note"&gt;Side Note&lt;a class="headerlink" href="#side-note" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Note that as a Python logging newbie, I am not 100% sure if I created more work for
myself by
frequently creating logging instances inside of the project’s static functions.  It is
possible that I can get away with a static logger variable created in the module’s
namespace at the top of the file, and not worry about creating any other loggers within
the same file.
However, in all the examples I have seen to date, the logger is
either declared at the top of a simple file or within the &lt;code&gt;__init__&lt;/code&gt; method of a
class.  As a lot of the helper classes are a collection of functions that are labelled
with the &lt;code&gt;@staticmethod&lt;/code&gt; annotation, I am not sure if one instance at the top of the
file is the correct way to go.  While
it might be more effort than I really need, I am confident that I am covering all
the logging situations properly.  If I learn something differently about logging, I
will come back and revisit it.&lt;/p&gt;
&lt;h2 id="better-error-reporting"&gt;Better Error Reporting&lt;a class="headerlink" href="#better-error-reporting" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;When I initially proofed out the plugin architecture for the linter, I added a
&lt;code&gt;BadPluginError&lt;/code&gt; class to help identify plugin issues and report them back to the
command line.  Using this same pattern to integrate error handling for the parser to
the linter, I added the &lt;code&gt;BadParsingError&lt;/code&gt; class, raising this error when there were
exceptions raised during the parser’s tokenization of the Markdown text.  A bit more
typing and a short while later, I had the &lt;code&gt;__handle_error&lt;/code&gt; function with refactored
content.  This newly minted function reused the error handling meant for the
&lt;code&gt;BadPluginError&lt;/code&gt; class to handle both the &lt;code&gt;BadPluginError&lt;/code&gt; class and the
&lt;code&gt;BadParsingError&lt;/code&gt; class in the same manner.&lt;/p&gt;
&lt;p&gt;With that tweak done, I had confidence that the error reporting was done, and I wouldn’t
need anything more serious until far later in the project. That is what I foolishly
thought until about 2 days later. After doing some work on implementing the first two
rules, I realized that some things needed to be fixed with error reporting.&lt;/p&gt;
&lt;p&gt;The first change I made was to change the name of the error class from &lt;code&gt;BadParsingError&lt;/code&gt;
to &lt;code&gt;BadTokenizationError&lt;/code&gt; to reflect the problem area more accurately.  While it is
more of a mouthful to say, it accurately describes that it is a problem with the
tokenization of the document, not a generic “parsing” issue. A good example of this is
when the &lt;code&gt;TokenizedMarkdown&lt;/code&gt; class is created.  Upon creation, one of the things
that it does is load the &lt;code&gt;entities.json&lt;/code&gt; file from the resources directory, as detailed
in
&lt;a href="https://jackdewinter.github.io/2020/02/24/markdown-linter-starting-inline-processing/#character-references"&gt;this article&lt;/a&gt;.
If that resource file is not
loaded properly, that code was changed to raise a &lt;code&gt;BadTokenizationError&lt;/code&gt; instead of
what it was previously doing.  Without this file, parsing the Markdown text would still
be possible without any issues.  But to properly tokenize the Markdown text, the parser
needs to know if the named character entities that are provided in the Markdown
document refer to valid named entities.  It may
appear to be a semantic difference to some, but in my experience, it is the attention
to detail on little things like that which help improve the project’s maintainability.&lt;/p&gt;
&lt;p&gt;In addressing the above case, I stumbled into the second issue: too many exit
points.
While it does not show it in the commit for the &lt;code&gt;BadTokenizationError&lt;/code&gt; fix documented
in the paragraph above, the first pass at addressing that issue was messy. It caught
any raised error, did some bare bones reporting, and then performed a &lt;code&gt;sys.exit(1)&lt;/code&gt; to
stop the program with an error code of 1.  Doing a quick search through the code, I
stopped counting once I hit the third instance of a &lt;code&gt;sys.exit(1)&lt;/code&gt; call in the code.
It was time for a refactor.&lt;/p&gt;
&lt;p&gt;Beginning with the initial case that started the search, I took a quick look at the
various search results and came up with a good rubric to follow.  If possible,
I would try and more correctly classify the error using one of the two existing error
classes, &lt;code&gt;BadTokenizationError&lt;/code&gt; or &lt;code&gt;BadPluginError&lt;/code&gt;, which were already handled at the
top level by the &lt;code&gt;__handle_error&lt;/code&gt; function.  If the error occurred in the
&lt;code&gt;main.py&lt;/code&gt; file and didn’t fall into either of those categories, I would call the
&lt;code&gt;__handle_error&lt;/code&gt; function directly, striving to give a clean and concise message on
what that error was and why it occurred.  If I encountered any errors outside of those
parameters, I would save them for last and re-evaluate my rules.&lt;/p&gt;
&lt;p&gt;Based on what I found in the project, the first two rules were enough, as I did
not find an error that could not neatly fit into one of those two categories.
Instead of a few different ways of exiting the linter with an error condition,
&lt;code&gt;__handle_error&lt;/code&gt; was now the sole conduit for exiting with an error.  I went over the
tests in the &lt;code&gt;test_main.py&lt;/code&gt;,
&lt;code&gt;test_plugin_manager.py&lt;/code&gt; and &lt;code&gt;test_markdown_entity_and_numeric_character_references.py&lt;/code&gt;
files to make sure everything looked consistent, and things were good!&lt;/p&gt;
&lt;h2 id="what-was-my-experience-so-far"&gt;What Was My Experience So Far?&lt;a class="headerlink" href="#what-was-my-experience-so-far" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;As I have mentioned in previous articles, I like refactoring, and this stretch of
refactoring was no
exception.  Each of these tasks were little tasks, but I felt better knowing that they
were addressed before I shifted my focus to writing the rules for the linter.  The
change to using source providers would be pivotal in dealing with test sources (strings)
and live sources (files) as sibling concepts. Replacing &lt;code&gt;print&lt;/code&gt; with &lt;code&gt;log.debug&lt;/code&gt; was
also pivotal to using live sources, keeping the ability to debug what was going
on for experienced users, but not flooding a casual user with all of that information.
Finally, getting
all of the error reporting to go through one conduit just seems cleaner and more
concise to me.  Getting these taken care of just felt like the right refactoring to
do at the right time.&lt;/p&gt;
&lt;p&gt;I also realized that I enjoy the cadence I have established with refactoring.  While
there are
short bursts where it is just adding new features, for the most part I have tried to
switch off between refactoring and adding new features.  I feel that for my development
style, I have found a good balance between fixing things and adding things, even if it
needs tweaking every so often.  Perhaps it is because of that sense of balance that I
have been able to focus on this project for so long without losing energy on it.
For me, I believe it boils down to a feeling that this project is not about adding
features as much as it is about continual improvement of the project towards its goal,
taking my time to do things right as I go.&lt;/p&gt;
&lt;p&gt;Looking forward, I am sure I am not done adding features, refactoring code,
or learning something new and interesting.&lt;/p&gt;
&lt;h2 id="what-is-next"&gt;What is Next?&lt;a class="headerlink" href="#what-is-next" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Taking a bit of a jump back in time a couple of days from where I am leaving off,
in the next article I am going to start talking about the rules that I am developing,
and how their development proceeded.  Please stay tuned!&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr/&gt;
&lt;ol&gt;
&lt;li id="fn:linkReferenceDefinitionError"&gt;
&lt;p&gt;Due to link reference definitions being a multiline element, some of the error cases required the parser to be rewritten to handle lines that need to be “rewound”, as documented in &lt;a href="https://jackdewinter.github.io/2020/04/06/markdown-linter-adding-link-reference-definitions/#hitting-implementation-issues"&gt;this previous article&lt;/a&gt;. &lt;a class="footnote-backref" href="#fnref:linkReferenceDefinitionError" title="Jump back to footnote 1 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</content><category term="Software Quality"></category><category term="markdown linter"></category><category term="core linter"></category></entry><entry><title>Markdown Linter - Splitting Up The Articles</title><link href="https://jackdewinter.github.io/2020/05/03/markdown-linter-splitting-up-the-articles/" rel="alternate"></link><published>2020-05-03T00:00:00-07:00</published><updated>2020-05-03T00:00:00-07:00</updated><author><name>Jack De Winter</name></author><id>tag:jackdewinter.github.io,2020-05-03:/2020/05/03/markdown-linter-splitting-up-the-articles/</id><summary type="html">
&lt;h2 id="introduction"&gt;Introduction&lt;a class="headerlink" href="#introduction" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Wow!  Getting to this point in the parser took a good amount of time, but in my head,
I didn’t expect it to create 17 articles!  Looking back at what I wanted to achieve by
writing about the linter as I develop it, it makes sense to me …&lt;/p&gt;</summary><content type="html">
&lt;h2 id="introduction"&gt;Introduction&lt;a class="headerlink" href="#introduction" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Wow!  Getting to this point in the parser took a good amount of time, but in my head,
I didn’t expect it to create 17 articles!  Looking back at what I wanted to achieve by
writing about the linter as I develop it, it makes sense to me, and I am not sorry that
I wrote any of the articles.&lt;/p&gt;
&lt;p&gt;However, that does leave me with a bit of a problem.  This is article 18 in a series on
writing a linter, and I have not really done any serious work on the linter yet.&lt;/p&gt;
&lt;h2 id="splitting-up-the-articles"&gt;Splitting Up the Articles&lt;a class="headerlink" href="#splitting-up-the-articles" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;While going back and changing the names of the articles to “Markdown Tokenizer…” was
attractive, thinking about it made me feel like I would be lying to any readers.&lt;/p&gt;
&lt;p&gt;In the end, the best option that emerged was to use this article as a jumping off point
for the other aspects of the project.  Basically, a jump page.  While not glamorous,
it is honest, and follows
&lt;a href="https://jackdewinter.github.io/2020/02/10/markdown-linter-adding-html-blocks/#changing-the-narrative"&gt;one of the things&lt;/a&gt;
that I am trying to inspire: “Stuff happens, pick yourself up, dust yourself off, and
figure out what to do next.”&lt;/p&gt;
&lt;h2 id="jump-links-for-the-linter-project"&gt;Jump Links For the Linter Project&lt;a class="headerlink" href="#jump-links-for-the-linter-project" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Here are the various directions that I have gone in documenting the further development
on the project.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://jackdewinter.github.io/tags#markdown-linter-ref"&gt;Chronological&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://jackdewinter.github.io/tags#core-linter-ref"&gt;Core Linter&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://jackdewinter.github.io/tags#linter-tokenizer-ref"&gt;Linter Tokenizer&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://jackdewinter.github.io/tags#linter-rules-ref"&gt;Linter Rules&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><category term="Software Quality"></category><category term="markdown linter"></category><category term="pymarkdown"></category></entry><entry><title>Markdown Linter - Reducing the Parser's Technical Debt</title><link href="https://jackdewinter.github.io/2020/04/27/markdown-linter-reducing-the-parsers-technical-debt/" rel="alternate"></link><published>2020-04-27T00:00:00-07:00</published><updated>2020-04-27T00:00:00-07:00</updated><author><name>Jack De Winter</name></author><id>tag:jackdewinter.github.io,2020-04-27:/2020/04/27/markdown-linter-reducing-the-parsers-technical-debt/</id><summary type="html">
&lt;h2 id="introduction"&gt;Introduction&lt;a class="headerlink" href="#introduction" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;First off, despite what I said at the end of the
&lt;a href="https://jackdewinter.github.io/2020/04/27/markdown-linter-reducing-the-parsers-technical-debt/#what-is-next"&gt;last article&lt;/a&gt;,
no, I am not going to call this “Refactoring: The Sequel”… even if that would be a
cool name.  From my point of view, refactoring is anything involving getting rid of
technical debt, usually increasing the …&lt;/p&gt;</summary><content type="html">
&lt;h2 id="introduction"&gt;Introduction&lt;a class="headerlink" href="#introduction" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;First off, despite what I said at the end of the
&lt;a href="https://jackdewinter.github.io/2020/04/27/markdown-linter-reducing-the-parsers-technical-debt/#what-is-next"&gt;last article&lt;/a&gt;,
no, I am not going to call this “Refactoring: The Sequel”… even if that would be a
cool name.  From my point of view, refactoring is anything involving getting rid of
technical debt, usually increasing the correctness, readability, or maintainability of
a project.  This can be as simple as writing clear and concise documentation, or a
more difficult task involving the rewriting of project code.  If a task moves
the project in a positive direction while not adding a new feature to the project, I
believe that that task falls under the category of refactoring.  It is a simple
definition, but it has served me well.&lt;/p&gt;
&lt;p&gt;Since this project has been ongoing since 22 Nov 2019, there have been a decent number
of issues that have been added to the parser’s debt list, and a decent number
of issues removed from that same list due to informal “refactor weeks” that I had.
Most of the issues that I added to that list had a very specific reason that I decided
to put them on the list instead of handling that issue right there. But as I am
only human, there were probably a few times where it was just easier to deal with it
later.  Regardless of how each issue was added to the list of debt, I wanted
to try and make a decent size dent to the pile of parser’s debt before
closing out the main development effort on it.  As my goal is to give better
perspective on what I am doing and why, I thought an article just focusing on these
items would be informative to anyone that has been following the project
so far.&lt;/p&gt;
&lt;p&gt;Just to keep everything above board, I am not going to talk about every individual
commit between the two commit points noted in the next section, just the interesting
ones.  In that uninteresting category are some changes to get ready for future
features, some changes to fix cut-and-paste issues from past changes, and some changes
to correct something that I forgot to do.  While they are necessary, they are not
interesting.  They just prove I am human and make mistakes just like everyone else.&lt;/p&gt;
&lt;p&gt;And like everyone else, I sometimes put things off until later.  But at some point,
the bill is due.  For me, it was now that I wanted to pay some of that bill off.&lt;/p&gt;
&lt;h2 id="what-is-the-audience-for-this-article"&gt;What Is the Audience For This Article?&lt;a class="headerlink" href="#what-is-the-audience-for-this-article" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;While detailed more eloquently in
&lt;a href="https://jackdewinter.github.io/2020/04/05/what-is-the-audience-for-my-blog/#what-is-the-audience-for-my-blog"&gt;this article&lt;/a&gt;,
my goal for this technical article is to focus on the reasoning behind my solutions,
rather that the solutions themselves.  For a full record of the solutions presented in
this article, please go to this project’s GitHub repository and consult the
commits between
&lt;a href="https://github.com/jackdewinter/pymarkdown/commit/e638e0bd6bc069ad17f9d22b3473e639c8caaa01"&gt;05 April 2020&lt;/a&gt; and
&lt;a href="https://github.com/jackdewinter/pymarkdown/commit/3b2025a01c436a810d1b084ab6bf38fd83a627d1"&gt;11 April 2020&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id="refactor-1-matching-commonmark-character-encoding"&gt;Refactor 1: Matching CommonMark Character Encoding&lt;a class="headerlink" href="#refactor-1-matching-commonmark-character-encoding" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;The issue that was the parent of this one was an interesting issue to find, and this
issue was generated to perform the cleanup for that issue.  The HTML output for the
examples in the
&lt;a href="https://github.github.com/gfm"&gt;GFM specification&lt;/a&gt;
are generated by processing the Markdown text examples through
&lt;a href="https://commonmark.org/"&gt;CommonMark&lt;/a&gt;,
mainly because CommonMark is considered the reference implementation for the
specification.  In each of the following scenario tests, the parser’s output for the
&lt;code&gt;href&lt;/code&gt; attribute in each link was arguably correct, but the output did not match the
output in the examples.  To resolve this issue and ensure that the scenario tests
passed, I needed to fix the link functionality in the parser so that it encodes the
right characters according to CommonMark’s “right way” to ensure the parser passed
the tests.&lt;/p&gt;
&lt;p&gt;It would have been easy if the encoding misses were all the same thing, but they
were not.  In the &lt;code&gt;href&lt;/code&gt; attribute for
&lt;a href="https://github.github.com/gfm/#example-603"&gt;example 603&lt;/a&gt;,
the ampersand character &lt;code&gt;&amp;amp;&lt;/code&gt; is replaced with the string &lt;code&gt;&amp;amp;amp;&lt;/code&gt;.  In
&lt;a href="https://github.github.com/gfm/#example-510"&gt;example 510&lt;/a&gt;, the &lt;code&gt;\&lt;/code&gt; is replaced by the
string &lt;code&gt;%5C&lt;/code&gt;.  However, in
&lt;a href="https://github.github.com/gfm/#example-509"&gt;example 509&lt;/a&gt;,
the &lt;code&gt;?&lt;/code&gt; and &lt;code&gt;#&lt;/code&gt; characters are both left alone, and not specially encoded.  Just
small differences in how the characters were represented, and each one a bit different.&lt;/p&gt;
&lt;p&gt;To be clear, the main goal of resolving the original issue with those tests was not to
figure out what the “actual right way” of encoding the &lt;code&gt;href&lt;/code&gt; attribute was, but to
match what CommonMark was doing.  Specifically, I wanted to make sure I have a solid
starting point for matching my parser against others, and CommonMark seemed a better
candidate than others.  After all, they published a specification on what they expect
from the CommonMark parser in the GFM specification.  But as the above cases only
caught a small number of issues in 3 tests, I determined that I needed to figure out
what the proper set of ASCII character encodings are for CommonMark.&lt;/p&gt;
&lt;p&gt;To properly figure out what CommonMark encodes and does not encode, I added in the tests
in the &lt;code&gt;test_markdown_extra.py&lt;/code&gt; file that specifies, in sequence, each of the possible
characters after the &lt;code&gt;space&lt;/code&gt; character and before the &lt;code&gt;del&lt;/code&gt; character in the ASCII
table.  While I could have done something clever using the
&lt;a href="https://docs.python.org/3.7/library/string.html"&gt;Python string constants&lt;/a&gt;,
I wanted the test to be explicit about what it was testing.  After submitting the
newly generated Markdown sample to
&lt;a href="https://johnmacfarlane.net/babelmark2/"&gt;Babelmark&lt;/a&gt;,
I copied Babelmark’s response for CommonMark back into the test as the response.
From there, I just kept on adjusting the encoding code until the HTML output matched
Babelmark’s output for CommonMark exactly.&lt;/p&gt;
&lt;p&gt;Did I have to do this? Not really.  Technically, I was already meeting the minimum
requirements by passing the scenario tests.  However, I just felt that it was better to
do the thorough job than to leave it to chance.&lt;/p&gt;
&lt;h2 id="refactor-2-more-fun-with-tabs"&gt;Refactor 2:  More Fun with Tabs&lt;a class="headerlink" href="#refactor-2-more-fun-with-tabs" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;When people start developing code in any programming language, one of the first things
that they learn is that the tab character in most languages is a bad
idea.  After that, the religious conversations start about whether to replace a tab
character with 2 spaces or 4 spaces, but that is not something I want to go into.
Those kinds of conversations usually just devolve into
&lt;a href="https://en.wiktionary.org/wiki/bikeshedding"&gt;bike-shedding&lt;/a&gt;
within minutes.&lt;/p&gt;
&lt;p&gt;In the GPF specification, they avoid this conversation nicely by making it clear:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Tabs in lines are not expanded to spaces. However, in contexts where whitespace helps to define block structure, tabs behave as if they were replaced by spaces with a tab stop of 4 characters.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Good!  So tab characters have a width of 4 characters.&lt;sup id="fnref:holdIt"&gt;&lt;a class="footnote-ref" href="#fn:holdIt"&gt;1&lt;/a&gt;&lt;/sup&gt;  That sounds right.  I
then changed my &lt;code&gt;calculate_length&lt;/code&gt; function to count every tab character as 4
characters and every non-tab character as 1 character.  No problem. Then I went
back to fix
&lt;a href="https://github.github.com/gfm/#example-6"&gt;example 6&lt;/a&gt;
which was marked as skipped and
&lt;a href="https://github.github.com/gfm/#example-7"&gt;example 7&lt;/a&gt;
which was added incorrectly as a test.  Reading the preface for those tests:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Normally the &amp;gt; that begins a block quote may be followed optionally by a space, which is not considered part of the content. In the following case &amp;gt; is followed by a tab, which is treated as if it were expanded into three spaces. Since one of these spaces is considered part of the delimiter, foo is considered to be indented six spaces inside the block quote context, so we get an indented code block starting with two spaces.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;That statement did not sound right to me.  The math was wrong.  The block quote start
character is followed by 2 tab characters for a total count of 8 whitespace
characters.  Subtract
1 from that for the whitespace character following the block quote character and you
have 7, not 6.  I read the entire section on tabs about 4 or 5 times, being either
persistent or stubborn, depending on your point of view.  Then finally I keyed in on
the phrase “expanded into three spaces”.&lt;/p&gt;
&lt;p&gt;Something was wrong.  I rechecked my math using 3 spaces instead of 4 spaces for
that example, and it worked.  But it said at the top that tabs were the equivalent of 4
spaces, didn’t it?  Rereading the preface for Markdown tab characters, for what seemed
like the 10th time, it was then that I noticed it.  Not a tab width of 4 characters,
but a tab stop of 4 characters.
While it may seem like a simple difference, it is not.&lt;/p&gt;
&lt;p&gt;A tab stop of 4 means that if a tab character is encountered, the parser should consider
there to be spaces until reaching a column index that is a multiple of 4. In the above
example, the tab character was encountered after the block quote start character,
effectively at an index of 1 on that line.  That meant when the parser encountered the
tab character, it should be considered the same as 3 space characters, as it would take
adding 3 space character to get from the current position of 1 to the next tab stop at
index 4.&lt;/p&gt;
&lt;p&gt;While somewhat interesting, the impact of those changes was more interesting
to me.  The first impact was that I needed to rewrite the &lt;code&gt;calculate_length&lt;/code&gt; function to
expand tabs based on a possibly non-zero index starting point.  This wasn’t a really
big deal as it was a small function, but as the complexity increased enough to where
I was worried about properly calculating the length, I added the &lt;code&gt;test_calculate_length&lt;/code&gt;
module to properly test all of its cases.&lt;/p&gt;
&lt;p&gt;The second impact was on the block quote blocks and list blocks, both of which are
container blocks.  Before this change, the start position of an enclosed block inside
of a container block was not an issue.  With this change, to properly account for tabs
and tab stops, the parser needs to know the exact position on the line where the
current string started in case it contained tabs.  This proved to be complicated
enough that I spread it over 2 commits.&lt;/p&gt;
&lt;p&gt;In between, the third impact was discovered, the tokens for indented code blocks.  As
a bit of a shortcut, instead of grabbing the required whitespace from the
string being parsed, I simply used a string containing 4 space characters as the leading
whitespace for the code block.  I needed to change that to grabbing the correct
whitespace as the length of the tab character was now variable.&lt;/p&gt;
&lt;p&gt;In the end, 3 small examples, 1 tab character, 3 impacted areas, and a lot of grumbling
on my behalf.  But it got fixed… it just took a while.&lt;/p&gt;
&lt;h2 id="refactor-3-fenced-code-blocks"&gt;Refactor 3: Fenced Code Blocks&lt;a class="headerlink" href="#refactor-3-fenced-code-blocks" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;In getting rid of some of the technical debt, there were a couple of issues with the
fenced code blocks that I really wanted to address: fenced code blocks inside of
block quotes and fenced code blocks with starting whitespace.&lt;/p&gt;
&lt;p&gt;The examination of the first issue, fenced code blocks inside of block quotes, started
off easy enough.  In
&lt;a href="https://github.github.com/gfm/#example-98"&gt;example 98&lt;/a&gt;,
which is as follows:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="o"&gt;```&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;aaa&lt;/span&gt;

&lt;span class="n"&gt;bbb&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;a fenced code block is started within the block quote.  As such, when the block quote
ends, the fenced code block is closed.  That part was already working fine.  However,
when the first and only line in the code block was extracted, it was extracted with 2
extra characters of whitespace in front of it, providing for a token representation of
&lt;code&gt;[text:aaa:  ]&lt;/code&gt; instead of &lt;code&gt;[text:aaa:]&lt;/code&gt;.  This in turn added the string &lt;code&gt;aaa&lt;/code&gt; to
the HTML document instead of &lt;code&gt;aaa&lt;/code&gt;, causing the scenario test to fail.&lt;/p&gt;
&lt;p&gt;This issue was easy to fix, making sure that the indent count was considered when
returning the remaining string in the fenced code block.  Along the way,
just to make sure things were parsing properly, I added 2 extra variants of example
98, one with an extra &lt;code&gt;&amp;gt;&lt;/code&gt; character at the start of the second line and one without any
&lt;code&gt;&amp;gt;&lt;/code&gt; at the start of the second line, just to make sure they were properly parsed.
Seeing as there was already one issue found in that area, I figured the extra tests
would not hurt.&lt;/p&gt;
&lt;p&gt;Following that quick find-and-fix, I moved on to
&lt;a href="https://github.github.com/gfm/#example-101"&gt;example 101&lt;/a&gt; and
&lt;a href="https://github.github.com/gfm/#example-103"&gt;example 103&lt;/a&gt;
which also dealt with inconsistent spacing with fenced code blocks.  However, in the
case of these examples, it was an issue with properly handling the leading spaces before
the fenced code block start, code block content, and fenced code block end.&lt;/p&gt;
&lt;p&gt;In the case of example 101:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt; &lt;span class="o"&gt;```&lt;/span&gt;
 &lt;span class="n"&gt;aaa&lt;/span&gt;
&lt;span class="n"&gt;aaa&lt;/span&gt;
&lt;span class="o"&gt;```&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;the fenced code block start sequence is preceded by a single space character, as is the
first line of the code block content.  The specification clearly states:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;If the leading code fence is indented N spaces, then up to N spaces of indentation are removed from each line of the content (if present).&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Looking at the source code, it was obvious to me that any indentation for the fenced
code block start was extracted and then immediately thrown out.  A quick change to
how the fenced code block was storing the information to include the indent count of
the fenced code block start, some other code to remove up to that many whitespace
characters from the start of any content lines, and it was done.  This was the same
for example 103, just with more of an additional indent, and the added concern of
having one of the lines have fewer indent characters than the fenced code block
start line.&lt;/p&gt;
&lt;p&gt;These two small issues only took a matter of hours before they were fixed,
but they were good fixes.  I am not sure why, but I felt that these issues were going
to be larger than they were and seeing them in my “to fix” list was causing
me a bit of stress.  Regardless of the effort required, it was good to get them
taking care of.  Sometimes you move the project in a positive direction in big steps,
and sometimes they are baby steps.  The important thing to remember is that they
are both moving the project in the right direction.&lt;/p&gt;
&lt;h2 id="refactor-4-html-blocks-inside-of-lists"&gt;Refactor 4: HTML Blocks inside of Lists&lt;a class="headerlink" href="#refactor-4-html-blocks-inside-of-lists" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Sometimes I look at some code, and I get a feeling that it isn’t quite right. I often
cannot immediately point to something specific, but I just have a feeling that usually
turns
out to be accurate indicator of bad code. That was the case with
&lt;a href="https://github.github.com/gfm/#example-144"&gt;example 144&lt;/a&gt;.
Ignoring any previous statements that I have made about the use of HTML in Markdown,
I wanted to make sure that this example was being parsed properly.  In this example:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;div&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;foo&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;what should be created is a list with an item containing a single &lt;code&gt;&amp;lt;div&amp;gt;&lt;/code&gt; HTML item and
another list item with the text &lt;code&gt;foo&lt;/code&gt;.  To be honest, I had to check the HTML and list
specifications a couple of times to find out which of them overruled the other.  As I
should have gathered, the list (a container block) has higher precedence than the
HTML block (a leaf block), so when the next list item within the list block starts, the
HTML block from the first item is automatically closed.&lt;/p&gt;
&lt;p&gt;It is probably because of my uncertainty with the specification regarding which block
had the higher precedence that I decided to add an extra test, &lt;code&gt;test_html_blocks_144a&lt;/code&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;div&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;foo&lt;/span&gt;

&lt;span class="n"&gt;foo&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;I realize it might seem like the extra paragraph is unwarranted, but I wanted to
make extra sure that everything was being unwound properly, including the list.  Whether
or not the extra test really adds anything, I’ll double check it later.  Even though
there was nothing wrong with this test, I still trust my previous experience with code.
I would rather double check some code and find nothing rather than not check and miss
something important.  But at the same time, it had me looking at the list block code,
which is how I started looking at the issues for the next section.&lt;/p&gt;
&lt;h2 id="refactor-5-more-fun-with-lists"&gt;Refactor 5: More Fun with Lists&lt;a class="headerlink" href="#refactor-5-more-fun-with-lists" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;As I mentioned previously, I often get a feeling that a given set of code is not 100%
correct, and this time it was about lists, specifically sublists. While each of the
required scenario tests for sublists were passing, there was just this little voice in
my head saying that something did not feel right.  There was just something there that
inspired me to add an issue to my notes to check them out further, but not enough for
me to give anything more than a vague feeling.&lt;/p&gt;
&lt;p&gt;Unlike how things turned out in the previous section with HTML blocks, after I did
some digging in the code, I found that my feeling was correct!  Due to my digging,
I found several problems with sublists, specifically with indenting and switching
between sublists and other lists.  To debug these problems and to make sure they
stayed fixed, I introduced a total of 16 variations on existing, passing scenario
tests to properly address these issues.  I am still trying to figure out if these
issues are due to how I implemented the parser or if they are legitimate edge cases
for the specification.  Stay tuned for that!&lt;/p&gt;
&lt;p&gt;These issues fall into 2 categories: indenting and
switching list start sequences.  My examples will mostly deal with unordered lists, but
I added the same types of tests for both ordered and unordered lists.&lt;/p&gt;
&lt;p&gt;As a good example of what I looked for, consider
&lt;a href="https://github.github.com/gfm/#example-281"&gt;example 281&lt;/a&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;foo&lt;/span&gt;
&lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;bar&lt;/span&gt;
&lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;baz&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Looking at this Markdown, it should be obvious that it is a pair of unordered lists,
the first having two elements and the second having a single element. Playing around
with the structure a bit, I decided to keep all the list start characters the same but
changed the indent of the second list item to make it into a sublist.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;foo&lt;/span&gt;
  &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;bar&lt;/span&gt;
&lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;baz&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;And… boom!  The parser returned an unordered list that contained another list with
2 items in that sublist.  Thinking it was a fluke, I changed the last list start
character to the &lt;code&gt;+&lt;/code&gt; character:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;foo&lt;/span&gt;
  &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;bar&lt;/span&gt;
&lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;baz&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;And boom… again! The results were not as expected.  Working my way through many of
the examples of lists in the GFM specification, I found 16 variations of
simple changes to existing scenario tests that created sublists that were parsed
incorrectly.  If I worked them out on paper or by using Babelmark, the paper and
Babelmark results backed each other up, but the parser’s results were off.  I was
missing something important somewhere.  But where?&lt;/p&gt;
&lt;p&gt;Taking a bit of time to cool down, when I started looking at those examples and various
patterns of indentation, start character, and sublists emerged.  Adding some debug
code to aid in the diagnosis, I ran each of the newly added tests again.  After some
screaming at my monitor in frustration&lt;sup id="fnref:rubberDucking"&gt;&lt;a class="footnote-ref" href="#fn:rubberDucking"&gt;2&lt;/a&gt;&lt;/sup&gt;, I was rewarded with a common
thread that went across all of the tests: starting conditions.&lt;/p&gt;
&lt;p&gt;When I start a list in the parser, the most relevant information about the list start
is the starting index of the list and the start character.  For single level lists and
lists that are neat (that is all the sublists are indented the same amount), there
are no issues with this approach as everything lines up.  But when I started moving the
starting locations of the list items and the starting locations of the text within the
list items, that is when things fell apart.  The big issue was not with the parser
going down into the sublists, but in how it recovered when exiting from those
sublists, understanding which lists to take off the list stack on the way back out.&lt;/p&gt;
&lt;p&gt;With a large amount of grumbling on my part, I worked through each of the new scenario
tests and added code that not only remembered where the list item character was, but
where the text for that item started.  This allowed me to properly figure out where the
list itself started, allowing me to create better comparisons on whether or not a list
should be removed on the way out.  It wasn’t an easy experience, but one by one the
failing tests became passing tests as I worked through the various combinations
required to get it working properly.&lt;/p&gt;
&lt;p&gt;Sure, I grumbled a lot on this one.  But I was glad that I followed a feeling and did
some exploratory testing to put that feeling to rest, rather than dismiss it!  In
my experience, there are many times where you can look at code and instantly
know it is wrong and why it is wrong.  (And no, I am not talking about tabs, or line
spacing, or curly bracket positioning, or…)  However, the really interesting times
are when you have to trust your gut feeling and explore some scenarios, either to find
an issue or to be able to increase your confidence to where you do not have that
feeling anymore.&lt;/p&gt;
&lt;p&gt;Whether it is a “I can see that is wrong” bug or a “I feel like there is something
wrong there” feeling, both have a valid place in your arsenal for improving the
quality of the project.&lt;/p&gt;
&lt;h2 id="what-was-my-experience-so-far"&gt;What Was My Experience So Far?&lt;a class="headerlink" href="#what-was-my-experience-so-far" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;The purpose of this dedicated session of refactoring was not to eliminate all
the parser’s technical debt, just make a good dent in it.  Based on that metric,
I feel good that I have reduced this debt a decent amount.  Furthermore,
I took some steps to reorganize the remaining items into more organized lists,
for further study.  After making some forward progress with other components of
the linter, I will inevitably come back to the list in a few weeks and try and deal
with a couple more of those items.&lt;/p&gt;
&lt;p&gt;Other than the logistics, I feel good about the parser.  There are a decent number of
issues documented in the list, 40 items in all, but a lot of them are either suggestions
for more complete testing or questions about whether something is possible or
desired.  Doing a quick scan of those items as I write this article, there are not any
open items that I am very worried about, just concerns and ideas that I want explored.
Basically, I have things that I want to deal with, but it is okay if they wait a bit.&lt;/p&gt;
&lt;p&gt;It is with mixed feelings that I move from writing the parser to writing the
rules that will take advantage of the parser.  I know that I am moving from having
conquered one challenge to starting another challenge, and I am okay with that.  On
one hand, that transition means that the hard work I have put into the parser will
pay off.  On the other hand, it means that I will be subjecting that same work to
more stringent tests as I go forward with the rules and the rest of the linter.&lt;/p&gt;
&lt;p&gt;In the end, I guess it boils down to two things.  I have confidence in the work I
have done to date with the parser, and if anything is missing or needs fixing, I
know I will be able to handle it.  I also know that the best way to show my confidence
in the project is to move ahead and write rules that rely on that parser.&lt;/p&gt;
&lt;h2 id="what-is-next"&gt;What is Next?&lt;a class="headerlink" href="#what-is-next" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;While I know the parser is not perfect, and it may never be, I know it is good enough
to base the rules on top of it.  As such, my next set of tasks involves making some
changes to how the parser interacts with the rest of the project code, to ensure
that it can handle a wide variety of requirements that I may throw at it!&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr/&gt;
&lt;ol&gt;
&lt;li id="fn:holdIt"&gt;
&lt;p&gt;Yes, I know. That does not sound right to me now either.  But at the time, I honestly thought it said a tab width of 4 characters.  Keep on reading. &lt;a class="footnote-backref" href="#fnref:holdIt" title="Jump back to footnote 1 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:rubberDucking"&gt;
&lt;p&gt;While I don’t frequently use screaming at my monitor as a form of &lt;a href="https://en.wikipedia.org/wiki/Rubber_duck_debugging"&gt;rubber duck debugging&lt;/a&gt;, it does have it’s benefits sometimes. &lt;a class="footnote-backref" href="#fnref:rubberDucking" title="Jump back to footnote 2 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</content><category term="Software Quality"></category><category term="markdown linter"></category><category term="linter tokenizer"></category></entry></feed>